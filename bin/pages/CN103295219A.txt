<!DOCTYPE html><html><head><title>专利 CN103295219A - 图像分割的方法与装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="图像分割的方法与装置"><meta name="DC.contributor" content="石坤" scheme="inventor"><meta name="DC.contributor" content="杨铀" scheme="inventor"><meta name="DC.contributor" content="北京数码视讯科技股份有限公司" scheme="assignee"><meta name="DC.date" content="2012-3-2" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供了一种图像分割的方法和装置，用以解决现有技术中的图像分割方法效率不高的问题。该方法包括：对输入图像进行下采样，得到预处理图像；按照预处理图像建立图像数据模型；通过对图像数据模型的计算确定目标图像的边缘轮廓；利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；按照目标图像在输入图像的位置提取目标图像。采用本发明的技术方案，有助于减少图像分割过程的计算量，从而提高图像分割的速度，有效节省分割时间。"><meta name="DC.date" content="2013-9-11"><meta name="DC.relation" content="CN:101216841:A" scheme="references"><meta name="DC.relation" content="CN:101937508:A" scheme="references"><meta name="DC.relation" content="US:20090060366:A1" scheme="references"><meta name="citation_reference" content="吴相颖 等: &quot;一种基于Graph Cuts的多尺度乳腺肿块分割方法&quot;, 《传感技术学报》, vol. 24, no. 10, 31 October 2011 (2011-10-31)"><meta name="citation_reference" content="王钧铭，高立鑫，赵力: &quot;GrabCut彩色图像分割算法的研究&quot;, 《数字视频》, vol. 32, no. 6, 30 June 2008 (2008-06-30)"><meta name="citation_patent_publication_number" content="CN:103295219:A"><meta name="citation_patent_application_number" content="CN:201210054179"><link rel="canonical" href="https://www.google.com/patents/CN103295219A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103295219A?cl=zh"/><meta name="title" content="专利 CN103295219A - 图像分割的方法与装置"/><meta name="description" content="本发明提供了一种图像分割的方法和装置，用以解决现有技术中的图像分割方法效率不高的问题。该方法包括：对输入图像进行下采样，得到预处理图像；按照预处理图像建立图像数据模型；通过对图像数据模型的计算确定目标图像的边缘轮廓；利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；按照目标图像在输入图像的位置提取目标图像。采用本发明的技术方案，有助于减少图像分割过程的计算量，从而提高图像分割的速度，有效节省分割时间。"/><meta property="og:title" content="专利 CN103295219A - 图像分割的方法与装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103295219A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103295219A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=XInSCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103295219A&amp;usg=AFQjCNG8KlU7pM3fp3JI7Wd7w2ppNqh7pg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/0554748c758f7a9bfa5c/CN103295219A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/0554748c758f7a9bfa5c/CN103295219A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103295219A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103295219A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103295219A?cl=zh" style="display:none"><span itemprop="description">本发明提供了一种图像分割的方法和装置，用以解决现有技术中的图像分割方法效率不高的问题。该方法包括：对输入图像进行下采样，得到预处理图像；按照预处理图像建立图像数据模型；通过对图像数据模型的计算确定目标...</span><span itemprop="url">https://www.google.com/patents/CN103295219A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103295219A - 图像分割的方法与装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103295219A - 图像分割的方法与装置" title="专利 CN103295219A - 图像分割的方法与装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103295219 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210054179</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年9月11日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年3月2日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年3月2日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210054179.X, </span><span class="patent-bibdata-value">CN 103295219 A, </span><span class="patent-bibdata-value">CN 103295219A, </span><span class="patent-bibdata-value">CN 201210054179, </span><span class="patent-bibdata-value">CN-A-103295219, </span><span class="patent-bibdata-value">CN103295219 A, </span><span class="patent-bibdata-value">CN103295219A, </span><span class="patent-bibdata-value">CN201210054179, </span><span class="patent-bibdata-value">CN201210054179.X</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%9F%B3%E5%9D%A4%22">石坤</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%A8%E9%93%80%22">杨铀</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E6%95%B0%E7%A0%81%E8%A7%86%E8%AE%AF%E7%A7%91%E6%8A%80%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京数码视讯科技股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103295219A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103295219A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103295219A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=XInSCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210054179&amp;usg=AFQjCNEIdG5ADzaf8QKSUIYAFzQcMSTIzQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=XInSCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103295219A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEu_l1oXVjkYyXcYiQC1EOraOCKzw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT128243576" lang="ZH" load-source="patent-office">图像分割的方法与装置</invention-title>
      </span><br><span class="patent-number">CN 103295219 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA121632749" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供了一种图像分割的方法和装置，用以解决现有技术中的图像分割方法效率不高的问题。该方法包括：对输入图像进行下采样，得到预处理图像；按照预处理图像建立图像数据模型；通过对图像数据模型的计算确定目标图像的边缘轮廓；利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；按照目标图像在输入图像的位置提取目标图像。采用本发明的技术方案，有助于减少图像分割过程的计算量，从而提高图像分割的速度，有效节省分割时间。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(9)</span></span></div><div class="patent-text"><div mxw-id="PCLM56251711" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种图像分割的方法，其特征在于，包括:  对输入图像进行下采样，得到预处理图像；  按照所述预处理图像建立图像数据模型；  通过对所述图像数据模型的计算确定目标图像的边缘轮廓； 利用所述边缘轮廓在所述预处理图像中的位置确定所述目标图像在输入图像的位置；  按照所述目标图像在输入图像的位置提取所述目标图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，  所述对输入图像进行下采样之前还包括:获取用户划定的包含目标图像的图像区域；  所述得到预处理图像之后还包括:  计算所述包含目标图像的图像区域在所述预处理图像中的对应区域；  以所述对应区域为中心形成取样区域；  所述按照所述预处理图像建立图像数据模型包括:  按照预处理图像的取样区域内的图像部分建立图像数据模型。</div>
    </div>
    </div> <div class="claim"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要 求2所述的方法，其特征在于，所述用户划定的包含目标图像的图像区域为矩形。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的方法，其特征在于，所述利用所述边缘轮廓在所述预处理图像中的位置确定所述目标图像在输入图像的位置包括:  对所述预处理图像进行上采样，得到与输入图像大小相同的对应图像；  根据所述边缘轮廓在所述对应图像中的位置确定所述目标图像在输入图像的位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1至4中任一项所述的方法，其特征在于，  所述按照所述预处理图像建立图像数据模型包括:按照所述预处理图像建立高斯混合GMM彩色图像数据模型；  所述通过对所述图像数据模型的计算确定目标图像的边缘轮廓包括:使用Grab Cut算法对所述GMM彩色图像数据模型计算得到目标图像的边缘轮廓。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1至4中任一项所述的方法，其特征在于，所述对输入图像进行下采样使用下列任一种方式进行:邻域平均、像素分除、或像素抽选。</div>
    </div>
    </div> <div class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.一种图像分割的装置，其特征在于，包括:  下采样模块，用于对输入图像进行下采样，得到预处理图像；  建模模块，用于按照所述预处理图像建立图像数据模型；  轮廓提取模块，用于通过对所述图像数据模型的计算确定目标图像的边缘轮廓；位置确定模块，用于利用所述边缘轮廓在所述预处理图像中的位置确定所述目标图像在输入图像的位置；  目标图像提取模块，用于按照所述目标图像在输入图像的位置提取所述目标图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的装置，其特征在于，还包括:  获取模块，用于获取用户划定的包含目标图像的图像区域；  区域对应模块，用于计算所述包含目标图像的图像区域在所述预处理图像中的对应区域；  取样区域形成模块，用于以所述对应区域为中心形成取样区域；所述建模模块，还用于按照预处理图像的取样区域内的图像部分建立图像数据模型。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求7或8所述的装置，其特征在于， 所述建模模块还用于:按照所述预处理图像建立高斯混合GMM彩色图像数据模型；所述轮廓提取模块还用于:使用Grab Cut算法对所述GMM彩色图像数据模型计算得到目标图像的边缘 轮廓。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES63239844" lang="ZH" load-source="patent-office" class="description">
    <p>图像分割的方法与装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及图像处理领域，尤其涉及一种图像分割的方法与装置。</p>
    <p>背景技术</p>
    <p>[0002]	在数字图像应用过程中，人们往往只对一幅图像中的某些部分感兴趣，这些感兴趣的部分一般对应图像中特定的、具有特殊性质的区域，称之为目标图像或前景；而其它部分称为图像的背景。为了辨识和分析目标图像，需要把目标图像从原始图像中分割出来，从而对目标图像进行后期处理。在图像、视频中提取所需目标图像，是对图像、视频进行编辑、修改、制作的前提。</p>
    <p>[0003]目前已有多种图像分割的方法:</p>
    <p>[0004]	Magic Wand法，通过用户指定的点或者区域计算出一个像素相互连接组成的区域，在该区域中像素满足用户指定区域处的颜色统计的某个范围内，用户交互简单，但是计算合适的颜色统计结果容许范围较为困难，导致分割出的目标图像质量不高。</p>
    <p>[0005]	Intelligent Scissors法,通过用户鼠标移动确定初始的轮廓,然后利用求取最小消耗的方法求取较精确边界，但是用户交互较为复杂，需要用户进行大量的操作。</p>
    <p>[0006]	Graph Cut法，在图像分割领域引入了图论中的思想，将图像分割问题转化为图论中的最大流-最小割问题，通过求解方程得到分割结果。此外，这种方法利用的是图像灰度直方图信息，对于彩色图像，只能将图像首先转换为灰度图像后进行处理，无法利用图像的颜色信息从而降低了结果的准确性。</p>
    <p>[0007]	Grab Cut法,这种方法是对Graph cuts算法的改进,具有分割精度高,交互式操作少的优点，并将分割从灰度图像推广到了彩色图像领域。该方法利用了图像中的纹理(颜色)信息和边界(反差)信息，只要少量的用户交互操作即可得到比较好的分割结果，另外在对图像进行建模时采用混合高斯模型代替了灰度直方图，从而可以直接利用图像中包含更多信息的RGB颜色数据得到更准确的数据。</p>
    <p>[0008]	在现有技术中,MagicWand法和Intelligent Scissors法因为其明显的局限性导致使用范围较小，Grab Cut法作为Graph Cut法的改进，因其步骤少，分割精度高的特点应用越来越广。但是Grab Cut法的效率不高，对于实时性要求较高的用户来说，时间消耗过长。</p>
    <p>[0009]	针对现有技术中存在的图像分割方法效率不高的问题，目前尚未提出有效的解决方案。</p>
    <p>发明内容</p>
    <p>[0010]	本发明的主要目的是提供一种图像分割的方法和装置，以解决现有技术中的图像分割方法效率不高的问题。</p>
    <p>[0011]	为了实现上述目的，根据本发明的一个方面，提供了一种图像分割的方法。该方法包括:对输入图像进行下采样，得到预处理图像；按照上述预处理图像建立图像数据模型；通过对图像数据模型的计算确定目标图像的边缘轮廓；利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；按照目标图像在输入图像的位置提取目标图像。</p>
    <p>[0012]	进一步地，在对输入图像进行下采样之前，该方法还包括:获取用户划定的包含目标图像的图像区域；在得到预处理图像之后还包括:计算包含目标图像的图像区域在预处理图像中的对应区域；以对应区域为中心形成取样区域；按照预处理图像建立图像数据模型包括:按照预处理图像的取样区域内的图像部分建立图像数据模型。</p>
    <p>[0013]	进一步地，用户划定的包含目标图像的图像区域为矩形。</p>
    <p>[0014]	进一步地，利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置包括:对预处理图像进行上采样，得到与输入图像大小相同的对应图像；根据边缘轮廓在对应图像中的位置确定目标图像在输入图像的位置。</p>
    <p>[0015]	进一步地，按照预处理图像建立图像数据模型包括:按照预处理图像建立高斯混合GMM彩色图像数据模型；通过对图像数据模型的计算确定目标图像的边缘轮廓包括:使用Grab Cut算法对GMM彩色图像数据模型计算得到目标图像的边缘轮廓。</p>
    <p>[0016]	进一步地，对输入图像进行下采样使用下列任一种方式进行:邻域平均、像素分除、或像素抽选。</p>
    <p>[0017]	根据本发明的另一个方面，提供了一种图像分割的装置，该装置包括:下采样模块，用于对输入图像进行下采样，得到预处理图像；建模模块，用于按照预处理图像建立图像数据模型；轮廓提取模块，用于通过对图像数据模型的计算确定目标图像的边缘轮廓；位置确定模块，用于利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；目标图像提取模块，用于按照目标图像在输入图像的位置提取目标图像。</p>
    <p>[0018]	进一步地，上述图像分割的装置还包括:获取模块，用于获取用户划定的包含目标图像的图像区域；区域对应模块，用于计算包含目标图像的图像区域在预处理图像中的对应区域；取样区域形成模块，用于以对应区域为中心形成取样区域；建模模块，还用于按照预处理图像的取样区域内的图像部分建立图像数据模型。</p>
    <p>[0019]	进一步地，建模模块还用于:按照预处理图像建立高斯混合GMM彩色图像数据模型；轮廓提取模块还用于:使用Grab Cut算法对GMM彩色图像数据模型计算得到目标图像的边缘轮廓。</p>
    <p>[0020]	根据本发明的技术方案，对输入图像进行下采样后，建立数据模型，计算提取目标图像，有助于减少图像分割过程的计算量，从而提高图像分割的速度，有效地节省分割时间。</p>
    <p>附图说明</p>
    <p>[0021]	说明书附图用来提供对本发明的进一步理解，构成本申请的一部分，本发明的示意性实施例及其说明用于解释本发明，并不构成对本发明的不当限定。在附图中:</p>
    <p>[0022]	图1是根据本发明第一实施例的图像分割的方法的示意图；</p>
    <p>[0023]	图2是根据本发明第二实施例的图像分割的方法的示意图；</p>
    <p>[0024]	图3A是根据本发明第二实施例的分割图像方法的输入图像；</p>
    <p>[0025]	图3B是根据本发明第二实施例的分割图像方法的包含目标图像的矩形区域的示意图；[0026]	图3C是根据本发明第二实施例的分割图像方法的分割出的目标图像的效果图；</p>
    <p>[0027]	图4是根据本发明实施例的图像分割的装置的示意图。</p>
    <p>具体实施方式</p>
    <p>[0028]	需要说明的是，在不冲突的情况下，本申请中的实施例及实施例中的特征可以相互组合。下面将参考附图并结合实施例来详细说明本发明。</p>
    <p>[0029]	图1是根据本发明第一实施例的图像分割的方法的示意图，如图1所示，该方法主要包括如下步骤:</p>
    <p>[0030]	步骤Sll:对输入图像进行下采样，得到预处理图像；</p>
    <p>[0031]	步骤S13:按照预处理图像建立图像数据模型；</p>
    <p>[0032]	步骤S15:通过对图像数据模型的计算确定目标图像的边缘轮廓；</p>
    <p>[0033]	步骤S17:利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；</p>
    <p>[0034]	步骤S19:按照目标图像在输入图像的位置提取目标图像。</p>
    <p>[0035]	步骤Sll中，对图像下采样可以降低图像的分辨率，现有技术中图像下采样技术用于对图像进行存储、传输对图像大小有要求的领域。对图像进行下采样的具体算法可以采用多种方式，比如邻域平均、像素分除、或像素抽选。</p>
    <p>[0036]	邻域平均是将划分好的区域内的像素的数据进行平均，将该平均数据作为一个新的像素，按照原来区域的排列顺序重新进行排列，以得到新的图像。</p>
    <p>[0037]	像素分除是按照一定的算法去除图像中的某些像素，将剩余像素重新排列，已得到新的图像。</p>
    <p>[0038]	像素抽选与像素分除相类似，是按照一定的算法选取图像中的某些像素，重新进行排列，得到新的图像。</p>
    <p>[0039]	经过下采样得到的预处理图像在尽量保持输入图像的视觉质量的情况下，压缩了图像的大小，减小了图像的数据量。根据步骤Sll中得出的预处理图像进行图像分割可以大大减小数据模型建立和图像分割中的计算量，而且可以提高某些图像分割算法的效果。</p>
    <p>[0040]	为进一步减少计算量，第一实施例的图像分割的方法在步骤Sll之前还可以包括:获取用户划定的包含目标图像的图像区域，在步骤Sll之后，计算包含目标图像的图像区域在预处理图像中的对应区域；以对应区域为中心形成取样区域；按照预处理图像的取样区域内的图像部分建立图像数据模型。这样的优化利用用户较少的交互操作，划定了目标图像的所在区域，并在预处理图像中对应得出相应的区域，并根据对应区域形成取样区域，仅对取样区域内的图像进行图像建模，从而进一步减小了数据模型的计算量，而且通过以上步骤，可以避免当输入图像中包含多个与目标图像类似的图像时，图像分割算法的实效。另外，对于某些特定图像分割技术，如Graph Cut法或Grab Cut法本身就需要用户首先划定的包含目标图像的图像区域。</p>
    <p>[0041]	对应区域为中心形成取样区域的具体方式有多种，比如将对应区域等比例的扩大，或者预先规定大小的取样区域等。划定的包含目标图像的图像区域也有多种方式可以选择，比如拖放矩形框或者圆形框，也可以使用鼠标等交互工具勾画出包含目标图像的区域。用户的直接操作最少的方法，就是使用矩形工具选择图像区域。[0042]	上述步骤17的具体方法可以包括:对预处理图像进行上采样，得到与输入图像大小相同的对应图像；根据边缘轮廓在所述对应图像中的位置确定所述目标图像在输入图像的位置。通过上采样可以将预处理图像扩充为与原始输入图像相同大小的对应图像，那么预处理图像中边缘轮廓的大小也得到相应扩充，则通过边缘轮廓在对应图像中的位置与目标图像在输入图像中的位置的对应关系，就可以确定目标图像在输入图像的位置。</p>
    <p>[0043]	本发明第二实施例是对输入图像为RGB彩色图像进行分割的方法，第二实施例是在第一实施的基础上对RGB彩色图像使用Grab Cut法进行图像分割的方法，图2是根据本发明第二实施例的图像分割的方法的示意图，如图2所示，该方法包括:</p>
    <p>[0044]	步骤S21:获取用户划定的包含目标图像的矩形区域；</p>
    <p>[0045]	步骤S23:对输入图像进行下采样得到预处理图像，计算上述矩形区域的在预处理图像中的对应区域；</p>
    <p>[0046]	步骤S25:以上述对应区域为中心，比例放大该对应区域形成取样区域，对取样区域内的预处理图像中建立GMM模型；</p>
    <p>[0047]	步骤S27:根据GMM模型使用Grab Cut算法提取出目标图像数据的边缘轮廓；</p>
    <p>[0048]	步骤S29:利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像中的位置，按照目标图像在输入图像中的位置提取目标图像。</p>
    <p>[0049]	Grab Cut算法在Graph Cut基础上的改进,主要是利用高斯混合模型(GaussianMixture Model,GMM)代替了直方图，将灰度图像扩展到了彩色图像。对于输入图像为灰度图像的情况，使用第二实施例提供的图像分割方法，可以在步骤S21之前采取将灰度图进行伪彩色处理，将灰度图转化为RGB的彩色图像。</p>
    <p>[0050]	其中步骤S27中确定目标图像在输入图像中的位置可以使用与第一实施例相同的对预处理图像进行上采样的方式确定。</p>
    <p>[0051]	图3A是根据本发明第二实施例的分割图像方法的输入图像，图3B是根据本发明第二实施例的分割图像方法的包含目标图像的矩形区域的示意图，图3C是根据本发明第二实施例的分割图像方法的分割出的目标图像的效果图，如图所示，使用E55002.8GHZ的CPU、2G内存的试验环境，输入图像为800x600大小的荷花图、利用未进行下采样的图像获得目标荷花图像的时间为5.07s，利用实施例二的图像分割方法获得目标荷花图像的时间为0.55s，效率提高了约90%。</p>
    <p>[0052]	此外，本发明提供的实施例还可以使用Graph Cut法进行图像分割的方法，与第二实施例唯一的区别是，步骤S25为对取样区域内的预处理图像建立灰度直方图模型，步骤S27为根据灰度直方图模型使用Graph Cut算法提取出边缘轮廓。</p>
    <p>[0053]	图4是根据本发明实施例的图像分割的装置的示意图，如图4，该图像分割的装置40包括:下采样模块41，用于对输入图像进行下采样，得到预处理图像；建模模块43，用于按照预处理图像建立图像数据模型；轮廓提取模块45，用于通过对图像数据模型的计算确定目标图像的边缘轮廓；位置确定模块47，用于利用边缘轮廓在预处理图像中的位置确定目标图像在输入图像的位置；目标图像提取模块49，用于按照目标图像在输入图像的位置提取目标图像。</p>
    <p>[0054]	本发明实施例的图像分割的装置还可以包括:获取模块，用于获取用户划定的包含目标图像的图像区域；区域对应模块，用于计算包含目标图像的图像区域在预处理图像中的对应区域；取样区域形成模块，用于以对应区域为中心形成取样区域；建模模块43，还可以用于按照预处理图像的取样区域内的图像部分建立图像数据模型。</p>
    <p>[0055]	对于彩色图像使用Grab Cut法进行图像分割的情况，建模模块43还可以用于:按照预处理图像建立高斯混合GMM彩色图像数据模型；轮廓提取模块45还可以用于:使用Grab Cut算法对GMM彩色图像数据模型计算得到目标图像的边缘轮廓。</p>
    <p>[0056]	根据本发明的技术方案，有助于减少图像分割过程的计算量，从而提高图像分割的速度，有效地节省分割时间。</p>
    <p>[0057]	显然，本领域的技术人员应该明白，上述的本发明的各模块或各步骤可以用通用的计算装置来实现，它们可以集中在单个的计算装置上，或者分布在多个计算装置所组成的网络上，可选地，它们可以用计算装置可执行的程序代码来实现，从而，可以将它们存储在存储装置中由计算装置来执行，或者将它们分别制作成各个集成电路模块，或者将它们中的多个模块或步骤制作成单个集成电路模块来实现。这样，本发明不限制于任何特定的硬件和软件结合。</p>
    <p>[0058]	以上所述仅为本发明的优选实施例而已，并不用于限制本发明，对于本领域的技术人员来说，本发明可以有各种更改和变化。凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101216841A?cl=zh">CN101216841A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年1月14日</td><td class="patent-data-table-td patent-date-value">2008年7月9日</td><td class="patent-data-table-td ">南京搜拍信息技术有限公司</td><td class="patent-data-table-td ">交互式图像搜索系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101937508A?cl=zh">CN101937508A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年9月30日</td><td class="patent-data-table-td patent-date-value">2011年1月5日</td><td class="patent-data-table-td ">湖南大学;湖南创合制造有限公司</td><td class="patent-data-table-td ">一种基于高清图像的车牌定位与识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090060366">US20090060366</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年10月29日</td><td class="patent-data-table-td patent-date-value">2009年3月5日</td><td class="patent-data-table-td ">Riverain Medical Group, Llc</td><td class="patent-data-table-td ">Object segmentation in images</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">吴相颖 等: "<a href='http://scholar.google.com/scholar?q="%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8EGraph+Cuts%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E4%B9%B3%E8%85%BA%E8%82%BF%E5%9D%97%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95"'>一种基于Graph Cuts的多尺度乳腺肿块分割方法</a>", 《传感技术学报》, vol. 24, no. 10, 31 October 2011 (2011-10-31)</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">王钧铭，高立鑫，赵力: "<a href='http://scholar.google.com/scholar?q="GrabCut%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6"'>GrabCut彩色图像分割算法的研究</a>", 《数字视频》, vol. 32, no. 6, 30 June 2008 (2008-06-30)</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=XInSCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0007000000">G06T7/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年10月16日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/0554748c758f7a9bfa5c/CN103295219A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%8E%E8%A3%85%E7%BD%AE.pdf?id=XInSCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2LSNVn-gWU2dkVJq1ZqdUm2jcMfg"},"sample_url":"https://www.google.com/patents/reader?id=XInSCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>