<!DOCTYPE html><html><head><title>专利 CN102782751A - 社会网络中的数字媒体语音标签 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="社会网络中的数字媒体语音标签"><meta name="DC.contributor" content="C&#183;M&#183;丹尼斯" scheme="inventor"><meta name="DC.contributor" content="J&#183;B&#183;埃利斯" scheme="inventor"><meta name="DC.contributor" content="J&#183;E&#183;克里斯滕森" scheme="inventor"><meta name="DC.contributor" content="M&#183;拜利" scheme="inventor"><meta name="DC.contributor" content="R&#183;G&#183;法雷尔" scheme="inventor"><meta name="DC.contributor" content="T&#183;D&#183;埃里克森" scheme="inventor"><meta name="DC.contributor" content="W&#183;A&#183;凯罗格" scheme="inventor"><meta name="DC.contributor" content="国际商业机器公司" scheme="assignee"><meta name="DC.date" content="2011-2-3" scheme="dateSubmitted"><meta name="DC.description" content="一种语音加标签系统包括客户端计算装置，该客户端计算装置包括媒体对象捕获装置及语音捕获装置，并运行将媒体对象与语音样本相关联的客户端应用。该系统还包括：通信网络，其耦接至该客户端计算装置；语音加标签系统，其耦接至该通信网络并接收第一媒体对象和第一语音样本之间的至少一个关联；以及数据库，其耦接至该语音加标签系统，该数据库包括一个或多个语音标签，每个语音标签耦接至一个或多个语音样本。"><meta name="DC.date" content="2012-11-14"><meta name="DC.relation" content="CN:1343337:A" scheme="references"><meta name="DC.relation" content="CN:1852354:A" scheme="references"><meta name="DC.relation" content="US:20060036441:A1" scheme="references"><meta name="DC.relation" content="US:20080057922:A1" scheme="references"><meta name="DC.relation" content="US:20090210226:A1" scheme="references"><meta name="DC.relation" content="US:20090271380:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102782751:A"><meta name="citation_patent_application_number" content="CN:201180012464"><link rel="canonical" href="https://www.google.com/patents/CN102782751A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102782751A?cl=zh"/><meta name="title" content="专利 CN102782751A - 社会网络中的数字媒体语音标签"/><meta name="description" content="一种语音加标签系统包括客户端计算装置，该客户端计算装置包括媒体对象捕获装置及语音捕获装置，并运行将媒体对象与语音样本相关联的客户端应用。该系统还包括：通信网络，其耦接至该客户端计算装置；语音加标签系统，其耦接至该通信网络并接收第一媒体对象和第一语音样本之间的至少一个关联；以及数据库，其耦接至该语音加标签系统，该数据库包括一个或多个语音标签，每个语音标签耦接至一个或多个语音样本。"/><meta property="og:title" content="专利 CN102782751A - 社会网络中的数字媒体语音标签"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102782751A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102782751A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102782751A&amp;usg=AFQjCNHuMRdtwkqXTNJ-2suUlP0iyYSa_A" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/4b3f3e7f5172c3cdef0c/CN102782751A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/4b3f3e7f5172c3cdef0c/CN102782751A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102782751A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102782751A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102782751A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102782751B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102782751A?cl=zh" style="display:none"><span itemprop="description">一种语音加标签系统包括客户端计算装置，该客户端计算装置包括媒体对象捕获装置及语音捕获装置，并运行将媒体对象与语音样本相关联的客户端应用。该系统还包括：通信网络，其耦接至该客户端计算装置；语音加标签系统...</span><span itemprop="url">https://www.google.com/patents/CN102782751A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102782751A - 社会网络中的数字媒体语音标签</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102782751A - 社会网络中的数字媒体语音标签" title="专利 CN102782751A - 社会网络中的数字媒体语音标签"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102782751 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201180012464</td></tr><tr><td class="patent-bibdata-heading"> 专利合作条约 (PCT) 编号</td><td class="single-patent-bibdata">PCT/US2011/023557</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年11月14日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年2月3日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年3月5日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102782751B?hl=zh-CN&amp;cl=zh">CN102782751B</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8903847?hl=zh-CN&amp;cl=zh">US8903847</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110219018?hl=zh-CN&amp;cl=zh">US20110219018</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2011109137A1?hl=zh-CN&amp;cl=zh">WO2011109137A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201180012464.9, </span><span class="patent-bibdata-value">CN 102782751 A, </span><span class="patent-bibdata-value">CN 102782751A, </span><span class="patent-bibdata-value">CN 201180012464, </span><span class="patent-bibdata-value">CN-A-102782751, </span><span class="patent-bibdata-value">CN102782751 A, </span><span class="patent-bibdata-value">CN102782751A, </span><span class="patent-bibdata-value">CN201180012464, </span><span class="patent-bibdata-value">CN201180012464.9, </span><span class="patent-bibdata-value">PCT/2011/23557, </span><span class="patent-bibdata-value">PCT/US/11/023557, </span><span class="patent-bibdata-value">PCT/US/11/23557, </span><span class="patent-bibdata-value">PCT/US/2011/023557, </span><span class="patent-bibdata-value">PCT/US/2011/23557, </span><span class="patent-bibdata-value">PCT/US11/023557, </span><span class="patent-bibdata-value">PCT/US11/23557, </span><span class="patent-bibdata-value">PCT/US11023557, </span><span class="patent-bibdata-value">PCT/US1123557, </span><span class="patent-bibdata-value">PCT/US2011/023557, </span><span class="patent-bibdata-value">PCT/US2011/23557, </span><span class="patent-bibdata-value">PCT/US2011023557, </span><span class="patent-bibdata-value">PCT/US201123557</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22C%C2%B7M%C2%B7%E4%B8%B9%E5%B0%BC%E6%96%AF%22">C&#183;M&#183;丹尼斯</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22J%C2%B7B%C2%B7%E5%9F%83%E5%88%A9%E6%96%AF%22">J&#183;B&#183;埃利斯</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22J%C2%B7E%C2%B7%E5%85%8B%E9%87%8C%E6%96%AF%E6%BB%95%E6%A3%AE%22">J&#183;E&#183;克里斯滕森</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22M%C2%B7%E6%8B%9C%E5%88%A9%22">M&#183;拜利</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22R%C2%B7G%C2%B7%E6%B3%95%E9%9B%B7%E5%B0%94%22">R&#183;G&#183;法雷尔</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22T%C2%B7D%C2%B7%E5%9F%83%E9%87%8C%E5%85%8B%E6%A3%AE%22">T&#183;D&#183;埃里克森</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22W%C2%B7A%C2%B7%E5%87%AF%E7%BD%97%E6%A0%BC%22">W&#183;A&#183;凯罗格</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%9B%BD%E9%99%85%E5%95%86%E4%B8%9A%E6%9C%BA%E5%99%A8%E5%85%AC%E5%8F%B8%22">国际商业机器公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102782751A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102782751A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102782751A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (13),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201180012464&amp;usg=AFQjCNEOdODYQva_HXtpAwrq6psKv77z4Q"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102782751A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNELBv0ZGI0aP86Nud1_Rv9FK-YGyQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT117120645" lang="ZH" load-source="patent-office">社会网络中的数字媒体语音标签</invention-title>
      </span><br><span class="patent-number">CN 102782751 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA102268938" lang="ZH" load-source="patent-office">
    <div class="abstract">一种语音加标签系统包括客户端计算装置，该客户端计算装置包括媒体对象捕获装置及语音捕获装置，并运行将媒体对象与语音样本相关联的客户端应用。该系统还包括：通信网络，其耦接至该客户端计算装置；语音加标签系统，其耦接至该通信网络并接收第一媒体对象和第一语音样本之间的至少一个关联；以及数据库，其耦接至该语音加标签系统，该数据库包括一个或多个语音标签，每个语音标签耦接至一个或多个语音样本。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM46290021" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种系统，包括：  客户端计算装置，所述客户端计算装置包括媒体对象捕获装置和语音捕获装置，并运行将媒体对象与语音样本相关联的客户端应用；  通信网络，其耦接至所述客户端计算装置；  语音加标签系统，其耦接至所述通信网络并接收第一媒体对象和第一语音样本之间的至少�个关联；以及  数据库，其耦接至所述语音加标签系统，所述数据库包括一个或多个语音标签，每个语音标签耦接至�个或多个语音样本。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求I所述的系统，其中，存储在所述数据库中的至少�个语音样本具有音素表不。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的系统，其中，所述至少�个语音样本被链接至讲话者标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求I所述的系统，其中，所述客户端计算装置是蜂窝电话。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求I所述的系统，其中，具有类似音素表示的多个语音样本被链接至�个语首标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求I所述的系统，其中，所述第一媒体对象是图像。</div>
    </div>
    </div> <div class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.	�种对媒体对象加标签的方法，所述方法包括：  在服务器处接收第一语音样本和第一媒体对象之间的关联；  比较所述第一语音样本与一个或多个其它语音样本；  将所述第一语音样本链接至第一语音标签；  将所述第一语音标签链接至所述第一媒体对象；以及  将所述第一语音样本、所述第一语音标签、所述第一媒体对象以及它们之间的任何链接存储在耦接至所述服务器的数据库中。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求7所述的方法，其中，从蜂窝电话接收所述关联。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.如权利要求8所述的方法，其中，在所述蜂窝电话处创建所述第一媒体&#23550;象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.如权利要求8所述的方法，其中，从所述数据库中检索所述第一媒体对象并呈现在所述蜂窝电话上。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.如权利要求7所述的方法，其中比较包括：  形成用于所述第一语音样本的第一音素表不；以及  比较所述第一音素表示与链接至所述�个或多个其它语音样本的其它音素表示。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.如权利要求11所述的方法，其中，在所述第一音素表示匹配所述�个或多个其它语音样本中的�个的情况下，将所述第一语音样本链接至所述第一语音标签，所述第一语音标签先前被链接至所述�个或多个其它语音样本中的所述�个。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.如权利要求11所述的方法，其中，在所述第一音素表示不匹配所述�个或多个其它语音样本中的�个的情况下，将所述第一语音样本链接至所述第一语音标签进一&#27497;包括：  在确定所述第一音素表示不匹配所述�个或多个其它语音样本中的�个之后，创建所述第一标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.如权利要求8所述的方法，进�步包括：  将所述第一媒体对象存储在所述数据库中。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.如权利要求8所述的方法，进�步包括：  将所述第一语音标签链接至第二媒体&#23550;象。</div>
    </div>
    </div> <div class="claim"> <div num="16" class="claim">
      <div class="claim-text">16.	&#8212;种搜索含有已加语音标签的媒体对象的数字数据库的方法，所述方法包括：  在服务器处接收第一音频搜索；  比较所述第一音频搜索与存储在所述数字数据库中的语音标签的数字表示；以及  返回链接至匹配所述第一音频搜索的语音标签的�个或多个媒体&#23550;象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.如权利要求16所述的方法，其中，从蜂窝电话接收所述第一音频搜索。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.如权利要求16所述的方法，其中，比较包括：  将所述第一音频搜索转换为第一音素表示；以及  计算所述第一音素表示和链接至所述语音标签的其它音素表示之间的相似性计分。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.如权利要求18所述的方法，其中，所述相似性计分基于所述第一音素表示的开头部分。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.如权利要求16所述的方法，其中，返回包括：  重放所述第一音频搜索的至少一部分。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES52629132" lang="ZH" load-source="patent-office" class="description">
    <p>社会网络中的数字媒体语音标签</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及表征媒体，且更具体而言，利用语音标签表征数字媒体。</p>
    <p>背景技术</p>
    <p>[0002]	数字图书馆、照片共享站点、图像搜索引擎、在线百科全书及其它计算机系统皆在文件系统或数据库中拥有大量图像。访问这些站点的用户可能在查找想要的图像方面有困难，因为与文档不同，图像（及其它数字媒体）不包括可索引的字或短语。</p>
    <p>[0003]	对查找想要的图像的问题的一种解决方案是图像识别，但此方法对于用户生成的内容花费极高，且并不高度准确。另一已知方法是按指定种类（诸如，文件夹）对图像分组以促进存取。然而，这需要人工努力，且必须提前知晓图像。 [0004]	存在组织这些图像的许多方式，包括收集、集合及分层结构。组织收集的一种常用方法为加标签。当用户看到图像时，用户可键入字或短语以对该图像“加标签”（描述该图像）。多个用户可将一个或多个标签添加至同一图像。当另一用户访问该站点时，用户可接着导航至由特定标签标记的图像。</p>
    <p>[0005]	存在可使用标签实现图像导航的各种方式。举例而言，用户可键入作为用于一个或多个图像的集合的现有标签的字或短语。或者，用户可看到按各种方式（按字母顺序、按流行度等）排列的标签，且接着选择描述（这些）图像的标签。用于社会导航的文本加标签的功效被广泛使用且良好地理解。</p>
    <p>[0006]	也存在呈现数字媒体以使得用户能够扫描且识别项目的多个方式（拼贴、网格、可视化）。这些方法的主要缺点为其不可缩放：显示变得杂乱，且屏幕可能用完像素，尤其是在小屏幕上，诸如，在移动装置上。</p>
    <p>[0007]	也存在“自动”处理数字媒体以得出可接着用于搜索的元数据的多个方式。元数据（位置、时间）可在图像获取时捕获，且随后用以导航至视觉数字媒体。</p>
    <p>[0008]	然而，存在不可能或不方便创建或使用文本标签的许多情形。实例包括当用户：正使用移动电话（花费长时间或将注意力自视觉任务转至键入字或短语）时；身体残疾（不能键入字或短语）时；由于受教育有限而文盲或半文盲（仅具有有限的阅读或书写能力）时；或具有视力问题（不能看到字或短语）或这些情形的组合时。</p>
    <p>发明内容</p>
    <p>[0009]	根据本发明的一个实施例，提供一种系统，其包括客户端计算装置，该客户端计算装置包括媒体对象捕获装置和语音捕获装置并运行将媒体对象与语音样本相关联的客户端应用。此实施例的系统还包括：通信网络，其耦接至该客户端计算装置；语音加标签系统，其耦接至该通信网络并接收第一媒体对象和第一语音样本之间的至少一个关联；以及数据库，其耦接至该语音加标签系统，该数据库包括一个或多个语音标签，每个语音标签耦接至一个或多个语音样本。</p>
    <p>[0010]	根据本发明的另一实施例，公开一种对媒体对象加标签的方法。此实施例的方法包括：在服务器处接收第一语音样本和第一媒体对象之间的关联；比较该第一语音样本与一个或多个其它语音样本；将该第一语音样本链接至第一语音标签；将该第一语音标签链接至该第一媒体对象；以及将该第一语音样本、该第一语音标签、该第一媒体对象以及它们之间的任何链接存储在耦接至该服务器的数据库中。</p>
    <p>[0011]	根据本发明的另一实施例，公开一种搜索含有已加语音标签的媒体对象的数字数据库的方法。该方法包括：在服务器处接收第一音频搜索；比较该第一音频搜索与存储在该数字数据库中的语音标签的数字表示；以及返回链接至匹配该第一音频搜索的语音标签的一个或多个媒体对象。</p>
    <p>[0012]	经由本 发明的技术认识到额外特征及优点。本发明的其它实施例及方面在本文中得以详细描述且被认为是所主张的本发明的一部分。为了更好地理解具有这些优点及特征的本发明，参考描述及附图。</p>
    <p>附图说明</p>
    <p>[0013]	本认为是本发明的主题被特别地指出并清楚地在说明书结尾处的权利要求书中被请求。本发明的上述和其它特征和优点从结合附图的下述详细描述中将是明显的，在图中：</p>
    <p>[0014]	图I示出本发明的实施例可实施于其上的计算系统的实例；</p>
    <p>[0015]	图2示出根据本发明的一个实施例的系统的实例；</p>
    <p>[0016]	图3示出可在图2中示出的系统中利用的数据库的一个实施例的方块图；</p>
    <p>[0017]	图4为图3中示出的数据库的更详细描绘；</p>
    <p>[0018]	图5为示出根据本发明的可对媒体对象加标签的方法的流程图；</p>
    <p>[0019]	图6为示出根据本发明的一个实施例的形成数据库的方法的流程图；以及</p>
    <p>[0020]	图7为示出根据本发明的一个实施例的搜索且检索已加语音标签的媒体对象的方法的流程图。</p>
    <p>具体实施方式</p>
    <p>[0021]	本发明的实施例可解决以上描述的问题或其它未提到的问题中的一些或全部。在一些情况下，本发明的系统及方法允许用户利用音频标识符对媒体对象加标签。这些音频标识符可在本文中被称作“语音样本”。此外，本发明包括用于基于“语音查询”来搜索链接至数据库中的语音样本的媒体对象的系统及方法。语音查询为人类语言中的一连串字，每个字由一连串音素组成。若语音查询听起来像一个或多个语音样本，则链接至这些语音样本的这些标签将被用于检索媒体对象。</p>
    <p>[0022]	在一个实施例中，提供用于用户利用其说出字或短语的语音的音频记录对数字媒体加标签的方法，以及用于用户使用这些语音标签来搜索和浏览数字媒体的另一方法。应理解，“用户”是说出所述字或短语的人，未必是向其提供语音标签的装置的拥有者。</p>
    <p>[0023]	具体而言，一些实施例提供用于利用口头音频（例如，字及短语）对图像及其它数字媒体加标签的系统及方法。本文中公开的系统及方法可包括将语音样本中的音素序列识别为标签的能力。随后，若同一或另一用户讲出紧密匹配的音素序列，则本文中公开的系统及方法可检索数字媒体。[0024]	还提供用于用户收听语音标签并选择标签中的一个来接着检索相关联的数字媒体的方法。可按字母顺序、按流行度、按分层结构或按其它方式排列标签。在分层结构中，可在较具体标签前呈现较概括标签，且标签可具有同义词，如由用户对标签的特定性或相似性层级的判断所确定的。若选择处于给定层级的标签，则可呈现在下一向下层级的更具体标签或可记录用于选定标签的新同义词。若在给定层级下无标签被选择，则一标签可被记录且在此层级处添加至分层结构。当用户收听语音标签时，所链接的语音样本的音频特性（例如，响度）可被用于指示该标签相对于全部标签集合的流行度或其它特性以及身份(若扬声器可被用于根据偏好来选择标签或标签的特定语音样本）。举例而言，一个人可能在听到其它用户的语音前更喜欢听到其自己的语音用于标签。</p>
    <p>[0025]	图I示出本发明的实施例可实施于其上的计算系统的实例。在此实施例中，系统100具有一个或多个中央处理单元（处理器）101a、101b、IOlc等（被共称作或统称作处理器101)。在一个实施例中，每个处理器101可包括精简指令集计算机（RISC)微处理器。处理器101经由系统总线113耦接至系统内存114及各种其它部件。只读存储器（ROM) 102耦接至系统总线113，且可包括基本输入/输出系统（BIOS)，该BIOS控制系统100的某些基本功能。 </p>
    <p>[0026]	图I进一步描绘耦接至系统总线113的输入/输出（I/O)适配器107及网络适配器106。I/O适配器107可为与硬盘103和/或磁带存储驱动器105或任何其它类似部件通信的小计算机系统接口（SCSI)适配器。I/O适配器107、硬盘103及磁带存储驱动器105在本文中被共称作大容量存储器104。网络适配器106把总线113与外部网络116互连，从而使数据处理系统100能够与其它这些系统通信。屏幕（例如，显示监视器）115利用显示适配器112连接至系统总线113，显示适配器112可包括用以改进图形密集型应用的性能的图形适配器及视频控制器。在一个实施例中，适配器107、106及112可连接至一个或多个I/O总线，该一个或多个I/O总线可经由中间总线桥接器（未示出）连接至系统总线113。用于连接外围装置（诸如，硬盘控制器、网络适配器及图形适配器）的合适的I/O总线通常包括共同协议，诸如，外围部件接口（PCI)。另外的输入/输出装置被示出为经由用户接口适配器108及显示适配器112连接至系统总线113。键盘109、鼠标110及扬声器111皆经由用户接口适配器108互连至总线113，用户接口适配器108可包括例如将多个装置适配器整合至单个集成电路中的超级I/O芯片。当然，可包括诸如数字相机或数字视频相机（或以数字格式供应一个或多个图像的其它设备）及麦克风的其它输入作为另外的输入装置。</p>
    <p>[0027]	因此，如图I中所配置的，系统100包括呈处理器101的形式的处理设备、包括系统内存114及大容量存储器104的存储设备、诸如键盘109及鼠标110的输入设备，以及包括扬声器111及显不器115的输出设备。在一个实施例中，系统内存114及大容量存储器104的一部分共同地存储操作系统（诸如，来自IBM Corporation的AIX&#174;操作系统）以协调图I中示出的各种部件的功能。</p>
    <p>[0028]	应认识到，系统100可以是任何合适的计算机或计算平台，且可包括终端机、无线装置、信息用具、装置、工作站、微型计算机、大型计算机、个人数字助理（PDA)或其它计算装置。应理解，系统100可包括利用通信网络链接在一起的多个计算装置。举例而言，在两个系统之间可存在客户端一服务器关系，且可在两者之间分开进行处理。</p>
    <p>[0029]	可由系统100支持的操作系统的实例包括Windows 95、Windows98、WindowsNT4. O、Windows XP、Windows 2000、Windows CE、Windows Vista、Mac OS、Java、AIX、LINUX及UNIX或任何其它合适的操作系统。系统100还包括用于在网络116上通信的网络接口106。网络116可为局域网（LAN)、城域网（MAN)或广域网（WAN)，诸如因特网或万维网。</p>
    <p>[0030]	系统100的用户可经由任何合适的网络接口 116连接（诸如，标准电话线、数字用户线、LAN或WAN链路（例如，Tl、T3)、宽带连接（帧中继、ATM)及无线连接（例如，802. ll(a)、802. 11(b),802. 11(g)))连接至网络。</p>
    <p>[0031]	如本文中所公开的，系统100包括存储在机器可读介质（例如，硬盘104)上的机器可读指令，用于用户对屏幕115上示出的信息的捕获及交互显示。如本文中论述，这些指令被称作“软件”120。可使用本领域中已知的软件开发工具生产软件120。软件120可包括本领域中已知的用于提供用户交互能力的各种工具及特征。</p>
    <p>[0032]	在一些实施例中，将软件120提供为对另一程序的覆盖。举例而言，可将软件120 提供为针对一应用程序（或操作系统）的“插件（add-in)”。注意，术语“插件”通常指本领域中已知的补充程序代码。在这种实施例中，软件120可替换其合作的应用程序或操作系统的结构或对象。</p>
    <p>[0033]	应理解，在一个实施例中，本发明的系统可按一特定方式配置，且包括多个计算装置。为此，图2示出根据本发明的一个实施例的系统200的实例。可利用系统200来实施本文中公开的方法。</p>
    <p>[0034]	系统200包括一个或多个客户端计算装置202。客户端计算装置202可为任何类型的计算装置。在一个实施例中，客户端计算装置202包括麦克风及扬声器。在一个实施例中，且如图2中所示，客户端计算装置202可为蜂窝或“智能”电话、PDA或包括麦克风204及扬声器206的其它手持型通信（计算）装置。为了完整性，客户端计算装置202的其它部件可包括数字相机208、显示屏210及输入小键盘212。应理解，可将客户端计算装置202的部件中的一些组合在一起。举例而言，显示屏210可包括输入能力，且因此，包括用于输入信息以及显示例如图像的设备。在一个实施例中，客户端计算装置202可包括运行客户端应用、连接至无线数据网络、捕获一个或多个图像、显示图像、捕获音频及广播音频的能力。</p>
    <p>[0035]	客户端计算装置202可耦接至通信网络214。在一个实施例中，通信网络214可为蜂窝网络。举例而言，通信网络214可为GSM、TDMA、2G、3G或4G无线网络。通信网络214也可为诸如WIMAX或802. 11的无线数据网络。当然，通信链路216可为无线或实体的。在一个实施例中，通信网络可为内联网或因特网。</p>
    <p>[0036]	系统200还可包括语首加标签系统218。语首加标签系统218&#31281;接至通彳目网络214。因此，语音加标签系统218可在通信网络214上与客户端计算装置202通信。在一个实施例中，可将语音加标签系统218植入于服务器上。在一些实施例中，语音加标签系统218可被配置成运行web应用，该web应用处理对媒体对象及语音标签的请求且执行语音标签匹配。在一个实施例中，语音加标签系统218可包括具有用于人类语言的音素层级话语模型的话语处理单元，给定一语音样本，则该话语处理单元将返回最紧密匹配的音素序列。当然，该话语处理单元可处于独立的单元中或可实施于独立的单元上。</p>
    <p>[0037]	系统200还可包括耦接至语音加标签系统218的数据库220。数据库220可存储由语音加标签系统218利用的信息。在一个实施例中，语音加标签系统218可在其内包括数据库220。[0038]	图3a示出可存储在数据库220中的信息的实例。在一个实施例中，数据库220可包括语音标签存储302、数字媒体304及讲话者注册表306。当然，数据库220无需按此特定方式划分。</p>
    <p>[0039]	数字媒体存储304可包括数字媒体对象。数字媒体对象可包括能够视觉重现的任何类型的媒体，包括但不限于图像、文档、动画及视频。应理解，在一个实施例中，可用于语音加标签系统218(图2)的所有数字媒体可不存储在单个位置中，且可散布在多个数据库220 上。</p>
    <p>[0040]	讲话者注册表306可包括与特定讲话者相关联的语音剪辑。在一个实施例中，语音剪辑中的一些或全部可与相应语音剪辑的音素表示相关联。这可能对于语音加标签并不需要，但可用于以下论述的讲话者身份验证（SIV)中。</p>
    <p>[0041]	语音标签为存储一个或多个语音剪辑与一个或多个数字媒体对象之间的关联的对象，且存储在语音标签存储302中。在一个实施例中，“加标签”应指创建媒体对象与语音样本之间的关联。相比之下，语音标签存储302中的语音标签包括至至少一个媒体对象及 一个语音样本的链接。</p>
    <p>[0042]	图3b示出讲话者注册表306的较详细版本。讲话者注册表唯一地识别语音加标签系统的用户。讲话者可具有被识别的不同方式：使用触摸屏键入其姓名或特殊代码、匹配的语音剪辑（“说出字‘baggage’”)、来自呼叫者ID的电话号码，或产生可链接至语音剪辑以识别在记录语音剪辑时正交谈的讲话者的唯一讲话者标识符的任何其它方式。</p>
    <p>[0043]	图4示出具有数字媒体存储304与讲话者注册表306之间的链接的数据库220的一个实例。更详细地，图4示出语音剪辑402、404、406及408与数字媒体对象430及432之间的可能连接中的一些的实例。第一语音剪辑402表示某一讲话者讲出字“wheat”的剪辑。第一语音剪辑402链接至第一语音剪辑402的讲话者标识符410及音素表示412。</p>
    <p>[0044]	可按许多不同方式形成音素表示412 (以及用于其它语音剪辑的任何其它音素表示）。在一个实施例中，可将音频剪辑分成语音片段及非语音片段，且接着，可利用已知的或日后开发的技术来识别语音部分的音素。如所示出的，以实例说明，第一语音剪辑402可表示描绘为各字母“wheet”的音素“hwet”。</p>
    <p>[0045]	第一语音标签426也可链接至耦接至第二讲话者标识符414及音素表示416的第二语音剪辑404。在此实施例中，第二语音剪辑404表示由各字母“weet”描绘的音素“wet”。可实施音素匹配算法以推断：当由不同人讲话时，第一语音剪辑402和第二语音剪辑404实际上为同一个字。这种匹配可包括例如基于字的开始且因此基于字的音素序列的开头按同一方式分类的语音剪辑。因此，举例而言，每个语音剪辑中的前N=3个音素被识别且与其它相比较。当然，可利用其它分类技术，诸如，表示使两个序列相同所需的添加、删除及移动的数目的“编辑距离”。无论如何，第一语音标签426与第一数字媒体对象430相关联。</p>
    <p>[0046]	第二语音标签428与第一数字媒体对象430及第二数字媒体对象432两者相关联。这说明本发明允许将一个语音标签链接至包括不同类型的数字媒体对象（诸如，图像及视频）的一个或多个数字媒体对象的原理。类似于第一语音标签426，第二语音标签428可链接至一个或多个语音剪辑。在此实例中，第二语音标签428链接至第三语音剪辑406及第四语音剪辑408。第三语音剪辑406链接至讲话者标识符418及音素表示420。类似地，第四语音剪辑408链接至讲话者标识符422及音素表示424。当然，在一个实施例中，可组合这些讲话者标识符。</p>
    <p>[0047]	用户可创建语音剪辑与媒体对象之间的关联。这些关联可被用于创建语音标签并创建语音标签、数字媒体对象和语音剪辑之间的链接，如图4中所示。这些链接可例如由语音加标签系统218(图I)创建。当记录语音剪辑时，可创建讲话者标识符与语音剪辑之间的链接。也可由语音加标签系统218创建与每个语音剪辑相关联的音素表示且将其链接至语音剪辑。如所示，讲话者I (块422)讲出语音剪辑406及408两者。当收听标签428时，语音剪辑406可较佳，这是由于任意数量的包括清晰性、讲话时间、音量等的可配置原因。</p>
    <p>[0048]	对图像加标签</p>
    <p>[0049]	存在可根据本发明对图像加标签的若干方式。关于图5公开了一种方法。在块502处，获取媒体对象且将其呈现给用户。可按不同方式获取媒体对象。举例而言，媒体对 象可由用户利用内置于用户的蜂窝电话中的数字相机拍照而获取。在另一实施例中，可从数据库将媒体对象下载至用户的蜂窝电话的屏幕。当然，在不脱离本发明的情况下，可执行其它获取图像的方法。在一个实施例中，媒体对象必须对用户来说可见以便对图像加标签。当然，这并非必需。</p>
    <p>[0050]	在块504处，启用语首加标签应用。语首加标签应用可以是例如能够接收语首样本且使其与正观看的图像相关联的客户端应用。在一个实施例中，语音加标签应用是蜂窝电话上的客户端应用。</p>
    <p>[0051]	在块506处，从用户接收语音样本。在一个实施例中，可在向用户呈现图像或其它媒体对象时接收语音样本。</p>
    <p>[0052]	在块507处，可分析语音样本以确定讲话者的身份。若无讲话者可被识别，则语音加标签系统可利用匿名讲话者操作。可使用各种信息来确定讲话者身份，包括但不限于呼叫者ID(电话号码）、讲话者身份验证（SIV)及在电话小键盘上键入姓名。存储在讲话者注册表中的一个或多个语音样本也可被用于匹配由用户提供并存储在讲话者注册表中的语音样本。可选地，若在块507处不存在匹配，则可在讲话者注册表中创建新的讲话者标识符。在此情况下，可能需要与用户的对话以记录语音剪辑、姓名、电话号码或其它识别信息。</p>
    <p>[0053]	在块508处，创建语音样本与媒体对象之间的关联。此关联可处于语音样本与下载的媒体文件、已加载于装置上的媒体或由用户创建的媒体对象之间。无论如何，所述关联可描述语音剪辑的位置及媒体对象位置及创建关联的时间。</p>
    <p>[0054]	在块510处，可将所述关联传输至语音加标签系统。当然，若语音样本或媒体对象先前未存储在数据库中，则可将语音样本或媒体对象与所述关联一起传输。举例而言，若用户从数据库220 (图2)下载图像，且用语音样本对该图像加标签，则仅需要传输该语音样本及关联。所传输的除了关联之外的数据可以是系统特定且可配置的，且取决于具体情形。</p>
    <p>[0055]	创建已加标签的图像的数据库</p>
    <p>[0056]	如上论述，各个用户可创建语音样本与媒体对象之间的关联。这些关联形成图4中示出的链接的基础。图6为示出根据本发明的一个实施例的形成数据库的方法的流程图。</p>
    <p>[0057]	在块602处，接收关联。该关联使语音样本与媒体对象相关联。该关联可来自例如同时记录语音样本并显示图像。或者，该关联可来自允许在不显示图像的情况下进行关联的系统。在一个实施例中，媒体对象及语音样本中的一个或两者可与关联一起接收，例如在媒体对象或语音样本中的一个或两者尚未存在于数据库中的情况下。可例如由语音加标签系统218 (图2)接收所述关联。</p>
    <p>[0058]	在块604处，将语音样本转换成音素表示。可利用已知技术来创建音素表示。音素表示被链接至语音样本。此外，若语音样本的讲话者已知，则其可被链接至讲话者注册表中的语音样本的创建者。此链接可将每个语音样本链接至至少一个讲话者标识符。例如，当不能识别唯一讲话者时，或当不使用讲话者识别且因此所有语音样本链接至匿名讲话者标识符时，讲话者标识符可识别唯一匿名用户。当然，多个样本可链接至单个标识符。</p>
    <p>[0059]	在块606处，比较数据库中的现有语音样本的音素表示与新 接收的语音样本的音素表示。存在执行这种匹配的许多方式。一个实例包括匹配（并因此分类）基于字的开始听起来相似的字。这种匹配可包括：针对这些N个音素中的每一个，提取在语音样本中识别的前M个音素。对于一些情形，可使用少至M=3个音素。对于每个语音标签，顺序地比较这些音素。标签接收基于与其第M个音素的匹配程度的计分。与第M-I个音素的匹配可被加权高于第M个音素。在一个实施例中，匹配程度基于音素的匹配特征（诸如，浊辅音及清辅音）的数目，且无匹配接收计分-I。每个音素存在5个特征，因此，最佳计分为15且最差为_3。</p>
    <p>[0060]	在块608处，确定是否存在新语音样本与现有语音样本之间的匹配。若多个现有语音样本被从现有语音样本的数据库中检索出且匹配，则用户可选择最佳者。在存在与单个语音样本的匹配的情况下，在块610处，新语音样本被链接至现有语音样本被链接至的语音标签。举例而言，再次参看图4，第一语音剪辑402及第二语音剪辑404均链接至语音标签426。这可发生是因为第一语音剪辑402先前被链接至语音标签426。当将第二语音剪辑404放置于系统中时，第二音素表示416匹配第一音素表示412。因此，它们均被分配至同一个语音标签（语音标签426)。</p>
    <p>[0061]	现返回参看图6，如上所论述，每个语音标签链接至至少一个媒体对象及至少一个语音样本。在块612处，确定链接至现有语音标签的媒体对象是否匹配与新语音样本相关联的媒体对象。若是，则可记录关于加标签过程的信息且该过程可结束。举例而言，可将已对图像加标签的次数记录于数据库220 (图2)中。否则，在块614处，将语音标签链接至与新语音样本相关联的媒体对象。以此方式，可将单个语音标签与多个媒体对象相关联。</p>
    <p>[0062]	在不存在新语音样本与现有语音样本之间的匹配（即，这是先前未讲出的字的语音样本）的情况下，在块616处，创建新语音标签。接着在块618处，将新创建的语音标签链接至新语音样本。新创建的语音标签被用于开始于已描述的块612处的处理。因此，若这是与匹配媒体对象的关联，则将新语音标签链接至语音样本先前相关联的媒体对象。若这是非匹配的新媒体对象，则将新创建的标签链接至该新媒体对象。因此可能使用新记录的语音样本对新捕获的图像加语音标签，在该情况下，该语音样本不匹配任何现有标签。</p>
    <p>[0063]	如上所论述，讲话者注册表306可被用于唯一地识别语音加标签系统的用户。可如上所述搜集用于讲话者的信息。</p>
    <p>[0064]	搜索已加标签的图像的数据库</p>
    <p>[0065]	以上描述详述了可创建及修改数据库的方式，以下描述描述在一个实施例中可如何搜索数据库。[0066]	图7为示出搜索且检索已加语音标签的媒体对象的方法的流程图。在块702处，语音加标签系统的用户启用在其客户端计算装置上的系统。在一个实施例中，客户端计算装置可为蜂窝电话。在另一实施例中，能够拍照且记录及播放声音且在WiFi网络上操作的触摸屏装置可形成客户端计算装置。</p>
    <p>[0067]	在块704处，创建利用语音搜索项的搜索。这可包括用户对着麦克风说出字。接着在块706处将搜索提交至服务器。</p>
    <p>[0068]	在块708处，服务器（例如，语音加标签系统218，图2)将（多个）语音搜索项与现有语音标签进行匹配。此匹配可包括将（多个）搜索项分成语音片段及非语音片段。接着，针对每个语音片段，可形成音素表示。可比较这些音素表示与链接至语音标签的现有音素表示，且基于与语音标签一起存储的现有语音样本的音素表示的匹配计分为每个语音标签创建“匹配计分”。可使用以上描述的匹配计分为每个语音标签确定最佳匹配。 </p>
    <p>[0069]	在块710处，将结果返回至搜索者。在多个语音标签具有足够高计分的情况下，返回那些标签。在未找到标签的情况下，可将此对搜索者指示。假定存在匹配，则可将关联呈现给用户。向搜索者显示链接至选定标签的一个或多个匹配媒体对象。在触摸屏装置上选择匹配媒体对象可通过播放具有最佳计分的相关联的语音样本来播放与每个媒体对象相关联的语首标签。</p>
    <p>[0070]	在替代实施例中，捕获图像且经由MMS(多媒体消息传送服务）来发送，且系统执行语音输入的层次分类。在此实施例中，系统可包括“语音网关”，该语音网关自身是将用户的电话（经由公共交换电话网络或PSTN)连接至计算机系统的部件的组合。</p>
    <p>[0071]	现返回参看图2，在此实施例中，语音加标签系统218可被配置成操作交互式语音响应系统（IVR)。IVR系统可处理用户的小键盘输入，且引导语音网关播放和/或记录音频流（也被称作音频剪辑或语音剪辑）。系统还可包括无线手持电话，该无线手持电话能够记录和显示图像并具有与语音加标签系统218的无线数据连接。如先前所述，图像（或其它数字媒体）可存储并链接于数据库220中。该系统还可包括用于对其它用户通知新书签的至外部（在本IVR外部）服务的一个或多个接口。实例为公共域电子邮件网络、由无线载体（服务提供者）拥有并操作的SMS(短消息服务）及丽S(多媒体消息服务）网络、及公共交换电话网络（PSTN)。</p>
    <p>[0072]	在此实施例中，用户调用在连接至PSTN的任意移动相机电话上的IVR系统，且历经以下步骤来按层次地分类照片：1.用户利用其相机电话拍摄照片；用户将照片自其移动电话（使用电子邮件或MMS)发送至IVR服务；3. IVR服务将照片存储至数据库中并将照片添加至未加标签的照片的队列；4.用户登录IVR服务。用户的电话的呼叫者ID或明确的登录还被用于识别用户；用户通过收听与每个未加标签的照片相关联的元数据的文本至话音（TTS)生成而使用IVR菜单来选择照片。在此实施例中，使用该队列中每个未加标签的照片的上载时间；接着由IVR提示用户是否想要对该照片加标签，且若是，则从先前记录的语音标签的分层结构构建IVR菜单树；8.在IVR菜单树中的每个层级N处，提示所述用户：a)选择适当标签，b)创建新标签，或c)删除标签；9.若用户已选择适当标签，则检索层级N+1处的语音标签 '及10.若无更多特定标签可用，则将该语音标签与照片一起存储。</p>
    <p>[0073]	本文中使用的术语仅用于描述特定实施例的目的，且并不意欲限制本发明。如本文中所使用的，单数形式的“一”、“一个”及“该/所述”意欲还包括复数形式，除非上下文另有清晰指示。应进一步理解，当词语“包括”用于此说明书中时，其指定所述的特征、整数、步骤、操作、元件和/或部件的存在，但并不排除一个或多个其它特征、整数、步骤、操作、元件、部件及/或其群组的存在或添加。</p>
    <p>[0074]	权利要求中的所有设备或步骤加功能元件的对应结构、材料、动作及等效物意欲包括用于连同如具体所主张的其它所主张元件一起执行功能的任何结构、材料或动作。已呈现本发明的描述以用于达成说明及描述的目的，但其并不意欲为详尽的或限于所公开的形式下的本发明。在不脱离本发明的范围及精神的情况下，许多修改及变化对于本领域普通技术人员将显而易见。选择并描述了实施例以便最佳地解释本发明的原理及实践应用，且使其它本领域普通技术人员能够针对具有适合于所预期特定用途的各种修改的各种实施例来理解本发明。</p>
    <p>[0075]	本文中描绘的流程图仅为一个实例。在不脱离本发明的精神的情况下，可存在对本文中描述的该图或步骤（或操作）的许多变化。举例而言，可按不同次序执行这些步骤，或者可添加、删除或修改步骤。将所有这些变化考虑为所主张的本发明的一部分。</p>
    <p> [0076]	尽管已描述了本发明的优选实施例，但本领域技术人员应理解，在现在及将来，可进行落入权利要求的范围的各种改进及增强。这些权利要求应被解释为维持对最初描述的本发明的适度保护。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1343337A?cl=zh">CN1343337A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2000年3月1日</td><td class="patent-data-table-td patent-date-value">2002年4月3日</td><td class="patent-data-table-td ">佳能株式会社</td><td class="patent-data-table-td ">数据库注释和获取</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1852354A?cl=zh">CN1852354A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年10月17日</td><td class="patent-data-table-td patent-date-value">2006年10月25日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">收集用户行为特征的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060036441">US20060036441</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年8月10日</td><td class="patent-data-table-td patent-date-value">2006年2月16日</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Data-managing apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080057922">US20080057922</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年10月31日</td><td class="patent-data-table-td patent-date-value">2008年3月6日</td><td class="patent-data-table-td ">Kokes Mark G</td><td class="patent-data-table-td ">Methods of Searching Using Captured Portions of Digital Audio Content and Additional Information Separate Therefrom and Related Systems and Computer Program Products</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090210226">US20090210226</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年2月15日</td><td class="patent-data-table-td patent-date-value">2009年8月20日</td><td class="patent-data-table-td ">Changxue Ma</td><td class="patent-data-table-td ">Method and Apparatus for Voice Searching for Stored Content Using Uniterm Discovery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090271380">US20090271380</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value">2009年10月29日</td><td class="patent-data-table-td ">Luc Julia</td><td class="patent-data-table-td ">System and method for enabling search and retrieval operations to be performed for data items and records using data obtained from associated voice files</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103399737A?cl=zh">CN103399737A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月18日</td><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">百度在线网络技术（北京）有限公司</td><td class="patent-data-table-td ">基于语音数据的多媒体处理方法及装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0017000000">G10L17/00</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L17/00">G10L17/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L17/005">G10L17/005</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M3/4936">H04M3/4936</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2203/303">H04M2203/303</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30244">G06F17/30244</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=Y10S707/915">Y10S707/915</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L15/10">G10L15/10</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=Y10S707/916">Y10S707/916</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=IZmuBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L15/26">G10L15/26</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06F17/30M</span>, <span class="nested-value">G10L15/10</span>, <span class="nested-value">G10L17/00U</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年1月2日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年2月11日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/4b3f3e7f5172c3cdef0c/CN102782751A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%A4%BE%E4%BC%9A%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%97%E5%AA%92%E4%BD%93%E8%AF%AD%E9%9F%B3%E6%A0%87.pdf?id=IZmuBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3OFqzTyU-IOlCT-fknDM0H1QuvLw"},"sample_url":"https://www.google.com/patents/reader?id=IZmuBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>