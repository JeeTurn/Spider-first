<!DOCTYPE html><html><head><title>专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种基于单训练样本的人脸特征提取方法"><meta name="DC.contributor" content="高涛" scheme="inventor"><meta name="DC.contributor" content="赵祥模" scheme="inventor"><meta name="DC.contributor" content="张超超" scheme="inventor"><meta name="DC.contributor" content="吴晓龙" scheme="inventor"><meta name="DC.contributor" content="冯兴乐" scheme="inventor"><meta name="DC.contributor" content="长安大学" scheme="assignee"><meta name="DC.date" content="2014-4-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于单训练样本的人脸特征提取方法，包括步骤：一、人脸图像信号的采集及上传；二、人脸图像的分辨率调整及矩阵表示；三、图像特征提取：301、对图像矩阵X进行横向分块，302、采用二维Gabor滤波器组对图像矩阵X进行滤波，303、求取人脸子图像矩阵中的每个像素值的纹理贡献度，304、求取人脸图像G的特征向量W；四、处理结果同步输出。本发明设计合理、实现方便且投入成本低，操作简便，人脸特征提取速度快、效果好，实用性强，解决了现有技术中的图像特征提取方法在单训练样本条件下，很多传统方法失效、人脸识别率急剧下降等缺陷，性能方面明显优于现有的多种单训练样本的图像特征提取方法。"><meta name="DC.date" content="2014-7-16"><meta name="citation_patent_publication_number" content="CN:103927527:A"><meta name="citation_patent_application_number" content="CN:201410182023"><link rel="canonical" href="https://www.google.com/patents/CN103927527A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103927527A?cl=zh"/><meta name="title" content="专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法"/><meta name="description" content="本发明公开了一种基于单训练样本的人脸特征提取方法，包括步骤：一、人脸图像信号的采集及上传；二、人脸图像的分辨率调整及矩阵表示；三、图像特征提取：301、对图像矩阵X进行横向分块，302、采用二维Gabor滤波器组对图像矩阵X进行滤波，303、求取人脸子图像矩阵中的每个像素值的纹理贡献度，304、求取人脸图像G的特征向量W；四、处理结果同步输出。本发明设计合理、实现方便且投入成本低，操作简便，人脸特征提取速度快、效果好，实用性强，解决了现有技术中的图像特征提取方法在单训练样本条件下，很多传统方法失效、人脸识别率急剧下降等缺陷，性能方面明显优于现有的多种单训练样本的图像特征提取方法。"/><meta property="og:title" content="专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103927527A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103927527A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=rn4QCQABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103927527A&amp;usg=AFQjCNHrhpEuu_1-oBbznZJG-vUZEH50wA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/6bf587ab54b983973e05/CN103927527A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/6bf587ab54b983973e05/CN103927527A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103927527A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103927527A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103927527A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于单训练样本的人脸特征提取方法，包括步骤：一、人脸图像信号的采集及上传；二、人脸图像的分辨率调整及矩阵表示；三、图像特征提取：301、对图像矩阵X进行横向分块，302、采用二维Gabor滤波器组对图...</span><span itemprop="url">https://www.google.com/patents/CN103927527A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法" title="专利 CN103927527A - 一种基于单训练样本的人脸特征提取方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103927527 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201410182023</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2014年7月16日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2014年4月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2014年4月30日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201410182023.9, </span><span class="patent-bibdata-value">CN 103927527 A, </span><span class="patent-bibdata-value">CN 103927527A, </span><span class="patent-bibdata-value">CN 201410182023, </span><span class="patent-bibdata-value">CN-A-103927527, </span><span class="patent-bibdata-value">CN103927527 A, </span><span class="patent-bibdata-value">CN103927527A, </span><span class="patent-bibdata-value">CN201410182023, </span><span class="patent-bibdata-value">CN201410182023.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%AB%98%E6%B6%9B%22">高涛</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B5%B5%E7%A5%A5%E6%A8%A1%22">赵祥模</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BC%A0%E8%B6%85%E8%B6%85%22">张超超</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%90%B4%E6%99%93%E9%BE%99%22">吴晓龙</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%86%AF%E5%85%B4%E4%B9%90%22">冯兴乐</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E9%95%BF%E5%AE%89%E5%A4%A7%E5%AD%A6%22">长安大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103927527A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103927527A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103927527A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=rn4QCQABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201410182023&amp;usg=AFQjCNFVOi4l1oig7LypHyE_3rJjHK8nnQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=rn4QCQABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103927527A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFSLwGrF0LYFeqSsIjMRPkyMb7zFw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT137953285" lang="ZH" load-source="patent-office">一种基于单训练样本的人脸特征提取方法</invention-title>
      </span><br><span class="patent-number">CN 103927527 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA135792748" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于单训练样本的人脸特征提取方法，包括步骤：一、人脸图像信号的采集及上传；二、人脸图像的分辨率调整及矩阵表示；三、图像特征提取：301、对图像矩阵X进行横向分块，302、采用二维Gabor滤波器组对图像矩阵X进行滤波，303、求取人脸子图像矩阵中的每个像素值的纹理贡献度，304、求取人脸图像G的特征向量W；四、处理结果同步输出。本发明设计合理、实现方便且投入成本低，操作简便，人脸特征提取速度快、效果好，实用性强，解决了现有技术中的图像特征提取方法在单训练样本条件下，很多传统方法失效、人脸识别率急剧下降等缺陷，性能方面明显优于现有的多种单训练样本的图像特征提取方法。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(6)</span></span></div><div class="patent-text"><div mxw-id="PCLM67042601" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于单训练样本的人脸特征提取方法，其特征在于该方法包括以下步骤:步骤一、人脸图像信号的采集及上传:图像采集设备(I)采集人脸图像信号并将其实时所采集的人脸图像信号通过图像信号传输装置(2)上传给处理器(3)；  步骤二、人脸图像的分辨率调整及矩阵表示:首先，处理器(3)调用分辨率差值调整模块将其所接收到的人脸图像信号的分辨率调整为128X128，得到人脸图像G ;然后，处理器(3)将所述人脸图像G表示为图像矩阵X ；  步骤三、图像特征提取:处理器(3)对步骤二中所得到的图像矩阵X进行分析处理，得到人脸图像G的特征向量W，其分析处理过程如下:  步骤301、对图像矩阵X进行横向分块:将图像矩阵X横向分为q块，得到:<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00021.png"> <img id="icf0001" file="CN103927527AC00021.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00021.png" class="patent-full-image" alt="Figure CN103927527AC00021"> </a> </div>   其中，q为自然数且q的取值为4、6、8、16、32或64，Xn(i = 1，2，...，q)为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00022.png"> <img id="icf0002" file="CN103927527AC00022.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00022.png" class="patent-full-image" alt="Figure CN103927527AC00022"> </a> </div>维                                                                       的人脸子图像矩阵；  步骤302、采用二维Gabor滤波器组对图像矩阵X进行滤波，具体过程如下:  步骤3021、构建时域下的二维Gabor滤波器组:<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00023.png"> <img id="icf0003" file="CN103927527AC00023.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00023.png" class="patent-full-image" alt="Figure CN103927527AC00023"> </a> </div>   其中，Φ6(χ, y, f, θ，σ )为偶对称的二维Gabor滤波器，Φ0(χ, y, f, θ，σ )为奇对称的二维Gabor滤波器，f为中心频率，x为时域下的横坐标变量，y为时域下的纵坐标变量，Θ为空间相位角，σ为空间常数，g(x，y, ο )为高斯函数且<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00024.png"> <img id="icf0004" file="CN103927527AC00024.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00024.png" class="patent-full-image" alt="Figure CN103927527AC00024"> </a> </div>  步骤3022、将时域下的二维Gabor滤波器组变换为频域下的二维Gabor滤波器组:<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00025.png"> <img id="icf0005" file="CN103927527AC00025.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00025.png" class="patent-full-image" alt="Figure CN103927527AC00025"> </a> </div>    其中，Φ x (u, V, f, θ，σ ) = exp {_2 π 2 σ 2 [ (u_f cos θ )2+(v-f s in θ )2] }，Φ2 (u, V, f, θ，σ) = exp{_2 π 2 σ 2[(u+fcos θ )2+(v+fsin θ )2]}，Φβ (u, ν, f, θ , σ )为Φ6(χ，y，f，θ，σ )的 Fourier 变换，Φ0(&#971;，ν，f，θ，σ )为 φο(χ，y，f，θ，σ )的 Fourier 变换，j为虚数单位且J = P，U, V为频域下的空间频率变量；   步骤3023、首先，将所述人脸子图像矩阵Xn(i = I, 2,..., q)中的每个像素值表示为Xil (X，y) (i = 1, 2,..., q);然后，采用频域下的二维Gabor滤波器组对Xil (x, y) (i =1，2，...，q)进行滤波，得到滤波结果: <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00026.png"> <img id="icf0006" file="CN103927527AC00026.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00026.png" class="patent-full-image" alt="Figure CN103927527AC00026"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00031.png"> <img id="icf0007" file="CN103927527AC00031.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00031.png" class="patent-full-image" alt="Figure CN103927527AC00031"> </a> </div>其中，<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00032.png"> <img id="icf0008" file="CN103927527AC00032.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00032.png" class="patent-full-image" alt="Figure CN103927527AC00032"> </a> </div>为采用偶对称的二维Gabor滤波器对Xn(x，y) (i = 1，2，...，q)进行滤波的滤波结果，<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00033.png"> <img id="icf0009" file="CN103927527AC00033.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00033.png" class="patent-full-image" alt="Figure CN103927527AC00033"> </a> </div>采用奇对称的二维Gabor滤波器对Xil (x，y) (i =.1，2，...，q)进行滤波的滤波结果，Fi (U，V)为 Xil (X，y) (i = I, 2,..., q)的 Fourier 变换；步骤3024、选择Ii1个不同的中心频率f，并对每个中心频率f，选择n2个不同的空间相位角Θ，形成Ii1Xn2个Gabor滤波通道,对每个Gabor滤波通道的滤波结果,提取其幅值作为代表该Gabor滤波通道的特征；其中，采用偶对称的二维Gabor滤波器对Xil (x, y)(i = 1，2，…，q)进行滤波的滤波结果武<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00034.png"> <img id="icf0010" file="CN103927527AC00034.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00034.png" class="patent-full-image" alt="Figure CN103927527AC00034"> </a> </div>0的幅值为4(/，妁，采用奇对称的二维Gabor滤波器对Xil (x, y) (i = 1，2，...，q)进行滤波的滤波结果戎<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00035.png"> <img id="icf0011" file="CN103927527AC00035.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00035.png" class="patent-full-image" alt="Figure CN103927527AC00035"> </a> </div>的幅值为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00036.png"> <img id="icf0012" file="CN103927527AC00036.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00036.png" class="patent-full-image" alt="Figure CN103927527AC00036"> </a> </div>  步骤3025、对每个Gabor滤波通道的滤波结果<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00037.png"> <img id="icf0013" file="CN103927527AC00037.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00037.png" class="patent-full-image" alt="Figure CN103927527AC00037"> </a> </div>妁的幅值4':(/，妁按行展开，形成一个行向量<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00038.png"> <img id="icf0014" file="CN103927527AC00038.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00038.png" class="patent-full-image" alt="Figure CN103927527AC00038"> </a> </div>;并对每个Gabor滤波通道的滤波结果礼<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00039.png"> <img id="icf0015" file="CN103927527AC00039.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC00039.png" class="patent-full-image" alt="Figure CN103927527AC00039"> </a> </div>的幅值<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000310.png"> <img id="icf0016" file="CN103927527AC000310.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000310.png" class="patent-full-image" alt="Figure CN103927527AC000310"> </a> </div>按行展开，形成一个行向量<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000311.png"> <img id="icf0017" file="CN103927527AC000311.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000311.png" class="patent-full-image" alt="Figure CN103927527AC000311"> </a> </div>   步骤3026、将Ii1Xn2 fGabor滤波通道的Ii1 Xn2X 2个行向量依次连接，形成Xil (x，y)(i = I, 2,..., q)的二维 Gabor 滤波器组的特征 Wi (i = I, 2,...q)；   步骤303、求取所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值Xil (x，y) (i=1，2，...，q)的纹理贡献度，具体过程如下:  步骤3031、定义人脸图像G的熵函数为:<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000312.png"> <img id="icf0018" file="CN103927527AC000312.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000312.png" class="patent-full-image" alt="Figure CN103927527AC000312"> </a> </div>  其中，X(x’，y’)为图像矩阵X的像素值，X’为图像X(x’，y’)的横向坐标，y’为图像W，&#939; )的纵向坐标，m为人脸图像G的灰度级别总数，Pa为第a个灰度级别出现的概率，a为自然数且a的取值为I~m ;  步骤3032、定义局部信息熵图谱LHO对应的图像熵为:    LH(i，，j，)=H(F(i，，j，)w)  其中，w为滑动可变窗口的大小，H(F(i’，j’)w)为图像F(i’，j’)w的熵函数，(i’，j’)为图像F(i’，j’)w中每个像素的位置<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000313.png"> <img id="icf0019" file="CN103927527AC000313.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000313.png" class="patent-full-image" alt="Figure CN103927527AC000313"> </a> </div>，i’为图像F(i’，j’)w的横向坐标，j’为图像F(i’，j’)w的纵向坐标，F(i’，j’)w为以(i’，j’)为中心滑动可变窗口内的子图像且:    F(i，，j，)w= {X(x，，y，)|xe [i，-w/2, i，+w/2-1]，y，e [j，-w/2, j，+w/2_l]}；   步骤3033、定义所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值Xil (x’，y’)(i = 1，2，...，q)的纹理贡献度为:  <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000314.png"> <img id="icf0020" file="CN103927527AC000314.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000314.png" class="patent-full-image" alt="Figure CN103927527AC000314"> </a> </div>其中40^’+(卜1)\(1，7’)为将图像矩阵父横向分为(1块后第1块子图像中(x’，y’)处的像素值，s为将图像矩阵X横向分为q块后每一块子图像的纵向像素个数且s = 128/q ；步骤304、根据公式<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000315.png"> <img id="icf0021" file="CN103927527AC000315.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AC000315.png" class="patent-full-image" alt="Figure CN103927527AC000315"> </a> </div>求取人脸图像G的特征向量W ；  步骤四、处理结果同步输出:步骤三中进行图像特征提取过程中，处理器(3)通过与其相接的显示器(4)对步骤三中的图像信号处理过程及图像特征提取结果进行同步显示。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.按照权利要求1所述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3021中所述σ的取值为I。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.按照权利要求1所述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3024中所述Ii1的取值为6，6个不同的中心频率f的取值分别为2Hz、4Hz、8Hz、16Hz、32Hz和 64Hz。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.按照权利要求1所述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3024中所述n2的取值为4，4个不同的空间相位角Θ的取值分别为0° ,45° ,90°和.135。。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.按照权利要求1所述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3031中所述m的取值为256。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.按照权利要求1所述的一种基于单训练样本的人脸特征提取方法，其特征在于:所述处理器(3)为计算机。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES75453455" lang="ZH" load-source="patent-office" class="description">
    <p>一种基于单训练样本的人脸特征提取方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明属于图像处理技术领域，具体涉及一种基于单训练样本的人脸特征提取方法。</p>
    <p>背景技术</p>
    <p>[0002]	现有技术中，对于具有多训练样本的人脸识别方法已经取得了非常优秀的成果。但是在实际的应用中，经常会遇到缺乏训练样本的情况，例如恐怖分子的布控、海关安防、公安系统等等。因此，单样本人脸识别的研究在近几年内也成了研究的热点，目前对于单样本的人脸特征描述近多年也提出了多种解决方法，总结起来主要分为两类:</p>
    <p>[0003]	1、使用各种方法对训练样本进行扩充，主要思想是扩充训练样本以使用全局特征描述方法，该类方法的优点是操作简单，但是缺点是扩充的训练样本和原训练样本一致性过高，很难达到多样本的效果；</p>
    <p>[0004]	2、对单样本的图像进行局部的纹理描述，旨在最大程度地描述图像的局部特征，该类方法对单样本人脸特征描述具有较高的稳定性和识别率，但是该方法的缺陷在于没有考虑每个局部特征对于图像整体描述的贡献，对于所有的局部特征描述的重要性没有区分。</p>
    <p>[0005]	综上所述，现有技术中的对于单训练样本人脸图像特征提取方法存在着对局部特征的贡献考虑不足、分类识别效果差、稳定性低等缺陷和不足，不能很好地满足实际应用的需求。</p>
    <p>发明内容</p>
    <p>[0006]	本发明所要解决的技术问题在于针对上述现有技术中的不足，提供一种基于单训练样本的人脸特征提取方法，其设计合理、实现方便且投入成本低，操作简便，人脸特征提取速度快、效果好，能够适用于实际应用中众多缺乏训练样本的场景，实用性强。</p>
    <p>[0007]为解决上述技术问题，本发明采用的技术方案是:一种基于单训练样本的人脸特征提取方法，其特征在于该方法包括以下步骤:</p>
    <p>[0008]	步骤一、人脸图像信号的采集及上传:图像采集设备采集人脸图像信号并将其实时所采集的人脸图像信号通过图像信号传输装置上传给处理器；</p>
    <p>[0009]	步骤二、人脸图像的分辨率调整及矩阵表示:首先，处理器调用分辨率差值调整模块将其所接收到的人脸图像信号的分辨率调整为128X128，得到人脸图像G ;然后，处理器将所述人脸图像G表示为图像矩阵X ；</p>
    <p>[0010]	步骤三、图像特征提取:处理器对步骤二中所得到的图像矩阵X进行分析处理，得到人脸图像G的特征向量W，其分析处理过程如下:</p>
    <p>[0011]	步骤301、对图像矩阵X进行横向分块:将图像矩阵X横向分为q块，得到:[0012]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00061.png"> <img id="idf0001" file="CN103927527AD00061.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00061.png" class="patent-full-image" alt="Figure CN103927527AD00061"> </a> </div>
    <p>[0013]	其中4为自然数且9的取值为4、6、8、16、32或6441(1 = 1，2，...4)为&#8212;&#8212;xl28</p>
    <p>                                                                                    q</p>
    <p>维的人脸子图像矩阵；</p>
    <p>[0014]	步骤302、采用二维Gabor滤波器组对图像矩阵X进行滤波，具体过程如下:</p>
    <p>[0015]	步骤3021、构建时域下的二维Gabor滤波器组:</p>
    <p>            [0016]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00062.png"> <img id="idf0002" file="CN103927527AD00062.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00062.png" class="patent-full-image" alt="Figure CN103927527AD00062"> </a> </div>
    <p>[0017]其中，Φ	e (χ, y, f, θ，σ )为偶对称的二维 Gabor 滤波器，Φ。(x, y, f, θ , σ )为奇对称的二维Gabor滤波器，f为中心频率，χ为时域下的横坐标变量，y为时域下的纵坐标变量，Θ为空间相位角，σ为空间常数，g(x, y, σ)为高斯函数且</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00063.png"> <img id="idf0003" file="CN103927527AD00063.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00063.png" class="patent-full-image" alt="Figure CN103927527AD00063"> </a> </div>
    <p>[0018]	步骤3022、将时域下的二维Gabor滤波器组变换为频域下的二维Gabor滤波器组:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00064.png"> <img id="idf0004" file="CN103927527AD00064.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00064.png" class="patent-full-image" alt="Figure CN103927527AD00064"> </a> </div>
    <p>[0020]其中，Φ	&#19972;(u，v，f，θ，σ ) = exp {-2 Ji 2 σ 2 [ (u&#8212;fcos θ )2+(v-f sin θ )2]}，Φ2 (u, ν, f, θ，σ) = exp{_2 π 2 σ 2[(u+fcos θ )2+(v+fsin θ )2]}，Φβ (u, ν, f, θ , σ )为Φ6(χ，y，f，θ，σ )的 Fourier 变换，Φ0(&#971;，ν，f，θ，σ )为 φο(χ，y，f，θ，σ )的 Fourier 变</p>
    <p>换，j为虚数单位且J = ^Tu XX，V为频域下的空间频率变量；</p>
    <p>[0021]	步骤3023、首先，将所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值表示为Xil (X，y) (i = I, 2,..., q);然后,采用频域下的二维Gabor滤波器组对Xil (x, y) (i =1，2，...，q)进行滤波，得到滤波结果:</p>
    <p>[0022]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00065.png"> <img id="idf0005" file="CN103927527AD00065.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00065.png" class="patent-full-image" alt="Figure CN103927527AD00065"> </a> </div>
    <p>[0024]	其中，Φ&#943; (χ,y,/,θ)为采用偶对称的二维Gabor滤波器对Xil (x, y) (i =</p>
    <p>1，2，...，q)进行滤波的滤波结果，武O)力采用奇对称的二维Gabor滤波器对</p>
    <p>Xil (χ, y) (i = I, 2,..., q)进行滤波的滤波结果，Fi (u, ν)为 Xil (x, y) (i = I, 2,..., q)的Fourier 变换；[0025]	步骤3024、选择Ii1个不同的中心频率f,并对每个中心频率f，选择n2个不同的空间相位角Θ，形成Ii1Xn2个Gabor滤波通道,对每个Gabor滤波通道的滤波结果,提取其幅值作为代表该Gabor滤波通道的特征；其中，采用偶对称的二维Gabor滤波器对Xil (x, y)</p>
    <p>(i = 1，2，...，q)进行滤波的滤波结果武(X,J，/，60的幅值为4(/，&#27794;)，采用奇对称的二维Gabor滤波器对Xil (x, y) (i = 1，2，...，q)进行滤波的滤波结果武(X,y，/，6&gt;)的幅值为Λ'Λ.&#943;\θ):</p>
    <p>[0026]	步骤3025、对每个Gabor滤波通道的滤波结果武(X,_y，/，60的幅值4(/，&#27794;)按行展开，形成一个行向量砂^(/，60;并对每个Gabor滤波通道的滤波结果武(U,/,60的幅值4(/，6&gt;)按行展开，形成一个行向量％:'(/，60 ；</p>
    <p>[0027]	步骤3026、将Ii1 Xn2 fGabor滤波通道的Ii1 Xn2X 2个行向量依次连接，形成Xil (χ, y) (i = I, 2,..., q)的二维 Gabor 滤波器组的特征 Wi (i = I, 2,...q)；</p>
    <p>[0028]	步骤303、求取所述人脸子图像矩阵Xil (i = 1，2，...，q)中的每个像素值Xil (x，y)(i = 1，2，...，q)的纹理贡献度，具体过程如下:</p>
    <p>[0029]	步骤3031、定义人脸图像G的熵函数为:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00071.png"> <img id="idf0006" file="CN103927527AD00071.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00071.png" class="patent-full-image" alt="Figure CN103927527AD00071"> </a> </div>
    <p>[0031]	其中，X(x’，y’)为图像矩阵X的像素值，x’为图像X(x’，y’)的横向坐标，y’为图像X(X’，y’)的纵向坐标，m为人脸图像G的灰度级别总数，Pa为第a个灰度级别出现的概率，a为自然数且a的取值为I~m ;</p>
    <p>[0032]	步骤3032、定义局部信息熵图谱LHO对应的图像熵为:</p>
    <p>[0033]	LH(i’，j’)= H(F(i’，j’)w)</p>
    <p>[0034]	其中，w为滑动可变窗口的大小，H(F(i’，j’)w)为图像F(i’，j’)w的熵函数，α’，j’)为图像F(i’，j’)w中每个像素的位置，i’为图像F(i’，j’)w的横向坐标，j’为图像F(i’，j’)w的纵向坐标，F(i’，j’)w为以(i，，j，)为中心滑动可变窗口内的子图像且:</p>
    <p>[0035]	F(i，，j，)w= {X(x，，y，)|xe [i' -w/2, i' +w/2-1], y' e [j' -w/2, j' +w/2-1]}；</p>
    <p>[0036]	步骤3033、定义所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值Xn (X，，y，)(i = 1，2，...，q)的纹理贡献度为:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00072.png"> <img id="idf0007" file="CN103927527AD00072.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00072.png" class="patent-full-image" alt="Figure CN103927527AD00072"> </a> </div>
    <p>[0038]	其中，X(x’+(1-l)Xq，y’)为将图像矩阵X横向分为q块后第i块子图像中(X’，I，)处的像素值，S为将图像矩阵X横向分为q块后每一块子图像的纵向像素个数且s=128/q ；</p>
    <p>[0039]	步骤304、根据公式W= [WdCM(IhWdCMO),…WJCM(q)]求取人脸图像G的特征向量W ；</p>
    <p>[0040]	步骤四、处理结果同步输出:步骤三中进行图像特征提取过程中，处理器通过与其相接的显示器对步骤三中的图像信号处理过程及图像特征提取结果进行同步显示。[0041]	上述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3021中所述σ的取值为I。</p>
    <p>[0042]	上述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3024中所述Ii1的取值为6，6个不同的中心频率f的取值分别为2Hz、4Hz、8Hz、16Hz、32Hz和64Hz。</p>
    <p>[0043]	上述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3024中所述n2的取值为4，4个不同的空间相位角Θ的取值分别为0° ,45° ,90°和135°。</p>
    <p>[0044]	上述的一种基于单训练样本的人脸特征提取方法，其特征在于:步骤3031中所述m的取值为256。</p>
    <p>[0045]	上述的一种基于单训练样本的人脸特征提取方法，其特征在于:所述处理器为计算机。</p>
    <p>[0046]	本发明与现有技术相比具有以下优点:</p>
    <p>[0047]	1、本发明的方法步骤简单，设计合理，实现方便且投入成本低，操作简便。</p>
    <p>[0048]	2、本发明能够适用于实际使用中单训练样本的人脸识别场合。</p>
    <p>[0049]	3、本发明不仅通过二维Gabor滤波器组提取出了多方向、多分辨率的详细纹理特征，并且充分考虑到了每个子图像块中的每个像素值对整体图像的纹理贡献度，能够很好地描述人脸特征，在性能方面明显优于局部主成份分析(local PCA)、局部二进制模式(LBP)、局部三进制模式(LTP)和二维Gabor滤波变换(2DGabor)等多种基于单训练样本的常见图像特征提取算法。</p>
    <p>[0050]	4、本发明的人脸特征提取速度快，稳定性强，实用性强，能够应用于人脸识别，实现人脸识别在视频监控、人机交互、身份认证等方面的应用，能够很好地满足实际应用的需求。</p>
    <p>[0051]	综上所述，本发明设计合理、实现方便且投入成本低，操作简便，人脸特征提取速度快、效果好，实用性强，解决了现有技术中的图像特征提取方法在单训练样本条件下，很多传统方法失效、人脸识别率急剧下降等缺陷，性能方面明显优于现有的多种单训练样本的图像特征提取方法。</p>
    <p>[0052]	下面通过附图和实施例，对本发明的技术方案做进一步的详细描述。</p>
    <p>附图说明</p>
    <p>[0053]	图1为本发明采用的人脸特征提取设备的电路原理框图。</p>
    <p>[0054]	图2为本发明人脸特征提取方法的方法流程框图。</p>
    <p>[0055]	图3为本发明与多种图像特征提取方法所得人脸识别结果的YALE人脸库比较图。</p>
    <p>[0056]	图4为本发明与多种图像特征提取方法所得人脸识别结果的ORL人脸库比较图。</p>
    <p>[0057]	附图标记说明:</p>
    <p>[0058]	I一图像采集设备；2&#8212;图像信号传输装置；3&#8212;处理器；</p>
    <p>[0059]	4 一显示器。</p>
    <p>具体实施方式</p>
    <p>[0060]	如图1和图2所示，本发明的基于单训练样本的人脸特征提取方法，包括以下步骤:[0061]	步骤一、人脸图像信号的采集及上传:图像采集设备I采集人脸图像信号并将其实时所采集的人脸图像信号通过图像信号传输装置2上传给处理器3 ；</p>
    <p>[0062]	步骤二、人脸图像的分辨率调整及矩阵表示:首先，处理器3调用分辨率差值调整模块将其所接收到的人脸图像信号的分辨率调整为128X128，得到人脸图像G ;然后，处理器3将所述人脸图像G表示为图像矩阵X ；</p>
    <p>[0063]	步骤三、图像特征提取:处理器3对步骤二中所得到的图像矩阵X进行分析处理，得到人脸图像G的特征向量W，其分析处理过程如下:</p>
    <p>[0064]	步骤301、对图像矩阵X进行横向分块:将图像矩阵X横向分为，块，得到:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00091.png"> <img id="idf0008" file="CN103927527AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00091.png" class="patent-full-image" alt="Figure CN103927527AD00091"> </a> </div>
    <p>[0066]	其中，q为自然数且q的取值为4、6、8、16、32或64，Xn(i = 1，2，...，q)为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00092.png"> <img id="idf0009" file="CN103927527AD00092.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00092.png" class="patent-full-image" alt="Figure CN103927527AD00092"> </a> </div>
    <p>维的人脸子图像矩阵；</p>
    <p>[0067]	步骤302、采用二维Gabor滤波器组对图像矩阵X进行滤波，具体过程如下:</p>
    <p>[0068]	步骤3021、构建时域下的二维Gabor滤波器组:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00093.png"> <img id="idf0010" file="CN103927527AD00093.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00093.png" class="patent-full-image" alt="Figure CN103927527AD00093"> </a> </div>
    <p>[0070]其中，Φε(χ，y，f，θ，σ	)为偶对称的二维 Gabor 滤波器，Φ0(χ, y, f, θ，σ )为奇对称的二维Gabor滤波器，f为中心频率，χ为时域下的横坐标变量，y为时域下的纵坐标变量，Θ为空间相位角，σ为空间常数，g(x, y, σ)为高斯函数且</p>
    <p>(</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00094.png"> <img id="idf0011" file="CN103927527AD00094.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00094.png" class="patent-full-image" alt="Figure CN103927527AD00094"> </a> </div>
    <p>[0071]	本实施例中，步骤3021中所述σ的取值为I。</p>
    <p>[0072]	步骤3022、将时域下的二维Gabor滤波器组变换为频域下的二维Gabor滤波器组:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00095.png"> <img id="idf0012" file="CN103927527AD00095.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00095.png" class="patent-full-image" alt="Figure CN103927527AD00095"> </a> </div>
    <p>[0074]其中，Φ	&#19972;(U，V，f，θ，σ ) = exp {_2 π 2 σ 2 [ (u&#8212;fcos θ )2+(v-f sin θ )2]}，Φ2 (u, ν, f, θ,σ) = exp{_2 π 2 σ 2[(u+fcos θ )2+(v+fsin θ )2]}，Φβ (u, ν, f, θ,σ)为Φ6(χ，y，f，θ，σ )的 Fourier 变换，Φ0(&#971;，ν，f，θ，σ )为 φο(χ，y，f，θ，σ )的 Fourier 变</p>
    <p>换，j为虚数单位且U, V为频域下的空间频率变量；</p>
    <p>[0075]	步骤3023、首先，将所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值表示为Xil (X，y) (i = I, 2,..., q);然后,采用频域下的二维Gabor滤波器组对Xil (x, y) (i =1，2，...，q)进行滤波，得到滤波结果:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00101.png"> <img id="idf0013" file="CN103927527AD00101.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00101.png" class="patent-full-image" alt="Figure CN103927527AD00101"> </a> </div>
    <p>[0078]	其中，戎(X,少,./‘，60为采用偶对称的二维Gabor滤波器对Xil (x, y) (i =</p>
    <p>1，2，...，q)进行滤波的滤波结果，戎(Χ,r/,60为采用奇对称的二维Gabor滤波器对</p>
    <p>Xil (χ, y) (i = I, 2,..., q)进行滤波的滤波结果，Fi (u, ν)为 Xil (x, y) (i = I, 2,..., q)的Fourier 变换；</p>
    <p>[0079]	步骤3024、选择Ii1个不同的中心频率f,并对每个中心频率f，选择n2个不同的空间相位角Θ，形成Ii1Xn2个Gabor滤波通道,对每个Gabor滤波通道的滤波结果,提取其幅值作为代表该Gabor滤波通道的特征；其中，采用偶对称的二维Gabor滤波器对Xil (x, y)</p>
    <p>(i = 1，2，...，(!)进行滤波的滤波结果戎O,J,/，6&gt;)的幅值为4； (/,6&gt;),采用奇对称的二维Gabor滤波器对Xil (x, y) (i = I, 2,..., q)进行滤波的滤波结果φ'ο(χ,r,/,θ)的幅值为Λ:Χ；&#943;\θ):</p>
    <p>[0080]	本实施例中，步骤3024中所述Ii1的取值为6，6个不同的中心频率f的取值分别为2Hz、4Hz、8Hz、16Hz、32Hz和64Hz ;步骤3024中所述n2的取值为4，4个不同的空间相位角Θ的取值分别为0° ,45° ,90°和135° ;因此本实施例能够形成24个Gabor滤波通道；</p>
    <p>[0081 ] 步骤加25、对每个Gabor滤波通道的滤波结果武(X,J，/，妁的幅值4(/，&#27794;)按行展开，形成一个行向量^(/，的；并对每个Gabor滤波通道的滤波结果.φ；Χχ,ν,/,θ)的幅值4 (/，6&#187;)按行展开，形成一个行向量JV:(/, Θ)；</p>
    <p>[0082]	步骤3026、将Ii1 Xn2 fGabor滤波通道的Ii1 Xn2X 2个行向量依次连接，形成Xil (χ, y) (i = I, 2,..., q)的二维 Gabor 滤波器组的特征 Wi (i = I, 2,...q)；</p>
    <p>[0083]	本实施例中，行向量的数量为48个；</p>
    <p>[0084]	步骤303、求取所述人脸子图像矩阵Xil (i = 1，2，…，q)中的每个像素值Xil (x，y)(i = 1，2，...，q)的纹理贡献度，具体过程如下:</p>
    <p>[0085]	步骤3031、定义人脸图像G的熵函数为:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00102.png"> <img id="idf0014" file="CN103927527AD00102.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00102.png" class="patent-full-image" alt="Figure CN103927527AD00102"> </a> </div>
    <p>[0087]	其中，X(x’，y’)为图像矩阵X的像素值，x’为图像X(x’，y’)的横向坐标，y’为图像X(X’，y’)的纵向坐标，m为人脸图像G的灰度级别总数，Pa为第a个灰度级别出现的概率，a为自然数且a的取值为I~m ;</p>
    <p>[0088]	本实施例中，步骤3031中所述m的取值为256。</p>
    <p>[0089]	步骤3032、定义局部信息熵图谱LHO对应的图像熵为:</p>
    <p>[0090]	LH(i’，j’)= H(F(i’，j’)w)</p>
    <p>[0091]	其中，w为滑动可变窗口的大小，H(F(i’，j’)w)为图像F(i’，j’)w的熵函数，α’，j’)为图像F(i’，j’)w中每个像素的位置，i’为图像F(i’，j’)w的横向坐标，j’为图像F(i’，j’)w的纵向坐标，F(i’，j’)w为以(i，，j，)为中心滑动可变窗口内的子图像且:</p>
    <p>[0092]	F(i，，j，)w= {X(x，，y，)|xe [i' -w/2, i' +w/2-1], y' e [j' -w/2, j' +w/2-1]}；</p>
    <p>[0093]	步骤3033、定义所述人脸子图像矩阵Xil (i = I, 2,..., q)中的每个像素值Xn (X，，y，)(i = 1，2，...，q)的纹理贡献度为:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00111.png"> <img id="idf0015" file="CN103927527AD00111.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103927527A/CN103927527AD00111.png" class="patent-full-image" alt="Figure CN103927527AD00111"> </a> </div>
    <p>[0095]	其中，X(x’+(1-l)Xq，y’)为将图像矩阵X横向分为q块后第i块子图像中(X’，I，)处的像素值，s为将图像矩阵X横向分为q块后每一块子图像的纵向像素个数且s=128/q ；</p>
    <p>[0096]	步骤304、根据公式W= [WdCM(IhWdCMO),…WJCM(q)]求取人脸图像G的特征向量W ；</p>
    <p>[0097]	步骤四、处理结果同步输出:步骤三中进行图像特征提取过程中，处理器3通过与其相接的显示器4对步骤三中的图像信号处理过程及图像特征提取结果进行同步显示。</p>
    <p>[0098]	本实施例中，所述处理器3为计算机。</p>
    <p>[0099]	对于一张人脸图像，整体图像的图像熵可以表达整张人脸的信息量，但是这对人脸特征的描述是没有意义的，而如果将一张人脸图像进行分块，每一块子图像的信息熵可以表示该子图像的信息量，同时也表示该子图像的细节纹理的丰富程度，纹理的丰富程度对人脸整体特征的描述有着重要的作用，所以可以根据子图像的局部图像信息熵来构建每个子图像纹理对整副人脸信息的贡献程度，能够很好地描述人脸特征。</p>
    <p>[0100]	为了验证本发明人脸特征提取方法的有效性和普适性，将本发明的人脸特征提取方法与局部主成份分析(local PCA)、局部二进制模式(LBP)、局部三进制模式(LTP)和二维Gabor滤波变换(2DGabor)的基于单训练样本的常见图像特征提取算法进行了比较，具体如下:</p>
    <p>[0101]	(I)在MATLAB的仿真环境下，以Yale人脸库为实验对象进行测试，Yale人脸库包括了 15个人每人11幅共165幅人脸图像，具备了睁眼闭眼、张口闭口、以及非常丰富的面部表情的变化，选取每人I幅人脸图像为训练样本，其余为测试样本，分别采用各种所要比较的人脸特征提取算法进行人脸特征提取，并对每种算法提取到的人脸特征采用现有技术中的RBF神经网络分类识别法进行分类识别，其分类识别比较结果如图3所示。</p>
    <p>[0102]	(2)在MATLAB的仿真环境下，以ORL人脸库为实验对象进行测试，ORL人脸库包括了 40个不同的光照、表情、发型和有无眼镜等人脸图像，每人10幅共400幅人脸，选取每人I幅人脸图像为训练样本，其余为测试样本，分别采用各种所要比较的人脸特征提取算法进行人脸特征提取，并对每种算法提取到的人脸特征采用现有技术中的RBF神经网络分类识别法进行分类识别，其分类识别比较结果如图4所示。</p>
    <p>[0103]	从图3和图4可以看出，本发明的人脸特征提取方法对人脸识别的识别率明显高于其它常见的基于单训练样本的常见图像特征提取算法，能够适用于实际应用中众多缺乏训练样本的场景。</p>
    <p>[0104]	以上所述，仅是本发明的较佳实施例，并非对本发明作任何限制，凡是根据本发明技术实质对以上实施例所作的任何简单修改、变更以及等效结构变化，均仍属于本发明技术方案的保护范围内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104464289A?cl=zh">CN104464289A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年12月4日</td><td class="patent-data-table-td patent-date-value">2015年3月25日</td><td class="patent-data-table-td ">赵常维</td><td class="patent-data-table-td ">一种车辆违章时驾驶信息的识别方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=rn4QCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2014年7月16日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年8月13日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/6bf587ab54b983973e05/CN103927527A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%95%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9.pdf?id=rn4QCQABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2PQbIcSFHaXXZtGvsXxnJHflYFkQ"},"sample_url":"https://www.google.com/patents/reader?id=rn4QCQABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>