<!DOCTYPE html><html><head><title>专利 CN103399737A - 基于语音数据的多媒体处理方法及装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于语音数据的多媒体处理方法及装置"><meta name="DC.contributor" content="曹立新" scheme="inventor"><meta name="DC.contributor" content="百度在线网络技术（北京）有限公司" scheme="assignee"><meta name="DC.date" content="2013-7-18" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供一种基于语音数据的多媒体处理方法及装置。本发明实施例通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。"><meta name="DC.date" content="2013-11-20"><meta name="DC.relation" content="CN:100521708" scheme="references"><meta name="DC.relation" content="CN:101452725:A" scheme="references"><meta name="DC.relation" content="CN:102625164:A" scheme="references"><meta name="DC.relation" content="CN:102782751:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:103399737:A"><meta name="citation_patent_application_number" content="CN:201310303801"><link rel="canonical" href="https://www.google.com/patents/CN103399737A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103399737A?cl=zh"/><meta name="title" content="专利 CN103399737A - 基于语音数据的多媒体处理方法及装置"/><meta name="description" content="本发明提供一种基于语音数据的多媒体处理方法及装置。本发明实施例通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。"/><meta property="og:title" content="专利 CN103399737A - 基于语音数据的多媒体处理方法及装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103399737A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103399737A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=uOniCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103399737A&amp;usg=AFQjCNEDCNDuLmyOgNhdrnvX-zgAsldplA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/3d427848637b2a4768f0/CN103399737A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/3d427848637b2a4768f0/CN103399737A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103399737A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103399737A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103399737A?cl=zh" style="display:none"><span itemprop="description">本发明提供一种基于语音数据的多媒体处理方法及装置。本发明实施例通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，...</span><span itemprop="url">https://www.google.com/patents/CN103399737A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103399737A - 基于语音数据的多媒体处理方法及装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103399737A - 基于语音数据的多媒体处理方法及装置" title="专利 CN103399737A - 基于语音数据的多媒体处理方法及装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103399737 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201310303801</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年11月20日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2013年7月18日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2013年7月18日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201310303801.0, </span><span class="patent-bibdata-value">CN 103399737 A, </span><span class="patent-bibdata-value">CN 103399737A, </span><span class="patent-bibdata-value">CN 201310303801, </span><span class="patent-bibdata-value">CN-A-103399737, </span><span class="patent-bibdata-value">CN103399737 A, </span><span class="patent-bibdata-value">CN103399737A, </span><span class="patent-bibdata-value">CN201310303801, </span><span class="patent-bibdata-value">CN201310303801.0</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9B%B9%E7%AB%8B%E6%96%B0%22">曹立新</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E7%99%BE%E5%BA%A6%E5%9C%A8%E7%BA%BF%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%EF%BC%88%E5%8C%97%E4%BA%AC%EF%BC%89%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">百度在线网络技术（北京）有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103399737A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103399737A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103399737A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=uOniCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201310303801&amp;usg=AFQjCNH9Aw_k59lB6-KDvbdMogViqQYa_A"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=uOniCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103399737A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFfngIohD6AuUMLCQLig8k7UQJeyA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT131190822" lang="ZH" load-source="patent-office">基于语音数据的多媒体处理方法及装置</invention-title>
      </span><br><span class="patent-number">CN 103399737 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA125561452" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供一种基于语音数据的多媒体处理方法及装置。本发明实施例通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(16)</span></span></div><div class="patent-text"><div mxw-id="PCLM56855032" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于语音数据的多媒体处理方法，其特征在于，包括:  接收客户端发送的第一语音数据；  确定多媒体文件的待添加标签的标签位置；  在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，所述确定多媒体文件的待添加标签的标签位置，包括:  接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置；以及根据所述进度信息，确定所述待读取位置，以作为所述标签位置；或者  根据配置信息所指示的可标签位置，确定所述标签位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1或2所述的方法，其特征在于，所述多媒体文件包括文本文件、图像文件、音频文件或视频文件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1&#12316;3任一权利要求所述的方法，其特征在于，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:  在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要 求4所述的方法，其特征在于，所述将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签之后，还包括:  接收所述客户端发送的第二语音数据；  利用所述第二语音数据与所述标签，进行匹配；  若匹配成功，根据所述标签，获得与所述标签关联的所述标签位置；  向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1&#12316;3任一权利要求所述的方法，其特征在于，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:  在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的方法，其特征在于，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签之后，还包括:  接收所述客户端发送的第二语音数据；  利用所述第二语音数据与所述标签，进行匹配；  若匹配成功，根据所述标签，获得与所述标签关联的所述多媒体文件的标识；  向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求1&#12316;7任一权利要求所述的方法，其特征在于，  所述接收客户端发送的第一语音数据之后，还包括:对所述第一语音数据进行语音识别，以获得语音识别结果；  所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:  在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9.一种基于语音数据的多媒体处理装置，其特征在于，包括:  接收单元，用于接收客户端发送的第一语音数据；  确定单元，用于确定多媒体文件的待添加标签的标签位置；  关联单元，用于在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的装置，其特征在于，  所述接收单元，还用于  接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置；&#183;  所述确定单元，具体用于  根据所述进度信息，确定所述待读取位置，以作为所述标签位置；  或者  所述确定单元，具体用于  根据配置信息所指示的可标签位置，确定所述标签位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求9或10所述的装置，其特征在于，所述多媒体文件包括文本文件、图像文件、音频文件或视频文件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求9&#12316;11任一权利要求所述的装置，其特征在于，所述关联单元，具体用于  在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的装置，其特征在于，  所述接收单元，还用于  接收所述客户端发送的第二语音数据；  所述装置还包括:  第一匹配单元，用于利用所述第二语音数据与所述标签，进行匹配；  第一获得单元，用于若所述第一匹配单元匹配成功，根据所述标签，获得与所述标签关联的所述标签位置；  第一发送单元，用于向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求9&#12316;11任一权利要求所述的装置，其特征在于，所述关联单元，具体用于  在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求14所述的装置，其特征在于，所述接收单元，还用于  接收所述客户端发送的第二语音数据；  所述装置还包括:  第二匹配单元，用于利用所述第二语音数据与所述标签，进行匹配；  第二获得单元，用于若所述第二匹配单元匹配成功，根据所述标签，获得与所述标签关联的所述多媒体文件的标识；  第二发送单元，用于向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求9&#12316;15任一权利要求所述的装置，其特征在于，  所述装置还包括识别单元，用于对所述第一语音数据进行语音识别，以获得语音识别结果;  所述关联单元，具体用于  在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文&#183;件的标签。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES63834280" lang="ZH" load-source="patent-office" class="description">
    <p>基于语音数据的多媒体处理方法及装置</p>
    <p>【技术领域】</p>
    <p>[0001]	本发明涉及多媒体处理技术，尤其涉及一种基于语音数据的多媒体处理方法及装置。</p>
    <p>【背景技术】</p>
    <p>[0002]	在基于多媒体文件，例如，文本、视频等，的应用中，有时候用户需要从多媒体文件中提炼出能够描述多媒体文件的内容的描述信息，通过客户端操作将其作为多媒体文件的标签(tag)，还可以称其为标注。现有技术中，客户端可以将用户从多媒体文件中提炼的文本形式的描述信息，作为该多媒体文件的标签。</p>
    <p>[0003]	然而，在一些情况下，例如，用户无法直接从多媒体文件中直接提炼出文本形式的描述信息，或者，再例如，用户不方便从多媒体文件中提炼出文本形式的描述信息，等，会使得对多媒体文件添加标签的操作时间较长，从而导致了多媒体文件的标签的处理效率的降低。</p>
    <p>【发明内容】 </p>
    <p>[0004]	本发明的多个方面提供一种基于语音数据的多媒体处理方法及装置，用以提高多媒体文件的标签的处理效率。</p>
    <p>[0005]	本发明的一方面，提供一种基于语音数据的多媒体处理方法，包括:</p>
    <p>[0006]	接收客户端发送的第一语音数据；</p>
    <p>[0007]	确定多媒体文件的待添加标签的标签位置；</p>
    <p>[0008]	在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0009]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述确定多媒体文件的待添加标签的标签位置，包括:</p>
    <p>[0010]	接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置；以及根据所述进度信息，确定所述待读取位置，以作为所述标签位置；或者</p>
    <p>[0011]	根据配置信息所指示的可标签位置，确定所述标签位置。</p>
    <p>[0012]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述多媒体文件包括文本文件、图像文件、音频文件或视频文件。</p>
    <p>[0013]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:</p>
    <p>[0014]	在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0015]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签之后，还包括:</p>
    <p>[0016]	接收所述客户端发送的第二语音数据；</p>
    <p>[0017]	利用所述第二语音数据与所述标签，进行匹配；</p>
    <p>[0018]	若匹配成功，根据所述标签，获得与所述标签关联的所述标签位置；</p>
    <p>[0019]	向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。</p>
    <p>[0020]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:</p>
    <p>[0021]	在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0022]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签之后，还包括:</p>
    <p>[0023]	接收所述客户端发送的第二语音数据；</p>
    <p>[0024]	利用所述第二语音数据与所述标签，进行匹配；</p>
    <p>[0025]	若匹配成功，根据所述标签，获得与所述标签关联的所述多媒体文件的标识；</p>
    <p>[0026]	向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。</p>
    <p>[0027]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，</p>
    <p>[0028]	所述接收客户端发送的第一语音数据之后，还包括:</p>
    <p>[0029]	对所述第一语音数据进行语音识别，以获得语音识别结果；</p>
    <p>[0030]	所述在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，包括:</p>
    <p>[0031]	在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0032]	本发明的另一方面，提供一种基于语音数据的多媒体处理装置，包括:</p>
    <p>[0033]	接收单元，用于接收客户端发送的第一语音数据；</p>
    <p>[0034]	确定单元，用于确定多媒体文件的待添加标签的标签位置；</p>
    <p>[0035]	关联单元，用于在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0036]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，</p>
    <p>[0037]	所述接收单元，还用于</p>
    <p>[0038]	接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置；</p>
    <p>[0039]	所述确定单元，具体用于</p>
    <p>[0040]	根据所述进度信息，确定所述待读取位置，以作为所述标签位置；</p>
    <p>[0041]	或者</p>
    <p>[0042]	所述确定单元，具体用于[0043]	根据配置信息所指示的可标签位置，确定所述标签位置。</p>
    <p>[0044]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述多媒体文件包括文本文件、图像文件、音频文件或视频文件。</p>
    <p>[0045]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述关联单元，具体用于</p>
    <p>[0046]	在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0047]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，</p>
    <p>[0048]	所述接收单元，还用于</p>
    <p>[0049]	接收所述客户端发送的第二语音数据；</p>
    <p>[0050]	所述装置还包括:</p>
    <p>[0051]	第一匹配单元，用于利用所述第二语音数据与所述标签，进行匹配；</p>
    <p>[0052]	第一获得单元，用于若所述第一匹配单元匹配成功，根据所述标签，获得与所述标签关联的所述标签位置；</p>
    <p>[0053]	第一发送单元，用于向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。</p>
    <p>[0054]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，所述关联单元，具体用于</p>
    <p>[0055]	在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0056]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，</p>
    <p>[0057]	所述接收单元，还用于</p>
    <p>[0058]	接收所述客户端发送的第二语音数据；</p>
    <p>[0059]	所述装置还包括:</p>
    <p>[0060]	第二匹配单元，用于利用所述第二语音数据与所述标签，进行匹配；</p>
    <p>[0061]	第二获得单元，用于若所述第二匹配单元匹配成功，根据所述标签，获得与所述标签关联的所述多媒体文件的标识；</p>
    <p>[0062]	第二发送单元，用于向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。</p>
    <p>[0063]	如上所述的方面和任一可能的实现方式，进一步提供一种实现方式，</p>
    <p>[0064]	所述装置还包括识别单元，用于对所述第一语音数据进行语音识别，以获得语音识别结果；</p>
    <p>[0065]	所述关联单元，具体用于</p>
    <p>[0066]	在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0067]	由上述技术方案可知，本发明实施例通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</p>
    <p>【附图说明】</p>
    <p>[0068]	为了更清楚地说明本发明实施例中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作一简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动性的前提下，还可以根据这些附图获得其他的附图。</p>
    <p>[0069]	图1为本发明一实施例提供的基于语音数据的多媒体处理方法的流程示意图；</p>
    <p>[0070]	图2为本发明另一实施例提供的基于语音数据的多媒体处理装置的结构示意图；</p>
    <p>[0071]	图3为本发明另一实施例提供的基于语音数据的多媒体处理装置的结构示意图；</p>
    <p>[0072]	图4为本发明另一实施例提供的基于语音数据的多媒体处理装置的结构示意图；</p>
    <p>[0073]	图5为本发明另一实施例提供的基于语音数据的多媒体处理装置的结构示意图。</p>
    <p>【具体实施方式】</p>
    <p>[0074]	为使本发明实施例的目&#183;的、技术方案和优点更加清楚，下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的全部其他实施例，都属于本发明保护的范围。</p>
    <p>[0075]	需要说明的是，本发明实施例中所涉及的终端可以包括但不限于手机、个人数字助理(Personal Digital Assistant, PDA)、无线手持装置、无线上网本、个人电脑、便携电脑、MP3播放器、MP4播放器等。</p>
    <p>[0076]	另外，本文中术语“和/或”，仅仅是一种描述关联对象的关联关系，表示可以存在三种关系，例如，A和/或B，可以表示:单独存在A，同时存在A和B，单独存在B这三种情况。另外，本文中字符“/”，一般表示前后关联对象是一种“或”的关系。</p>
    <p>[0077]	图1为本发明一实施例提供的基于语音数据的多媒体处理方法的流程示意图，如图1所示。</p>
    <p>[0078]	101、接收客户端发送的第一语音数据。</p>
    <p>[0079]	102、确定多媒体文件的待添加标签的标签位置。</p>
    <p>[0080]	其中，所述多媒体文件可以包括但不限于文本文件、图像文件、音频文件或视频文件，本实施例对此不进行特别限定。</p>
    <p>[0081]	103、在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0082]	需要说明的是，101的执行与102的执行可以没有固定的时间先后顺序，本实施例对此不进行特别限定。</p>
    <p>[0083]	需要说明的是，101&#12316;103的执行主体可以是多媒体处理引擎，可以位于本地的客户端中，以进行离线处&#183;理，或者还可以位于网络侧的服务器中，以进行在线处理，本实施例对此不进行限定。</p>
    <p>[0084]	可以理解的是，所述客户端可以是安装在终端上的应用程序，或者还可以是浏览器的一个网页，只要能够实现语音输入功能和多媒体处理功能，以提供语音服务和多媒体服务的客观存在形式都可以，本实施例对此不进行限定。</p>
    <p>[0085]	这样，通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</p>
    <p>[0086]另外，采用本发明提供的技术方案，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务、点播服务等。</p>
    <p>[0087]另外，采用本发明提供的技术方案，能够在整个多媒体文件的内容中的任何位置，例如，内容的开始位置、中间位置或结束位置等，或者还能够在多媒体文件的属性中的任何地方，例如，文件名词的后面等，对该多媒体文件进行标签的添加，会使得标签位置较为灵活，从而提高了多媒体文件的标签的处理灵活性。</p>
    <p>[0088]	可选地，在本实施例的一个可能的实现方式中，在102中，多媒体处理引擎具体可以接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置。然后，所述多媒体处理引擎则可以根据所述进度信息，确定所述待读取位置，以作为所述标签位置。例如，内容的开始位置、中间位置或结束位置等。</p>
    <p>[0089]	可选地，在本实施例的一个可能的实现方式中，在102中，多媒体处理引擎具体还可以根据配置信息所指示的可标签位置，确定所述标签位置。例如，文件名词的后面等。</p>
    <p>[0090]	可选地，在本实施例的一个可能的实现方式中，多媒体处理引擎具体可以在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0091]	具体地，在多媒体处理引擎执行关联操作之后，所述多媒体处理引擎还可以进一步接收所述客户端发送的第二语音数据。进而，所述多媒体处理引擎则可以利用所述第二语音数据与所述标签，进行匹配。具体的匹配方法，可以参见现有技术中，实现语音数据匹配的相关内容，此处不再赘述。若匹配成功，所述多媒体处理引擎则可以根据所述标签，获得与所述标签关联的所述标签位置，并向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。这样，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，点播服务等。</p>
    <p>[0092]	可选地，在本实施例的一个可能的实现方式中，在103中，多媒体处理引擎具体可以在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0093]	具体地，在多媒体处理引擎执行关联操作之后，所述多媒体处理引擎还可以进一步接收所述客户端发送的第二语音数据。进而，所述多媒体处理引擎则可以利用所述第二语音数据与所述标签，进行匹配。具体的匹配方法，可以参见现有技术中，实现语音数据匹配的相关内容，此处不再赘述。若匹配成功，所述多媒体处理引擎则可以根据所述标签，获得与所述标签关联的所述多媒体文件的标识，并向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。这样，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务等。</p>
    <p>[0094]	为了实现语音标签的内容可视化，在本实施例的一个可能的实现方式中，多媒体处理引擎还可以进一步对所接收到的第一语音数据进行语音识别，以获得语音识别结果。相应地，在103中，所述多媒体处理引擎具体可以在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。具体的关联方法的详细描述可以参见前述的相关内容，此处不再赘述。</p>
    <p>[0095]	本实施例中，通过接收客户端发送的第一语音数据，以及确定多媒体文件的待添加标签的标签位置，使得能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</p>
    <p>[0096]另外，采用本发明提供的技术方案，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务、点播服务等。</p>
    <p>[0097]另外，采用本发明提供的技术方案，能够在整个多媒体文件的内容中的任何位置，例如，内容的开始位置、中间位置或结束位置等，或者还能够在多媒体文件的属性中的任何地方，例如，文件名词的后面等，对该多媒体文件进行标签的添加，会使得标签位置较为灵活，从而提高了多媒体文件的标签的处理灵活性。</p>
    <p>[0098]	需要说明的是，对于前述的各方法实施例，为了简单描述，故将其都表述为一系列的动作组合，但是本领域技术人员应该知悉，本发明并不受所描述的动作顺序的限制，因为依据本发明，某些步骤可以采用其他顺序或者同时进行。其次，本领域技术人员也应该知悉，说明书中所描述的实施例均属于优选实施例，所涉及的动作和模块并不一定是本发明所必须的。</p>
    <p>[0099]	在上述实施例中，对各个实施例的描述都各有侧重，某个实施例中没有详述的部分，可以参见其他实施例的相关描述。</p>
    <p>[0100]	图2为本发明另一实施例提供的基于语音数据的多媒体处理装置的结构示意图，如图2所示。本实施例的基于语音数据的多媒体处理装置可以包括接收单元21、确定单元22和关联单元23。其中，接收单元21，用于接收客户端发送的第一语音数据；确定单元22，用于确定多媒体文件的待添加标签的标签位置；关联单元23，用于在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0101]	其中，所述多媒体文件可以包括但不限于文本文件、图像文件、音频文件或视频文件，本实施例对此不进行特别限定。</p>
    <p>[0102]	需要说明的是，本实施例提供的装置可以是多媒体处理引擎，可以位于本地的客户端中，以进行离线处理，或者还可以位于网络侧的服务器中，以进行在线处理，本实施例对此不进行限定。</p>
    <p>[0103]	可以理解的是，所述客户端可以是安装在终端上的应用程序，或者还可以是浏览器的一个网页，只要能够实现语音输入功能和多媒体处理功能，以提供语音服务和多媒体服务的客观存在形式都可以，本实施例对此不进行限定。</p>
    <p>[0104]	这样，通过接收单元接收客户端发送的第一语音数据，以及确定单元确定多媒体文件的待添加标签的标签位置，使得关联单元能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</p>
    <p>[0105]另外，采用本发明提供的技术方案，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务、点播服务等。</p>
    <p>[0106]另外，采用本发明提供的技术方案，能够在整个多媒体文件的内容中的任何位置，例如，内容的开始位置、中间位置或结束位置等，或者还能够在多媒体文件的属性中的任何地方，例如，文件名词的后面等，对该多媒体文件进行标签的添加，会使得标签位置较为灵活，从而提高了多媒体文件的标签的处理灵活性。</p>
    <p>[0107]	可选地，在本实施例的一个可能的实现方式中，所述接收单元21，还可以进一步用于接收所述客户端发送的所述多媒体文件的进度信息，所述进度信息用于指示所述多媒体文件的待读取位置。相应地，所述确定单元22，具体可以用于根据所述进度信息，确定所述待读取位置，以作为所述标签位置。例如，内容的开始位置、中间位置或结束位置等。</p>
    <p>[0108]	可选地，在本实施例的一个可能的实现方式中，所述确定单元22，具体可以用于根据配置信息所指示的可标签位置，确定所述标签位置。例如，文件名词的后面等。</p>
    <p>[0109]	可选地，在本实施例的一个可能的实现方式中，所述关联单元23，具体可以用于在所述标签位置上，将所述第一语音数据与所述标签位置，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0110]	进一步，所述接收单元21，还可以进一步用于接收所述客户端发送的第二语音数据。相应地，如图3所示，本实施例提供的基于语音数据的多媒体处理装置还可以进一步包括:</p>
    <p>[0111]	第一匹配单元31，用于利用所述第二语音数据与所述标签，进行匹配。具体的匹配方法，可以参见现有技术中，实现语音数据匹配的相关内容，此处不再赘述。</p>
    <p>[0112]	第一获得单元32，用于若所述第一匹配单元31匹配成功，根据所述标签，获得与所述标签关联的所述标签位置。</p>
    <p>[0113]	第一发送单元33，用于向所述客户端发送所述标签位置，以使得所述客户端根据所述标签位置，跳转到所述多媒体文件的待读取位置。</p>
    <p>[0114]	这样，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，点播服务等。</p>
    <p>[0115]	可选地，在本实施例的一个可能的实现方式中，所述关联单元23，具体可以用于在所述标签位置上，将所述第一语音数据与所述多媒体文件的标识，进行关联，以作为所述多媒体文件的标签。</p>
    <p>[0116]	进一步，所述接收单元21，还可以进一步用于接收所述客户端发送的第二语音数据。相应地，如图4所示，本实施例提供的基于语音数据的多媒体处理装置还可以进一步包括:</p>
    <p>[0117]	第二匹配单元41，用于利用所述第二语音数据与所述标签，进行匹配。具体的匹配方法，可以参见现有技术中，实现语音数据匹配的相关内容，此处不再赘述。</p>
    <p>[0118]	第二获得单元42，用于若所述第二匹配单元41匹配成功，根据所述标签，获得与所述标签关联的所述多媒体文件的标识。</p>
    <p>[0119]	第二发送单元43，用于向所述客户端发送所述多媒体文件的标识，以使得所述客户端根据所述多媒体文件的标识获取所述多媒体文件。</p>
    <p>[0120]	这样，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务等。</p>
    <p>[0121]	为了实现语音标签的内容可视化，在本实施例的一个可能的实现方式中，如图5所示，本实施例提供的基于语音数据的多媒体处理装置还可以进一步包括识别单元51，用于对所述第一语音数据进行语音识别，以获得语音识别结果。相应地，所述关联单元23，具体可以用于在所述标签位置上，将所述第一语音数据、所述语音识别结果与所述多媒体文件，进行关联，以作为所述多媒体文件的标签。具体的关联方法的详细描述可以参见前述的相关内容，此处不再赘述。</p>
    <p>[0122]	本实施例中，通过接收单元接收客户端发送的第一语音数据，以及确定单元确定多媒体文件的待添加标签的标签位置，使得关联单元能够在所述标签位置上，将所述第一语音数据与所述多媒体文件，进行关联，以作为所述多媒体文件的标签，由于语音数据的输入时间小于文本信息的输入时间，因此，采用语音数据作为多媒体文件的标签，能够使得对多媒体文件添加标签的操作时间缩短，从而提高了多媒体文件的标签的处理效率。</p>
    <p>[0123]另外，采用本发明提供的技术方案，由于采用语音数据作为多媒体文件的标签即语音标签，使得基于语音标签的语音搜索成为可能，即利用语音识别技术，对所述语音标签进行搜索，以提供更多的与标签相关的服务，例如，推荐服务、点播服务等。</p>
    <p>[0124]另外，采用本发明提供的技术方案，能够在整个多媒体文件的内容中的任何位置，例如，内容的开始位置、中间位置或结束位置等，或者还能够在多媒体文件的属性中的任何地方，例如，文件名词的后面等，对该多媒体文件进行标签的添加，会使得标签位置较为灵活，从而提高了多媒体文件的标签的处理灵活性。</p>
    <p>[0125]	所属领域的技术人员可以清楚地了解到，为描述的方便和简洁，上述描述的系统，装置和单元的具体工作过程，可以参考前述方法实施例中的对应过程，在此不再赘述。</p>
    <p>[0126]	在本发明所提供的几个实施例中，应该理解到，所揭露的系统，装置和方法，可以通过其它的方式实现。例如，以上所描述的装置实施例仅仅是示意性的，例如，所述单元的划分，仅仅为一种逻辑功能划分，实际实现时可以有另外的划分方式，例如多个单元或组件可以结合或者可以集成到另一个系统，或一些特征可以忽略，或不执行。另一点，所显示或讨论的相互之间的耦合或直接耦合或通信连接可以是通过一些接口，装置或单元的间接耦合或通信连接，可以是电性，机械或其它的形式。</p>
    <p>[0127]	所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部单元来实现本实施例方案的目的。</p>
    <p>[0128]	另外，在本发明各个实施例中的各功能单元可以集成在一个处理单元中，也可以是各个单元单独物理存在，也可以两个或两个以上单元集成在一个单元中。上述集成的单元既可以采用硬件的形式实现，也可以采用硬件加软件功能单元的形式实现。</p>
    <p>[0129]	上述以软件功能单元的形式实现的集成的单元，可以存储在一个计算机可读取存储介质中。上述软件功能单元存储在一个存储介质中，包括若干指令用以使得一台计算机装置(可以是个人计算机，服务器，或者网络装置等)或处理器(processor)执行本发明各个实施例所述方法的部分步骤。而前述的存储介质包括:U盘、移动硬盘、只读存储器(Read-Only Memory, ROM)、随机存取存储器(Random Access Memory, RAM)、磁碟或者光盘等各种可以存储程序代码的介质。</p>
    <p>[0130]	最后应说明的是:以上实施例仅用以说明本发明的技术方案，而非对其限制；尽管参照前述实施例对本发明进行了详细的说明，本领域的普通技术人员应当理解:其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本发明各实施例技术方案的精神和范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100521708C?cl=zh">CN100521708C</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年10月26日</td><td class="patent-data-table-td patent-date-value">2009年7月29日</td><td class="patent-data-table-td ">熊猫电子集团有限公司;南京联慧通信技术有限公司</td><td class="patent-data-table-td ">移动信息终端的语音识别与语音标签记录和调用方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101452725A?cl=zh">CN101452725A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年12月31日</td><td class="patent-data-table-td patent-date-value">2009年6月10日</td><td class="patent-data-table-td ">深圳市迅雷网络技术有限公司</td><td class="patent-data-table-td ">一种播放提示方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102625164A?cl=zh">CN102625164A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年4月6日</td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td ">上海车音网络科技有限公司</td><td class="patent-data-table-td ">多媒体数据处理平台及多媒体读物、系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102782751A?cl=zh">CN102782751A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年2月3日</td><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td ">国际商业机器公司</td><td class="patent-data-table-td ">社会网络中的数字媒体语音标签</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=uOniCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0009440000">G06F9/44</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年12月18日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/3d427848637b2a4768f0/CN103399737A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E9%9F%B3%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E6%96%B9.pdf?id=uOniCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3Uteiipu71Y1es3MJt91aVbqumAw"},"sample_url":"https://www.google.com/patents/reader?id=uOniCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>