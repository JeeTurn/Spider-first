<!DOCTYPE html><html><head><title>专利 CN101281598A - 基于多部件多特征融合的人脸识别方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于多部件多特征融合的人脸识别方法"><meta name="DC.contributor" content="苏光大" scheme="inventor"><meta name="DC.contributor" content="燕 相" scheme="inventor"><meta name="DC.contributor" content="清华大学" scheme="assignee"><meta name="DC.date" content="2008-5-23" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及基于多部件多特征融合的人脸识别方法，属于图像处理、计算机视觉、模式识别技术领域。该方法包括以下步骤：对训练集中所有人脸图像进行Gabor滤波，得到五种部件的Gabor特征图像，对已知人和待识别人的人脸图像采用同样方法对得到的五种部件的Gabor特征图像，分别提取五种人脸部件灰度图像的投影特征值；得到五种人脸部件的混合投影特征值；分别计算待识别人脸和已知人脸各个部件的混合投影特征值之间的欧式距离作为待识别的人脸和已知人脸的部件图像的相似度R，得到待识别的人脸和已知人脸的综合相似度R0，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。本发明具有更高的人脸识别率。"><meta name="DC.date" content="2008-10-8"><meta name="citation_patent_publication_number" content="CN:101281598:A"><meta name="citation_patent_application_number" content="CN:200810112626"><link rel="canonical" href="https://www.google.com/patents/CN101281598A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101281598A?cl=zh"/><meta name="title" content="专利 CN101281598A - 基于多部件多特征融合的人脸识别方法"/><meta name="description" content="本发明涉及基于多部件多特征融合的人脸识别方法，属于图像处理、计算机视觉、模式识别技术领域。该方法包括以下步骤：对训练集中所有人脸图像进行Gabor滤波，得到五种部件的Gabor特征图像，对已知人和待识别人的人脸图像采用同样方法对得到的五种部件的Gabor特征图像，分别提取五种人脸部件灰度图像的投影特征值；得到五种人脸部件的混合投影特征值；分别计算待识别人脸和已知人脸各个部件的混合投影特征值之间的欧式距离作为待识别的人脸和已知人脸的部件图像的相似度R，得到待识别的人脸和已知人脸的综合相似度R0，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。本发明具有更高的人脸识别率。"/><meta property="og:title" content="专利 CN101281598A - 基于多部件多特征融合的人脸识别方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101281598A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101281598A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=0rVkBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101281598A&amp;usg=AFQjCNGhdvqIpZizVd2egPy5QHeWSSjL6Q" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/46fc66ab6b5e1cf54952/CN101281598A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/46fc66ab6b5e1cf54952/CN101281598A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101281598A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101281598A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101281598A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN100557624C?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101281598A?cl=zh" style="display:none"><span itemprop="description">本发明涉及基于多部件多特征融合的人脸识别方法，属于图像处理、计算机视觉、模式识别技术领域。该方法包括以下步骤：对训练集中所有人脸图像进行Gabor滤波，得到五种部件的Gabor特征图像，对已知人和待识别人的人脸图 ...</span><span itemprop="url">https://www.google.com/patents/CN101281598A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101281598A - 基于多部件多特征融合的人脸识别方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101281598A - 基于多部件多特征融合的人脸识别方法" title="专利 CN101281598A - 基于多部件多特征融合的人脸识别方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101281598 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200810112626</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2008年10月8日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2008年5月23日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2008年5月23日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN100557624C?hl=zh-CN&amp;cl=zh">CN100557624C</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200810112626.6, </span><span class="patent-bibdata-value">CN 101281598 A, </span><span class="patent-bibdata-value">CN 101281598A, </span><span class="patent-bibdata-value">CN 200810112626, </span><span class="patent-bibdata-value">CN-A-101281598, </span><span class="patent-bibdata-value">CN101281598 A, </span><span class="patent-bibdata-value">CN101281598A, </span><span class="patent-bibdata-value">CN200810112626, </span><span class="patent-bibdata-value">CN200810112626.6</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%8B%8F%E5%85%89%E5%A4%A7%22">苏光大</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%87%95+%E7%9B%B8%22">燕 相</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%22">清华大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101281598A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101281598A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101281598A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (13),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=0rVkBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200810112626&amp;usg=AFQjCNGE4oWoHroJsC3tL22ZmNSN3HUFJA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=0rVkBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101281598A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHBeeloZHYeJxP7T7g3o_NN_Hz7iw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT70899365" lang="ZH" load-source="patent-office">基于多部件多特征融合的人脸识别方法</invention-title>
      </span><br><span class="patent-number">CN 101281598 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA109497368" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及基于多部件多特征融合的人脸识别方法，属于图像处理、计算机视觉、模式识别技术领域。该方法包括以下步骤：对训练集中所有人脸图像进行Gabor滤波，得到五种部件的Gabor特征图像，对已知人和待识别人的人脸图像采用同样方法对得到的五种部件的Gabor特征图像，分别提取五种人脸部件灰度图像的投影特征值；得到五种人脸部件的混合投影特征值；分别计算待识别人脸和已知人脸各个部件的混合投影特征值之间的欧式距离作为待识别的人脸和已知人脸的部件图像的相似度R，得到待识别的人脸和已知人脸的综合相似度R0，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。本发明具有更高的人脸识别率。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(1)</span></span></div><div class="patent-text"><div mxw-id="PCLM51286721" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1、一种基于多部件多特征融合的人脸识别方法，其特征在于，该方法包括以下步骤：</div>
      <div class="claim-text">1)对人脸图像进行五尺度八方向Gabor滤波，得到对应的人脸Gabor图像；</div>
      <div class="claim-text">2)从人脸Gabor图像中提取出裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像五种部件Gabor图像；</div>
      <div class="claim-text">3)分别对所述裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像均匀分块，取每块中所有象素点的平均值作为该块的特征象素点，所有特征象素点组合成五种部件的Gabor特征图像，实现五种部件Gabor图像的降维；</div>
      <div class="claim-text">4)对训练集中所有图像采用所述步骤1)-3)得到的五种部件的Gabor特征图像，利用基于主分量分析方法中的特征脸方法，形成Gabor特征裸脸、Gabor特征眉毛+眼睛、Gabor特征眼睛、Gabor特征鼻尖、Gabor特征嘴巴；</div>
      <div class="claim-text">5)对已知人的人脸图像采用所述步骤1)-3)得到五种部件的Gabor特征图像，利用基于主分量分析方法中的投影特征向量分析方法，分别提取所述已知人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</div>
      <div class="claim-text">6)利用基于部件主分量分析的多模式人脸识别方法，提取已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</div>
      <div class="claim-text">7)将已知人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，得到已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</div>
      <div class="claim-text">8)对待识别人的人脸图像采用步骤1)-3)得到五种部件的Gabor特征图像，利用基于主分量分析方法中的投影特征向量分析方法，分别提取所述待识别人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</div>
      <div class="claim-text">9)利用基于部件主分量分析的多模式人脸识别方法，提取待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</div>
      <div class="claim-text">10)将待识别人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，得到待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</div>
      <div class="claim-text">11)分别计算待识别人脸各个部件的混合投影特征值和已知人脸各个部件的混合投影特征值之间的欧式距离作为待识别的人脸和已知人脸的部件图像的相似度R，各部件图像相似度分别为裸脸图像R1、眼睛+眉毛图像R2、眼睛图像R3、鼻子图像R4、嘴巴图像R5；</div>
      <div class="claim-text">12)将相似度R1、R2、R3、R4、R5按照加权和规则进行融合，得到待识别的人脸和已知人脸的综合相似度R0，该R0作为人脸识别的人脸相似度；</div>
      <div class="claim-text">13)比较步骤12)得到的相似度R0与预先设定的阈值T的大小，T为选取错误接收率为0.1％时对应的相似度值，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES58328033" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">基于多部件多特征融合的人脸识别方法</invention-title>
    <technical-field>
      <p>[0001] 技术领域</p>
      <p>[0002] 本发明属于图像处理、计算机视觉、模式识别技术领域，特别涉及人脸识别方法。</p>
    </technical-field>
    <background-art>
      <p>[0003] 背景技术</p>
      <p>[0004] 生物特征识别技术是身份识别的有效技术，近来发展最快的是人脸识别技术以及与人脸识别技术相融合的生物特征识别技术。因此，本发明涉及人脸图像采集和识别算法，具有重要的应用价值。</p>
      <p>[0005] 目前已有的人脸识别方法主要是对整个人脸进行识别的，而在诸多的识别方法中，主要采用主分量分析(PCA-Principal&#160;Component&#160;Analysis)、弹性匹配、神经网络、几何特征等方法。</p>
      <p>[0006] 同时，人脸识别的难点还在于：</p>
      <p>[0007] (1)表情引起的人脸塑性变形</p>
      <p>[0008] (2)姿态引起的人脸多样性</p>
      <p>[0009] (3)年龄引起的人脸变化</p>
      <p>[0010] (4)发型、胡须、眼镜、化装等因素引起的人脸模式的多重性</p>
      <p>[0011] (5)光照的角度、强度以及传感器特性等因素引起的人脸图像的差异性</p>
      <p>[0012] 诸多的因素使得人脸识别成为一项棘手而富挑战性的课题，也因此在近年成为科研的热点。</p>
      <p>[0013] 与本发明相关的已有技术说明如下：</p>
      <p>[0014] 基于人脸部件主分量分析的多模式人脸识别方法：其主要特点是对人脸进行部件提取，再对人脸部件进行主分量分析及多模式识别，以达到高的识别率。该方法包括：</p>
      <p>[0015] 1)首先采用模板匹配和投影直方图的方法对人脸图像定位，确定出人脸粗定位区、左右眼球、鼻尖、嘴、下颌顶点的基本位置，然后从整个人脸中提取出裸脸、眉毛+眼睛、眼睛、鼻尖、嘴五种人脸部件；</p>
      <p>[0016] 2)对从训练集人脸中提取出来的裸脸、眉毛+眼睛、眼睛、鼻尖、嘴五种人脸部件，利用主分量分析方法中的特征脸方法，分别形成特征裸脸、特征(眼睛+眉毛)、特征眼睛、特征鼻子、特征嘴巴；</p>
      <p>[0017] 3)对已知人的人脸图像提取出的裸脸、眉毛+眼睛、眼睛、鼻尖、嘴五种人脸部件，利用主分量分析方法中的投影特征值分析方法，提取已知人脸的裸脸、眼睛+眉毛、眼睛、鼻子、嘴五种人脸部件的投影特征值；</p>
      <p>[0018] 4)对待识别人的人脸图像提取出的裸脸、眉毛+眼睛、眼睛、鼻尖、嘴五种人脸部件，利用主分量分析方法中的特征投影值分析方法，提取待识别人脸的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴的投影特征值；</p>
      <p>[0019] 5)分别计算已知人脸部件图像的投影特征值和待识别人脸对应部件图像的投影特征值之间的相似度；对裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴的相似度融合得到多模式的全局人脸识别方法，单个裸脸、眼睛+眉毛、眼睛、鼻子、嘴的相似度识别，或裸脸、眼睛+眉毛、眼睛、鼻子、嘴相互之间的组合识别就是多模式的局部人脸识别方法。</p>
      <p>[0020] Gabor方法：其主要特点是将Gabor基函数经过移位、旋转和比例变换以后得到的一组相似的Gabor函数，能够在保持空间关系的同时描述出图像中的频率结构，并能在空间域给出结果。在人脸识别的应用中，由于Gabor小波多分辨率、多方向地反映图像局部特性，所以对于光照的反应不敏感，和使用全局灰度特征进行识别相比较，对光照具有更好的适应性。</p>
      <p>[0021] 二维Gabor函数相当于一个被复正弦函数调制的二维高斯函数，在频域上则是二维高斯函数在两个频率轴上都发生了平移后的结果，是一个二维带通滤波器。由于每个Gabor滤波器相当于一个带通滤波器，为了提取人脸图像在多个方向多个尺度上的特征，通常会采用多个在不同尺度不同方向上的Gabor滤波器组成滤波器组。进行滤波时，将输入图像依次与滤波器组的各个滤波器卷积，并取其幅值作为输出，即输入图像的Gabor图像。</p>
      <p>[0022] 加权和规则：对于不同的特征，识别性别都不尽相同，加权和规则就是对不同的特征采用不同的权值进行融合。每个特征的权值是由该特征本身的特性(可分性，识别率等)所决定的，不同的融合特征对应不同的融合权值。对识别性能好的特征赋予较大的权值，而识别性能差的特征赋予较小的权值。</p>
    </background-art>
    <disclosure>
      <p>[0023] 发明内容</p>
      <p>[0024] 本发明的目的是为了提高人脸识别算法的适应性，提出一种基于多部件多特征融合的人脸识别方法，该方法具有更高的人脸识别率。</p>
      <p>[0025] 本发明提出的基于多部件多特征融合的人脸识别方法，其特征在于，包括以下步骤：</p>
      <p>[0026] 1)对人脸图像进行五尺度八方向Gabor滤波，得到对应的人脸Gabor图像；</p>
      <p>[0027] 2)从人脸Gabor图像中提取出裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像五种部件Gabor图像；</p>
      <p>[0028] 3)分别对所述裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像均匀分块，取每块中所有象素点的平均值作为该块的特征象素点，所有特征象素点组合成五种部件的Gabor特征图像，实现五种部件Gabor图像的降维；</p>
      <p>[0029] 4)对训练集中所有图像采用所述步骤1)-3)得到的五种部件的Gabor特征图像，利用基于主分量分析方法中的特征脸方法，形成Gabor特征裸脸、Gabor特征眉毛+眼睛、Gabor特征眼睛、Gabor特征鼻尖、Gabor特征嘴巴；</p>
      <p>[0030] 5)对已知人的人脸图像采用所述步骤1)-3)得到五种部件的Gabor特征图像，利用基于主分量分析方法中的投影特征向量分析方法，分别提取所述已知人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</p>
      <p>[0031] 6)利用基于部件主分量分析的多模式人脸识别方法，提取已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</p>
      <p>[0032] 7)将已知人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，得到已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</p>
      <p>[0033] 8)对待识别人的人脸图像采用步骤1)-3)得到五种部件的Gabor特征图像，利用基于主分量分析方法中的投影特征向量分析方法，分别提取所述待识别人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</p>
      <p>[0034] 9)利用基于部件主分量分析的多模式人脸识别方法，提取待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</p>
      <p>[0035] 10)将待识别人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，得到待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</p>
      <p>[0036] 11)分别计算待识别人脸各个部件的混合投影特征值和已知人脸各个部件的混合投影特征值之间的欧式距离作为待识别的人脸和已知人脸的部件图像的相似度R，各部件图像相似度分别为裸脸图像R1、眼睛+眉毛图像R2、眼睛图像R3、鼻子图像R4、嘴巴图像R5；</p>
      <p>[0037] 12)将相似度R1、R2、R3、R4、R5按照加权和规则进行融合，得到待识别的人脸和已知人脸的综合相似度R0，该R0作为人脸识别的人脸相似度；</p>
      <p>[0038] 13)比较步骤12)得到的相似度R0与预先设定的阈值T的大小，T为选取错误接收率为0.1％时对应的相似度值，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。</p>
      <p>[0039] 本发明的特点及效果</p>
      <p>[0040] 本发明对灰度图像和Gabor图像进行部件分割，再对部件的灰度图像和Gabor图像进行主分量分析以及融合，具有更高的人脸识别率。</p>
    </disclosure>
    <mode-for-invention>
      <p>[0041] 具体实施方式</p>
      <p>[0042] 本发明提出的基于多部件多特征融合的人脸识别方法结合附图及实施例详细说明如下，包括以下步骤：</p>
      <p>[0043] 1)对人脸图像进行五尺度八方向Gabor滤波，得到对应的人脸Gabor图像；</p>
      <p>[0044] Gabor滤波器的定义如式(1)：</p>
      <p>[0045] </p>
      <p>[0046] 其中，z＝(x，y)为对应点坐标，波矢量定义为：其中kv＝kmax/λv并且θμ＝πμ/n。v和μ分别定义了Gabor滤波器的尺度和方向。取n＝8，v∈{0，1，2，3，4}，μ∈{0，1，…，7}，σ＝2π，kmax＝π/2以及得到五尺度八方向的Gabor滤波器组。</p>
      <p>[0047] 将人脸图像I(z)与Gabor滤波器进行卷积，取卷积结果的幅值部分，得到对应的人脸Gabor图像Aμ，v(z)。</p>
      <p>[0048] Oμ，v(z)＝I(z)*ψμ，v(z)(2)</p>
      <p>[0049] </p>
      <p>[0050] 2)从人脸Gabor图像Aμ，v(z)中提取出裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像五种部件Gabor图像，裸脸Gabor图像的尺寸为90×120，眉毛+眼睛Gabor图像的尺寸为45×35，眼睛Gabor图像的尺寸为40×20，鼻尖Gabor图像的尺寸为20×30，嘴巴Gabor图像的尺寸为24×32。</p>
      <p>[0051] 3)分别对裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像均匀分块，每块大小为3×3，取每块中所有象素点的平均值作为该块的特征象素点，所有特征象素点组合成Gabor特征图像，实现五种部件Gabor图像的降维，降维后五部件的Gabor特征图像尺寸大小分别为30×40、15×11、13×6、6×10、8×10；</p>
      <p>[0052] 4)对训练集中所有图像采用所述步骤1)-3)得到的五种部件的Gabor特征图像，利用基于主分量分析方法中的特征脸方法，形成Gabor特征裸脸、Gabor特征眉毛+眼睛、Gabor特征眼睛、Gabor特征鼻尖、Gabor特征嘴巴；</p>
      <p>[0053] 具体的做法是：</p>
      <p>[0054] 用n×N矩阵X分别表示训练集中所有人脸Gabor特征裸脸或Gabor特征眉毛+眼睛或Gabor特征眼睛或Gabor特征鼻尖或Gabor特征嘴巴的矢量集，n为人脸Gabor特征裸脸或Gabor特征眉毛+眼睛或Gabor特征眼睛或Gabor特征鼻尖或Gabor特征嘴巴的像素数，N(N＞1000)为训练集人脸总数，则：</p>
      <p>[0055] </p>
      <p>[0056] (4)式中Xk＝(x1k，x2k，…，xnk)T，k＝(1，2，…，N)可以表示一个人脸Gabor特征裸脸矢量、Gabor特征眉毛+眼睛矢量、Gabor特征眼睛矢量、Gabor特征鼻尖矢量、Gabor特征嘴巴矢量，XT表示矩阵X的转置。</p>
      <p>[0057] 在计算矩阵C的特征向量和特征值时，由于计算XXT的维数很大(n2维)，而采用奇异值分解，改为计算XTX，这样可以间接获得C的特征向量和特征值，而XTX的维数降为N2维，XXT与XTX的特征值是一样的，而它们之间的特征向量的关系满足下式：</p>
      <p>[0058] </p>
      <p>[0059] (5)式中uk为XXT的特征向量，φk为XTX的特征向量；λk既是XTX的特征值，同时也是XXT的特征值。通过计算XTX的特征值λk和特征向量φk，而得到XXT的特征向量uk。按照λk数值按从大到小进行排序，取出前D(D＜＜N)个最大的特征值并保留与之相对应的D个特征向量uk就形成Gabor特征裸脸、Gabor特征眉毛+眼睛、Gabor特征眼睛、Gabor特征鼻尖、Gabor特征嘴巴，对于所述五种部件，D的取值分别为120、60、80、50、40。</p>
      <p>[0060] 5)对已知人的人脸图像采用所述步骤1)-3)得到五种部件的Gabor特征图像，采用下面(6)式的运算即基于主分量分析方法中的投影特征向量分析方法，分别提取所述已知人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</p>
      <p>[0061] </p>
      <p>[0062] (6)式中q分别为已知人脸的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴的Gabor特征图像矢量，uk分别为从训练集人脸中得到的Gabor特征脸、Gabor特征眼睛+眉毛、Gabor特征眼睛、Gabor特征鼻子、Gabor特征嘴巴。</p>
      <p>[0063] 6)利用基于部件主分量分析的多模式人脸识别方法，提取已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</p>
      <p>[0064] 7)将已知人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，融合比例为1∶0.75，得到已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</p>
      <p>[0065] 8)对待识别人的人脸图像采用步骤1)-3)得到五种部件的Gabor特征图像，采用下面(7)式的运算即基于主分量分析方法中的投影特征向量分析方法，分别提取所述待识别人脸的裸脸Gabor图像、眉毛+眼睛Gabor图像、眼睛Gabor图像、鼻尖Gabor图像、嘴巴Gabor图像的投影特征向量；</p>
      <p>[0066] </p>
      <p>[0067] (7)式中p分别为待识别人脸的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴的Gabor特征图像矢量，uk分别为从训练集人脸中得到的Gabor特征脸、Gabor特征眼睛+眉毛、Gabor特征眼睛、Gabor特征鼻子、Gabor特征嘴巴。</p>
      <p>[0068] 9)利用基于部件主分量分析的多模式人脸识别方法，提取待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件灰度图像的投影特征值；</p>
      <p>[0069] 10)将待识别人脸图像的同一部件的灰度图像投影特征值和对应的Gabor图像投影特征值按照加权和规则融合，融合比例为1∶0.75，得到待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值；</p>
      <p>[0070] 11)按照(8)式分别计算出待识别的人脸和已知人脸的部件图像的相似度R，各部件图像相似度分别为裸脸图像R1、眼睛+眉毛图像R2、眼睛图像R3、鼻子图像R4、嘴巴图像R5；</p>
      <p>[0071] </p>
      <p>[0072] 其中，B分别为7)中的已知人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值，A分别为10)中的待识别人脸图像的裸脸、眼睛+眉毛、眼睛、鼻子、嘴巴五种人脸部件的混合投影特征值。</p>
      <p>[0073] 12)将相似度R1、R2、R3、R4、R5按照加权和规则进行融合，其融合系数分别取作16∶1.5∶2.5∶2∶3，得到待识别的人脸和已知人脸的综合相似度R0，以R0作为人脸识别的人脸相似度；</p>
      <p>[0074] 13)选取错误接收率为0.1％时对应的相似度值为预设阈值T，T＝87，比较步骤12)得到的相似度R0与预先设定的阈值T的大小，如果R0≥T，则判断待识别人和已知人是同一个人；如果R0＜T，则判断待识别人和已知人不是同一个人。</p>
      <p>[0075] 基于人脸识别的二代证实名身份认证系统用VC++语言编程。所达到的识别率为：当错误接受率为0.1％时，正确识别率为78.96％。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101365102B?cl=zh">CN101365102B</a></td><td class="patent-data-table-td patent-date-value">2008年10月14日</td><td class="patent-data-table-td patent-date-value">2012年12月5日</td><td class="patent-data-table-td ">北京中星微电子有限公司</td><td class="patent-data-table-td ">基于视频内容识别的收视率统计的方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101819628A?cl=zh">CN101819628A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年4月2日</td><td class="patent-data-table-td patent-date-value">2010年9月1日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">结合形状特征的稀疏表示人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101819628B?cl=zh">CN101819628B</a></td><td class="patent-data-table-td patent-date-value">2010年4月2日</td><td class="patent-data-table-td patent-date-value">2011年12月28日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">结合形状特征的稀疏表示人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101819631A?cl=zh">CN101819631A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年4月16日</td><td class="patent-data-table-td patent-date-value">2010年9月1日</td><td class="patent-data-table-td ">深圳大学</td><td class="patent-data-table-td ">一种身份识别方法和身份识别系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101819631B?cl=zh">CN101819631B</a></td><td class="patent-data-table-td patent-date-value">2010年4月16日</td><td class="patent-data-table-td patent-date-value">2012年12月26日</td><td class="patent-data-table-td ">深圳大学</td><td class="patent-data-table-td ">一种身份识别方法和身份识别系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102446269A?cl=zh">CN102446269A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2012年5月9日</td><td class="patent-data-table-td ">微盟电子(昆山)有限公司</td><td class="patent-data-table-td ">可抑制杂讯及环境影响的脸部识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102446269B?cl=zh">CN102446269B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2015年10月14日</td><td class="patent-data-table-td ">微盟电子(昆山)有限公司</td><td class="patent-data-table-td ">可抑制杂讯及环境影响的脸部识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102622581A?cl=zh">CN102622581A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年2月20日</td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td ">华焦宝</td><td class="patent-data-table-td ">人脸检测方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102622581B?cl=zh">CN102622581B</a></td><td class="patent-data-table-td patent-date-value">2012年2月20日</td><td class="patent-data-table-td patent-date-value">2013年9月25日</td><td class="patent-data-table-td ">华焦宝</td><td class="patent-data-table-td ">人脸检测方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102800131A?cl=zh">CN102800131A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月24日</td><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">中国铁道科学研究院电子计算技术研究所</td><td class="patent-data-table-td ">火车票实名制验票系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103136250A?cl=zh">CN103136250A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月29日</td><td class="patent-data-table-td patent-date-value">2013年6月5日</td><td class="patent-data-table-td ">阿里巴巴集团控股有限公司</td><td class="patent-data-table-td ">信息更换识别方法、装置以及信息搜索方法、系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103136250B?cl=zh">CN103136250B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月29日</td><td class="patent-data-table-td patent-date-value">2016年1月6日</td><td class="patent-data-table-td ">阿里巴巴集团控股有限公司</td><td class="patent-data-table-td ">信息更换识别方法、装置以及信息搜索方法、系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015197029A1?cl=zh">WO2015197029A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2015年6月26日</td><td class="patent-data-table-td patent-date-value">2015年12月30日</td><td class="patent-data-table-td ">北京奇虎科技有限公司</td><td class="patent-data-table-td ">一种人脸相似度识别方法和系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=0rVkBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2008年10月8日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2008年12月3日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年11月4日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/46fc66ab6b5e1cf54952/CN101281598A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E9%83%A8%E4%BB%B6%E5%A4%9A%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E4%BA%BA%E8%84%B8.pdf?id=0rVkBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2sISYoo3dV7WnBBLsPxrTGavOnhw"},"sample_url":"https://www.google.com/patents/reader?id=0rVkBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>