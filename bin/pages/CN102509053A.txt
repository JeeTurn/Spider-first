<!DOCTYPE html><html><head><title>专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="用于验证授权的方法、处理器、设备和移动终端"><meta name="DC.contributor" content="其他发明人请求不公开姓名" scheme="inventor"><meta name="DC.contributor" content="唐辉" scheme="inventor"><meta name="DC.contributor" content="沈超" scheme="inventor"><meta name="DC.contributor" content="刘陆陆" scheme="assignee"><meta name="DC.contributor" content="唐辉" scheme="assignee"><meta name="DC.contributor" content="张宇峰" scheme="assignee"><meta name="DC.contributor" content="沈超" scheme="assignee"><meta name="DC.date" content="2011-11-23" scheme="dateSubmitted"><meta name="DC.description" content="一种用于验证授权的方法，包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述表情特征与表情模板进行匹配；确认匹配后授予权限。本发明以图像识别为基础，利用某种影像特征，例如人的表情，作为验证信息/密码，不仅增加了用户与设备之间的交互方式，带来新的用户体验，而且也提高了设备的安全性。本发明还公开一种处理器、设备和移动终端。"><meta name="DC.date" content="2012-6-20"><meta name="DC.relation" content="CN:101710383:A" scheme="references"><meta name="DC.relation" content="CN:101825947:A" scheme="references"><meta name="DC.relation" content="US:20010017584:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102509053:A"><meta name="citation_patent_application_number" content="CN:201110375129"><link rel="canonical" href="https://www.google.com/patents/CN102509053A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102509053A?cl=zh"/><meta name="title" content="专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端"/><meta name="description" content="一种用于验证授权的方法，包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述表情特征与表情模板进行匹配；确认匹配后授予权限。本发明以图像识别为基础，利用某种影像特征，例如人的表情，作为验证信息/密码，不仅增加了用户与设备之间的交互方式，带来新的用户体验，而且也提高了设备的安全性。本发明还公开一种处理器、设备和移动终端。"/><meta property="og:title" content="专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102509053A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102509053A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=ObtYBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102509053A&amp;usg=AFQjCNERMDnrJLgxLQXBZrqT1GCsi7Po0w" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/4e643482284dbc74ed92/CN102509053A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/4e643482284dbc74ed92/CN102509053A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102509053A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102509053A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102509053A?cl=zh" style="display:none"><span itemprop="description">一种用于验证授权的方法，包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述表情特征与表情模板进行匹配；确认匹配后授予权限。本发明以图像识别为基础，利用某种影像特征，例如人的...</span><span itemprop="url">https://www.google.com/patents/CN102509053A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端" title="专利 CN102509053A - 用于验证授权的方法、处理器、设备和移动终端"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102509053 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110375129</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年6月20日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年11月23日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年11月23日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110375129.7, </span><span class="patent-bibdata-value">CN 102509053 A, </span><span class="patent-bibdata-value">CN 102509053A, </span><span class="patent-bibdata-value">CN 201110375129, </span><span class="patent-bibdata-value">CN-A-102509053, </span><span class="patent-bibdata-value">CN102509053 A, </span><span class="patent-bibdata-value">CN102509053A, </span><span class="patent-bibdata-value">CN201110375129, </span><span class="patent-bibdata-value">CN201110375129.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%85%B6%E4%BB%96%E5%8F%91%E6%98%8E%E4%BA%BA%E8%AF%B7%E6%B1%82%E4%B8%8D%E5%85%AC%E5%BC%80%E5%A7%93%E5%90%8D%22">其他发明人请求不公开姓名</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%94%90%E8%BE%89%22">唐辉</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B2%88%E8%B6%85%22">沈超</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%88%98%E9%99%86%E9%99%86%22">刘陆陆</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%94%90%E8%BE%89%22">唐辉</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%BC%A0%E5%AE%87%E5%B3%B0%22">张宇峰</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B2%88%E8%B6%85%22">沈超</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102509053A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102509053A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102509053A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (8),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ObtYBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110375129&amp;usg=AFQjCNHJ3U1qrf6rbs9DauYVjFcF6KljKg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ObtYBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102509053A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHQAHttFXr_65OImEMt7kH-3b-Tlg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT113427953" lang="ZH" load-source="patent-office">用于验证授权的方法、处理器、设备和移动终端</invention-title>
      </span><br><span class="patent-number">CN 102509053 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA97385655" lang="ZH" load-source="patent-office">
    <div class="abstract">一种用于验证授权的方法，包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述表情特征与表情模板进行匹配；确认匹配后授予权限。本发明以图像识别为基础，利用某种影像特征，例如人的表情，作为验证信息/密码，不仅增加了用户与设备之间的交互方式，带来新的用户体验，而且也提高了设备的安全性。本发明还公开一种处理器、设备和移动终端。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(43)</span></span></div><div class="patent-text"><div mxw-id="PCLM43022740" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种用于验证授权的方法，其特征在于，包括： 采集图像；识别所述图像中的人脸信息； 提取所述人脸信息中的表情特征； 将所述表情特征与表情模板进行匹配； 确认匹配后授予权限。</div>
    </div>
    </div> <div class="claim"> <div num="2" class="claim">
      <div class="claim-text">2.	一种用于验证授权的方法，其特征在于，包括： 采集图像；识别所述图像中的人脸信息； 提取所述人脸信息中的表情特征；将所述人脸信息中的人脸特征和人脸模板进行匹配，将所述表情特征和表情模板进行匹配；人脸和表情二者都匹配时授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的方法，其特征在于，从所述图像的全局信息中提取相关的全局特征信息，从人脸各局部提取相关的局部特征信息；综合所述全局特征信息和局部特征信息，获得所述人脸的特征信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求1、2或3所述的方法，其特征在于，提取所述人脸信息中表情特征的步骤包括：对所述图像中的特征点进行定位并分离特征子区域；对所述图像的全局特征和所述特征子区域进行特征描述；综合所述图像的全局特征和特征子区域的特征，获得所述表情特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求4所述的方法，其特征在于，所述特征子区域包括眼睛、眉毛、嘴巴和脸颊中的至少一个区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求4所述的方法，其特征在于，所述图像的全局特征包括各所述特征子区域的相对位置、俯仰角和注视方向中的至少一种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求2至6任一项所述的方法，其特征在于，采用所述人脸特征与所述人脸模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求1至7任一项所述的方法，其特征在于，采用所述表情特征与所述表情模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.如权利要求1至8任一项所述的方法，其特征在于，授予操作设备的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.如权利要求9所述的方法，其特征在于，所述设备从睡眠模式进入唤醒模式后采集图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.如权利要求1至8任一项所述的方法，其特征在于，授予打开加密信息的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.如权利要求11所述的方法，其特征在于，检测到用户对所述加密信息实施打开操作后采集图像。</div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13.	一种用于验证授权的方法，其特征在于，包括： 采集图像；识别所述图像中的影像特征； 将所述影像特征与特征模板进行匹配；确认匹配后授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.如权利要求13所述的方法，其特征在于，采用所述影像特征与所述特征模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.如权利要求13或14所述的方法，其特征在于，所述影像特征是手势特征、动作特征、图案特征和形状特征中的至少一个；所述特征模板是手势特征模板、动作特征模板、图案特征模板和形状特征模板中的至少一个。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.如权利要求13、14或15所述的方法，其特征在于，授予操作设备的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.如权利要求16所述的方法，其特征在于，所述设备从第一模式进入第二模式后采集图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.如权利要求13、14或15所述的方法，其特征在于，授予打开加密信息的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.如权利要求18所述的方法，其特征在于，检测到用户对所述加密信息实施打开操作后采集图像。</div>
    </div>
    </div> <div class="claim"> <div num="20" class="claim">
      <div class="claim-text">20.	一种设备，包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，其特征在于，所述处理器包括：第一单元，用于识别图像中的人脸信息；第二单元，用于提取所述人脸信息中的表情特征；第三单元，用于将所述表情特征与表情模板进行匹配；和，第四单元，用于在所述表情特征与所述表情模板匹配时授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21.如权利要求20所述的设备，其特征在于，所述第四单元还用于，当所述表情特征与所述表情模板不匹配时拒绝授权。</div>
    </div>
    </div> <div class="claim"> <div num="22" class="claim">
      <div class="claim-text">22.	&#8212;种设备，包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，其特征在于，所述处理器包括：第一单元，用于识别图像中的人脸信息；第二单元，用于提取所述人脸信息中的表情特征；第五单元，用于将所述人脸信息中的人脸特征和人脸模板进行匹配；第三单元，用于将所述表情特征和表情模板进行匹配；和，第六单元，用于在人脸和表情二者都匹配时授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23.如权利要求22所述的设备，其特征在于，所述第六单元还用于，当人脸和表情二者中有一个不匹配时拒绝授权。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24.如权利要求22所述的设备，其特征在于，所述第一单元包括： 从所述图像的全局信息中提取相关的全局特征信息的单元； 从人脸各局部提取相关的局部特征信息的单元；和，综合所述全局特征信息和局部特征信息以获得所述人脸的特征信息的单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25.如权利要求20至M任一项所述的设备，其特征在于，所述第二单元包括： 对所述图像中的特征点进行定位并分离特征子区域的单元；对所述图像的全局特征和所述特征子区域进行特征描述的单元； 综合所述图像的全局特征和特征子区域的特征以获得所述表情特征的单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26.如权利要求22至25任一项所述的设备，其特征在于，采用所述人脸特征与人脸模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27.如权利要求20至沈任一项所述的方法，其特征在于，采用所述表情特征与表情模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28.如权利要求20至27任一项所述的设备，其特征在于，所述处理器还包括对图像进行预处理的单元；经过预处理的图像被发送到所述第一单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29.如权利要求20至27任一项所述的设备，其特征在于，所述处理器还包括发送提示信息的单元，用于在开始采集图像前或采集图像的过程中发送提示信息，提示用户输入验证信息；和/或，在识别所述图像中的人脸信息前发送提示信息，提示用户确认输入的信息；和/或，拒绝授权时发送提示信息，提示用户验证出错或未获授权或再次输入验证信肩、ο</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30.如权利要求20至四任一项所述的设备，其特征在于，授予操作设备的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31.如权利要求30所述的设备，其特征在于，所述设备从睡眠模式进入唤醒模式后所述图像采集装置开启，采集图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" class="claim">
      <div class="claim-text">32.如权利要求20至四任一项所述的设备，其特征在于，授予打开加密信息的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33.如权利要求32所述的方法，其特征在于，检测到用户对所述加密信息实施打开操作后所述图像采集装置开启，采集图像。</div>
    </div>
    </div> <div class="claim"> <div num="34" class="claim">
      <div class="claim-text">34.	一种设备，包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，其特征在于，所述处理器包括：影像识别单元，用于识别图像中的影像特征；匹配单元，用于将所述影像特征与特征模板进行匹配；和，授权单元，用于确认匹配后授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" class="claim">
      <div class="claim-text">35.如权利要求34所述的设备，其特征在于，所述影像特征包括表情特征、人脸特征、 手势特征、动作特征、图案特征和形状特征中的至少一个；所述特征模板包括表情特征模板、人脸特征模板、手势特征模板、动作特征模板、图案特征模板和形状特征模板中的至少一个。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" class="claim">
      <div class="claim-text">36.如权利要求35所述的设备，其特征在于，所述匹配单元将识别出的多个影像特征分别与相应的特征模板进行匹配，所述授权单元确认全部都匹配后授予权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" class="claim">
      <div class="claim-text">37.如权利要求34、35或36所述的方法，其特征在于，采用所述影像特征与所述特征模板的欧式距离作为匹配的依据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" class="claim">
      <div class="claim-text">38.如权利要求34、35或36所述的设备，其特征在于，授予操作设备的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" class="claim">
      <div class="claim-text">39.如权利要求38所述的设备，其特征在于，所述设备从第一模式进入第二模式后所述图像采集装置开启，采集图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40.如权利要求34、35或36所述的设备，其特征在于，授予打开加密信息的权限。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41.如权利要求40所述的设备，其特征在于，检测到用户对所述加密信息实施打开操作后所述图像采集装置开启，采集图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" class="claim">
      <div class="claim-text">42.	一种移动终端，包括屏幕和摄像头，其特征在于，还包括如权利要求20至41任一项所述的处理器；所述摄像头将其采集的图像发送给所述处理器；所述屏幕用于显示提示信息和所述摄像头采集的图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43.	一种如权利要求20至41任一项所述的处理器。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES47580781" lang="ZH" load-source="patent-office" class="description">
    <p>用于验证授权的方法、处理器、设备和移动终端</p>
    <p>技术领域</p>
    <p>[0001]	本发明属于数据处理技术领域，尤其涉及一种用于验证授权的方法、处理器、设备和移动终端。</p>
    <p>背景技术</p>
    <p>[0002]	随着消费电子的不断发展，诸如手机、平板电脑（pad)、笔记本电脑、电子书、个人数字助理（PDA)等越来越多的便携设备都具有显示屏幕和图像采集装置，例如前置摄像头和/或后置摄像头。目前，图像采集装置对便携设备来说只是用于照相，但实际上图像采集装置的功能和用途远不止于此。</p>
    <p>发明内容</p>
    <p>[0003]	有鉴于此，本发明的一个目的是提供一种用于验证授权的方法。为了对披露的实施例的一些方面有一个基本的理解，下面给出了简单的概括。该概括部分不是泛泛评述，也不是要确定关键/重要组成元素或描绘这些实施例的保护范围。其唯一目的是用简单的形式呈现一些概念，以此作为后面的详细说明的序言。</p>
    <p>[0004]	在一些可选的实施例中，所述用于验证授权的方法包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述表情特征与表情模板进行匹配；确认匹配后授予权限。</p>
    <p>[0005]	在一些可选的实施例中，所述用于验证授权的方法包括：采集图像；识别所述图像中的人脸信息；提取所述人脸信息中的表情特征；将所述人脸信息中的人脸特征和人脸模板进行匹配，将所述表情特征和表情模板进行匹配；人脸和表情二者都匹配时授予权限。</p>
    <p>[0006]	在一些可选的实施例中，授予操作设备的权限。</p>
    <p>[0007]	在一些可选的实施例中，授予打开加密信息的权限。</p>
    <p>[0008]	在一些可选的实施例中，所述用于验证授权的方法包括：采集图像；识别所述图像中的影像特征；将所述影像特征与特征模板进行匹配；确认匹配后授予权限。</p>
    <p>[0009]	在一些可选的实施例中，所述影像特征是手势特征、动作特征、图案特征和形状特征中的至少一个；所述特征模板是手势特征模板、动作特征模板、图案特征模板和形状特征模板中的至少一个。</p>
    <p>[0010]	本发明的另一个目的是提供一种设备。</p>
    <p>[0011]	在一些可选的实施例中，所述设备包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，所述处理器包括：第一单元，用于识别图像中的人脸信息；第二单元，用于提取所述人脸信息中的表情特征；第三单元，用于将所述表情特征与表情模板进行匹配；和，第四单元，用于在所述表情特征与所述表情模板匹配时授予权限。</p>
    <p>[0012]	在一些可选的实施例中，所述设备包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，所述处理器包括：第一单元，用于识别图像中的人脸信息；第二单元，用于提取所述人脸信息中的表情特征；第五单元，用于将所述人脸信息中的人脸特征和人脸模板进行匹配；第三单元，用于将所述表情特征和表情模板进行匹配；和， 第六单元，用于在人脸和表情二者都匹配时授予权限。</p>
    <p>[0013]	在一些可选的实施例中，所述第一单元包括：从所述图像的全局信息中提取相关的全局特征信息的单元；从人脸各局部提取相关的局部特征信息的单元；和，综合所述全局特征信息和局部特征信息以获得所述人脸的特征信息的单元。</p>
    <p>[0014]	在一些可选的实施例中，所述第二单元包括：对所述图像中的特征点进行定位并分离特征子区域的单元；对所述图像的全局特征和所述特征子区域进行特征描述的单元； 和，综合所述图像的全局特征和特征子区域的特征以获得所述表情特征的单元。</p>
    <p>[0015]	在一些可选的实施例中，所述处理器还包括对图像进行预处理的单元；经过预处理的图像被发送到所述第一单元。</p>
    <p>[0016]	在一些可选的实施例中，所述处理器还包括发送提示信息的单元，用于在开始采集图像前或采集图像的过程中发送提示信息，提示用户输入验证信息；和/或，在识别所述图像中的人脸信息前发送提示信息，提示用户确认输入的信息；和/或，拒绝授权时发送提示信息，提示用户验证出错或未获授权或再次输入验证信息。</p>
    <p>[0017]	在一些可选的实施例中，所述设备包括图像采集装置和处理器，所述图像采集装置将采集的图像发送给所述处理器，所述处理器包括：影像识别单元，用于识别图像中的影像特征；匹配单元，用于将所述影像特征与特征模板进行匹配；和，授权单元，用于确认匹配后授予权限。</p>
    <p>[0018]	可选地，所述影像特征包括表情特征、人脸特征、手势特征、动作特征、图案特征和形状特征中的至少一个；所述特征模板包括表情特征模板、人脸特征模板、手势特征模板、 动作特征模板、图案特征模板和形状特征模板中的至少一个。</p>
    <p>[0019]	在一些可选的实施例中，所述匹配单元将识别出的多个影像特征分别与相应的特征模板进行匹配，所述授权单元确认全部都匹配后授予权限。</p>
    <p>[0020]	本发明的另一个目的是提供一种移动终端。</p>
    <p>[0021]	在一些可选的实施例中，所述移动终端包括屏幕和摄像头，还包括前述任意一种处理器；所述摄像头将其采集的图像发送给所述处理器；所述屏幕用于显示提示信息和所述摄像头采集的图像。</p>
    <p>[0022]	本发明的另一个目的是提供一种机器可读介质，具有可执行指令，用于实现前述任意一种用于验证授权的方法。</p>
    <p>[0023]	所有的可选实施例都与现有的设置密码方式都不相同。本发明以图像识别为基础，利用某种影像特征，例如人的表情，作为验证信息/密码，不仅增加了用户与设备之间的交互方式，带来新的用户体验，而且也提高了设备的安全性。</p>
    <p>[0024]	为了上述以及相关的目的，一个或多个实施例包括后面将详细说明并在权利要求中特别指出的特征。下面的说明以及附图详细说明某些示例性方面，并且其指示的仅仅是各个实施例的原则可以利用的各种方式中的一些方式。其它的益处和新颖性特征将随着下面的详细说明结合附图考虑而变得明显，所公开的实施例是要包括所有这些方面以及它们的等同。</p>
    <p>[0025]	说明书附图</p>
    <p>[0026]	图1是一种可选的验证授权流程；[0027]	图2是另一种可选的验证授权流程；</p>
    <p>[0028]	图3是另一种可选的验证授权流程；</p>
    <p>[0029]	图4是利用表情进行授权验证的一种可选流程；</p>
    <p>[0030]	图5是利用表情和人脸的组合进行授权验证的一种可选流程；</p>
    <p>[0031]	图6是表情特征提取的一种可选流程；</p>
    <p>[0032]	图7是人脸识别及人脸特征提取的一种可选流程；</p>
    <p>[0033]	图8是一种可选的设备的示意图；</p>
    <p>[0034]	图9是另一种可选的设备的示意图；</p>
    <p>[0035]	图10是另一种可选的设备的示意图。</p>
    <p>具体实施方式</p>
    <p>[0036]	以下描述和附图充分地示出本发明的具体实施方案，以使本领域的技术人员能够实践它们。其他实施方案可以包括结构的、逻辑的、电气的、过程的以及其他的改变。实施例仅代表可能的变化。除非明确要求，否则单独的组件和功能是可选的，并且操作的顺序可以变化。一些实施方案的部分和特征可以被包括在或替换其他实施方案的部分和特征。本发明的实施方案的范围包括权利要求书的整个范围，以及权利要求书的所有可获得的等同物。在本文中，本发明的这些实施方案可以被单独地或总地用术语“发明”来表示，这仅仅是为了方便，并且如果事实上公开了超过一个的发明，不是要自动地限制该应用的范围为任何单个发明或发明构思。</p>
    <p>[0037]	今后的验证授权操作，可以利用一种或多种图形/图像信息作为验证信息或密码。例如可以采用特定的表情作为一种验证信息或密码，也可以同时采用人脸和表情作为验证信息进行多级验证。其它的，本领域技术人员也可以知道，特定的手势、特定的动作、特定的形状以及特定的图案等，都可以作为验证信息或密码。手势和动作的组合、形状和图案的组合、表情和手势的组合、表情和动作的组合等等，也都可以作为验证信息。</p>
    <p>[0038]	当采用某种特定的图形/图像作为验证信息时，需要提前录入该特定的图形/图像信息，并保存为模板。当用户需要获得某种授权时需要输入图形/图像，然后设备需要对用户输入的图形/图像进行识别，并将识别的结果与保存的模板进行匹配。如果匹配成功， 则给予用户授权，否则拒绝授权。</p>
    <p>[0039]	一种可选的验证授权流程如图1所示。采集图像（SlOl)；识别图像中的影像特征（Sl(^)；将影像特征与预先设置的特征模板进行匹配（Sl(XB)；确认匹配后授予权限 (S104)。其中，预先设置的特征模板可以但不限于是表情模板、人脸模板、手势模板、动作模板、形状模板和图案模板中的一个或多个；影像特征可以但不限于是表情特征、人脸特征、 手势特征、动作特征、形状特征和图案特征中的一种或多种。</p>
    <p>[0040]	当采用一种影像特征（例如采用表情、人脸、手势、动作、形状和图案中的一种）作为验证信息或密码时，一种可选的方式是，采用该影像特征与该影像特征模板的欧式距离作为匹配的依据。</p>
    <p>[0041]	当采用多种影像特征（例如采用表情和人脸、手势和动作、形状和图案、表情和手势、表情和动作）作为验证信息或密码时，一种可选的方式是，将识别出的多种影像特征分别与相应的特征模板进行匹配，全部都匹配才能通过验证授予权限。将多种影像特征分别与相应的特征模板进行匹配时，一种可选的方式是，采用各影像特征与其对应的特征模板的欧式距离作为匹配的依据。</p>
    <p>[0042]	图2示出了另一种可选的验证授权流程。采集图像（S201)；提示用户确认输入的信息（S202)；判断用户是否确认输入的信息（S203)；用户确认后，识别图像中的影像特征（S204)；将影像特征与预先设置的特征模板进行匹配620&#190; ；确认匹配后授予权限 (S206)。</p>
    <p>[0043]	图3示出了另一种可选的验证授权流程。采集图像（S301)；发送提示信息，提示用户输入验证信息或正在采集图像630&#190; ；识别图像中的影像特征（S30;3)；将影像特征与预先设置的特征模板进行匹配（S304)；确认匹配后授予权限630&#190;。本领域技术人员可以看出，在图3所示的可选流程中，发送提示信息630&#190;发生在采集图像（S301)的过程中，具体实现时也可以在采集图像前发送提示信息，提示用户输入用于验证的表情、动作、手势、 形状或图案。</p>
    <p>[0044]	本领域技术人员能够知道的另一种可选的验证授权流程，包括：采集图像；发送提示信息，提示用户输入验证信息或正在采集图像；提示并等待用户确认输入的信息；用户确认后识别图像中的影像特征；将影像特征与预先设置的特征模板进行匹配；确认匹配后授予权限。</p>
    <p>[0045]	如果影像特征与预先设置的特征模板不匹配，则未通过验证，拒绝授予权限。拒绝授予权限后，可以不做任何操作；也可以发提示信息，提示用户未通过验证或提示用户再次输入验证信息，再次进行验证。</p>
    <p>[0046]	本领域技术人员可以知道，利用影像信息作为验证信息或密码可以被广泛应用到多种领域。随着消费电子的不断发展，诸如手机、平板电脑（pad)、笔记本电脑、电子书、个人数字助理（PDA)等越来越多的便携设备都具有显示屏幕和图像采集装置，例如前置摄像头和/或后置摄像头。可以利用设备上的图像采集装置，完成对操作该设备的用户的验证授权。</p>
    <p>[0047]	图4示出一种利用表情进行授权验证的流程。采集图像（S401)；识别图像中的人脸信息640&#190; ；提取人脸信息中的表情特征（S40;3)；将获得的表情特征与保存的表情模板进行匹配（S404)；根据匹配结果决定是否授权（S405)。如果匹配，则授予权限（S406)；否则，拒绝授予权限（S407)。</p>
    <p>[0048]	采集图像时，一种可选的方式是在设备的屏幕上显示取景框，取景框尺寸可以由用户设置，例如可以是352X288像素的取景框，这样用户可以将面部图像置于取景框的中央，完成图像采集。另一种可选的方式是，不设置取景框而直接用摄像头采集用户的头像， 这种图像采集方式对于用户来说更随意，不再受到取景框的约束，但可能会增加后面人脸检测的难度。</p>
    <p>[0049]	人脸识别的目地在于检测出所采集图像中包含的人脸。在此，首先必须快速确认所采集的图像来自活体对象；其次需要对图像中的人脸进行基本的快速检测，判断所采集图像是否包含感兴趣区域及完整的感兴趣区域；然后是对包含完整的感兴趣区域的人脸图像进行具体的检测，涉及的基本步骤为图像预处理、人脸轮廓定位、人脸的精确定位、人脸各特征区域的分割等。关于人脸检测的方法，现有的参考模板法、人脸规则法、样品学习法、 肤色模型法以及特征子脸法等，都可供选择使用。[0050]	关于提取人脸表情特征的方法，现有的主元分分析法（PCA)、改进的二维主元分分析法QDPCA)和线性鉴别分析法（LDA)等，都可供选择使用。</p>
    <p>[0051]	有效的表情特征提取将提高匹配验证的准确性，好的表情特征提取结果可以从以下几个方面考虑：</p>
    <p>[0052]	(1)完整的表示出人脸表情的本质特征；</p>
    <p>[0053]	(2)去除噪声、光照及其他与表情无关的干扰信息；</p>
    <p>[0054]	(3)数据表示形式紧凑，避免过高的维数；</p>
    <p>[0055]	(4)不同类别表情的特征之间有较好的区分性。</p>
    <p>[0056]	为获得较好的识别率，一种可选的方式是采集多帧人脸图像，对多帧图像进行配准以获得更高质量的图像，从而降低图像质量恶劣，如光照严重不足、运动模糊严重等场景，带来的不良影响。另一种可选的方式是对采集的图像首先进行快速预处理，如亮度均衡、去除噪声和归一化等处理步骤，并根据预处理的需求调整图像采集设备的相关参数，以减少预处理的计算复杂度、提高图像质量。</p>
    <p>[0057]	亮度均衡处理的作用是对外界光照的过滤，使采集图像的对比度和亮度不依赖于外界光照。亮度均衡处理可以采用直方图均衡技术。</p>
    <p>[0058]	图像去除噪声处理采用中值滤波可以有效消除大量采集图像的噪声，同时去除不必要的高频分量。</p>
    <p>[0059]	归一化处理能够进一步提高图像特征提取的鲁棒性。虽然取景框尺寸固定，但对于不同环境下采集图像由于距离等因素，实际有效可用于特征提取的图像大小必然存在差异，归一化处理可以消除差异对特征提取造成的影响。</p>
    <p>[0060]	提取表情特征后，可以将提取获得的表情特征与保存的表情模板进行匹配。一种可选的方式是，采用欧式距离作为特征匹配的判决依据。</p>
    <p>[0061]	当特征距离的度量值d(F，F*)小于或等于某一阈值(T，即d(F，F*)彡(T，则认为提取出的表情特征与表情模板匹配。预设的距离阈值cT可以通过训练等方式预先确定，也可通过有效的人脸图像进行更新。</p>
    <p>[0062]	其中，d(F,F、= 4{F-F*)TM(F-Ft) ;Λ/(尸-圹广似(F-广)表示加权欧式距离，</p>
    <p>半正定矩阵M为加权矩阵；F表示对采集图像进行处理处理提取的特征描述；F*表示保存的表情模板的特征描述。</p>
    <p>[0063]	d(F,F*)刻画了输入特征与模板特征的匹配度，d (F，F*)越小表示所采集图像与模板越接近。这里矩阵M的选择可通过训练等方式预先确定，也可通过有效的人脸图像进行更新。</p>
    <p>[0064]	下面提出一个通过人的表情完成手机解锁的实施例。</p>
    <p>[0065]	过程可以分为两个阶段，第一阶段是表情特征训练，生成表情模板；第二阶段则是用表情对手机解锁。</p>
    <p>[0066]	在第一阶段，设置手机解锁的密码脸证信息时，手机处于正常工作状态，手机的处理器打开摄像头，将采集的图像显示在手机屏幕上供预览，用户根据屏幕预览调整手机位置，使面部处在图像特征提取区域，并做出一个表情。处理器将采集到的面部表情图像进行特征提取，将表情特征提取的结果储存在存储器作为面部表情特征识别的模板。</p>
    <p>[0067]	在第二阶段，手机处在待机模式并进入锁机状态，屏幕和摄像头处于关闭状态。用户通过按键或其它方式唤醒手机，手机从待机模式进入唤醒模式时依然处于锁机状态，处理器在锁机状态下开启摄像头，并将采集的图像显示在屏幕上供用户预览。用户可以根据屏幕上的预览调整手机位置，使面部处在图像识别区域。图像采集完成后，还可以将采集的图像显示在屏幕上，并发出提示信息，提示用户确认。用户确认后，处理器根据图像识别区域的图像进行人脸检测和表情特征提取。其中，表情特征提取的一种可选方式如图6所示。</p>
    <p>[0068]	步骤S601，对图像中的特征点进行定位并分离各特征子区域；其中，特征子区域包括眼睛、眉毛、嘴巴、脸颊等区域。</p>
    <p>[0069]	步骤S602，对图像的全局特征进行描述；如各特征子区域的相对位置、俯仰角、注视方向等。</p>
    <p>[0070]	步骤S603，对特征子区域进行特征描述。</p>
    <p>[0071]	步骤S604，综合图像的全局特征和特征子区域的特征，形成完整的表情特征描述。</p>
    <p>[0072]	将获得的表情特征和存储器中存储的表情特征进行匹配。如果匹配，则处理器进行解锁操作，授予用户操作手机的权限。如果不匹配，则继续保持锁机状态，拒绝授予用户对手机操作的权限。在不匹配时，处理器还可以通过屏幕显示提示信息，提示用户验证失败；还可以通知用户再次验证。</p>
    <p>[0073]	其中，表情特征可以但不限于是高兴、愤怒、恐惧、悲伤、惊奇或厌恶。</p>
    <p>[0074]	下面提出一个利用表情进行解密的实施例。</p>
    <p>[0075]	过程仍然可以分为两个阶段，第一阶段是表情特征训练，生成表情模板；第二阶段则是用表情进行解密。</p>
    <p>[0076]	在第一阶段，对信息加密时设置用于打开文件的验证信息/密码，手机处于正常工作状态，处理器打开摄像头，将采集的图像显示在手机屏幕上供预览，用户根据屏幕预览调整手机位置，使面部处在图像特征提取区域，并做出一个表情。处理器将采集到的面部表情图像进行特征提取，将表情特征提取的结果储存在存储器作为面部表情特征识别的模板。</p>
    <p>[0077]	在第二阶段，用户对加密信息进行打开操作时，处理器开启摄像头，并将采集的图像显示在屏供用户预览。在采集图像之前或采集图像的过程中，还可以在屏幕上显示提示信息，提示用户正在采集图像。用户可以根据屏幕上的预览调整手机位置，使面部处在图像识别区域。处理器根据图像识别区域采集到的图像进行人脸检测和表情特征提取，并和存储器中存储的表情特征进行匹配。如果匹配，则处理器授予用户打卡加密信息的权限，为用户打开加密信息。如果不匹配，则拒绝授予用户打开加密信息的权限。在不匹配时，处理器还可以通过屏幕显示提示信息，提示用户验证失败；还可以通知用户再次验证。</p>
    <p>[0078]	本领域技术人员能够看出，本发明与现有的设置密码方式都不相同。以图像识别为基础，利用某种影像特征，例如人的表情，作为验证信息/密码，不仅增加了用户与设备之间的交互方式，带来新的用户体验，而且也提高了设备的安全性。上述实施例虽然是以表情为例进行的说明，但本领域技术人员完全可以知道，无论现在还是今后，能利用图像分析 /目标识别等技术识别出来的影像特征都适用于本发明。例如，可以用某种手势作为验证信息/密码，也可以用某个动作、某个图案或某种形状作为验证信息/密码。</p>
    <p>[0079]	例如，用手势作为验证信息/密码，在利用手势识别技术进行验证授权时，现有的模板匹配法(Model/Template Matching)、神经网络法(NN, Neural Network)、动态时间规</p>
    <p>10整法（DTW，Dynamic Time Warping)及隐马尔可夫模型法(HMM, Hidden Markov Model)都可供选择。</p>
    <p>[0080]	除了使用上述单一的影像特征外，也可以用多个影像特征的组合作为验证信息/ 密码。例如，可以用表情和人脸的特征组合，也可以用表情和手势的组合，也可以用手势和动作的组合，也可以用图案和形状的组合，还可以用表情、人脸和手势的组合，等等。鉴于组合的灵活性和多样性，这里只做一些示范性的列举，而不做穷举说明。</p>
    <p>[0081]	利用多个影像特征的组合作为验证信息/密码比用单一的影像特征更加安全，适用于对安全性要求较高的情况。</p>
    <p>[0082]	图5示出一种利用表情和人脸的组合进行授权验证的流程。采集图像（S501)；识别图像中的人脸信息（S502)；提取人脸信息中的表情特征（S503)；将获得的人脸信息和表情特征与保存的人脸模板和表情模板分别进行匹配（S504)；根据匹配结果决定是否授权 650&#190;。如果人脸和表情全部都匹配，则授予权限（S506)；人脸和表情中有一个不匹配，则拒绝授予权限（S507)。</p>
    <p>[0083]	关于人脸识别的方法，现有的参考模板法、人脸规则法、样品学习法、肤色模型法以及特征子脸法等，都可供选择使用。</p>
    <p>[0084]	一种可选的人脸匹配方式是采用欧式距离作为特征匹配的判决依据。</p>
    <p>[0085]	当特征距离的度量值d(E，E*)小于或等于某一阈值d，即d(E，E*) ( d，则认为人脸特征与人脸模板匹配。预设的距离阈值d可以通过训练等方式预先确定，也可通过有效的人脸图像进行更新。</p>
    <p>[0086]其中，圹）=^(E-E*)TN(E-Et)	- E*)TN(E - E*)^示加权欧式距离，</p>
    <p>半正定矩阵N为加权矩阵；E表示对采集图像进行处理提取的特征描述；Ε*表示保存的人脸模板的特征描述。</p>
    <p>[0087]	d(E,E*)刻画了输入特征与模板特征的匹配度，d(E，Ε)越小表示所采集图像与模板越接近。这里矩阵N的选择可通过训练等方式预先确定，也可通过有效的人脸图像进行更新。</p>
    <p>[0088]	本领域技术人员能够看出，采用欧式距离进行特征匹配还适用于除表情、人脸之外的其它影像特征，包括但不限于手势的匹配、动作的匹配、图案的匹配、形状的匹配，等寸。</p>
    <p>[0089]	下面提出一个通过人脸和表情的组合完成手机解锁的实施例。</p>
    <p>[0090]	过程可以分为两个阶段，第一阶段是生成模板；第二阶段是对手机解锁。</p>
    <p>[0091]	在第一阶段，设置手机解锁的密码脸证信息时，手机处于正常工作状态，手机的处理器打开摄像头，将采集的图像显示在手机屏幕上供预览，用户根据屏幕预览调整手机位置，使面部处在图像特征提取区域，并做出一个表情。处理器将采集到的面部表情图像进行特征提取，将面部特征和表情特征提取的结果储存在存储器作为面部和表情特征识别的模板。</p>
    <p>[0092]	在第二阶段，手机处在待机模式并进入锁机状态，屏幕和摄像头处于关闭状态。用户通过按键或其它方式唤醒手机，手机从待机模式进入唤醒模式时依然处于锁机状态，处理器在锁机状态下开启摄像头，并将采集的图像显示在屏幕上供用户预览。用户可以根据屏幕上的预览调整手机位置，使面部处在图像识别区域。图像采集完成后，还可以将采集的图像显示在屏幕上，并发出提示信息，提示用户确认。用户确认后，处理器根据图像识别区域的图像进行人脸识别和表情特征提取，并和存储器中存储的面部特征和表情特征进行匹配。如果匹配，则处理器进行解锁操作，授予用户操作手机的权限。如果不匹配，则继续保持锁机状态，拒绝授予用户对手机操作的权限。在不匹配时，处理器还可以通过屏幕显示提示信息，提示用户验证失败；还可以通知用户再次验证。</p>
    <p>[0093]	下面提出一个利用人脸和表情的组合进行解密的实施例。</p>
    <p>[0094]	过程仍然可以分为两个阶段，第一阶段是生成模板；第二阶段是进行解密。</p>
    <p>[0095]	在第一阶段，对信息加密时设置用于打开文件的验证信息/密码，手机处于正常工作状态，处理器打开摄像头，将采集的图像显示在手机屏幕上供预览，用户根据屏幕预览调整手机位置，使面部处在图像特征提取区域，并做出一个表情。处理器将采集到的面部表情图像进行特征提取，将面部特征和表情特征提取的结果储存在存储器作为面部和表情特征识别的模板。</p>
    <p>[0096]	在第二阶段，用户对加密信息进行打开操作时，处理器开启摄像头，并将采集的图像显示在屏幕上供用户预览。在采集图像之前或采集图像的过程中，还可以在屏幕上显示提示信息，提示用户正在采集图像。用户可以根据屏幕上的预览调整手机位置，使面部处在图像识别区域。处理器根据图像识别区域采集到的图像进行人脸识别和表情特征提取，并和存储器中存储的面部特征和表情特征进行匹配。如果匹配，则处理器授予用户打卡加密信息的权限，为用户打开加密信息。如果不匹配，则拒绝授予用户打开加密信息的权限。在不匹配时，处理器还可以通过屏幕显示提示信息，提示用户验证失败；还可以通知用户再次验证。</p>
    <p>[0097]	其中，人脸识别及人脸特征提取的一种可选方式如图7所示。</p>
    <p>[0098]	步骤S701，对采集的图像进行预处理。包括对图像的有效区域的剪裁、光照一致化、调整图像的亮度和/或色度和/或饱和度等步骤。</p>
    <p>[0099]	步骤S702，判断采集的图像是否符合条件。当符合条件时，执行步骤S703 ；不符合条件时，重新采集图像并回到步骤S701。</p>
    <p>[0100]	步骤S703，从图像的全局信息中提取相关的全局特征信息；从人脸各局部提取相关的局部特征信息。人脸的局部包括眼睛、嘴巴和脸颊等区域。</p>
    <p>[0101]	S704，综合本次图像采集所获取的全局特征信息和局部特征信息，得到人脸特征 fn息ο</p>
    <p>[0102]	判断采集的图像是否符合条件时，可以但不限于从以下几个方面进行判断：</p>
    <p>[0103]	图像是否存在过度曝光、过度的运动模糊等不利于检测的因素；</p>
    <p>[0104]	图像是否来自真实的活体对象；</p>
    <p>[0105]	图像中是否存在人脸，人脸的各局部区域，如眼睛、嘴巴、脸颊等，是否完整。</p>
    <p>[0106]	当图像曝光适度，足够清晰，存在人脸且人脸的各局部区域完整，则可判定采集的图像符合条件。</p>
    <p>[0107]	本领域技术人员能够知道，在本发明中可以静态图像作为验证信息/密码，也可以连续变化的动作、手势、表情等动态图像作为验证信息/密码；既可以二维图像作为验证信息/密码，也可以3维图像作为验证信息/密码；对本发明的保护不应该在这些方面受到限制。[0108]	利用影像信息作为验证信息/密码，相比于现有的文本密码，无疑信息量更为复杂，更难被破解，从而大大提高了系统设备的安全性。在众多的影像信息中，表情、手势、动作、图像、形状等这些信息相比人脸而言具有更多的随机性。例如，人们在设置手机的解锁密码或为重要的信息设置打开密码时，可以随机地选择某种表情、某种动作、某个手势、某个图像和/或某种形状作为密码。如果只打算用人脸信息作为密码，则比较难做到随机选取。当利用这些具有很强的不确定性的影像信息，如表情、动作、手势、图像和/或形状，作为验证信息/密码时，会大大提高恶意破解密码的难度，大幅度提高系统/设备/信息的安全性。</p>
    <p>[0109]	图8示出一种可选的设备的示意图，该设备包括图像采集装置82和处理器81，图像采集装置82将采集的图像发送给处理器81。处理器81中的第一单元811对接收图像中的人脸信息进行识别。第一单元811识别出人脸信息后，第二单元812提取人脸信息中的表情特征，第三单元813将表情特征与预存的表情模板进行匹配。第四单元814根据第三单元813的匹配结果决定是否授予权限。如果表情特征与表情模板匹配，即表情匹配，则第四单元814授予权限；当表情特征与表情模板不匹配时，即表情不匹配时，第四单元814拒绝授权。</p>
    <p>[0110]	图9示出另一种可选的设备的示意图，包括图像采集装置82和处理器91，所述图像采集装置82将采集的图像发送给处理器91。处理器91中的第一单元811对接收图像中的人脸信息进行识别。第一单元811识别出人脸信息后，第二单元812提取人脸信息中的表情特征。第五单元915将人脸信息中的人脸特征和预存的人脸模板进行匹配，第三单元813 将表情特征与预存的表情模板进行匹配。第六单元916根据第三单元813的匹配结果和第五单元915的匹配结果决定是否授予权限。人脸和表情二者都匹配时，即人脸特征和人脸模板匹配且表情特征和表情模板匹配时，第六单元916授予权限。当人脸特征与人脸模板不匹配和/或表情特征与表情模板不匹配时，即人脸和表情有一个不匹配时，第六单元916 拒绝授权。</p>
    <p>[0111]	第一单元811的实现方式多种多样，一种可选的方式是，第一单元811包括以下三个单元：从图像的全局信息中提取相关的全局特征信息的单元；从人脸各局部提取相关的局部特征信息的单元；和，综合全局特征信息和局部特征信息以获得人脸的特征信息的单兀。</p>
    <p>[0112]	第二单元812的实现方式多种多样，一种可选的方式是，第二单元812包括以下三个单元：对图像中的特征点进行定位并分离特征子区域的单元；对图像的全局特征和特征子区域进行特征描述的单元；综合图像的全局特征和特征子区域的特征以获得表情特征的单元。</p>
    <p>[0113]	第三单元813将表情特征与表情模板进行匹配的方式有很多，一种可选的方式是采用表情特征与表情模板的欧式距离作为匹配的依据。通过计算</p>
    <p>广)可以获得表情特征与表情模板的匹配程度。其中，d(F，F*)</p>
    <p>表示特征距离的度量值，^/(F-i^fMiF-广)表示加权欧式距离，半正定矩阵M为加权矩阵；F表示对采集图像进行处理处理提取的特征描述；F*表示保存的表情模板的特征描述。 d(F,F*)越小表示表情特征和表情模板越接近，匹配度越高。当d(F，F*)小于或等于某一阈值cT，即d(F，F*)彡(T，则可以认为表情特征与表情模板匹配。</p>
    <p>[0114]	第五单元915将人脸特征和人脸模板进行匹配的方式有很多，一种可选的方式是采用人脸特征与人脸模板的欧式距离作为匹配的依据。通过计算 i/(五,广五Y "(五-f)可以获得人脸特征与人脸模板的匹配程度。其中，d(E，E*)</p>
    <p>表示特征距离的度量值，五-五&#910;Λ^-五&#906;表示加权欧式距离，半正定矩阵N为加权矩阵；E表示对采集图像进行处理提取的特征描述；Ε*表示保存的人脸模板的特征描述。d(E， E*)刻画了输入特征与模板特征的匹配度，d(E，E*)越小表示所采集图像与模板越接近。当 d(E，E*)小于或等于某一阈值d，即d(E，E*) ^ d，则认为人脸特征与人脸模板匹配。</p>
    <p>[0115]	为获得较好的识别率，一种可选的方式是采集多帧人脸图像，对多帧图像进行配准以获得更高质量的图像，从而降低图像质量恶劣，如光照严重不足、运动模糊严重等场景，带来的不良影响。另一种可选的方式是对采集的图像首先进行快速预处理，如亮度均衡、去除噪声和归一化等处理步骤，并根据预处理的需求调整图像采集设备的相关参数，以减少预处理的计算复杂度、提高图像质量。在这种情况下，处理器中可以增加一个对图像进行预处理的单元，经过预处理的图像被发送到第一单元811，以提高识别率。</p>
    <p>[0116]	为了使用户更加方便，将设备当前的一些操作通知用户，可以在处理器中增加发送提示信息的单元。在图像采集装置82开始采集图像前或采集图像的过程中，该单元可以发送提示信息，提示用户输入验证信息。也可以，在第一单元811识别图像中的人脸信息前发送提示信息，提示用户确认输入的信息。还可以，在第四单元814或第六单元916拒绝授权时发送提示信息，提示用户验证出错或未获授权或再次输入验证信息。</p>
    <p>[0117]	图10示出另一种可选的设备的示意图，包括图像采集装置82和处理器101，图像采集装置82将采集的图像发送给处理器101。处理器101中的影像识别单元1011对接收图像中的影像特征进行识别，匹配单元1012将影像识别单元1011提取的影像特征与预存的特征模板进行匹配，授权单元1013根据匹配单元1012的匹配结果决定是否授予权限。</p>
    <p>[0118]	其中，影像特征包括但不限于是表情特征、人脸特征、手势特征、动作特征、图案特征和形状特征中的一种或多种。同样地，特征模板包括但不限于是表情特征模板、人脸特征模板、手势特征模板、动作特征模板、图案特征模板和形状特征模板中的一种或多种。</p>
    <p>[0119]	影像识别单元1011提取的如果是一种影像特征，例如表情特征、人脸特征、手势特征、动作特征、形状特征或图案特征，一种可选的方式是，匹配单元1012采用该影像特征与该影像特征模板的欧式距离作为匹配的依据。</p>
    <p>[0120]	影像识别单元1011提取的如果是多种影像特征，例如采用表情和人脸、手势和动作、形状和图案、表情和手势、表情和动作等，一种可选的方式是，匹配单元1012将多种影像特征分别与相应的特征模板进行匹配。全部都匹配，才能通过验证授予权限。将多种影像特征分别与相应的特征模板进行匹配时，一种可选的方式是，采用各影像特征与其对应的特征模板的欧式距离作为匹配的依据。</p>
    <p>[0121]	本发明还公开一种移动终端，包括屏幕、摄像头和处理器。摄像头将其采集的图像发送给处理器；屏幕用于显示提示信息和摄像头采集到的图像。其中，处理器可以是前述多种处理器中的任意一种。</p>
    <p>[0122]	除非另外具体陈述，术语比如处理、计算、运算、确定、显示等等可以指一个或更多个处理或者计算系统、或类似设备的动作和/或过程，所述动作和/或过程将表示为处理系统的寄存器或存储器内的物理（如电子）量的数据操作和转换成为类似地表示为处理系统的存储器、寄存器或者其他此类信息存储、发射或者显示设备内的物理量的其他数据。信息和信号可以使用多种不同的技术和方法中的任何一种来表示。例如，在贯穿上面的描述中提及的数据、指令、命令、信息、信号、比特、符号和码片可以用电压、电流、电磁波、磁场或粒子、光场或粒子或者其任意组合来表示。</p>
    <p>[0123]	应该明白，公开的过程中的步骤的特定顺序或层次是示例性方法的实例。基于设计偏好，应该理解，过程中的步骤的特定顺序或层次可以在不脱离本公开的保护范围的情况下得到重新安排。所附的方法权利要求以示例性的顺序给出了各种步骤的要素，并且不是要限于所述的特定顺序或层次。</p>
    <p>[0124]	在上述的详细描述中，各种特征一起组合在单个的实施方案中，以简化本公开。不应该将这种公开方法解释为反映了这样的意图，即，所要求保护的主题的实施方案需要比清楚地在每个权利要求中所陈述的特征更多的特征。相反，如所附的权利要求书所反映的那样，本发明处于比所公开的单个实施方案的全部特征少的状态。因此，所附的权利要求书特此清楚地被并入详细描述中，其中每项权利要求独自作为本发明单独的优选实施方案。</p>
    <p>[0125]	本领域技术人员还应当理解，结合本文的实施例描述的各种说明性的逻辑框、模块、电路和算法步骤均可以实现成电子硬件、计算机软件或其组合。为了清楚地说明硬件和软件之间的可交换性，上面对各种说明性的部件、框、模块、电路和步骤均围绕其功能进行了一般地描述。至于这种功能是实现成硬件还是实现成软件，取决于特定的应用和对整个系统所施加的设计约束条件。熟练的技术人员可以针对每个特定应用，以变通的方式实现所描述的功能，但是，这种实现决策不应解释为背离本公开的保护范围。</p>
    <p>[0126]	用于执行本申请所述功能的通用处理器、数字信号处理器（DSP)、专用集成电路 (ASIC)、现场可编程门阵列（FPGA)或其它可编程逻辑器件、分立门或者晶体管逻辑、分立硬件组件或者其任意组合，可以实现或执行结合本文的实施例所描述的各种说明性的逻辑框图、模块和电路。通用处理器可以是微处理器，或者，该处理器也可以是任何常规的处理器、控制器、微控制器或者状态机。处理器也可能实现为计算设备的组合，例如，DSP和微处理器的组合、多个微处理器、一个或多个微处理器与DSP内核的结合，或者任何其它此种结构。</p>
    <p>[0127]	结合本文的实施例所描述的方法或者算法的步骤可直接体现为硬件、由处理器执行的软件模块或其组合。软件模块可以位于RAM存储器、闪存、ROM存储器、EPROM存储器、 EEPROM存储器、寄存器、硬盘、移动磁盘、CD-ROM或者本领域熟知的任何其它形式的存储介质中。一种示例性的存储介质连接至处理器，从而使处理器能够从该存储介质读取信息，且可向该存储介质写入信息。当然，存储介质也可以是处理器的组成部分。处理器和存储介质可以位于ASIC中。该ASIC可以位于用户终端中。当然，处理器和存储介质也可以作为分立组件存在于用户终端中。</p>
    <p>[0128]	为使本领域内的任何技术人员能够实现或者使用本发明，上面对所公开实施例进行了描述。对于本领域技术人员来说；这些实施例的各种修改方式都是显而易见的，并且本文定义的一般原理也可以在不脱离本公开的精神和保护范围的基础上适用于其它实施例。 因此，本公开并不限于本文给出的实施例，而是与本申请公开的原理和新颖性特征的最广</p>
    <p>15范围相一致。</p>
    <p>[0129]	对于软件实现，本申请中描述的技术可用执行本申请所述功能的模块（例如，过程、函数等）来实现。这些软件代码可以存储在存储器单元并由处理器执行。存储器单元可以实现在处理器内，也可以实现在处理器外，在后一种情况下，它经由各种手段以通信方式耦合到处理器，这些都是本领域中所公知的。</p>
    <p>[0130]	本文描述的各种存储介质表示为用于存储信息的一个或多个设备和/或其它机器可读介质。术语“机器可读介质”包括但不限于能够存储、包含和/或携带指令和/或数据的无线信道和各种其它介质。</p>
    <p>[0131 ] 上文的描述包括一个或多个实施例的举例。当然，为了描述上述实施例而描述部件或方法的所有可能的结合是不可能的，但是本领域普通技术人员应该认识到，各个实施例可以做进一步的组合和排列。因此，本文中描述的实施例旨在涵盖落入所附权利要求书的保护范围内的所有这样的改变、修改和变型。此外，就说明书或权利要求书中使用的术语 “包含”，该词的涵盖方式类似于术语“包括”，就如同“包括，”在权利要求中用作衔接词所解释的那样。此外，使用在权利要求书的说明书中的任何一个术语“或者”是要表示“非排它性的或者”。</p>
    <p>16</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101710383A?cl=zh">CN101710383A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年10月26日</td><td class="patent-data-table-td patent-date-value">2010年5月19日</td><td class="patent-data-table-td ">北京中星微电子有限公司</td><td class="patent-data-table-td ">一种身份认证的方法及认证装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101825947A?cl=zh">CN101825947A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月4日</td><td class="patent-data-table-td patent-date-value">2010年9月8日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">智能控制移动终端的方法、装置及移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20010017584">US20010017584</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2001年2月5日</td><td class="patent-data-table-td patent-date-value">2001年8月30日</td><td class="patent-data-table-td ">Takashi Shinzaki</td><td class="patent-data-table-td ">Mobile electronic apparatus having function of verifying a user by biometrics information</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103207678A?cl=zh">CN103207678A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年4月25日</td><td class="patent-data-table-td patent-date-value">2013年7月17日</td><td class="patent-data-table-td ">深圳市中兴移动通信有限公司</td><td class="patent-data-table-td ">一种电子设备及其解锁方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103259796A?cl=zh">CN103259796A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月15日</td><td class="patent-data-table-td patent-date-value">2013年8月21日</td><td class="patent-data-table-td ">金硕澳门离岸商业服务有限公司</td><td class="patent-data-table-td ">认证系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103269481A?cl=zh">CN103269481A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月13日</td><td class="patent-data-table-td patent-date-value">2013年8月28日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">对便携式电子设备的程序或文件加密保护的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103514389A?cl=zh">CN103514389A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月28日</td><td class="patent-data-table-td patent-date-value">2014年1月15日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">设备认证方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103700151A?cl=zh">CN103700151A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月20日</td><td class="patent-data-table-td patent-date-value">2014年4月2日</td><td class="patent-data-table-td ">天津大学</td><td class="patent-data-table-td ">一种晨跑签到方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103714282A?cl=zh">CN103714282A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月20日</td><td class="patent-data-table-td patent-date-value">2014年4月9日</td><td class="patent-data-table-td ">天津大学</td><td class="patent-data-table-td ">一种互动式的基于生物特征的识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104636734A?cl=zh">CN104636734A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2015年2月28日</td><td class="patent-data-table-td patent-date-value">2015年5月20日</td><td class="patent-data-table-td ">深圳市中兴移动通信有限公司</td><td class="patent-data-table-td ">终端人脸识别方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014044052A1?cl=zh">WO2014044052A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年4月19日</td><td class="patent-data-table-td patent-date-value">2014年3月27日</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">用户验证处理方法、用户设备和服务器</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=ObtYBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0021320000">G06F21/32</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=ObtYBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年6月20日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年3月11日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/4e643482284dbc74ed92/CN102509053A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%94%A8%E4%BA%8E%E9%AA%8C%E8%AF%81%E6%8E%88%E6%9D%83%E7%9A%84%E6%96%B9%E6%B3%95_%E5%A4%84%E7%90%86%E5%99%A8.pdf?id=ObtYBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3RnfqwQQn3g0bkIkKAw6RgyLEQgg"},"sample_url":"https://www.google.com/patents/reader?id=ObtYBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>