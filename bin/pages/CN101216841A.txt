<!DOCTYPE html><html><head><title>专利 CN101216841A - 交互式图像搜索系统和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="交互式图像搜索系统和方法"><meta name="DC.contributor" content="虞正华" scheme="inventor"><meta name="DC.contributor" content="南京搜拍信息技术有限公司" scheme="assignee"><meta name="DC.date" content="2008-1-14" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种图像的搜索系统和方法，是一种交互式图像搜索系统和方法，包括：用户选择物体照片，选定感兴趣区域，选择待识别物体类别，根据用户选择的区域和类别用前景提取方法自动分割前景区域，在前景区域中提取图像特征，根据图像特征在指定类别的图像数据库中寻找匹配图像，根据匹配图像获取相关物体信息，返回匹配图像的相关物体信息给用户。本发明对于任意图像，能够有效的提取图像中物体的信息，从而实现精细的对图像中物体的搜索。同时把目标物体的类别信息结合到图像搜索中，从而有效的提高了搜索精度，降低了运算复杂性。本发明实现了一个基于图像搜索的电子商务系统。"><meta name="DC.date" content="2008-7-9"><meta name="citation_patent_publication_number" content="CN:101216841:A"><meta name="citation_patent_application_number" content="CN:200810019132"><link rel="canonical" href="https://www.google.com/patents/CN101216841A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101216841A?cl=zh"/><meta name="title" content="专利 CN101216841A - 交互式图像搜索系统和方法"/><meta name="description" content="本发明涉及一种图像的搜索系统和方法，是一种交互式图像搜索系统和方法，包括：用户选择物体照片，选定感兴趣区域，选择待识别物体类别，根据用户选择的区域和类别用前景提取方法自动分割前景区域，在前景区域中提取图像特征，根据图像特征在指定类别的图像数据库中寻找匹配图像，根据匹配图像获取相关物体信息，返回匹配图像的相关物体信息给用户。本发明对于任意图像，能够有效的提取图像中物体的信息，从而实现精细的对图像中物体的搜索。同时把目标物体的类别信息结合到图像搜索中，从而有效的提高了搜索精度，降低了运算复杂性。本发明实现了一个基于图像搜索的电子商务系统。"/><meta property="og:title" content="专利 CN101216841A - 交互式图像搜索系统和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101216841A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101216841A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101216841A&amp;usg=AFQjCNEJ0Q6Misb-6Qg9Q4V_5qGe8gRbow" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/47fc51348799755d2d45/CN101216841A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/47fc51348799755d2d45/CN101216841A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101216841A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101216841A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101216841A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN100578508C?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101216841A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种图像的搜索系统和方法，是一种交互式图像搜索系统和方法，包括：用户选择物体照片，选定感兴趣区域，选择待识别物体类别，根据用户选择的区域和类别用前景提取方法自动分割前景区域，在前景区域中提取...</span><span itemprop="url">https://www.google.com/patents/CN101216841A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101216841A - 交互式图像搜索系统和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101216841A - 交互式图像搜索系统和方法" title="专利 CN101216841A - 交互式图像搜索系统和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101216841 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200810019132</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2008年7月9日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2008年1月14日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2008年1月14日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN100578508C?hl=zh-CN&amp;cl=zh">CN100578508C</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200810019132.3, </span><span class="patent-bibdata-value">CN 101216841 A, </span><span class="patent-bibdata-value">CN 101216841A, </span><span class="patent-bibdata-value">CN 200810019132, </span><span class="patent-bibdata-value">CN-A-101216841, </span><span class="patent-bibdata-value">CN101216841 A, </span><span class="patent-bibdata-value">CN101216841A, </span><span class="patent-bibdata-value">CN200810019132, </span><span class="patent-bibdata-value">CN200810019132.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%99%9E%E6%AD%A3%E5%8D%8E%22">虞正华</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8D%97%E4%BA%AC%E6%90%9C%E6%8B%8D%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">南京搜拍信息技术有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101216841A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101216841A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101216841A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (19),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (4),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200810019132&amp;usg=AFQjCNHBxevee_9ki5K5-9iQPscsDxJodw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101216841A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFOnsKfrCKuZjr5XLhZSBbbQq9HrQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT70727740" lang="ZH" load-source="patent-office">交互式图像搜索系统和方法</invention-title>
      </span><br><span class="patent-number">CN 101216841 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA38497428" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种图像的搜索系统和方法，是一种交互式图像搜索系统和方法，包括：用户选择物体照片，选定感兴趣区域，选择待识别物体类别，根据用户选择的区域和类别用前景提取方法自动分割前景区域，在前景区域中提取图像特征，根据图像特征在指定类别的图像数据库中寻找匹配图像，根据匹配图像获取相关物体信息，返回匹配图像的相关物体信息给用户。本发明对于任意图像，能够有效的提取图像中物体的信息，从而实现精细的对图像中物体的搜索。同时把目标物体的类别信息结合到图像搜索中，从而有效的提高了搜索精度，降低了运算复杂性。本发明实现了一个基于图像搜索的电子商务系统。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM5929685" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.交互式图像搜索系统，其特征在于：包括以下模块：    图像采集模块，用于采集需要搜索的物体的图像；    用户选择模块，用户选择图像的感兴趣区域和待识别物体类别；    图像分割模块，根据用户选择的区域和类别用前景提取方法自动分割前景区域；    特征提取模块，在前景区域中提取图像特征；    通讯模块，包括互联网或无线网络，在客户端和服务器之间传递信息；    图像检索模块，根据图像特征在指定类别的图像数据库中寻找匹配图像，根据匹配图像获取相关物体的信息；    数据库，存储图像特征向量和物体信息；    结果显示模块，返回匹配图像和相关物体信息给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. 如权利要求1所述的交互式图像搜索系统，其特征在于：所 述图像采集模块包括商品采集子模块，用于采集需要搜索的商品的图</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. 如权利要求1或2所述的交互式图像搜索系统，其特征在于: 所述图像检索模块包括商品图像检索子模块，根据商品图像特征在指 定类别的图像数据库中寻找匹配商品图像，根据商品匹配图像获取商 品的描述，价格，地址的超链接。</div>
    </div>
    </div> <div class="claim"> <div num="4" class="claim">
      <div class="claim-text">4. 交互式图像搜索方法，其特征在于：包括以下步骤：① 用户选择搜索图片；② 选定搜索照片的感兴趣区域；③ 选择待识别物体类别；④ 根据用户选择的搜索图片的区域和物品的类别用前景提取方法自动分割前景区域；⑤ 在前景区域中提取图像特征向量；⑥ 根据图像特征在指定类别的图像数据库中寻找匹配图像；⑦ 根据匹配图像获取相关物体信息；⑧ 返回匹配图像的相关物体信息给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述步骤①中，搜索图片的获得方法为通过图像采集设备拍摄图片或在 已有的图片库中找到图片。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述步骤②中，在图片上选定感兴趣区域的实现方法为用户通过一个输 入设备控制在感兴趣的区域上面拉一个框、用户通过一个语音输入控 制指令在感兴趣的区域上面拉一个框或用户通过一个输入设备控制 一个区域选择功能单元选择感兴趣的区域和/或不感兴趣的区域和/ 或未知的区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述步骤④中，前景提取方法为首先初始化划分图像区域，然后对所划 分的区域建立统计模型，通过优化代价函数来完成前景和背景的划 分；所述图像区域初始化划分的方法为：初始化为前景和未知两个区 域、初始化为背景和未知两个区域或初始化为前景，背景和未知三个 区域；所述代价函数至少包括区域因素、边缘因素和形状因素中的一 个因素；所述的优化方法为基于图分割方法或者基于马可夫随机场方 法。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述步骤⑤中，特征向量可以包括颜色特征向量，纹理特征向量，及形状特征向量；所述颜色特征向量的实现方法为：采用颜色直方图的方 式或采用MPEG-7标准中的主颜色描述符；所述纹理特征向量的实现 方法为：MPEG-7标准中的边缘直方图描述符或局部二值纹理；所述 形状特征向量的实现方法为：采用MPEG-7标准中的曲率尺度空间或 者边缘直方图描述符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述步骤⑥中，寻找匹配图像的方法为：采用最近邻方法在数据库中寻 找与输入图像综合距离最接近的图像，综合距离包括颜色，纹理，及 形状三方面的信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. 如权利要求4所述的交互式图像搜索方法，其特征在于：所 述物体为商品，所述物体信息包括商品的描述，价格，地址的超链接。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES10637957" lang="ZH" load-source="patent-office" class="description">
    <p>交互式图像搜索系统和方法技术领域本发明涉及一种图像的搜索系统和方法,具体的说是一种交互式 图像搜索系统和方法。 背景技术随着互联网的发展，搜索引擎已经成为重要的信息获取和商品营 销工具。传统信息搜索方式是使用文字进行搜索，这方面的例子包括谷歌（Google),百度等。然而，只用文字进行搜索难以描述复杂的 图像信息，所以下一代信息搜索方式必然需要图像搜索。图像搜索系统的基本原理是通过计算机分析图像的视觉特征而 构建搜索用的数据库，从而实现检索。传统的图像搜索方法采用对整 张图片分析的方法，这样做适合粗略的搜索，例如区分蓝天，海滩， 树林的照片。但是这样做无法实现更精细的搜索，例如搜索图像中的 某个物体。而从实际应用来说，能够搜索图像中的物体具有重要得多 的应用价值。搜索图像中的物体可以通过先对图像进行分割，然后分析分割区 域的方式实现。然而，对任意图像进行完全自动的分割是个很困难的 问题。目前已有的系统，采用完全自动分割的方法，尚无法比较理想 的提取某个物体的完整区域。目前的分割方法经常会把一个物体划分 为很多个区域，这样难以实现精细的对图像中物体的搜索。另外，传 统的图像搜索方法对搜索物体的类别通常是未知的，这样搜索的困难 较大，搜索精确度比较低，而且运算量高。 发明内容本发明的目的在于提出一种可以提高精度，降低运算复杂性的交 互式图像搜索系统和方法。本发明的目的可以通过以下技术方案来实现： 交互式图像搜索系统，包括以下模块： 图像采集模块，用于采集需要搜索的物体的图像；用户选择模块，用户选择图像的感兴趣区域和待识别物体类别；图像分割模块，根据用户选择的区域和类别用前景提取方法自动分割前景区域；特征提取模块，在前景区域中提取图像特征；通讯模块，包括互联网或无线网络，在客户端和服务器之间传递 f曰息；图像检索模块，根据图像特征在指定类别的图像数据库中寻找匹配图像，根据匹配图像获取相关物体的信息； 数据库，存储图像特征向量和物体信息； 结果显示模块，返回匹配图像和相关物体信息给用户。 交互式图像搜索方法，包括以下步骤-① 用户选择搜索图片；② 选定搜索照片的感兴趣区域；③ 选择待识别物体类别；④ 根据用户选择的搜索图片的区域和物品的类别用前景提取方 法自动分割前景区域；⑤ 在前景区域中提取图像特征向量；⑥ 根据图像特征在指定类别的图像数据库中寻找匹配图像；⑦ 根据匹配图像获取相关物体信息；⑧ 返回匹配图像的相关物体信息给用户。本发明的目的还可以通过以下技术措施来进一步实现： 前述的交互式图像搜索系统，其中所述图像采集模块包括商品采集子模块，用于采集需要搜索的商品的图像。前述的交互式图像搜索系统，其中所述图像检索模块包括商品图像检索子模块，根据商品图像特征在指定类别的图像数据库中寻找匹配商品图像，根据商品匹配图像获取商品的描述，价格，地址的超链接。前述的交互式图像搜索方法，其中所述步骤①中，搜索图片的获 得方法为通过图像采集设备拍摄图片或在己有的图片库中找到图片。前述的交互式图像搜索方法，其中所述步骤②中，在图片上选定 感兴趣区域的实现方法为用户通过一个输入设备控制在感兴趣的区 域上面拉一个框、用户通过一个语音输入控制指令在感兴趣的区域上 面拉一个框或用户通过一个输入设备控制一个区域选择功能单元选 择感兴趣的区域和/或不感兴趣的区域和/或未知的区域。前述的交互式图像搜索方法，其中所述步骤④中，前景提取方法 为首先初始化划分图像区域，然后对所划分的区域建立统计模型，通 过优化代价函数来完成前景和背景的划分；所述图像区域初始化划分 的方法为：初始化为前景和未知两个区域、初始化为背景和未知两个 区域或初始化为前景，背景和未知三个区域；所述代价函数至少包括 区域因素、边缘因素和形状因素中的一个因素；所述的优化方法为基 于图分割方法或者基于马可夫随机场方法。前述的交互式图像搜索方法，其中所述步骤⑤中，特征向量可以 包括颜色特征向量，纹理特征向量，及形状特征向量；所述颜色特征 向量的实现方法为：采用颜色直方图的方式或采用MPEG-7标准中的 主颜色描述符；所述纹理特征向量的实现方法为：MPEG-7标准中的边缘直方图描述符或局部二值纹理；所述形状特征向量的实现方法 为：采用MPEG-7标准中的曲率尺度空间或者边缘直方图描述符。前述的交互式图像搜索方法，其中所述步骤⑥中，寻找匹配图像 的方法为：采用最近邻方法在数据库中寻找与输入图像综合距离最接 近的图像，综合距离包括颜色，纹理，及形状三方面的信息。前述的交互式图像搜索方法，其中所述物体为商品，物体信息包 括商品的描述，价格，地址的超链接。本发明的优点为：本发明的一个主要优点是实现了基于目标物体的图像搜索，从而大大提高了图像搜索的应用范围。本发明的另一个 主要优点是把用户的交互和搜索目标物体的提取紧密结合起来，从而 可以更准确的提取目标物体特征，更准确的获取搜索的信息。另外本 发明把目标物体的类别信息结合到图像搜索中，从而有效的提高了搜 索精度，降低了运算复杂性。本发明的另一个主要优点是实现了一个 基于图像搜索的电子商务系统。 附图说明图1为实施例一的交互式图像搜索系统框图。图2为实施例二的交互式图像搜索系统框图。 图3为实施例五的交互式图像搜索方法流程图。 图4为实施例六的交互式图像搜索方法流程图。具体实施方式实施例一本实施例为一种交互式图像搜索系统，其框图如图l所示，包括 客户端和服务器两部分。客户端可以是一个计算机终端，或是一个手机。包括以下模块：图像采集模块，可以有多种实现，比如通过相机拍摄图片，或者在计算机内的图片库中找到一张图片，等等。用户选择模块，以选择图片的感兴趣区域和待识别物体类别。 图像分割和特征提取模块，功能是根据用户选择的区域和类别用前景提取方法自动分割前景区域，然后在前景区域中提取图像特征。 通讯模块，包括互联网或无线网络，用以在客户端和服务器之间传递信息。图像检索模块，功能是根据图像特征在指定类别的图像数据库中 寻找匹配图像，根据匹配图像获取相关物体的信息。 数据库，存储图像特征向量和物体信息。结果显示模块，功能是返回匹配图像和相关物体信息显示给用户。实施例二本实施例为另一种交互式图像搜索系统，其框图如图2所示，包 括客户端和服务器两部分。客户端可以是一个计算机终端，或是一个 手机。包括以下模块-图像采集模块，可以有多种实现，比如通过相机拍摄图片，或者 在计算机内的图片库中找到一张图片，等等。用户选择模块，以选择图片的感兴趣区域和待识别物体类别。图像分割和特征提取模块，功能是根据用户选择的区域和类别用 前景提取方法自动分割前景区域，然后在前景区域中提取图像特征。通讯模块，包括互联网或无线网络，用以在客户端和服务器之间 传递信息。图像检索模块，功能是根据图像特征在指定类别的图像数据库中 寻找匹配图像，根据匹配图像获取相关物体的信息。 数据库，存储图像特征向量和物体信息。结果显示模块，功能是返回匹配图像和相关物体信息显示给用户。实施例三本实施例为利用本发明的交互式图像搜索系统的电子商务信息 检索系统，框图同系统框图l所示，包括客户端和服务器两部分。客 户端可以是一个计算机终端，或是一个手机。包括以下模块：图像采集模块，可以有多种实现，比如通过相机拍摄商品图片， 或者在计算机内的图片库中找到一张商品图片，等等。用户选择模块，以选择图片的感兴趣区域和待识别商品类别。图像分割和特征提取模块，功能是根据用户选择的区域和类别用 前景提取方法自动分割前景区域，然后在前景区域中提取图像特征。通讯模块，包括互联网或无线网络，用以在客户端和服务器之间 传递信息。图像检索模块，功能是根据图像特征在指定类别的图像数据库中 寻找匹配图像，根据匹配图像获取相关商品的信息。 数据库，存储图像特征向量和商品信息。结果显示模块，功能是返回匹配图像和相关商品信息显示给用户。实施例四本实施例为利用本发明的交互式图像搜索系统的另一种电子商 务信息检索系统，框图同系统框图2所示，包括客户端和服务器两部 分。客户端可以是一个计算机终端，或是一个手机。包括以下模块：图像采集模块，可以有多种实现，比如通过相机拍摄商品图片， 或者在计算机内的图片库中找到一张商品图片，等等。用户选择模块，以选择图片的感兴趣区域和待识别商品类别。图像分割和特征提取模块，功能是根据用户选择的区域和类别用 前景提取方法自动分割前景区域，然后在前景区域中提取图像特征。通讯模块，包括互联网或无线网络，用以在客户端和服务器之间 传递信息。图像检索模块，功能是根据图像特征在指定类别的图像数据库中 寻找匹配图像，根据匹配图像获取相关商品的信息。 数据库，存储图像特征向量和商品信息。结果显示模块，功能是返回匹配图像和相关商品信息显示给用户。实施例五本实施例为交互式图像搜索方法，其流程如图3所示，按以下步骤进行：用户首先选择待搜索的商品照片，该图片的获得可以有多种方 法，比如通过相机拍摄图片，或者在计算机内的图片库中找到一张图 片，等等。然后用户在图片上选择选定感兴趣的区域，这个有很多种实现方 法。 一种方法是用户通过一个输入设备（如鼠标，触摸屏）控制在感 兴趣的区域上面拉一个框。另一种方法是用户通过一个语音输入控制 指令在感兴趣的区域上面拉一个框。另一种方法是用户通过一个输入 设备（如鼠标，触摸屏）控制一个刷子选择感兴趣的区域（前景区域) 和不感兴趣的区域（背景区域）。下面一个步骤是用户选择待识别商品的类别。比如，在一个服饰 类电子商务应用中，用户可以选择手提包，双肩包等类别。这些类别 集合的设定可以预先确定好。然后，根据用户选择的区域和类别，采用前景提取的方法自动分割前景区域。有很多的自动前景提取的方法可以采用，然而传统的前 景提取的方法是独立进行的，与用户的输入无关。本发明中的自动提 取方法结合了用户选择的区域和类别信息到前景提取过程中。具体来 说，本方法把图像中的点分为前景和背景两个区域，通过一个优化方 法来完成最终的前景和背景划分。最初用户的输入可以用来初始化划 分： 一种方法是初始化为前景和未知两个区域；另一种方法是初始化 为背景和未知两个区域；另一种方法是初始化为前景，背景和未知三 个区域。然后，对这些区域的点建立统计模型，而最终的前景和背景 的划分可以通过一个优化方法来完成。优化的代价函数可以包括以下 三个因素的部分或全部：区域因素，边缘因素，形状因素。区域因素 考虑所有的点和统计模型的匹配的合理性（例如，可以对前景和背景 分别建立高斯混合模型G画，然后统计所有的点符合这些高斯混合模 型的概率；或者前景和背景分别建立直方图，然后统计所有的点符合 这些直方图的概率）。边缘因素惩罚的是相近邻点的不联系性，比如 说，如果相近邻两个点颜色接近，那他们应该被分到同一个区域。这 个惩罚项也可以和两个点的距离有关，距离越远惩罚越轻。惩罚项可 以和局部的灰度的梯度，拉普拉斯过零检测，梯度方向，几何特性等 因素有关。形状因素考虑的是前景区域与用户选择的类别的合理性。 优化可以采用图分割（Graph Cut)用Maxflow方法求解或者用马可 夫随机场的方法求解。在图像分割以后，在前景区域中提取商品的图像特征，提取的特 征向量可以包括颜色，纹理，及形状等特征向量。颜色特征向量可以 用多种方法实现。 一种方法是采用直方图的方式。对于输入的彩色图 像（通常包括红，绿，蓝三种颜色），首先转化为HSV (色相、饱和 度和亮度）色度空间，然后建立166个分组的直方图。另一种方法可以采用MPEG-7标准中的主颜色描述符（Dominant Color Descriptor) 实现。纹理特征可以用多种方法实现， 一种方法是MPEG-7标准中的 边缘直方图描述符（Edge Histogram Descriptor);另一种方法是局 部二值纹理（Local Binary Pattern)。形状特征可以用多种方法实 现， 一种方法采用MPEG-7标准中的曲率尺度空间（Curvature scale space)实现。根据输入的图像特征和商品类别，在指定类别的图像数据库中寻 找匹配图像。这个寻找可以采用最近邻方法在数据库中寻找与输入图 像综合距离最接近的图像，综合距离包括颜色，纹理，及形状三方面 的信息，综合的方式可以有多种，可以是线性加权的，也可以是非线 性加权等。根据最优的若干匹配图像结果，在数据库中获取与查找的商品相 关的信息，这些信息可以包括商品的描述，价格，购买地址的超链接等。最后返回匹配图像和相关商品的信息给用户，这个结果可以在一 个手机或者一个计算机上显示。 实施例六本实施例为利用本发明的交互式图像搜索方法的电子商务图像 搜索方法，其流程如图4所示，按以下步骤进行：用户首先选择待搜索的商品照片，该图片的获得可以有多种方 法，比如通过相机拍摄图片，或者在计算机内的图片库中找到一张图 片，等等。然后用户在图片上选择选定感兴趣的区域，这个有很多种实现方 法。 一种方法是用户通过一个输入设备（如鼠标，触摸屏）控制在感 兴趣的区域上面拉一个框。另一种方法是用户通过一个语音输入控制指令在感兴趣的区域上面拉一个框。另一种方法是用户通过一个输入 设备（如鼠标，触摸屏）控制一个刷子选择感兴趣的区域（前景区域) 和不感兴趣的区域（背景区域）。下面一个步骤是用户选择待识别商品的类别。比如，在一个服饰 类电子商务应用中，用户可以选择手提包，双肩包等类别。这些类别 集合的设定可以预先确定好。然后，根据用户选择的区域和类别，采用前景提取的方法自动分 割前景区域。有很多的自动前景提取的方法可以采用，然而传统的前 景提取的方法是独立进行的，与用户的输入无关。本发明中的自动提 取方法结合了用户选择的区域和类别信息到前景提取过程中。具体来 说，本方法把图像中的点分为前景和背景两个区域，通过一个优化方 法来完成最终的前景和背景划分。最初用户的输入可以用来初始化划 分： 一种方法是初始化为前景和未知两个区域；另一种方法是初始化 为背景和未知两个区域；另一种方法是初始化为前景，背景和未知三 个区域。然后，对这些区域的点建立统计模型，而最终的前景和背景 的划分可以通过一个优化方法来完成。优化的代价函数可以包括以下 三个因素的部分或全部：区域因素，边缘因素，形状因素。区域因素 考虑所有的点和统计模型的匹配的合理性（例如，可以对前景和背景 分别建立高斯混合模型GMM，然后统计所有的点符合这些高斯混合模 型的概率；或者前景和背景分别建立直方图，然后统计所有的点符合 这些直方图的概率）。边缘因素惩罚的是相近邻点的不联系性，比如 说，如果相近邻两个点颜色接近，那他们应该被分到同一个区域。这 个惩罚项也可以和两个点的距离有关，距离越远惩罚越轻。惩罚项可 以和局部的灰度的梯度，拉普拉斯过零检测，梯度方向，几何特性等 因素有关。形状因素考虑的是前景区域与用户选择的类别的合理性。优化可以采用图分割（Graph Cut)用Maxflow方法求解或者用马可 夫随机场的方法求解。在图像分割以后，在前景区域中提取商品的图像特征，提取的特 征向量可以包括颜色，纹理，及形状等特征向量。颜色特征向量可以 用多种方法实现。 一种方法是采用直方图的方式。对于输入的彩色图 像（通常包括红，绿，蓝三种颜色），首先转化为HSV (色相、饱和 度和亮度）色度空间，然后建立166个分组的直方图。另一种方法可 以采用MPEG-7标准中的主颜色描述符（Dominant Color Descriptor) 实现。纹理特征可以用多种方法实现， 一种方法是MPEG-7标准中的 边缘直方图描述符（Edge Histogram Descriptor);另一种方法是局 部二值纹理（（Local Binary Pattern))。形状特征可以用多种方法 实现，一种方法采用MPEG-7标准中的曲率尺度空间（Curvature scale space)实现。根据输入的图像特征和商品类别，在指定类别的图像数据库中寻 找匹配图像。这个寻找可以采用最近邻方法在数据库中寻找与输入图 像综合距离最接近的图像，综合距离包括颜色，纹理，及形状三方面 的信息，综合的方式可以有多种，可以是线性加权的，也可以是非线 性加权等。根据最优的若干匹配图像结果，在数据库中获取与&#26619;找的商品相 关的信息，这些信息可以包括商品的描述，价格，购买地址的超链接 等。最后返回匹配图像和相关商品的信息给用户，这个结果可以在一 个手机或者一个计算机上显示。本发明还可以有其它实施方式，凡采用同等替换或等效变换形成 的技术方案，均落在本发明要求的保护范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101340661B?cl=zh">CN101340661B</a></td><td class="patent-data-table-td patent-date-value">2008年8月14日</td><td class="patent-data-table-td patent-date-value">2011年12月28日</td><td class="patent-data-table-td ">北京中星微电子有限公司</td><td class="patent-data-table-td ">实现导游控制的移动设备和服务器以及导游控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101676953B?cl=zh">CN101676953B</a></td><td class="patent-data-table-td patent-date-value">2009年8月24日</td><td class="patent-data-table-td patent-date-value">2012年8月29日</td><td class="patent-data-table-td ">奥多比公司</td><td class="patent-data-table-td ">自动视频图像分割</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101853299A?cl=zh">CN101853299A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月31日</td><td class="patent-data-table-td patent-date-value">2010年10月6日</td><td class="patent-data-table-td ">杭州淘淘搜科技有限公司</td><td class="patent-data-table-td ">一种基于感性认知的图像检索结果排序方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101963991A?cl=zh">CN101963991A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2011年2月2日</td><td class="patent-data-table-td ">辜进荣</td><td class="patent-data-table-td ">图片准确搜索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102298499A?cl=zh">CN102298499A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月15日</td><td class="patent-data-table-td patent-date-value">2011年12月28日</td><td class="patent-data-table-td ">盛乐信息技术（上海）有限公司</td><td class="patent-data-table-td ">确定虚拟道具的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102375867A?cl=zh">CN102375867A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年7月25日</td><td class="patent-data-table-td patent-date-value">2012年3月14日</td><td class="patent-data-table-td ">株式会社泛泰</td><td class="patent-data-table-td ">使用过滤信息来识别对象的装置和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102422319A?cl=zh">CN102422319A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年3月3日</td><td class="patent-data-table-td patent-date-value">2012年4月18日</td><td class="patent-data-table-td ">公立大学法人大阪府立大学</td><td class="patent-data-table-td ">图像检索方法、图像检索程序和图像登记方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102422319B?cl=zh">CN102422319B</a></td><td class="patent-data-table-td patent-date-value">2010年3月3日</td><td class="patent-data-table-td patent-date-value">2014年4月30日</td><td class="patent-data-table-td ">公立大学法人大阪府立大学</td><td class="patent-data-table-td ">图像检索方法和图像存储方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102446272A?cl=zh">CN102446272A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月5日</td><td class="patent-data-table-td patent-date-value">2012年5月9日</td><td class="patent-data-table-td ">Tcl集团股份有限公司</td><td class="patent-data-table-td ">一种台标分割及识别的方法、装置及电视机</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102687140B?cl=zh">CN102687140B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月30日</td><td class="patent-data-table-td patent-date-value">2016年3月16日</td><td class="patent-data-table-td ">诺基亚技术有限公司</td><td class="patent-data-table-td ">用于有助于基于内容的图像检索的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102842190A?cl=zh">CN102842190A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月25日</td><td class="patent-data-table-td patent-date-value">2012年12月26日</td><td class="patent-data-table-td ">东芝泰格有限公司</td><td class="patent-data-table-td ">结账装置及商品销售数据处理方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102842190B?cl=zh">CN102842190B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月25日</td><td class="patent-data-table-td patent-date-value">2015年12月2日</td><td class="patent-data-table-td ">东芝泰格有限公司</td><td class="patent-data-table-td ">结账装置及商品销售数据处理方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102968473A?cl=zh">CN102968473A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td patent-date-value">2013年3月13日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">基于人脸图像的信息检索方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103258012A?cl=zh">CN103258012A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年4月16日</td><td class="patent-data-table-td patent-date-value">2013年8月21日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种获取图片信息的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103295219A?cl=zh">CN103295219A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月2日</td><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">北京数码视讯科技股份有限公司</td><td class="patent-data-table-td ">图像分割的方法与装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103369352A?cl=zh">CN103369352A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年4月10日</td><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">云联（北京）信息技术有限公司</td><td class="patent-data-table-td ">一种实现视频搜索和点播的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8402050">US8402050</a></td><td class="patent-data-table-td patent-date-value">2011年2月24日</td><td class="patent-data-table-td patent-date-value">2013年3月19日</td><td class="patent-data-table-td ">Pantech Co., Ltd.</td><td class="patent-data-table-td ">Apparatus and method for recognizing objects using filter information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014183591A1?cl=zh">WO2014183591A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年5月9日</td><td class="patent-data-table-td patent-date-value">2014年11月20日</td><td class="patent-data-table-td ">Beijing Jingdong Shangke Information Technology Co, Ltd.</td><td class="patent-data-table-td ">一种提供图像的方法和服务器装置以及终端装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015027787A1?cl=zh">WO2015027787A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年7月31日</td><td class="patent-data-table-td patent-date-value">2015年3月5日</td><td class="patent-data-table-td ">Baidu Online Network Technology (Beijing) Co., Ltd.</td><td class="patent-data-table-td ">在触屏设备中进行检索的方法和装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0007000000">G06T7/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009620000">G06K9/62</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=chFeBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009460000">G06K9/46</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2008年7月9日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2008年9月3日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年9月23日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年9月23日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SHANGHAI BOKANG INTELLIGENT INFORMATION TECHNOLOGY</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: NANJING SOUPAI INFORMATION TECHNOLOGY CO., LTD.</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090821</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年1月6日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/47fc51348799755d2d45/CN101216841A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%9B%BE%E5%83%8F%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%92%8C%E6%96%B9%E6%B3%95.pdf?id=chFeBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3pS1Sw51OSuM-eXWti-0l2fFmVlw"},"sample_url":"https://www.google.com/patents/reader?id=chFeBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>