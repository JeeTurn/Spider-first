<!DOCTYPE html><html><head><title>专利 CN102375867A - 使用过滤信息来识别对象的装置和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="使用过滤信息来识别对象的装置和方法"><meta name="DC.contributor" content="朴喜靖" scheme="inventor"><meta name="DC.contributor" content="朴赞熙" scheme="inventor"><meta name="DC.contributor" content="李美那" scheme="inventor"><meta name="DC.contributor" content="李荣宰" scheme="inventor"><meta name="DC.contributor" content="梁珍模" scheme="inventor"><meta name="DC.contributor" content="金亨基" scheme="inventor"><meta name="DC.contributor" content="金南锡" scheme="inventor"><meta name="DC.contributor" content="金昶焕" scheme="inventor"><meta name="DC.contributor" content="株式会社泛泰" scheme="assignee"><meta name="DC.date" content="2011-7-25" scheme="dateSubmitted"><meta name="DC.description" content="一种使用过滤信息的对象识别方法，该方法包括：获取包括感兴趣的对象的对象图像信息；获取用于从对象图像信息中识别感兴趣的对象的过滤信息；以及使用过滤信息来识别感兴趣的对象。一种使用过滤信息的对象识别装置，该装置包括：对象信息获取单元，用于获取包括感兴趣的对象的对象图像信息；过滤信息输入单元，用于获取过滤信息；输出单元，用于输出图像信息和过滤信息；以及控制器，用于使用过滤信息来识别对象图像信息中的感兴趣的对象。"><meta name="DC.date" content="2012-3-14"><meta name="DC.relation" content="CN:101216841:A" scheme="references"><meta name="DC.relation" content="CN:101976461:A" scheme="references"><meta name="DC.relation" content="CN:102436663:A" scheme="references"><meta name="DC.relation" content="CN:1674035:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:102375867:A"><meta name="citation_patent_application_number" content="CN:201110208965"><link rel="canonical" href="https://www.google.com/patents/CN102375867A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102375867A?cl=zh"/><meta name="title" content="专利 CN102375867A - 使用过滤信息来识别对象的装置和方法"/><meta name="description" content="一种使用过滤信息的对象识别方法，该方法包括：获取包括感兴趣的对象的对象图像信息；获取用于从对象图像信息中识别感兴趣的对象的过滤信息；以及使用过滤信息来识别感兴趣的对象。一种使用过滤信息的对象识别装置，该装置包括：对象信息获取单元，用于获取包括感兴趣的对象的对象图像信息；过滤信息输入单元，用于获取过滤信息；输出单元，用于输出图像信息和过滤信息；以及控制器，用于使用过滤信息来识别对象图像信息中的感兴趣的对象。"/><meta property="og:title" content="专利 CN102375867A - 使用过滤信息来识别对象的装置和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102375867A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102375867A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102375867A&amp;usg=AFQjCNEg0U4BSOLoRoGvf1n4w9TnEvQUPQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/0dd6a1fb502c406a99c6/CN102375867A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/0dd6a1fb502c406a99c6/CN102375867A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102375867A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102375867A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102375867A?cl=zh" style="display:none"><span itemprop="description">一种使用过滤信息的对象识别方法，该方法包括：获取包括感兴趣的对象的对象图像信息；获取用于从对象图像信息中识别感兴趣的对象的过滤信息；以及使用过滤信息来识别感兴趣的对象。一种使用过滤信息的对象识别装置，...</span><span itemprop="url">https://www.google.com/patents/CN102375867A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102375867A - 使用过滤信息来识别对象的装置和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102375867A - 使用过滤信息来识别对象的装置和方法" title="专利 CN102375867A - 使用过滤信息来识别对象的装置和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102375867 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110208965</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年3月14日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年7月25日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年8月13日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP2418606A2?hl=zh-CN&amp;cl=zh">EP2418606A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2418606A3?hl=zh-CN&amp;cl=zh">EP2418606A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8402050?hl=zh-CN&amp;cl=zh">US8402050</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120041971?hl=zh-CN&amp;cl=zh">US20120041971</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130163878?hl=zh-CN&amp;cl=zh">US20130163878</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110208965.6, </span><span class="patent-bibdata-value">CN 102375867 A, </span><span class="patent-bibdata-value">CN 102375867A, </span><span class="patent-bibdata-value">CN 201110208965, </span><span class="patent-bibdata-value">CN-A-102375867, </span><span class="patent-bibdata-value">CN102375867 A, </span><span class="patent-bibdata-value">CN102375867A, </span><span class="patent-bibdata-value">CN201110208965, </span><span class="patent-bibdata-value">CN201110208965.6</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9C%B4%E5%96%9C%E9%9D%96%22">朴喜靖</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9C%B4%E8%B5%9E%E7%86%99%22">朴赞熙</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E7%BE%8E%E9%82%A3%22">李美那</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E8%8D%A3%E5%AE%B0%22">李荣宰</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%A2%81%E7%8F%8D%E6%A8%A1%22">梁珍模</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%87%91%E4%BA%A8%E5%9F%BA%22">金亨基</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%87%91%E5%8D%97%E9%94%A1%22">金南锡</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%87%91%E6%98%B6%E7%84%95%22">金昶焕</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE%E6%B3%9B%E6%B3%B0%22">株式会社泛泰</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102375867A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102375867A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102375867A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (7),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110208965&amp;usg=AFQjCNHLpmelnUcZ7wN4SbaYf4H0ITR26Q"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102375867A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHRuOB-BuIAoCx0PxAA2xF_wN3XoQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT112041834" lang="ZH" load-source="patent-office">使用过滤信息来识别对象的装置和方法</invention-title>
      </span><br><span class="patent-number">CN 102375867 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA95507765" lang="ZH" load-source="patent-office">
    <div class="abstract">一种使用过滤信息的对象识别方法，该方法包括：获取包括感兴趣的对象的对象图像信息；获取用于从对象图像信息中识别感兴趣的对象的过滤信息；以及使用过滤信息来识别感兴趣的对象。一种使用过滤信息的对象识别装置，该装置包括：对象信息获取单元，用于获取包括感兴趣的对象的对象图像信息；过滤信息输入单元，用于获取过滤信息；输出单元，用于输出图像信息和过滤信息；以及控制器，用于使用过滤信息来识别对象图像信息中的感兴趣的对象。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(17)</span></span></div><div class="patent-text"><div mxw-id="PCLM40860842" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种对象识别方法，该方法包括： 获取包括感兴趣的对象的对象图像信息；获取用于从所述对象图像信息中识别所述感兴趣的对象的过滤信息；以及使用所述过滤信息来识别所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的对象识别方法，其中所述过滤信息包括显示所述感兴趣的对象的轮廓的轮廓图像数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的对象识别方法，其中获取所述过滤信息包括： 输出获取到的对象图像信息；接收所述感兴趣的对象的轮廓图像数据；以及输出所述轮廓图像数据以与所述对象图像信息重叠。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的对象识别方法，其中所述过滤信息包括与所述感兴趣的对象相关的详细信息或位置信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的对象识别方法，该方法还包括：如果使用所述过滤信息没有识别到所述感兴趣的对象，则输出用于输入附加过滤信息的请求；接收来自用户的所述附加过滤信息；以及使用所述附加过滤信息来识别所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的对象识别方法，该方法还包括： 搜索与所述感兴趣的对象相关的元数据；以及输出所述元数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的对象识别方法，其中输出所述元数据包括：如果找到两条或两条以上用于所述感兴趣的对象的元数据，则根据预定的优先级来输出所述元数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求1所述的对象识别方法，其中使用所述过滤信息来识别所述感兴趣的对象包括：检测对象识别信息，其中所述对象识别信息包括对应于所述感兴趣的对象的特征信息；将所述对象识别信息与存储的参考特征信息进行比较；以及如果所述对象识别信息与存储的参考特征信息相匹配，则识别所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求1所述的对象识别方法，该方法还包括：获取与识别到的感兴趣的对象相关的元数据，其中所述元数据与所述感兴趣的对象一起被输出。</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10.	一种使用过滤信息的对象识别装置，该对象识别装置包括：对象信息获取单元，该对象信息获取单元用于获取包括感兴趣的对象的对象图像信息；过滤信息输入单元，该过滤信息输入单元用于获取过滤信息，所述过滤信息用于从所述图像信息中识别所述感兴趣的对象；输出单元，该输出单元用于输出所述图像信息和所述过滤信息；以及控制器，该控制器用于使用所述过滤信息来识别所述对象图像信息中的所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求10所述的对象识别装置，其中所述控制器通过所述输出单元输出所述图像信息，以及输出所述过滤信息来与所述对象图像信息重叠。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求10所述的对象识别装置，其中如果使用所述对象信息和所述过滤信息没有识别到所述感兴趣的对象，则所述控制器输出用于请求附加过滤信息的消息并接收所述附加过滤信息以通过使用所述附加过滤信息来识别所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求10所述的对象识别装置，该对象识别装置还包括用于存储所述感兴趣的对象的元数据的元数据存储器，其中所述控制器搜索与所述感兴趣的对象相关的元数据并通过所述输出单元输出所述元数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求13所述的对象识别装置，其中如果找到两条或两条以上用于所述感兴趣的对象的元数据，则所述控制器根据预定的优先级来输出所述元数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求10所述的对象识别装置，该对象识别装置还包括用于存储参考特征信息的对象识别信息存储器，所述参考特征信息用于与检测到的对象识别信息做比较。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求15所述的对象识别装置，其中如果所述对象识别信息与所述参考特征信息相匹配，则识别到所述感兴趣的对象。</div>
    </div>
    </div> <div class="claim"> <div num="17" class="claim">
      <div class="claim-text">17.	一种使用过滤信息的对象识别装置，该对象识别装置包括：对象信息获取单元，该对象信息获取单元用于获取包括感兴趣的对象的图像信息；过滤信息输入单元，该过滤信息输入单元用于获取过滤信息，所述过滤信息用于从所述图像信息中识别所述感兴趣的对象；输出单元，该输出单元用于输出所述图像信息和所述过滤信息；对象识别信息存储器，该对象识别信息存储器用于存储参考特征信息；元数据存储器，该元数据存储器用于存储与所述感兴趣的对象相关的详细信息；以及控制器，该控制器用于使用所述过滤信息和所述参考特征信息来识别所述图像信息中的所述感兴趣的对象。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES46323236" lang="ZH" load-source="patent-office" class="description">
    <p>使用过滤信息来识别对象的装置和方法</p>
    <p>[0001]	相关申请的交叉引用</p>
    <p>[0002]	本申请根据35U. S.C. § 119(a)要求于2010年8月13日提交的韩国专利申请 No. 10-2010-0078462的优先权及权益，其所公开的内容作为引用而被结合于此以用于各种目的。</p>
    <p>技术领域</p>
    <p>[0003]	下面的描述涉及一种用于识别对象的增强现实（AR)装置和方法。 背景技术</p>
    <p>[0004]	增强现实（AR)是一种将虚拟对象或虚拟信息与真实环境相合成以使得虚拟对象或虚拟信息看起来好像是可以存在于真实世界环境中的真实对象或真实信息的计算机图形技术。</p>
    <p>[0005]	不同于仅针对虚拟空间和虚拟对象的现有的虚拟现实（VR)，AR的特征在于基于真实世界来合成虚拟对象，从而提供不能容易地从真实世界获得的附加信息。基于AR的该特性，不同于现有的已经被应用到有限领域（诸如游戏）的VR，AR能够被应用到各种真实环境。AR的特性使得AR技术成为适用于无处不在的环境的下一代显示技术的焦点。</p>
    <p>[0006]	例如，AR可以被实现为将信息重叠在真实世界的图像上的方法。如果用其中安装有GPS传感器的移动电话的相机获得了特定方向处的旅游点，则可以显示与位于由移动电话捕获到的街道的真实世界图像中的街道上的正在出售的各种商店或饭店相关的AR数据。</p>
    <p>[0007]	为了提供这样的AR数据，可以对真实世界中存在的对象进行识别。也就是说，识别不得不从其获得AR数据的商店或具体项目的能力是AR技术的一个因素。</p>
    <p>[0008]	常规识别技术能够识别预指定的标记，但是在使用基于无标记的识别技术（诸如边缘和边界检测）时很难确保高的识别率。为了提供更有效的AR服务，可以开发对这种基于无标记的识别技术的改进。</p>
    <p>[0009]	此外，常规识别技术不能容易地从包括多个对象的图像信息中检测感兴趣的对象。而且，常规识别技术会识别用户不感兴趣的对象并提供与不期望的对象相关的元数据， 这会不期望地消耗处理器或时间资源。另外，会不期望地消耗大量的时间来从相似的预存储对象中寻找想要的对象，以标识被识别的对象。</p>
    <p>发明内容</p>
    <p>[0010]	本发明的示例性实施方式提供了一种通过使用过滤信息来识别对象的装置。本发明的示例性实施方式还提供了一种通过使用过滤信息来识别对象的方法。</p>
    <p>[0011]	将在下面的描述中对本发明的附加特征进行阐述，并且部分这些特征将通过以下描述而变得显而易见，或通过实践本发明可以学习到这些特征。</p>
    <p>[0012]	本发明的示例性实施方式提供了一种使用过滤信息的对象识别装置，包括：对象信息获取单元，用于获取包括感兴趣的对象的对象图像信息；过滤信息输入单元，用于获取过滤信息，该过滤信息用于从图像信息中识别感兴趣的对象；以及控制器，用于使用过滤信息来识别对象图像信息中的感兴趣的对象。</p>
    <p>[0013]	本发明的示例性实施方式提供了一种使用过滤信息的对象识别装置，包括：对象信息获取单元，用于获取包括感兴趣的对象的图像信息；过滤信息输入单元，用于获取过滤信息，该过滤信息用于从图像信息中识别感兴趣的对象；输出单元，用于输出图像信息和过滤信息；对象识别信息存储器，用于存储参考特征信息；元数据存储器，用于存储与感兴趣的对象相关的详细信息；以及控制器，用于使用过滤信息和参考特征信息来识别图像信息中的感兴趣的对象。</p>
    <p>[0014]	本发明的示例性实施方式提供了一种使用过滤信息来识别对象的方法，包括：获取包括感兴趣的对象的对象图像信息；获取用于从对象图像信息中识别感兴趣的对象的过滤信息；以及使用过滤信息来识别感兴趣的对象。</p>
    <p>[0015]	可以理解的是，上面的一般性描述和随后的详细描述都是示例性和说明性的，并致力于提供对权利要求书所要求的本发明的进一步解释。其他的特点和方面将通过随后的详细描述、附图以及权利要求书而变得显而易见。</p>
    <p>附图说明</p>
    <p>[0016]	被包括以提供对本发明的进一步理解并且被合并到本说明书中并构成本说明书的一部分的附图示出了本发明的实施方式，并与以下描述一起来用于解释本发明的原理。</p>
    <p>[0017]	图1示出了根据本发明示例性实施方式的使用过滤信息的对象识别装置；</p>
    <p>[0018]	图2示出了根据本发明示例性实施方式的使用过滤信息的对象识别方法的流程图；</p>
    <p>[0019]	图3示出了根据本发明示例性实施方式的对象信息图像；</p>
    <p>[0020]	图4和图5示出了根据本发明示例性实施方式的在图3所示的对象信息图像中包括感兴趣的对象的过滤信息的图像；</p>
    <p>[0021]	图6示出了根据本发明示例性实施方式的对象信息图像；</p>
    <p>[0022]	图7示出了根据本发明示例性实施方式的在图6所示的对象信息图像中包括感兴趣对象的过滤信息的图像。</p>
    <p>具体实施方式</p>
    <p>[0023]	以下参考附图来更全面地描述本发明，其中，附图中示出了本发明的实施方式。然而，本发明可被体现在许多不同的形式中，并且不应当被解释为局限于本文阐述的实施方式。相反地，提供这些实施方式是为了使本公开更为透彻，并将向本领域技术人员完全传达本发明的范围。可以理解的是，出于本公开的目的，“每个中的至少一者”将被解释为意指遵照各种语言的所列举元素的任意组合包括多个所列举元素的组合。例如，“x、Y和Z中的至少一者”将被解释为意指仅X、仅Y、仅Z或Χ、Υ和Z中的两个或更多项的任意组合（例如， χγζαζ,γζ,χγ)。除非特别说明，否则整个附图及详细描述中，相同的附图参考标记将被理解为指代相同的元件、特征以及结构。为了清楚、例示以及方便，这些元件的相对尺寸和绘图可以被夸大。[0024]	图1示出了根据本发明示例性实施方式的使用过滤信息的对象识别装置。</p>
    <p>[0025]	参考图1，该对象识别装置包括：对象信息获取单元110、输出单元120、过滤信息输入单元130、对象识别信息存储器140、控制器170，并且还可以包括元数据存储器150以及操纵单元160。</p>
    <p>[0026]	对象信息获取单元110用来获取包括存在于真实环境中的至少一个感兴趣的对象的对象信息。该对象信息可以包括图像信息、位置信息、声音信息等等。在一个示例中， 感兴趣的对象可以是在真实世界中存在的物、人、状态或标记、具体位置、气候、速度、视觉数据、听觉数据、嗅觉数据等等。此外，对象信息获取单元110可以包括用于获取和输出包括感兴趣的对象的图像的相机或图像传感器，用于获取声音的麦克风，用于输出声音的扬声器，嗅觉数据传感器，GPS传感器，地磁传感器或速度传感器。通过对象信息获取单元110 接收到的对象信息图像的示例在图3和图6中示出。</p>
    <p>[0027]	尽管在图中没有示出，但是对象信息获取单元110可以由通信接口或功能来实现，以获取存储在存储器中的对象信息。例如，对象信息获取单元110可以通过使用GPS传感器通过检测对应于用户的当前位置信息的地图信息来获取关于用户的当前位置的信息作为对象信息，并然后传送该对象信息到控制器170。</p>
    <p>[0028]	输出单元120输出从控制器170传送的控制信号和各种数据。在一个示例中，输出单元120可以包括用于输出视觉数据的显示器、用于以可听到的声音的形式输出声音数据的扬声器等。根据一个示例，输出单元120可将从对象信息获取单元110获取的图像信息、通过过滤信息输入单元130接收到的过滤信息、元数据以及用户接口信息输出到控制器170以进行处理。</p>
    <p>[0029]	过滤信息输入单元130用来从获取到的对象信息中获得感兴趣的对象的过滤信息。例如，过滤信息输入单元130可以是触发器被按下时用于生成过滤后的数据的输入单元。该触发器可以是触摸传感器、鼠标、获取声音数据的麦克风等。</p>
    <p>[0030]	可以以各种形式来提供过滤信息。在一个示例中，过滤信息可以包括感兴趣的对象的位置信息、属性、轮廓图像数据等等。更具体地，过滤信息可以是示出所显示图像上的多个重叠对象中的感兴趣对象的轮廓的轮廓图像数据（见图4)、感兴趣的对象的详细信息 (诸如感兴趣的对象的制造商）、或感兴趣的对象（诸如国家公园）的位置信息。例如，在图3示出的对象信息的情况中，过滤信息可以是车辆的商标，诸如“大众汽车TM”。</p>
    <p>[0031]	在图4、图5和图7中示出了在显示器上显示的过滤信息的示例。参考图4，将显示车辆的轮廓的轮廓图像数据（其可由用户输入）显示为过滤信息。</p>
    <p>[0032]	而且，过滤信息可以被分类成主要过滤信息和次要过滤信息。例如，如图4所示， 为感兴趣的对象车辆的轮廓图像数据410可以是主要过滤信息。此外，如图5所示，可以是感兴趣的对象的详细信息的车窗的轮廓510可以是次要过滤信息。</p>
    <p>[0033]	因此，主要过滤信息可以是关于感兴趣的对象的一般过滤信息，并且如果能够通过使用主要过滤信息来识别感兴趣的对象，则控制器170可以请求用户输入次要过滤信息来获得识别到的感兴趣的对象的详细信息。</p>
    <p>[0034]	而且，过滤信息可以包括对象的可至少部分地由用户估计的轮廓图像数据以及对象的容易在所显示的图像中识别到的轮廓图像数据。例如，如图6所示，为感兴趣的对象的建筑物610被另一建筑物620部分遮挡。在这种情况下，如图7所示，用户可以输入显示包括建筑物610的被遮挡部分的建筑物610的整个形状的绘图信息630，作为过滤信息。</p>
    <p>[0035]	对象识别信息存储器140存储感兴趣的对象的参考特征信息，作为用于识别对象的映射信息。参考特征信息可包括关于感兴趣的对象的形状、颜色、纹理、图案、颜色柱状图以及边缘的信息。控制器170将通过应用过滤信息获取的对象识别信息与存储的参考特征信息做比较，以确定是什么对象，从而识别检测到的感兴趣的对象。</p>
    <p>[0036]	在一个示例中，对象识别信息存储器140可以被安装在对象识别装置中或可被置于对象识别装置外部，并通过网络传送数据。在对象识别信息存储器140被置于对象识别装置外部的情况下，对象识别信息存储器140还可包括用于进行网络通信的通信接口。</p>
    <p>[0037]	元数据存储器150存储与感兴趣的对象相关的各种类型信息。例如，如果某种对象是树，则对象的元数据可以是显示树的名称、主要栖息地、生态特征和其他相关信息的标签图像。可以向每条元数据分配与分配给相应感兴趣的对象的标识符相同的标识符。</p>
    <p>[0038]	元数据存储器150还可以被安装在对象识别装置中或可被置于对象识别装置外部，并通过网络接收数据。在元数据存储器150被置于对象识别装置外部的情况下，元数据存储器150还可包括用于进行网络通信的通信接口。</p>
    <p>[0039]	操纵单元160是从用户接收输入信息的用户接口。操纵单元160可以是当触发器被按下的情况下用于生成数据的输入单元。该触发器可以是按钮、触摸传感器、鼠标等。根据一个示例，可以通过操纵单元160来接收元数据、优先级信息、选择信息等。</p>
    <p>[0040]	控制器170控制上述各个部件执行通过使用过滤信息来识别对象的操作。控制器 170可以是硬件处理器或在硬件处理器中被执行的软件模块。下面将参考图2来更详细地描述控制器170的操作。</p>
    <p>[0041]	尽管没有在图中示出，但是控制器170可包括提供感测信息（例如，当前时间、当前位置、拍摄方向等）的各种类型的传感器，以帮助对象检测以及用于对象检测的元数据检测。</p>
    <p>[0042]	下文中，将参考图2来描述使用过滤信息的对象识别方法。图2示出了根据本发明示例性实施方式的使用过滤信息的对象识别方法的流程图。简便起见，图2将被描述为由上述的对象识别装置执行的方法。然而，该方法不限于此。</p>
    <p>[0043]	参考图1和图2，如果通过用户的输入设置了对象识别模式，则控制器170可驱动对象信息获取单元110来获取包括至少一个感兴趣的对象的对象信息（步骤210)。该对象信息可包括图像信息、位置信息、声音信息等等。</p>
    <p>[0044]	然后，控制器170接收过滤信息（步骤220)。控制器170可通过输出单元120输出第一对象信息，以允许用户输入过滤信息，这并未在该图中示出。例如，如果第一对象信息是图像信息，则控制器170可通过输出单元120如图3或图6所示那样在显示屏幕上输出该图像信息。</p>
    <p>[0045]	然后，如果用户想要看到包括在图像信息中的车辆的元数据，他或她可输入显示如图4所示的车辆轮廓的轮廓图像数据作为过滤信息，以便于将该车辆检测为感兴趣的对象。在从用户接收到过滤信息后，控制器170可通过将过滤信息重叠到检测到的感兴趣的对象上，来将过滤信息应用到在显示的图像中检测到的感兴趣的对象。</p>
    <p>[0046]	然后，控制器170通过使用过滤信息和参考特征信息来从对象信息中检测并识别感兴趣的对象（步骤230)。根据一个示例，过滤信息可被控制器170用于两个目的。首先，过滤信息可用于从包括多个对象的对象图像信息中检测感兴趣的对象。例如，过滤信息可用作用于从显示有许多建筑物的图像中检测或选择特定建筑物的信息。</p>
    <p>[0047]	其次，过滤信息可用来增加对象识别率或对象识别速度。更具体地，控制器170 可将通过应用过滤信息到对象信息而获取的对象识别信息与来自对象识别信息存储器140 的至少一条参考特征信息做比较。做此比较的目的是识别检测到的感兴趣的对象。在一个示例中，控制器170对至少一条与存储在对象识别信息存储器140中的过滤后的参考特征信息相似的对象识别信息进行过滤，以及将从对象识别信息存储器140中提取的过滤后的参考特征信息与从对象信息检测到的对象识别信息相比较来识别检测到的感兴趣的对象。 此外，能够减少识别所需的时间并提高识别率。</p>
    <p>[0048]	总而言之，控制器170使用过滤信息来从可包括多个对象的图像信息中检测感兴趣的对象。然后，控制器170将对象识别信息与存储在对象识别信息存储器140中的存储的参考特征信息做比较来识别感兴趣的对象。更具体地，控制器170检测分配给参考特征信息的标识符，并将同一标识符映射到检测到的感兴趣的对象。而且，控制器170可基于从各种类型的传感器感测到的信息来检测对象信息。</p>
    <p>[0049]	同时，上述的操作220到230可被重复多次。如果使用由用户输入的主要过滤信息的对象识别失败，则控制器170可输出用于请求用户输入次要过滤信息的消息，从用户接收该次要过滤信息，然后使用该次要过滤信息来执行对象识别。</p>
    <p>[0050]	然而，在操作230中，如果过滤信息和对象信息都被用来从对象识别信息存储器 140中搜索感兴趣的对象，则会存在着两个或两个以上的对象都被检测为感兴趣的对象的情况。在这种情况下，控制器170可输出检测到的结果来允许用户输入用于选择感兴趣的对象的确切信息。</p>
    <p>[0051]	接着，控制器170搜索与识别到的感兴趣的对象相关的元数据（步骤M0)。例如， 控制器170可搜索与分配给识别到的感兴趣的对象具有相同标识符的感兴趣的对象。此时，可找到两条或两条以上针对感兴趣的对象的元数据。然后，控制器170可输出找到的元数据（步骤250)。如果找到两条或两条以上元数据，则控制器170可根据优先级来输出元数据。可根据提前存储的用户的喜好来提前设置优先级或可实时地从用户接收该优先级。</p>
    <p>[0052]	对于本领域技术人员而言显而易见的是，在不背离本发明的精神或范围的情况下，能够对本发明进行各种修改和变形。因此，因此，认为这些修改和变形位于所附权利要求书及其等同形式的范围内，意欲使本发明覆盖本发明这些修改和变形。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1674035A?cl=zh">CN1674035A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年3月22日</td><td class="patent-data-table-td patent-date-value">2005年9月28日</td><td class="patent-data-table-td ">佳能株式会社</td><td class="patent-data-table-td ">图像处理设备和图像处理方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101216841A?cl=zh">CN101216841A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年1月14日</td><td class="patent-data-table-td patent-date-value">2008年7月9日</td><td class="patent-data-table-td ">南京搜拍信息技术有限公司</td><td class="patent-data-table-td ">交互式图像搜索系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101976461A?cl=zh">CN101976461A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月25日</td><td class="patent-data-table-td patent-date-value">2011年2月16日</td><td class="patent-data-table-td ">北京理工大学</td><td class="patent-data-table-td ">一种新的户外增强现实无标跟踪注册算法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102436663A?cl=zh">CN102436663A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年7月25日</td><td class="patent-data-table-td patent-date-value">2012年5月2日</td><td class="patent-data-table-td ">株式会社泛泰</td><td class="patent-data-table-td ">用于对增强现实进行选择性过滤的用户设备、服务器和方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30247">G06F17/30247</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T19/006">G06T19/006</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=QySHBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/228">G06K9/228</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06F17/30M1</span>, <span class="nested-value">G06K9/22W</span>, <span class="nested-value">G06T19/00R</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年3月14日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年4月25日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年8月8日</td><td class="patent-data-table-td ">C53</td><td class="patent-data-table-td ">Correction of patent for invention or patent application</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年8月8日</td><td class="patent-data-table-td ">COR</td><td class="patent-data-table-td ">Change of bibliographic data</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECT: INVENTOR; FROM: JIN NANXI JIN CHANGHUAN JIN HENGJI PARK CHAN-HEE PARK HUI-JONG LIANG ZHENMO LI MEINA LI RONGZAI TO: JIN NANXI</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年5月7日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/0dd6a1fb502c406a99c6/CN102375867A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BD%BF%E7%94%A8%E8%BF%87%E6%BB%A4%E4%BF%A1%E6%81%AF%E6%9D%A5%E8%AF%86%E5%88%AB%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%A3%85.pdf?id=QySHBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1owSO_4XIfgvsyEZqdStsFPpxw-Q"},"sample_url":"https://www.google.com/patents/reader?id=QySHBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>