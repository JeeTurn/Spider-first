<!DOCTYPE html><html><head><title>专利 CN103365404A - 一种人机交互的方法和装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5115ea495017d9115e613207d3810e5a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5115ea495017d9115e613207d3810e5a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种人机交互的方法和装置"><meta name="DC.contributor" content="陈柯" scheme="inventor"><meta name="DC.contributor" content="付荣耀" scheme="inventor"><meta name="DC.contributor" content="杨锦平" scheme="inventor"><meta name="DC.contributor" content="联想(北京)有限公司" scheme="assignee"><meta name="DC.date" content="2012-4-1" scheme="dateSubmitted"><meta name="DC.description" content="本发明实施例提供了一种人机交互的方法和装置，解决了摄像头视角局限的问题，使得用户在人机交互过程中获得良好的人机交互体验。该方法应用于具有摄像头的电子设备，包括：通过所述摄像头获取包括所述识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象；通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内；根据摄像头获取的识别对象的图像信息识别用户指令。本发明涉及人机交互技术领域。"><meta name="DC.date" content="2013-10-23"><meta name="DC.relation" content="CN:101072332:A" scheme="references"><meta name="DC.relation" content="CN:101720024:A" scheme="references"><meta name="DC.relation" content="CN:102053702:A" scheme="references"><meta name="DC.relation" content="CN:102222342:A" scheme="references"><meta name="DC.relation" content="CN:201054660" scheme="references"><meta name="DC.relation" content="CN:201213278" scheme="references"><meta name="DC.relation" content="CN:201845345" scheme="references"><meta name="DC.relation" content="US:20100208038:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103365404:A"><meta name="citation_patent_application_number" content="CN:201210096556"><link rel="canonical" href="https://www.google.com/patents/CN103365404A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103365404A?cl=zh"/><meta name="title" content="专利 CN103365404A - 一种人机交互的方法和装置"/><meta name="description" content="本发明实施例提供了一种人机交互的方法和装置，解决了摄像头视角局限的问题，使得用户在人机交互过程中获得良好的人机交互体验。该方法应用于具有摄像头的电子设备，包括：通过所述摄像头获取包括所述识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象；通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内；根据摄像头获取的识别对象的图像信息识别用户指令。本发明涉及人机交互技术领域。"/><meta property="og:title" content="专利 CN103365404A - 一种人机交互的方法和装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103365404A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103365404A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=s8LbCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103365404A&amp;usg=AFQjCNHzZ-HN6Orng6uLi-wVtB21SVyzng" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/00545ee72ee3c3b42d12/CN103365404A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/00545ee72ee3c3b42d12/CN103365404A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103365404A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103365404A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103365404A?cl=zh" style="display:none"><span itemprop="description">本发明实施例提供了一种人机交互的方法和装置，解决了摄像头视角局限的问题，使得用户在人机交互过程中获得良好的人机交互体验。该方法应用于具有摄像头的电子设备，包括：通过所述摄像头获取包括所述识别对象的图像...</span><span itemprop="url">https://www.google.com/patents/CN103365404A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103365404A - 一种人机交互的方法和装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103365404A - 一种人机交互的方法和装置" title="专利 CN103365404A - 一种人机交互的方法和装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103365404 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210096556</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年10月23日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年4月1日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年4月1日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210096556.6, </span><span class="patent-bibdata-value">CN 103365404 A, </span><span class="patent-bibdata-value">CN 103365404A, </span><span class="patent-bibdata-value">CN 201210096556, </span><span class="patent-bibdata-value">CN-A-103365404, </span><span class="patent-bibdata-value">CN103365404 A, </span><span class="patent-bibdata-value">CN103365404A, </span><span class="patent-bibdata-value">CN201210096556, </span><span class="patent-bibdata-value">CN201210096556.6</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E6%9F%AF%22">陈柯</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E4%BB%98%E8%8D%A3%E8%80%80%22">付荣耀</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%A8%E9%94%A6%E5%B9%B3%22">杨锦平</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%81%94%E6%83%B3(%E5%8C%97%E4%BA%AC)%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">联想(北京)有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103365404A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103365404A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103365404A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (8),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=s8LbCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210096556&amp;usg=AFQjCNHICd7N7Q_bC6gLJxVbb25FwTKiiw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=s8LbCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103365404A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNExMxLCE4jdafC55P84vJw4oxST6w"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT131026564" lang="ZH" load-source="patent-office">一种人机交互的方法和装置</invention-title>
      </span><br><span class="patent-number">CN 103365404 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA125154977" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明实施例提供了一种人机交互的方法和装置，解决了摄像头视角局限的问题，使得用户在人机交互过程中获得良好的人机交互体验。该方法应用于具有摄像头的电子设备，包括：通过所述摄像头获取包括所述识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象；通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内；根据摄像头获取的识别对象的图像信息识别用户指令。本发明涉及人机交互技术领域。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM56580686" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种人机交互的方法，其特征在于，应用于具有摄像头的电子设备，该方法包括:通过所述摄像头获取包括识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象；通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内；根据摄像头获取的识别对象的图像信息识别用户指令。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，通过控制所述摄像头转动跟踪所述识别对象的步骤包括:根据所述识别对象在所述图像信息中的位置，确定所述识别对象是否在所述摄像头预设的视角范围内；若所述识别对象不在所述摄像头预设的视角范围内，则控制所述摄像转动跟踪所述识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其特征在于，所述预设的视角范围小于所述摄像头实际的视角范围。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的方法，其特征在于，通过控制所述摄像头转动跟踪所述识别对象的步骤包括:识别所述识别对象的图像，确定所述识别对象的图像是否为预设的图像；若所述识别对象的图像为预设的图像，则控制所述摄像头转动跟踪所述识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1-4任一项所述的方法，其特征在于，所述识别对象为手部，所述摄像头采集的识别对象的图像是手部的形状图像或运动轨迹图像。`</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的方法，其特征在于，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象或所述根据摄像头采集的识别对象的图像信息识别用户指令具体包括:通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像信息和预设的脸部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预设的脸部和手部的位置关系和预设的手部特征信息识别所述手部，或根据所述脸部在所述图像信息中的位置、预设的脸部、手部的位置关系、预设的手部特征信息和预设的手部图像信息识别用户指令。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1所述的方法，其特征在于，所述根据摄像头采集的识别对象的图像信息识别用户指令包括:将所述摄像头采集的所述识别对象的图像的运动轨迹与摄像头自身的运动轨迹叠加， 得到所述识别对象的运动轨迹，根据所述识别对象的运动轨迹和预设的识别对象的运动轨迹识别用户指令。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.&#8212;种人机交互装置，其特征在于，应用于具有摄像头的电子设备，该装置包括:识别单元和跟踪单元；所述识别单元，用于通过所述摄像头获取包括识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象；所述跟踪单元，用于通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内；所述识别单元，还用于根据摄像头采集的识别对象的图像信息识别用户指令。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的装置，其特征在于，所述跟踪单元通过控制所述摄像头转动跟踪所述识别对象的步骤包括:用于根据所述识别对象在所述图像信息中的位置，确定所述识别对象是否在所述摄像头预设的视角范围内；若所述识别对象不在所述摄像头预设的视角范围内，则控制所述摄像转动跟踪所述识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的装置，其特征在于，所述预设的视角范围小于所述摄像头实际的视角范围。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求8所述的装置，其特征在于，所述跟踪单元通过控制所述摄像头转动跟踪所述识别对象的步骤包括:识别所述识别对象的图像，确定所述识别对象的图像是否为预设的图像；若所述识别对象的图像为预设的图像，则控制所述摄像头转动跟踪所述识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求8-11任一项所述的装置，其特征在于，所述识别对象为手部，所述摄像头采集的识别对象的图像是手部的形状图像或运动轨迹图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的装置，其特征在于，所述识别单元通过所述摄像头获取包括所述识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对象或根据摄像头采集的识别对象的图像信息识别用户指令具体包括:通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像信息和预设的脸部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预设的脸部和手部的位置关系和预设的手部特征信息识别所述手部，或根据所述脸部在所述图像信息中的位置、预设的脸部、手部的位置关系、预设的手部特征信息和预设的手部图像信息识别用户指令。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求8所 述的装置，其特征在于，所述识别单元根据摄像头采集的识别对象的图像信息识别用户指令包括:将所述摄像头采集的识别对象的图像的运动轨迹与摄像头自身的运动轨迹叠加，得到所述识别对象的运动轨迹，根据识别对象的运动轨迹和预设的识别对象的运动轨迹识别用户指令。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES63563371" lang="ZH" load-source="patent-office" class="description">
    <p>一种人机交互的方法和装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及电子信息技术领域，尤其涉及一种人机交互的方法和装置。</p>
    <p>背景技术</p>
    <p>[0002]	现有技术中摄像头成为一种司空见惯的设备，如监控、识别、人机交互识别等方方 面面。</p>
    <p>[0003]	为了摄像头能够获取到识别对象的信息，识别对象必须位于摄像头的视角范围 内。若识别对象位于摄像头的视角范围外，需要识别对象主动移动。例如现有技术中的手 势交互的方法，通常需要摄像头来识别手部动作，但是摄像头一般处于固定不变的方向或 位置。由于摄像头的视角范围有限，这样用户的手部动作一旦超出摄像头的视角范围，机器 设备则无法识别用户的手部动作，使得用户无法获得良好的人机交互体验。</p>
    <p>发明内容</p>
    <p>[0004]	本发明的实施例提供一种人机交互的方法和装置，解决了摄像头视角局限的问 题，使得用户在人机交互过程中获得良好的人机交互体验。</p>
    <p>[0005]	为达到上述目的，本发明的实施例采用如下技术方案:</p>
    <p>[0006]	一种人机交互的方法，应用于具有摄像头的电子设备，该方法包括:</p>
    <p>[0007]	通过所述摄像头获取包括识别对象的图像信息，根据所述图像信息和预设的识别 对象的特征信息识别出所述识别对象；</p>
    <p>[0008]	通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位于摄像 头预设的视角范围内；</p>
    <p>[0009]	在所述摄像头预设的视角范围内识别出识别对象的动作图像。</p>
    <p>[0010]	一种人机交互装置，应用于具有摄像头的电子设备，该装置包括:识别单元和跟踪 单元；</p>
    <p>[0011]	所述识别单元，用于通过所述摄像头获取包括识别对象的图像信息，根据所述图 像信息和预设的识别对象的特征信息识别出所述识别对象；</p>
    <p>[0012]	所述跟踪单元，用于通过控制所述摄像头转动跟踪所述识别对象，使得所述识别 对象的位置位于摄像头预设的视角范围内；</p>
    <p>[0013]	所述识别单元，还用于在所述摄像头预设的视角范围内识别出识别对象的动作图像。</p>
    <p>[0014]	本发明实施例提供了一种人机交互的方法和装置，通过摄像头获取的包括所述识 别对象的图像信息和预设的识别对象的特征信息识别出识别对象，然后控制摄像头转动跟 踪所述识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内，在所述摄像头 预设的视角范围内识别出识别对象的动作图像。采用控制摄像头转动跟踪识别对象，使得 识别对象处于摄像头预设的视角范围内进行人机交互操作，从而解决了摄像头视角局限的 问题，使得用户在人机交互过程中获得良好的人机交互体验。附图说明</p>
    <p>[0015]	为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现 有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本 发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以 根据这些附图获得其他的附图。</p>
    <p>[0016]	图1为本发明实施例一提供的一种人机交互的方法流程示意图；</p>
    <p>[0017]	图2为摄像头视角范围的图像的像素信息对应的坐标的示意图；</p>
    <p>[0018]	图3为本发明实施例二提供的一种人机交互的装置的结构示意图。</p>
    <p>具体实施方式</p>
    <p>[0019]	下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完 整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于 本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他 实施例，都属于本发明保护的范围。</p>
    <p>[0020]	实施例一、</p>
    <p>[0021]	本发明实施例提供了一种人机交互的方法，该方法应用于电子设备，该电子设备 包括摄像头，如图1所示，包括:</p>
    <p>[0022]	S101、通过所述摄像头获取包括识别对象的图像信息，根据所述图像信息和预设 的识别对象的特征信息识别出所述识别对象。</p>
    <p>[0023]	通过摄像头获取到摄像头的视角范围内的图像信息，该图像信息中包括所述识别 对象，根据所述图像信息和预设的识别对象的特征信息可以识别出所述识别对象。</p>
    <p>[0024]	例如，识别对象以人体手部为例来进行说明。摄像头在获取到包括手部的图像后， 电子设备对该图像进行处理，提取该图像中的多个轮廓曲线特征信息。同时根据摄像头获 取的图像的像素信息获得提取的多个轮廓曲线的像素信息。电子设备预设有手部的轮廓曲 线特征信息。电子设备根据预设的手部的轮廓曲线特征信息与从所述图像中提取的轮廓曲 线特征信息进行比对匹配，从而可以识别手部。</p>
    <p>[0025]	当然，本发明还可以采用其它的方式对所述图像进行处理来对识别对象进行识 另U，本发明在此不作限定。</p>
    <p>[0026]	S102、通过控制所述摄像头转动跟踪所述识别对象，使得所述识别对象的位置位 于摄像头预设的视角范围内。</p>
    <p>[0027]	S103、根据摄像头获取的识别对象的图像信息识别用户指令。</p>
    <p>[0028]	识别对象可以作出各种动作图像，摄像头获取该动作图像后电子设备识别该动 作。</p>
    <p>[0029]	上述所述的识别对象可以是人体的手部，也可以是人体的脸部等人体部位。</p>
    <p>[0030]	可选的，所述通过控制所述摄像头转动跟踪所述识别对象可以是:根据所述识别 对象在所述图像信息中的位置，确定所述识别对象是否在所述摄像头预设的视角范围内； 若所述识别对象不在预设的视角范围内，则控制摄像头转动跟踪所述识别对象。</p>
    <p>[0031]	可选的，所述预设的摄像头视角范围小于所述摄像实际的视角范围。[0032]	在电子设备识别到识别对象后，电子设备可以通过获取识别对象在摄像头获取的 图像信息中的像素信息，根据该像素信息可以获取该识别对象在所述图像中的位置，从而 根据所述识别对象在所述图像中位置判断所述识别对象否在预设的像素范围内。</p>
    <p>[0033]	例如，如图2所示，摄像头获取的图像的像素为640*480，该摄像头的视角范围为 60度，我们以该图像的中心位置的像素设为坐标(0，0)，这样坐标八(0，320)为摄像头获取 的上方60度的图像的像素点，坐标B (240，0)为摄像头右方60度的图像的像素点，坐标 C(0, -320)为摄像头下方60度的图像的像素点，坐标D(-240，0)为摄像头左方60度的图 像的像素点。若摄像头预设的视角范围为45度，这样摄像头的45度角对应的预设像素坐 标为:坐标Al (0，240)，BI (180，0)，Cl (0，-240) Dl (-180,0)围成的图像区域。这样在电 子设备根据该预设的像素坐标范围判断所述识别对象位置的像素坐标是否在预设的像素 坐标范围内，从而可以确定所述识别对象是否在摄像头视角45度以外。</p>
    <p>[0034]	若所述识别对象此时的像素坐标为点E为(200，-288)。这样计算该坐标点E与 中心坐标的之间的关系，从而可以计算出识别对象在摄像头右方50度，下方54度，这样可 以控制所述摄像向右转动50度，再向下转动54度跟踪识别对象，从而可以使识别对象位于 所述摄像头获取的图像的中心位置。</p>
    <p>[0035]	当然，电子设备也可以根据识别对象的像素坐标点，计算摄像头调整的最小角度， 从而可以使得识别对象位于所述预设的像素范围内即可，例如所述识别对象的坐标点E为 (200，288)，这样识别对象相对于BI向右5度，相对于Cl向下9度，所以摄像头只需要向右 转动5度，向下转动9度跟踪识别对象，这样识别对象则可以位于预设的像素范围内。</p>
    <p>[0036]	当然摄像头调整的角度的计算方法还可以采用其它方式，本发明实施例在此不作 限定。</p>
    <p>[0037]	可选的，所述预设的视角范围为所述摄像头实际的视角范围。这样只要在所述摄 像头视角的视角范围内，电子设备可以不控制摄像头转动跟踪所述识别对象。</p>
    <p>[0038]	可选的，所述通过控制所述摄像头转动跟踪所述识别对象可以是:识别所述识别 对象的图像信息，确定所述识别对象的图像是否为预设的图像；若所述识别对象的图像为 预设的图像，则控制所述摄像头转动跟踪所述识别对象。</p>
    <p>[0039]	电子设备还可以通过识别到识别对象的图像为预设图像后控制摄像头转动跟踪 识别对象。</p>
    <p>[0040]	电子设备中预设有控制摄像头转动跟踪识别对象的有效图像的特征信息，当识别 对象作出有效的图像后，摄像头在获取该有效图像后，比对预设的有效图像的特征信息，识 别出该有效图像后，则主动跟踪识别对象，使得识别对象处于所述摄像头的预设视角范围 内。</p>
    <p>[0041]	可选的，所述识别对象为手部，所述摄像头采集的识别对象的图像是手部的形状 图像或运动轨迹图像。</p>
    <p>[0042]	可选的，若所述识别对象为手部，则根据所述图像信息和预设的识别对象的特征 信息识别出所述识别对象具体包括:</p>
    <p>[0043]	通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像信息和预设的脸 部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预设的脸部和手部 的位置关系和预设的手部特征信息识别所述手部。[0044]	可选的，若所述识别对象为手部，则所述根据摄像头采集的识别对象的图像信息 识别用户指令具体包括:通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像 信息和预设的脸部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预 设的脸部、手部的位置关系、预设的手部特征信息和预设的手部图像信息识别用户指令。</p>
    <p>[0045]	可选的，所述根据摄像头采集的识别对象的图像信息识别用户指令包括:</p>
    <p>[0046]	将摄像头采集的识别对象的图像的运动轨迹与摄像头自身的运动轨迹叠加，得到 所述识别对象的运动轨迹，根据识别对象的运动轨迹和预设的识别对象的运动轨迹识别用 户指令。</p>
    <p>[0047]	这样根据预设的脸部和手部的位置关系可以提高识别所述手部和用户指令的准确度。</p>
    <p>[0048]	在用户在与电子设备交互操作时，当识别对象的运动轨迹离开摄像头的预设的视 角范围内或摄像头跟踪识别对象时，为了跟踪识别对象使得识别对象处于摄像头的视角范 围内控制摄像头转动，这样通过摄像头获取的识别对象的图像会处于图像的某一固定位 置，无法获取识别对象的有效运动轨迹。这样为了识别出识别对象的有效运动轨迹，电子设 备可以将识别对象的图像的运动轨迹与摄像头自身的运动轨迹叠加，得到所述识别对象的 运动轨迹，根据识别对象的运动轨迹和预设的识别对象的运动轨迹进行比对匹配识别用户 指令。</p>
    <p>[0049]	例如，摄像头采集手部在Tl时刻的像素坐标为(120，0)，摄像头处于从左向右的 运动速度10像素点每秒，这样，识别对象的运动轨迹为在T2时刻的像素坐标为((T2-T1) S*10+120，0)。这样电子设备可以通过摄像头采集到识别对象多个时刻的位置获得识别对 象的运动轨迹。</p>
    <p>[0050]	本发明实施例提供了一种人机交互的方法，通过摄像头获取的包括所述识别对象 的图像信息和预设的识别对象的特征信息识别出识别对象，然后控制摄像头转动跟踪所述 识别对象，使得所述识别对象的位置位于摄像头预设的视角范围内，根据摄像头获取的识 别对象的图像信息识别用户指令。采用控制摄像头转动跟踪识别对象，使得识别对象处于 摄像头预设的视角范围内进行人机交互操作，从而解决了摄像头视角局限的问题，使得用 户在人机交互过程中获得良好的人机交互体验。</p>
    <p>[0051]	实施例二、</p>
    <p>[0052]	本发明实施例还提供了一种人机交互的装置30，该装置30应用于具有摄像头的 电子设备，如图3所示，包括:识别单元31、跟踪单元32。</p>
    <p>[0053]	所述识别单元31，用于通过所述摄像头获取包括识别对象的图像信息，根据所述 图像信息和预设的识别对象的特征信息识别出所述识别对象。</p>
    <p>[0054]	所述识别单元31通过摄像头获取到摄像头的视角范围内的图像信息，该图像信 息中包括所述识别对象，根据所述图像信息和预设的识别对象的特征信息可以识别出所述 识别对象。</p>
    <p>[0055]	例如，识别对象以人体手部为例来进行说明。所述识别单元31在获取到包括手部 的图像后，对该图像进行处理，提取该图像中的多个轮廓曲线特征信息。同时根据摄像头获 取的图像的像素信息获得提取的多个轮廓曲线的像素信息。所述识别单元31预设有手部 的轮廓曲线特征信息。所述识别单元31根据预设的手部的轮廓曲线特征信息与从所述图像中提取的轮廓曲线特征信息进行匹配，从而可以识别手部。</p>
    <p>[0056]	当然，本发明的识别单元31还可以采用其它的方式对所述图像进行处理来对识 别对象进行识别，本发明在此不作限定。</p>
    <p>[0057]	所述跟踪单元32，用于通过控制所述摄像头转动跟踪所述识别对象，使得所述识 别对象的位置位于摄像头预设的视角范围内。</p>
    <p>[0058]	所述识别单元31，还用于根据摄像头采集的识别对象的图像信息识别用户指令。</p>
    <p>[0059]	识别对象可以作出各种动作图像，以供所述识别单元31通过摄像头获取该动作 图像后识别该动作。</p>
    <p>[0060]	上述所述的识别对象可以是人体的手部，也可以是人体的脸部等人体部位。</p>
    <p>[0061]	可选的，所述跟踪单元32通过控制所述摄像头转动跟踪所述识别对象的步骤包 括:用于根据所述识别对象在所述图像信息中的位置，确定所述识别对象是否在所述摄像 头预设的视角范围内；若所述识别对象不在所述摄像头预设的视角范围内，则控制所述摄 像转动跟踪所述识别对象。</p>
    <p>[0062]	可选的，所述预设的摄像头视角范围小于所述摄像实际的视角范围。</p>
    <p>[0063]	在所述识别单元31识别到识别对象后，所述跟踪单元32可以通过获取识别对象 在摄像头获取的图像信息中的像素信息，根据该像素信息可以获取该识别对象在所述图像 中的位置，从而根据所述识别对象在所述图像中位置判断所述识别对象否在预设的像素范 围内。</p>
    <p>[0064]	例如，如图2所示，摄像头获取的图像的像素为640*480，该摄像头的视角范围为 60度，我们以该图像的中心位置的像素设为坐标(0，0)，这样坐标八(0，320)为摄像头获取 的上方60度的图像的像素点，坐标B (240，0)为摄像头右方60度的图像的像素点，坐标 C(0, -320)为摄像头下方60度的图像的像素点，坐标D(-240，0)为摄像头左方60度的图 像的像素点。若摄像头预设的视角范围为45度，这样摄像头得45度角对应的预设像素坐 标为:坐标Al (0，240)，BI (180，0)，Cl (0，-240)和Dl (-180，0)围成的图像区域。这样在电 子设备根据该预设的像素范围判断所述识别对象位置的像素坐标信息是否在预设的像素 坐标范围内，从而所述跟踪单元32可以确定所述识别对象是否在摄像头视角45度以外。</p>
    <p>[0065]	若所述识别对象此时的像素坐标为点E为(200，-288)。这样所述跟踪单元32计 算该坐标点E与中心坐标的之间的关系，从而可以计算出识别对象在摄像头右方50度，下 方54度，这样所述跟踪单元32驱动所述摄像向右转动50度，再向下转动54度跟踪识别对 象，从而可以使识别对象位于所述摄像头获取的图像的中心位置。</p>
    <p>[0066]	当然，所述跟踪单元32也可以根据识别对象的像素坐标点，计算摄像头调整的最 小角度，从而可以使得识别对象位于所述预设的像素范围内即可，例如所述识别对象的坐 标点E为(200，288)，这样识别对象相对于BI向右5度，相对于Cl向下9度，所以所述跟踪 单元32可以控制摄像头向右转动5度，向下转动9度跟踪识别对象，这样识别对象则可以 位于预设的像素范围内。</p>
    <p>[0067]	当然所述跟踪单元32控制摄像头调整的角度的方法还可以采用其它方式，本发 明实施例在此不作限定。</p>
    <p>[0068]	可选的，所述跟踪单元32通过控制所述摄像头转动跟踪所述识别对象的步骤包 括:[0069]	可选的，所述预设的视角范围为所述摄像头实际的视角范围。这样只要在所述摄 像头视角的视角范围内，电子设备可以不控制摄像头转动跟踪所述识别对象。</p>
    <p>[0070]	可选的，所述跟踪单元32通过控制所述摄像头转动跟踪所述识别对象的步骤包 括:</p>
    <p>[0071]	通过识别单元31识别所述识别对象的图像信息，确定所述识别对象的图像是否 为预设的图像；若所述识别对象的图像为预设的图像，则控制所述摄像头转动跟踪所述识 别对象。</p>
    <p>[0072]	所述跟踪单元32还可以通过识别单元31识别到识别对象的图像为预设图像后控 制摄像头转动跟踪识别对象。</p>
    <p>[0073]	所述识别对象31中预设有控制摄像头转动跟踪识别对象的有效动作图像的特征 信息，当识别对象在摄像头的视角范围作出有效的动作图像后，所述识别对象31通过摄像 头获取该有效动作图像信息后，比对预设的有效动作图像的特征信息，识别出该有效动作 图像后，所述跟踪单元32则控制摄像头转动主动跟踪识别对象，使得识别对象处于所述摄 像头的预设视角范围内。</p>
    <p>[0074]	可选的，所述识别对象为手部，所述摄像头采集的识别对象的图像信息是手部的 形状或手部的运动轨迹图像。</p>
    <p>[0075]	可选的，若所述识别对象为手部，所述识别单元31通过所述摄像头获取包括所述 识别对象的图像信息，根据所述图像信息和预设的识别对象的特征信息识别出所述识别对 象具体包括:</p>
    <p>[0076]	通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像信息和预设的脸 部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预设的脸部和手部 的位置关系和预设的手部特征信息识别所述手部。</p>
    <p>[0077]	可选的，若所述识别对象为手部，所述识别单元31根据摄像头采集的识别对象的 图像信息识别用户指令具体包括:</p>
    <p>[0078]	通过所述摄像头获取包括手部和脸部的图像信息，根据所述图像信息和预设的脸 部特征信息识别出所述脸部；根据所述脸部在所述图像信息中的位置、预设的脸部、手部的 位置关系、预设的手部特征信息和预设的手部图像信息识别用户指令。</p>
    <p>[0079]	这样根据预设的脸部和手部的位置关系可以提高识别所述手部和用户指令的准 确度。</p>
    <p>[0080]	在用户在与电子设备交互操作时，当识别对象的运动轨迹离开摄像头的预设的视 角范围内或摄像头跟踪识别对象时，所述跟踪单元32为了跟踪识别对象使得识别对象处 于摄像头的视角范围内控制摄像头转动，这样通过摄像头获取的识别对象的图像会处于图 像的某一固定位置，所述识别单元31无法获取识别对象的有效运动轨迹。这样为了识别出 识别对象的有效运动轨迹，所述识别单元31可以将识别对象的图像的运动轨迹与摄像头 自身的运动轨迹叠加，得到所述识别对象的运动轨迹，根据识别对象的运动轨迹和预设的 识别对象的运动轨迹进行比对匹配识别用户指令。具体的，可以通过以下公式计算:</p>
    <p>[0081]	例如，摄像头采集手部在Tl时刻的像素坐标为(120，0)，摄像头处于从左向右的 运动速度10像素点每秒，这样，识别对象的运动轨迹为在T2时刻的像素坐标为((T2-T1) S*10+120，0)。这样识别单元31可以采集到识别对象多个时刻的位置获得识别对象的运动轨迹。</p>
    <p>[0082]	本发明实施例提供了一种人机交互的装置，所述识别单元通过摄像头获取包括所 述识别对象的图像后，所述跟踪单元控制摄像头转动跟踪所述识别对象，使得所述识别对 象的位置位于摄像头预设的视角范围内，所述识别单元根据摄像头获取的识别对象的图像 信息识别用户指令。采用控制摄像头转动跟踪识别对象，使得识别对象处于摄像头预设的 视角范围内进行人机交互操作，从而解决了摄像头视角局限的问题，使得用户在人机交互 过程中获得良好的人机交互体验。</p>
    <p>[0083]	本领域普通技术人员可以理解:实现上述方法实施例的全部或部分步骤可以通过 程序指令相关的硬件来完成，前述的程序可以存储于一计算机可读取存储介质中，该程序 在执行时，执行包括上述方法实施例的步骤；而前述的存储介质包括:R0M、RAM、磁碟或者 光盘等各种可以存储程序代码的介质。</p>
    <p>[0084]	以上所述，仅为本发明的具体实施方式，但本发明的保护范围并不局限于此，任何 熟悉本技术领域的技术人员在本发明揭露的技术范围内，可轻易想到变化或替换，都应涵 盖在本发明的保护范围之内。因此，本发明的保护范围应以所述权利要求的保护范围为准。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101072332A?cl=zh">CN101072332A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年6月4日</td><td class="patent-data-table-td patent-date-value">2007年11月14日</td><td class="patent-data-table-td ">深圳市融合视讯科技有限公司</td><td class="patent-data-table-td ">一种自动跟踪活动目标进行拍摄的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101720024A?cl=zh">CN101720024A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年11月23日</td><td class="patent-data-table-td patent-date-value">2010年6月2日</td><td class="patent-data-table-td ">深圳市宾利达智能科技有限公司</td><td class="patent-data-table-td ">智能识别监控系统及其监控方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102053702A?cl=zh">CN102053702A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月26日</td><td class="patent-data-table-td patent-date-value">2011年5月11日</td><td class="patent-data-table-td ">南京航空航天大学</td><td class="patent-data-table-td ">动态手势控制系统与方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102222342A?cl=zh">CN102222342A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年4月16日</td><td class="patent-data-table-td patent-date-value">2011年10月19日</td><td class="patent-data-table-td ">上海摩比源软件技术有限公司</td><td class="patent-data-table-td ">人体运动跟踪及其识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201054660Y?cl=zh">CN201054660Y</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年2月15日</td><td class="patent-data-table-td patent-date-value">2008年4月30日</td><td class="patent-data-table-td ">联想(北京)有限公司</td><td class="patent-data-table-td ">一种摄像头装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201213278Y?cl=zh">CN201213278Y</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年7月2日</td><td class="patent-data-table-td patent-date-value">2009年3月25日</td><td class="patent-data-table-td ">希姆通信息技术（上海）有限公司</td><td class="patent-data-table-td ">手机摄像人脸智能追踪装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201845345U?cl=zh">CN201845345U</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2011年5月25日</td><td class="patent-data-table-td ">吉林大学</td><td class="patent-data-table-td ">一种基于主动视觉的面部表情识别数据采集系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100208038">US20100208038</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value">2010年8月19日</td><td class="patent-data-table-td ">Omek Interactive, Ltd.</td><td class="patent-data-table-td ">Method and system for gesture recognition</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2016019768A1?cl=zh">WO2016019768A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2015年6月26日</td><td class="patent-data-table-td patent-date-value">2016年2月11日</td><td class="patent-data-table-td ">杭州海康威视数字技术股份有限公司</td><td class="patent-data-table-td ">用于视频监控的声源定向控制装置及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=s8LbCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003010000">G06F3/01</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/00545ee72ee3c3b42d12/CN103365404A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5115ea495017d9115e613207d3810e5a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE.pdf?id=s8LbCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0gq1s0q8y-Okc6oYb1OdAfrQ0NsA"},"sample_url":"https://www.google.com/patents/reader?id=s8LbCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>