<!DOCTYPE html><html><head><title>专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种用于获取与现实场景相关的共享对象的设备和方法"><meta name="DC.contributor" content="徐&#28635;" scheme="inventor"><meta name="DC.contributor" content="陈莹" scheme="inventor"><meta name="DC.contributor" content="百度在线网络技术（北京）有限公司" scheme="assignee"><meta name="DC.date" content="2011-3-22" scheme="dateSubmitted"><meta name="DC.description" content="本发明的目的是提供一种用于获取与现实场景相关的共享对象的方法和设备，网络设备通过获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；将所述一个或多个共享对象提供给所述用户设备。与现有技术相比，本发明通过根据场景图像进行匹配查询，为用户提供了与现实场景相关的共享对象，不仅方便人们获取场景相关信息，也支持不同用户之间基于同一个场景进行对象共享，从而使得人们获取信息、相互沟通更为便捷，并提升了用户的使用体验。"><meta name="DC.date" content="2012-9-26"><meta name="DC.relation" content="CN:101000623:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:102694826:A"><meta name="citation_patent_application_number" content="CN:201110069874"><link rel="canonical" href="https://www.google.com/patents/CN102694826A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102694826A?cl=zh"/><meta name="title" content="专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法"/><meta name="description" content="本发明的目的是提供一种用于获取与现实场景相关的共享对象的方法和设备，网络设备通过获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；将所述一个或多个共享对象提供给所述用户设备。与现有技术相比，本发明通过根据场景图像进行匹配查询，为用户提供了与现实场景相关的共享对象，不仅方便人们获取场景相关信息，也支持不同用户之间基于同一个场景进行对象共享，从而使得人们获取信息、相互沟通更为便捷，并提升了用户的使用体验。"/><meta property="og:title" content="专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102694826A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102694826A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102694826A&amp;usg=AFQjCNE-rdxKMtjW6BMWfkLKC_hTCdfKpQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/ff377db3958a477d84aa/CN102694826A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/ff377db3958a477d84aa/CN102694826A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102694826A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102694826A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102694826A?cl=zh" style="display:none"><span itemprop="description">本发明的目的是提供一种用于获取与现实场景相关的共享对象的方法和设备，网络设备通过获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得...</span><span itemprop="url">https://www.google.com/patents/CN102694826A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法" title="专利 CN102694826A - 一种用于获取与现实场景相关的共享对象的设备和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102694826 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110069874</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年9月26日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年3月22日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年3月22日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US20140082018?hl=zh-CN&amp;cl=zh">US20140082018</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2012126381A1?hl=zh-CN&amp;cl=zh">WO2012126381A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110069874.9, </span><span class="patent-bibdata-value">CN 102694826 A, </span><span class="patent-bibdata-value">CN 102694826A, </span><span class="patent-bibdata-value">CN 201110069874, </span><span class="patent-bibdata-value">CN-A-102694826, </span><span class="patent-bibdata-value">CN102694826 A, </span><span class="patent-bibdata-value">CN102694826A, </span><span class="patent-bibdata-value">CN201110069874, </span><span class="patent-bibdata-value">CN201110069874.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BE%90%E6%BF%9B%22">徐&#28635;</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E8%8E%B9%22">陈莹</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E7%99%BE%E5%BA%A6%E5%9C%A8%E7%BA%BF%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%EF%BC%88%E5%8C%97%E4%BA%AC%EF%BC%89%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">百度在线网络技术（北京）有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102694826A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102694826A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102694826A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110069874&amp;usg=AFQjCNExenhiPJI1Ls0ktwvusFkSUl_Zew"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102694826A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEFVqKbbSkVohOEcLPS3kBG9OspFQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT115905744" lang="ZH" load-source="patent-office">一种用于获取与现实场景相关的共享对象的设备和方法</invention-title>
      </span><br><span class="patent-number">CN 102694826 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA100787609" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明的目的是提供一种用于获取与现实场景相关的共享对象的方法和设备，网络设备通过获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；将所述一个或多个共享对象提供给所述用户设备。与现有技术相比，本发明通过根据场景图像进行匹配查询，为用户提供了与现实场景相关的共享对象，不仅方便人们获取场景相关信息，也支持不同用户之间基于同一个场景进行对象共享，从而使得人们获取信息、相互沟通更为便捷，并提升了用户的使用体验。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(29)</span></span></div><div class="patent-text"><div mxw-id="PCLM45485454" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种在网络设备端实现获取与现实场景相关的共享对象的方法，其中，该方法包括以下步骤：  a获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；b根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的�个或多个共享对象；  c将所述�个或多个共享对象提供给所述用户设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的方法，其中，所述步骤a还包括：  -获取所述访问请求，其中，所述访问请求包括与所述现实场景相对应的场景相关信息；  其中，所述步骤b还包括：  -根据所述场景图像与所述场景相关信息，在所述共享对象库中进行匹配查询，以获取所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其中，所述场景相关信息包括以下至少任�项：  -所述现实场景的位置信息；  -所述现实场景的描述信息；  -所述现实场景的标志性信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求I至3中任一项所述的方法，其中，该方法还包括：  -对所述场景图像进行图像识别处理，以获得与所述场景图像相对应的图像相关信息；  其中，所述步骤b还包括：  -根据所述场景图像与所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的方法，其中，所述图像相关信息包括以下至少任�项：  -所述场景图像所对应的背景信息；  -所述场景图像所对应的对象信息；  -所述场景图像所对应的关键词信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求I至5中任一项所述的方法，其中，所述步骤c还包括：  -根据所述�个或多个共享对象所对应的对象状态信息，将所述�个或多个共享对象提供给所述用户设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的方法，其中，所述对象状态信息包括以下至少任�项：  -所述共享对象的标签信息；  -所述共享对象的类别信息；  -所述共享对象的图层信息；  -所述共享对象的属性信息；  -所述共享对象的布局信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求I至7中任一项所述的方法，其中，所述步骤b还包括：  -根据所述场景图像，结合所述用户的用户相关信息，在所述共享对象库中进行匹配查询，以获得所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的方法，其中，所述用户相关信息包括以下至少任�项：-所述用户的基本属性；  -所述用户的地理位置；  -所述用户的历史操作记录。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求I至9中任一项所述的方法，其中，该方法还包括：  -获取所述用户对所述一个或多个共享对象中至少�个的对象修改操作；  -据所述对象修改操作，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求I至10中任一项所述的方法，其中，该方法还包括：  -获取大量用户对�个或多个现实场景的共享对象的对象共享操作；  -根据所述对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，建立或更新所述共享对象库。</div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12.	&#8212;种在用户设备端辅助实现获取与现实场景相关的共享对象的方法，其中，该方法包括以下步骤：  A获取用户通过用户设备提供的与现实场景相对应的场景图像；  B向网络设备发送基于所述场景图像的访问请求；  其中，该方法还包括：  -接收自所述网络设备发送的基于所述访问请求的�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的方法，其中，所述方法还包括：  L获取与所述现实场景相对应的场景相关信息；  其中，所述步骤B还包括：  -向所述网络设备发送所述访问请求，其中，所述访问请求包括所述场景相关信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求13所述的方法，其中，所述场景相关信息包括所述现实场景的位置信息；  其中，所述步骤L还包括：  -根据位置提供服务，获取与所述现实场景相对应的所述位置信息。</div>
    </div>
    </div> <div class="claim"> <div num="15" class="claim">
      <div class="claim-text">15.	一种用于实现获取与现实场景相关的共享对象的网络设备，其中，该设备包括：  第一获取装置，用于获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；  查询装置，用于根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的�个或多个共享对象；  提供装置，用于将所述�个或多个共享对象提供给所述用户设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求15所述的网络设备，其中，所述第一获取装置还用于：  -获取所述访问请求，其中，所述访问请求包括与所述现实场景相对应的场景相关信息；  其中，所述查询装置还用于：  -根据所述场景图像与所述场景相关信息，在所述共享对象库中进行匹配查询，以获取所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求16所述的网络设备，其中，所述场景相关信息包括以下至少任�项：  -所述现实场景的位置信息；-所述现实场景的描述信息；  -所述现实场景的标志性信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求15至17中任�项所述的网络设备，其中，该设备还包括识别装置，用于： -对所述场景图像进行图像识别处理，以获得与所述场景图像相对应的图像相关信息；  其中，所述查询装置还用于：  -根据所述场景图像与所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.根据权利要求18所述的网络设备，其中，所述图像相关信息包括以下至少任�项：  -所述场景图像所对应的背景信息；  -所述场景图像所对应的对象信息；  -所述场景图像所对应的关键词信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.根据权利要求15至19中任�项所述的网络设备，其中，所述提供装置还用于：  -根据所述�个或多个共享对象所对应的对象状态信息，将所述�个或多个共享对象提供给所述用户设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21.根据权利要求20所述的网络设备，其中，所述对象状态信息包括以下至少任�项：  -所述共享对象的标签信息；  -所述共享对象的类别信息；  -所述共享对象的图层信息；  -所述共享对象的属性信息；  -所述共享对象的布局信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22.根据权利要求15至21中任�项所述的网络设备，其中，所述查询装置还用于：  -根据所述场景图像，结合所述用户的用户相关信息，在所述共享对象库中进行匹配查询，以获得所述�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23.根据权利要求22所述的网络设备，其中，所述用户相关信息包括以下至少任�项：  -所述用户的基本属性；  -所述用户的地理位置；  -所述用户的历史操作记录。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24.根据权利要求15至23中任�项所述的网络设备，其中，该设备还包括第一更新装置，用于：  -获取所述用户对所述一个或多个共享对象中至少�个的对象修改操作；  -据所述对象修改操作，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25.根据权利要求15至24中任�项所述的网络设备，其中，该设备还包括第二更新装置，用于：  -获取大量用户对�个或多个现实场景的共享对象的对象共享操作；  -根据所述对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，建立或更新所述共享对象库。</div>
    </div>
    </div> <div class="claim"> <div num="26" class="claim">
      <div class="claim-text">26.	一种用于辅助实现获取与现实场景相关的共享对象的用户设备，其中，该设备包括：  第二获取装置，用于获取用户通过用户设备提供的与现实场景相对应的场景图像；  发送装置，用于向网络设备发送基于所述场景图像的访问请求；  其中，该设备还包括： 接收装置，用于接收自所述网络设备发送的基于所述访问请求的�个或多个共享对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27.根据权利要求26所述的用户设备，其中，所述设备还包括第三获取装置，用于：  -获取与所述现实场景相对应的场景相关信息；  其中，所述发送装置还用于：  -向所述网络设备发送所述访问请求，其中，所述访问请求包括所述场景相关信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28.根据权利要求27所述的用户设备，其中，所述场景相关信息包括所述现实场景的位置信息；  其中，所述第三获取装置还用于：  -根据位置提供服务，获取与所述现实场景相对应的所述位置信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29.	一种用于实现获取与现实场景相关的共享对象的系统，包括如权利要求15至25中任一项所述的网络设备及如权利要求26至28中任一项所述的用户设备。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES51840663" lang="ZH" load-source="patent-office" class="description">
    <p>一种用于获取与现实场景相关的共享对象的设备和方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及互联网领域，尤其涉及一种用于获取与现实场景相关的共享对象的技术。</p>
    <p>背景技术</p>
    <p>[0002]	互联网技术的发展与应用，创造和丰富了人们获取信息和相互沟通的方式，例如用户可以通过电子邮件、博客、微博等方式与其好友分享趣闻、共同关注的事件和个人最新</p>
    <p>动态等信息。</p>
    <p>[0003]	然而，随着互联网通信技术和终端设备技术的快速发展，特别是用户设备的大尺寸屏幕显示和良好的人机交互方式，人们逐渐不满足于最初的偏重文本的信息获取或沟通方式，希望能够进行更为直观的交互，以获得更好的用户使用体验。譬如，人们希望获取关于某一个场景的相关信息，如当用户在某一火车站时，他希望当其屏幕显示该火车站场景时，在其用户设备的屏幕上相应地显示他希望了解的关于该火车站的相关信息，如车次信息、或者其他用户分享的关于该火车站的注意事项信息。</p>
    <p>[0004]	因此，如何使得用户获取与现实场景相关的共享对象，以提高用户沟通效率并改善用户使用体验，成为本领域技术人员亟须解决的问题之一。</p>
    <p>发明内容</p>
    <p>[0005]	本发明的目的是提供一种用于获取与现实场景相关的共享对象的设备和方法。</p>
    <p>[0006]	根据本发明的一个方面，提供一种在网络设备端实现获取与现实场景相关的共享对象的方法，其中，该方法包括以下步骤：</p>
    <p>[0007]	a获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；</p>
    <p>[0008]	b根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；</p>
    <p>[0009]	c将所述一个或多个共享对象提供给所述用户设备。</p>
    <p>[0010]	根据本发明的另一个方面，提供一种在用户设备端辅助实现获取与现实场景相关的共享对象的方法，其中，该方法包括以下步骤：</p>
    <p>[0011]	A获取用户通过用户设备提供的与现实场景相对应的场景图像；</p>
    <p>[0012]	B向网络设备发送基于所述场景图像的访问请求；</p>
    <p>[0013]	其中，该方法还包括：</p>
    <p>[0014]-接收自所述网络设备发送的基于所述访问请求的一个或多个共享对象。</p>
    <p>[0015]	根据本发明的又一个方面，还提供了一种用于实现获取与现实场景相关的共享对象的网络设备，其中，该设备包括：</p>
    <p>[0016]	第一获取装置，用于获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；</p>
    <p>[0017]	查询装置，用于根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；</p>
    <p>[0018]	提供装置，用于将所述一个或多个共享对象提供给所述用户设备。</p>
    <p>[0019]	根据本发明的再一个方面，还提供了一种用于辅助实现获取与现实场景相关的共享对象的用户设备，其中，该设备包括：</p>
    <p>[0020]	第二获取装置，用于获取用户通过用户设备提供的与现实场景相对应的场景图像；</p>
    <p>[0021]	发送装置，用于向网络设备发送基于所述场景图像的访问请求；</p>
    <p>[0022]	其中，该设备还包括：</p>
    <p>[0023]	接收装置，用于接收自所述网络设备发送的基于所述访问请求的一个或多个共享 对象。</p>
    <p>[0024]	根据本发明的再一个方面，还提供了一种用于获取与现实场景相关的共享对象的系统，包括上述的网络设备及上述的用户设备。</p>
    <p>[0025]	与现有技术相比，本发明通过根据场景图像进行匹配查询，为用户提供了与现实场景相关的共享对象，不仅方便人们获取场景相关信息，也支持不同用户之间基于同一个场景进行对象共享，从而使得人们获取信息、相互沟通更为便捷，并提升了用户的使用体验。</p>
    <p>附图说明</p>
    <p>[0026]	通过阅读参照以下附图所作的对非限制性实施例所作的详细描述，本发明的其它特征、目的和优点将会变得更明显：</p>
    <p>[0027]	图I示出根据本发明一个方面的用于获取与现实场景相关的共享对象的系统拓扑图；</p>
    <p>[0028]	图2示出根据本发明一个方面的用于获取与现实场景相关的共享对象的设备示意图；</p>
    <p>[0029]	图3示出根据本发明一个优选实施例的用于获取与现实场景相关的共享对象的设备不意图；</p>
    <p>[0030]	图4示出根据本发明另一个方面的用于获取与现实场景相关的共享对象的方法流程图；</p>
    <p>[0031]	图5示出根据本发明一个优选实施例的用于获取与现实场景相关的共享对象的方法流程图。</p>
    <p>[0032]	附图中相同或相似的附图标记代表相同或相似的部件。</p>
    <p>具体实施方式</p>
    <p>[0033]	下面结合附图对本发明作进一步详细描述。</p>
    <p>[0034]	图I示出根据本发明一个方面的用于获取与现实场景相关的共享对象的系统拓扑图，其中包括网络设备I以及多个与之经由网络相连接的用户设备2。其中，网络设备I可与多个用户设备2经由网络相连接，并获取用户通过用户设备2发送的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；将所述一个或多个共享对象提供给所述用户设备2。在此，网络包括但不限于互联网、广域网、城域网、局域网、VPN网络、无线自组织网络（Ad Hoc网络)等。</p>
    <p>[0035]	另外，网络设备I包括但不限于网络主机、单个网络服务器、多个网络服务器集或多个服务器构成的云。在此，云由基于云计算（Cloud Computing)的大量计算机或网络服务器构成，其中，云计算是分布式计算的一种，由一群松散耦合的计算机集组成的一个超级虚拟计算机。而用户设备2包括但不限于任何一种可与用户通过键盘、鼠标、遥控器、触摸板、或手写设备等方式进行人机交互的电子产品，例如计算机、手机、照相机、摄像机、PDA、掌上电脑PPC、IPTV或MP4等。网络设备I与用户设备2之间的通信相互独立，包括但不限于基于诸如TCP/IP协议、UDP协议等的分组数据传输。 [0036]	本领域技术人员应能理解上述网络设备I、用户设备2以及连接其间的网络或通信方式仅为举例，其他现有的或今后可能出现的网络设备、用户设备或网络、通信方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0037]	本领域技术人员还应能理解，图I中仅为简明起见而示出的各类网络元素的数量可能小于一个实际网络中的数量，但这种省略无疑地是以不会影响对本发明进行清楚、充分的公开为前提的。</p>
    <p>[0038]	为简明起见，下面以一个用户设备2为例进行描述。本领域技术人员应能理解，网络设备I可以同时与多个用户设备2交互，并根据从不同用户设备2获取的基于与现实场景相对应的场景图像的访问请求；根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；将所述一个或多个共享对象提供给对之相对应的用户设备2。</p>
    <p>[0039]	图2示出根据本发明一个方面的用于获取与现实场景相关的共享对象的设备示意图，其中，网络设备I包括第一获取装置11、查询装置12和提供装置13 ;用户设备2包括第二获取装置21、发送装置22和接收装置23。</p>
    <p>[0040]	网络设备I和用户设备2的各个装置之间互相配合，以完成获取与现实场景相关的共享对象。具体地，用户设备2中的第二获取装置21获取用户通过用户设备2提供的与现实场景相对应的场景图像；发送装置22向网络设备I发送基于所述场景图像的访问请求；网络设备I中的第一获取装置11获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；查询装置12根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；提供装置13将所述一个或多个共享对象提供给所述用户设备2 ;用户设备2中的接收装置23接收自所述网络设备I发送的基于所述访问请求的一个或多个共享对象。优选地，上述各个装置之间是持续不断工作的。在此，本领域技术人员应理解“持续”是指上述各装置分别按照设定的或实时调整的工作模式要求进行场景图像的获取、访问请求的发送与接收，共享对象的匹配、提供及接收，直至该用户在较长时间内停止通过用户设备2进行场景图像的提供。</p>
    <p>[0041]	更具体地，用户设备2的第二获取装置21用于获取用户通过用户设备提供的与现实场景相对应的场景图像。具体地，用户提供场景图像的方式，包括但不限于在用户设备2中的文件夹、应用程序或客户端软件中调用、拍摄或者扫描一张包含现实场景的图像。例如，用户可以用手机拍摄一张以“上海置地广场”为背景的照片、或用电子绘图工具绘制一张以“徐家汇天主教堂”为对象的建筑画、或调用一张存储在电脑内的已有场景图片或者用户无需拍照或录制视频只需开启摄像头对准目标就可以提供该场景的场景图片等等；随后，第二获取装置21通过例如调用用户设备2提供的应用程序接口（API)、或调用绘图程序中的保存程序或者调用摄像程序中的捕获图像程序等等，获取所述用户提供的场景图像。本领域技术人员应能理解上述获取场景图像的方式仅为举例，其他现有的或今后可能出现的获取场景图像的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0042]	发送装置22用于向网络设备发送基于所述场景图像的访问请求。具体地，发送装置22根据第二获取装置21获取的用户通过用户设备提供的与现实场景相对应的场景图像，生成基于该场景图像的访问请求，随后发送装置22通过例如与网络设备I建立信道链路或一次或多次调用网络设备I提供的应用程序接口（API)等其他通信方式，将基于所述场景图像的访问请求发送至网络设备I。优选地，所述访问请求包含了所述场景图像。更优选地，所述访问请求的发送方式可以是自动的，例如客户端捕获到有摄像头的动作就自动发送访问请求，也可以是用户通过点击某个按钮后触发的，例如用户在菜单上选择“请求”选项或用户在用户设备2中选择“访问”按钮等等。本领域技术人员应能理解上述发送访 问请求的方式仅为举例，其他现有的或今后可能出现的发送访问请求的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0043]	网络设备I中的第一获取装置11用于获取用户通过用户设备2发送的基于与现实场景相对应的场景图像的访问请求。具体地，第一获取装置11例如通过如前例所述的API或其他约定的通信方式，获取发送装置22发送的根据第二获取装置21获取的场景图像生成的访问请求。本领域技术人员应能理解上述获取访问请求的方式仅为举例，其他现有的或今后可能出现的获取访问请求的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0044]	查询装置12用于根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。具体地，查询装置12根据第一获取装置11获取的基于场景图像的访问请求，从中解析出与所述现实场景相对应的场景图像，例如根据所述场景图像的内容、标签、关键字等信息，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，网络设备I可以根据大量用户对某个现实场景的共享对象的对象共享操作，并结合所述共享对象库中与所述共享对象操作行对应的场景标识，建立或更新共享对象库。因此，在所述共享对象库中不仅存储了大量的共享对象和场景标识（其存储形式包括但不限于文字、文档、图片等），同时也存储了两者间的映射关系。优选地，所述映射关系的存储形式包括但不限于：a)作为独立的数据存储，b)将共享对象与场景标识做成相对应的表格存储，c)将所述场景标识作为所述共享对象的一个状态信息（如共享对象的标签）存储。例如，当有用户选择将“百脑汇商场”的“打折信息”共享时，网络设备I就可以将该“打折信息”作为共享对象、将“百脑汇商场”作为场景标识，并且同时将“打折信息”与“百脑汇商场”的对应关系作为共享对象与场景标识的映射关系保存到对象数据库中。之后，一旦有用户发送与“百脑汇商场”相对应的访问请求，查询装置12即可根据共享对象与场景标识的映射关系，在所述共享对象库中进行匹配查询，获得与“百脑汇商场”有映射关系的一个或多个共享对象，如“打折信息”、“促销信息”或者“新品信息”等。本领域技术人员应能理解上述获得共享对象的方式仅为举例，其他现有的或今后可能出现的获得共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0045]	提供装置13用于将所述一个或多个共享对象提供给所述用户设备2。具体地，提供装置13根据查询装置12获得的一个或多个共享对象，例如通过图层叠加或页面处理技术，将所述一个或多个共享对象提供给所述用户设备2，例如将这些共享对象叠加显示于场景图像之上，或者利用JSP、ASP等页面处理技术将这些共享对象生成页面，并提供给用户设备2。接上例，当查询装置12获得到与“百脑汇商场”对应的共享对象后，提供装置13就将所述共享对象，如“打折信息”、“促销信息”或者“新品信息”提供给所述用户设备2。优选地，提供装置13可以通过短信、彩信或电子邮件的方式，也可以通过数据包打包的方式发送给用户，还可以按所述共享对象的原尺寸或缩略图等形式直接将共享对象显示在用户屏幕上。更优选地，所述提供方式可以是一次性将所有共享对象提供给用户，也可以是由用户按动特定功能键选择提供装置13提供上一个或下一个共享对象，该特定功能键例如可以是“ + ”和丨”和“丨”。更优选地，所述一个或多个共享对象的提供数目可以是缺省的也可由用户设定。本领域技术人员应能理解上述提供共享对象的方式仅为举例，其他现有的或今后可能出现的提供共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0046]	接收装置23用于接收来自所述网络设备I发送的基于所述访问请求的一个或多个共享对象。具体地，接收装置23接收来自提供装置13提供的根据查询装置12获得的一个或多个共享对象。优选地，其接收方式可以是自动的，也可以是用户通过点击某个按钮后触发的，例如，用户设备2可以先通过一个对话框询问用户是否接收共享对象，用户选择“是”后接收装置23遂开始接收。更优选地，接收装置23接收到所述共享对象后，可以自动打开所述共享对象，也可以先将其存储在用户设备2中等待用户通过例如打开收件箱或解压缩等方式打开。接上例，若“打折信息”、“促销信息”或者“新品信息”等是以短信的方式提供的，则用户可以通过打开收件箱接收；若共享对象是以数据包的方式提供的，则用户可以通过下载并解压缩接收；若共享对象是直接显示在屏幕上的，则用户无需另行接收。优选 地，所述共享对象的显示方式可以是通过新页面显示，也可以是以悬浮形式叠加在原有屏幕上。更优选地，当以悬浮形式叠加在原有屏幕上显示时，所述共享对象可以是在页面的某个固定的区域显示，也可以由用户设定的位置确定。接上例，当提供装置13将“打折信息”、“促销信息”或“新品信息”直接显示在用户的屏幕上时，接收装置23可以通过新页面显示，也可以是以悬浮窗形式将所述信息叠加在原有“百脑汇商场”图像的上方、下方或左右。本领域技术人员应能理解上述接收共享对象的方式仅为举例，其他现有的或今后可能出现的接收共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0047]	图3示出根据本发明一个优选实施例的用于获取与现实场景相关的共享对象的设备示意图，用户设备2还可以包括第三获取装置24’。其中，网络设备I中的第一获取装置11’、查询装置12’和提供装置13’分别与图2所示对应装置11-13相同，用户设备2中的第二获取装置21’、发送装置22’和接收装置23’分别与图2所示对应装置21-23相同，故此处不再赘述，并通过引用的方式包含于此。  [0048]	其中，用户设备2中的第三获取装置24’用于获取与所述现实场景相对应的场景相关信息；所述发送装置22’还用于向所述网络设备I发送所述访问请求，其中，所述访问请求包括所述场景相关信息；网络设备I中的第一获取装置11’还用于获取该访问请求；所述查询装置12’还用于根据所述场景图像与所述场景相关信息，在所述共享对象库中进行匹配查询，以获取所述一个或多个共享对象。具体地，第三获取装置24’通过例如对现实场景进行定位服务、或接收用户对场景添加的批注或者对场景图像进行图像识别等方式，获取与所述现实场景相对应的场景相关信息，如现实场景的描述信息、关键词信息等；随后发送装置22’根据第二获取装置21’获取的场景图像与第三获取装置24’获取的场景相关信息生成访问请求，并向网络设备I发送该访问请求；第一获取装置11’获取该访问请求后，查询装置12’从该访问请求中解析出所述场景图像与场景相关信息，根据该场景图像的标签或关键词，结合场景相关信息的内容，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。在此，所述场景相关信息既可以是网络设备I独立获取的，也可以是接受来自用户设备2记录的，或者接受来自其他产品或第三方设备所获取的场景相关信息。例如，所述场景相关信息可以是第三获取装置24’通过全球定位服务（GPS)获取的场景地理位置“上海市徐汇区漕溪北路333号”、或通过接收用户添加的批注获取的“徐家汇电子商场”或者通过图像识别处理获取的场景形状是“鸟巢”等等。本领域技术人员应能理解上述获取场景相关信息的方式仅为举例，其他现有的或今后可能出现的获取场景相关信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。&#183;</p>
    <p>[0049]	优选地，所述场景相关信息包括但不限于：</p>
    <p>[0050]-所述现实场景的位置信息；</p>
    <p>[0051]-所述现实场景的描述信息；</p>
    <p>[0052]-所述现实场景的标志性信息。具体地，结合所述场景相关信息可以更准确地帮助查询装置12’确认所述基于与现实场景相对应的场景图像的访问请求所对应的现实场景，从而获得与访问请求相对应的一个或多个共享对象。以位置信息为例，当第三获取装置24’通过全球定位服务（GPS)获取到的场景相关信息是“上海市徐汇区漕溪北路333号”时，所述查询装置12’就能根据场景图像的内容、标签、关键词等结合该场景相关信息确定现实场景就是“徐家汇百脑汇商场”，进而获得对应的一个或多个共享对象；以描述信息为例，当第三获取装置24’通过用户添加的批注获取到的场景相关信息是“徐家汇电子商场”时，所述查询装置12’也能根据场景图像的内容、标签、关键词等结合该场景相关性信息确定现实场景就是“徐家汇百脑汇商场”;以标志性信息为例，当第三获取装置24’通过图像识别处理获取到的场景相关信息是“鸟巢”，所述查询装置12’就能根据场景图像的内容、标签、关键词等结合该场景相关信息确定现实场景就是“国家体育场”。本领域技术人员应能理解上述场景相关信息仅为举例，其他现有的或今后可能出现的场景相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0053]	更优选地，所述场景相关信息包括所述现实场景的位置信息，其中，用户设备2中的第三获取装置24’还用于根据位置提供服务，获取与所述现实场景相对应的所述位置信息。优选地，所述位置信息包括但不限于：1)绝对地理位置信息，如现实场景的经度、维度坐标；2)场景的相对地理位置信息，如“位于虹口区和闸北区的交界处”。更优选地，第三获取装置24’获取与所述现实场景相对应的所述位置信息的方法包括但不限于：对该现实场景进行全球定位系统（GPS)定位、蜂窝基站定位或者位置服务器定位等方式。例如，第三获取装置24’通过GPS定位，获取某一场景的位置信息为“上海市徐汇区漕溪北路333号”，随后发送装置22’将包括该位置信息的访问请求发送给网络设备1，查询装置12’根据该位置信息匹配查询到与“徐家汇百脑汇”相对应的共享对象。本领域技术人员应能理解上述获取位置信息的方式仅为举例，其他现有的或今后可能出现的获取位置信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0054]	本领域技术人员应能理解，上述第二获取装置和第三获取装置仅为示例，在实践中，它们可以是二个独立的模块，也可集成在一个模块中。</p>
    <p>[0055]	在一个优选实施例中（参见图2)，所述网络设备I还包括识别装置（未示出），用于对所述场景图像进行图像识别处理，以获得与所述场景图像相对应的图像相关信息；其中，所述查询装置12还用于根据所述场景图像与所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。具体地，第一获取装置11从发送装置22处获取与现实场景相对应的场景图像的访问请求后，网络设备I从中解析出场景图像，随 后识别装置对所述场景图像进行图像识别，包括但不限于对所述场景图像进行特征识别、 文字识别或者边缘识别等，以获得与所述场景图像相对应的图像相关信息，例如图像的背景信息、描述信息等等。随后所述查询装置12根据该图像相关信息的内容，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。例如，若识别装置识别出用户发送的场景图像是“百脑汇商场”，则查询装置12即可根据共享对象与场景标识的映射关系，在所述共享对象库中进行匹配查询，获得与“百脑汇商场”有映射关系的一个或多个共享对象。本领域技术人员应能理解上述获得图像相关信息的方式仅为举例，其他现有的或今后可能出现的获得图像相关信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0056]	更优选地，所述图像相关信息包括以下至少任一项：</p>
    <p>[0057]-所述场景图像所对应的背景信息；</p>
    <p>[0058]-所述场景图像所对应的对象信息；</p>
    <p>[0059]-所述场景图像所对应的关键词信息。具体地，该图像识别过程包括但不限于对场景图像进行特征识别、文字识别或者边缘识别。以边缘识别和背景信息为例，若用户发送一张以“上海东方明珠”为背景的照片，则所述识别装置首先对该建筑物与其他背景间的交界线进行定位，随后判断出该边缘轮廓线条是3个大小不一但有排列有序的“球形”以及若干“圆柱体”的组合，从而得出该建筑是“上海东方明珠”的背景信息。以文字识别和对象信息为例，若用户发送了一张以“上海梅龙镇广场”招牌为拍摄对象的图片后，所述识别装置首先对照片中的文字进行剥离，随后通过文字识别辨认出“上”、“海”、“梅”、“龙”、“镇”、“广”、“场”，从而得出该场景是“上海梅龙镇广场”的对象信息。以特征识别和关键词信息为例，若用户发送了一张含有“徐家汇天主教堂”的图片，由于天主教堂相对于其他建筑物具有比较明显的特征，如尖顶，长线条，繁密排列，因此识别装置可以通过这些特征识别出该场景是“徐家汇天主教堂”的特征信息。随后，查询装置12就可以根据获得的图像相关信息，如“上海东方明珠”、“上海梅龙镇广场”或“徐家汇天主教堂”，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。本领域技术人员应能理解上述图像相关信息仅为举例，其他现有的或今后可能出现的图像相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。[0060]	更优选地（参见图3)，所述查询装置12’还用于根据所述场景图像与所述场景相关信息，结合所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。具体地，所述查询装置12’还用于根据所述第一获取装置11’获取的场景图像，与第三获取装置24’获取的场景相关信息，如位置信息、描述信息、标志性信息，结合识别装置获得的图像相关信息，如背景信息、对象信息、关键词信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。例如，第一获取装置11’除了获取自于第二获取装置21’的场景图像之外，也获取来自于第三获取装置24’的场景相关信息，如通过GPS定位获取的位置信息“上海市徐汇区漕溪北路333号”，同时识别装置通过图像识别技术得出该场景图像的背景信息是“徐家汇百脑汇”，则查询装置12’首先匹配位置信息，在位置信息与“徐家汇百脑汇商场”场景标识的位置信息匹配成功时，再匹配图像相关信息，对图像相关信息的匹配度允许一定的容错机制。例如，网络设备I可以设置如果位置信息完全相同，且图像相关信息中80%以上匹配，则获得与该场景标识相对应的共享对象。本领域技术人员应能理解上述获得共享对象的方式仅为举例，其他现有的或今后可能出现的获得共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式 包含于此。</p>
    <p>[0061]	在另一个优选实施例中（参见图2)，所述提供装置13还用于根据所述一个或多个共享对象所对应的对象状态信息，将所述一个或多个共享对象提供给所述用户设备。具体地，提供装置13根据查询装置12获得的一个或多个共享对象，结合所述一个或多个共享对象所对应的对象状态信息，例如所述共享对象的标签信息、类别信息、图层信息、属性信息、布局信息等，将所述一个或多个共享对象提供给所述用户设备2。例如，网络设备I可以根据大量用户对一个或多个现实场景的共享对象的对象共享操作，并结合所述共享对象的对象状态信息，建立或更新所述共享对象库。因此，在所述共享对象库中不仅存储了大量的共享对象，并且不同的共享对象还拥有各自不同的对象状态信息。具体地，所述网络设备2可根据共享对象的内容、类别不同，将不同的共享对象存储在不同的类别或标签中，故而，所述提供装置13可以根据不同的类别或标签中将一个或多个共享对象提供给用户。本领域技术人员应能理解上述提供共享对象的方式仅为举例，其他现有的或今后可能出现的提供共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0062]	优选地，所述对象状态信息包括以下至少任一项：</p>
    <p>[0063]-所述共享对象的标签信息；</p>
    <p>[0064]-所述共享对象的类别信息；</p>
    <p>[0065]-所述共享对象的图层信息；</p>
    <p>[0066]-所述共享对象的属性信息；</p>
    <p>[0067]-所述共享对象的布局信息。</p>
    <p>[0068]	其中，标签信息包括但不限于共享对象所映射的场景标识，如“打折信息a”的标签是“置地广场”，“打折信息b”的标签是“百脑汇商场”等等；类别信息包括但不限于共享对象的种类，如“商品信息”、“服务信息”、“交通信息”;图层信息包括但不限于共享对象在屏幕上的显示图层，例如，后台可以把不同类别的共享对象设置在不同图层上，接上例，假设屏幕初始显示的“百脑汇商场”的场景图像是第一图层，则“商品信息”类别的共享对象叠加显示在第一图层之上，即第二图层，“服务信息”显示在第三图层上，以此类推，方便用户筛选类别；属性信息包括但不限于共享对象的类型（如文本、图形或者图文结合）、共享对象的内容、大小、形状等等；布局信息包括但不限于共享对象显示在屏幕上的位置，例如，后台可以把不同类别的共享对象设置在屏幕上的不同位置上，接上例，假设屏幕初始显示的是“百脑汇商场”场景图像，则“商品信息”类别的共享对象显示在场景图像的上方，“服务信息”显示在场景图像的下方，以此类推，供用户加以区分。优选地，所述共享对象的对象状态信息既可以是网络设备I独立获取的，如后台根据图像识别、内容识别或者位置识别而自动设置的，也可以是接受来自用户设备2记录的，如由用户设置的，或者接受来自其他产品或第三方设备所获取的共享对象的对象状态信息。本领域技术人员应能理解上述对象状态信息仅为举例，其他现有的或今后可能出现的对象状态信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0069]	在又一个优选实施例中（参见图2)，所述查询装置12还用于根据所述场景图像，结合所述用户的用户相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多 个共享对象。具体地，查询装置12根据第一获取装置11获取的场景图像访问请求，从中解析出与所述现实场景相对应的场景图像，根据所述场景图像，结合所述用户的用户相关信息，例如所述用户的基本属性、地理位置、历史操作记录等，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，对男性、女性、儿童、老年人等，当其所提供的场景图像中包含“**商场”时，其实际需求区别较大，其中，男性用户可能对运动产品、男性服饰、电子产品更感兴趣、女性用户可能对护肤/化妆品、女性服饰更感兴趣，儿童用户可能对儿童服饰、儿童读物和卡通等更感兴趣，而老年用户可能对老年服饰、保养品更感兴趣。当然，用户的个人背景，如教育背景、生活背景、宗教背景等也会成为影响获得共享对象的要素，例如拥有海外留学或生活背景的用户对于进口商品就会比一般用户更感兴趣。此外，用户以往的操作历史记录也可以成为确定共享对象的指示信息。在此，所述用户相关信息既可以是网络设备I独立获取的，也可以是接受来自用户设备2记录的，或者接受来自其他产品或第三方设备所获取的用户相关信息。本领域技术人员应能理解上述获得共享对象的方法仅为举例，其他现有的或今后可能出现的获得共享对象的的方法如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0070]	优选地，所述用户相关信息包括以下至少任一项：</p>
    <p>[0071]-所述用户的基本属性；</p>
    <p>[0072]-所述用户的地理位置；</p>
    <p>[0073]-所述用户的历史操作记录。</p>
    <p>[0074]	其中，用户的基本属性包括但不限于用户预先输入的个人背景信息，例如性别、年龄、宗教、国籍、教育程度等，用户的喜好信息等等；用户的地理位置包括但不限于用户的绝对地理位置，例如经纬度，或者用户的相对地理位置，例如用户处于哪一区域和哪一区域的交界；用户的历史操作记录包括但不限于用户历史的购买记录、浏览记录等。查询装置12根据所述场景图像，结合所述用户的用户相关信息，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，用户扫描到家乐福超市的场景图像时，当用户的地理位置显示其位于五角场地区，并且用户年龄偏长、平时喜好购买打折商品，则所述查询装置12可以基于以上用户信息，获得五角场家乐福超市的优惠信息，当用户的地理位置显示其位于万里地区，并且用户年龄偏轻、具有居住在国外的经历，则所述查询装置12可以基于以上用户信息，获得万里家乐福超市的进口商品信息。本领域技术人员应能理解上述用户相关信息仅为举例，其他现有的或今后可能出现的用户相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0075]	在一个优选实施例中（参见图2)，所述网络设备I还包括第一更新装置（未示出）。所述第一更新装置用于获取所述用户对所述一个或多个共享对象中至少一个的对象修改操作；根据所述对象修改操作，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。具体地，所述第一更新装置根据与用户设备2及用户的交互，获取所述用户通过接收装置23接收到一个或多个共享对象后对其中至少一个的对象修改操作，如修改共享对象的内容、形状、图层等，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。例如，当用户通过拍摄并上传场景照片获得了对象数据库中的共享对象后，用户可以对所述共享对象进行修改，并且选择继续将其更新至共享对象库中。则之后的用户获得的共享对象就将是已经被改动过 的共享对象。优选地，所述共享对象的修改权限可以由用户设置也可以是后台设置。更优选地，用户或后台在设置修改权限时可以限制修改共享对象的主体，比如只有自己可以修改，也可以限制可以被修改的共享对象状态信息，比如只有共享对象的图层信息可以被修改。本领域技术人员应能理解上述建立或更新共享对象库的方式仅为举例，其他现有的或今后可能出现的建立或更新共享对象库的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0076]	在另一个优选实施例中（参见图2)，所述网络设备I还包括第二更新装置（未示出）。所述第二更新装置用于获取大量用户对一个或多个现实场景的共享对象的对象共享操作；根据所述对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，建立或更新所述共享对象库。具体地，所述第二更新装置根据与用户设备2及用户的交互获取大量用户的对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，例如用户输入的预设信息和场景标识，记录和更新对象数据库。因此，在所述共享对象库中不仅存储了大量的共享对象和场景标识，存储形式包括但不限于文字、文档、图片等，同时也存储了两者间的映射关系。优选地，所述映射关系的存储形式包括但不限于：a)作为独立的数据存储，b)将共享对象与场景标识做成相对应的表格存储，c)将所述场景标识作为所述共享对象的一个状态信息（如共享对象的标签）存储。例如，若某一用户事先想在某地预留一张虚拟便条，那他可以事先编辑好便条的内容和对应的地址，并将其存储在共享对象库中。本领域技术人员应能理解上述建立或更新共享对象库的方式仅为举例，其他现有的或今后可能出现的建立或更新共享对象库的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0077]	本领域技术人员应能理解，上述第一更新装置和第二更新装置仅为示例，在实践中，它们可以是二个独立的模块，也可集成在一个模块中。</p>
    <p>[0078]	图4示出根据本发明另一个方面的用于获取与现实场景相关的共享对象的方法流程图。</p>
    <p>[0079]	网络设备I和用户设备2的各个步骤之间互相配合，以完成获取与现实场景相关的共享对象。具体地，在步骤SI中，用户设备2获取用户通过用户设备2提供的与现实场景相对应的场景图像；在步骤S2中，用户设备2向网络设备I发送基于所述场景图像的访问请求；网络设备I获取用户通过用户设备发送的基于与现实场景相对应的场景图像的访问请求；在步骤S3中，网络设备I根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象；在步骤S4中，网络设备I将所述一个或多个共享对象提供给所述用户设备2 ;用户设备2接收自所述网络设备I发送的基于所述访问请求的一个或多个共享对象。优选地，上述各个步骤之间是持续不断工作的。在此，本领域技术人员应理解“持续”是指上述各步骤分别按照设定的或实时调整的工作模式要求进行场景图像的获取、访问请求的发送与接收，共享对象的匹配、提供及接收，直至该用户在较长时间内停止通过用户设备2进行场景图像的提供。</p>
    <p>[0080]	更具体地，在步骤SI中，用户设备2获取用户通过用户设备2提供的与现实场景相对应的场景图像。具体地，用户提供场景图像的方式，包括但不限于在用户设备2中的文件夹、应用程序或客户端软件中调用、拍摄或者扫描一张包含现实场景的图像。例如，用户可以用手机拍摄一张以“上海置地广场”为背景的照片、或用电子绘图工具绘制一张以“徐家汇天主教堂”为对象的建筑画、或调用一张存储在电脑内的已有场景图片或者用户无需拍照或录制视频只需开启摄像头对准目标就可以提供该场景的场景图片等等；随后，在步 骤SI中，用户设备2通过例如调用用户设备2提供的应用程序接口（API)、或调用绘图程序中的保存程序或者调用摄像程序中的捕获图像程序等等，获取所述用户提供的场景图像。本领域技术人员应能理解上述获取场景图像的方式仅为举例，其他现有的或今后可能出现的获取场景图像的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0081]	在步骤S2中，用户设备2向网络设备I发送基于所述场景图像的访问请求。具体地，在步骤S2中，用户设备2根据在步骤SI中所获取的用户通过用户设备2提供的与现实场景相对应的场景图像，生成基于该场景图像的访问请求，随后在步骤S2中，用户设备2通过例如与网络设备I建立信道链路或一次或多次调用网络设备I提供的应用程序接口(API)等其他通信方式，将基于所述场景图像的访问请求发送至网络设备I。优选地，所述访问请求包含了所述场景图像。更优选地，所述访问请求的发送方式可以是自动的，例如客户端捕获到有摄像头的动作就自动发送访问请求，也可以是用户通过点击某个按钮后触发的，例如用户在菜单上选择“请求”选项或用户在用户设备2中选择“访问”按钮等等。本领域技术人员应能理解上述发送访问请求的方式仅为举例，其他现有的或今后可能出现的发送访问请求的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0082]	网络设备I获取用户通过用户设备2发送的基于与现实场景相对应的场景图像的访问请求。具体地，在步骤S2中，网络设备I例如通过如前例所述的API或其他约定的通信方式，获取用户设备2发送的根据在步骤SI中所获取的场景图像生成的访问请求。本领域技术人员应能理解上述获取访问请求的方式仅为举例，其他现有的或今后可能出现的获取访问请求的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0083]	在步骤S3中，网络设备I根据所述场景图像，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。具体地，在步骤S3中，网络设备I根据在步骤S2中所获取的基于场景图像的访问请求，从中解析出与所述现实场景相对应的场景图像，例如根据所述场景图像的内容、标签、关键字等信息，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，网络设备I可以根据大量用户对某个现实场景的共享对象的对象共享操作，并结合所述共享对象库中与所述共享对象操作行对应的场景标识，建立或更新共享对象库。因此，在所述共享对象库中不仅存储了大量的共享对象和场景标识（其存储形式包括但不限于文字、文档、图片等），同时也存储了两者间的映射关系。优选地，所述映射关系的存储形式包括但不限于：a)作为独立的数据存储，b)将共享对象与场景标识做成相对应的表格存储，c)将所述场景标识作为所述共享对象的一个状态信息（如共享对象的标签）存储。例如，当有用户选择将“百脑汇商场”的“打折信息”共享时，网络设备I就可以将该“打折信息”作为共享对象、将“百脑汇商场”作为场景标识，并且同时将“打折信息”与“百脑汇商场”的对应关系作为共享对象与场景标识的映射关系保存到对象数据库中。之后，一旦有用户发送与“百脑汇商场”相对应的访问请求，在步骤S3中，网络设备I即可根据共享对象与场景标识的映射关系，在所述共享对象库中进行匹配查询，获得与“百脑汇商场”有映射关系的一个或多个共享对象，如“打折信息”、“促销信息”或者“新品信息”等。本领域技术人员应能理解上述获得共享对象的方式仅为 举例，其他现有的或今后可能出现的获得共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0084]	在步骤S4中，网络设备I将所述一个或多个共享对象提供给所述用户设备2。具体地，在步骤S4中，网络设备I根据在步骤S3中所获得的一个或多个共享对象，例如通过图层叠加或页面处理技术，将所述一个或多个共享对象提供给所述用户设备2，例如将这些共享对象叠加显示于场景图像之上，或者利用JSP、ASP等页面处理技术将这些共享对象生成页面，并提供给用户设备2。接上例，当网络设备I在步骤S3中获得与“百脑汇商场”对应的共享对象后，在步骤S4中，网络设备I就将所述共享对象，如“打折信息”、“促销信息”或者“新品信息”提供给所述用户设备2。优选地，在步骤S4中，网络设备I可以通过短信、彩信或电子邮件的方式，也可以通过数据包打包的方式发送给用户，还可以按所述共享对象的原尺寸或缩略图等形式直接将共享对象显示在用户屏幕上。更优选地，所述提供方式可以是一次性将所有共享对象提供给用户，也可以是由用户按动特定功能键选择网络设备I提供上一个或下一个共享对象，该特定功能键例如可以是“ + ”和丨”和“丨”。更优选地，所述一个或多个共享对象的提供数目可以是缺省的也可由用户设定。本领域技术人员应能理解上述提供共享对象的方式仅为举例，其他现有的或今后可能出现的提供共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0085]	用户设备2接收来自所述网络设备I发送的基于所述访问请求的一个或多个共享对象。具体地，在步骤S4中，用户设备2接收来自网络设备I提供的根据在步骤S3中所获得的一个或多个共享对象。优选地，其接收方式可以是自动的，也可以是用户通过点击某个按钮后触发的，例如，用户设备2可以先通过一个对话框询问用户是否接收共享对象，用户选择“是”后，用户设备2遂开始接收。更优选地，用户设备2接收到所述共享对象后，可以自动打开所述共享对象，也可以先将其存储在用户设备2中等待用户通过例如打开收件箱或解压缩等方式打开。接上例，若“打折信息”、“促销信息”或者“新品信息”等是以短信的方式提供的，则用户可以通过打开收件箱接收；若共享对象是以数据包的方式提供的，则用户可以通过下载并解压缩接收；若共享对象是直接显示在屏幕上的，则用户无需另行接收。优选地，所述共享对象的显示方式可以是通过新页面显示，也可以是以悬浮形式叠加在原有屏幕上。更优选地，当以悬浮形式叠加在原有屏幕上显示时，所述共享对象可以是在页面的某个固定的区域显示，也可以由用户设定的位置确定。接上例，当在步骤S4中，用户设备2将“打折信息”、“促销信息”或“新品信息”直接显示在用户的屏幕上时，用户设备2可以通过新页面显示，也可以是以悬浮窗形式将所述信息叠加在原有“百脑汇商场”图像的上方、下方或左右。本领域技术人员应能理解上述接收共享对象的方式仅为举例，其他现有的或今后可能出现的接收共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0086]	图5示出根据本发明一个优选实施例的用于获取与现实场景相关的共享对象的方法流程图，其中，步骤SI’、S4’分别与图4所示对应步骤SI及S4相同，故此处不再赘述，</p>
    <p>并通过引用的方式包含于此。</p>
    <p>[0087]	其中，在步骤S5’中，用户设备2获取与所述现实场景相对应的场景相关信息；在步骤S2’中，用户设备2还可以向所述网络设备I发送所述访问请求，其中，所述访问请求包括所述场景相关信息；网络设备I获取该访问请求；在步骤S3’中，网络设备I根据所述场景图像与所述场景相关信息，在所述共享对象库中进行匹配查询，以获取所述一个或多个共享对象。具体地，在步骤S5’中，用户设备2通过例如对现实场景进行定位服务、或接收用户对场景添加的批注或者对场景图像进行图像识别等方式，获取与所述现实场景相对应的场景相关信息，如现实场景的描述信息、关键词信息等；随后在步骤S2’中，用户设备2根据在步骤S5’中所获取的场景图像与在步骤S5’中所获取的场景相关信息生成访问请求，向网络设备I发送该访问请求；网络设备I获取该访问请求后，在步骤S3’中，网络设备I从该访问请求中解析出所述场景图像与场景相关信息，根据该场景图像的标签或关键词，结合场景相关信息的内容，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。在此，所述场景相关信息既可以是网络设备I独立获取的，也可以是接受来自用户设备2记录的，或者接受来自其他产品或第三方设备所获取的场景相关信息。例如，所述场景相关信息可以是用户设备2通过全球定位服务（GPS)获取的场景地理位置“上海市徐汇区漕溪北路333号”、或通过接收用户添加的批注获取的“徐家汇电子商场”或者通过图像识别处理获取的场景形状是“鸟巢”等等。本领域技术人员应能理解上述获取场景相关信息的方式仅为举例，其他现有的或今后可能出现的获取场景相关信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0088]	优选地，所述场景相关信息包括但不限于：</p>
    <p>[0089]-所述现实场景的位置信息；</p>
    <p>[0090]-所述现实场景的描述信息；</p>
    <p>[0091]-所述现实场景的标志性信息。</p>
    <p>[0092]	具体地，结合所述场景相关信息可以更准确地帮助网络设备I在步骤S3’中确认所述基于与现实场景相对应的场景图像的访问请求所对应的现实场景，从而获得与访问请求相对应的一个或多个共享对象。以位置信息为例，当在步骤S5’中，用户设备2通过全球定位服务（GPS)获取到的场景相关信息是“上海市徐汇区漕溪北路333号”时，所述网络设备I就能根据场景图像的内容、标签、关键词等结合该场景相关信息确定现实场景就是“徐家汇百脑汇商场”，进而获得对应的一个或多个共享对象；以描述信息为例，当在步骤S5’中，用户设备2通过用户添加的批注获取到的场景相关信息是“徐家汇电子商场”时，所述网络设备I在步骤S3’中也能根据场景图像的内容、标签、关键词等结合该场景相关性信息确定现实场景就是“徐家汇百脑汇商场”；以标志性信息为例，当在步骤S5’中，用户设备2通过图像识别处理获取到的场景相关信息是“鸟巢”，所述网络设备I在步骤S3’中就能根据场景图像的内容、标签、关键词等结合该场景相关信息确定现实场景就是“国家体育场”。本领域技术人员应能理解上述场景相关信息仅为举例，其他现有的或今后可能出现的场景相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0093]	更优选地，所述场景相关信息包括所述现实场景的位置信息，其中，在步骤S5’中，用户设备2还可以根据位置提供服务，获取与所述现实场景相对应的所述位置信息。优选地，所述位置信息包括但不限于：1)绝对地理位置信息，如现实场景的经度、维度坐标；2) 场景的相对地理位置信息，如“位于虹口区和闸北区的交界处”。更优选地，在步骤S5’中，用户设备2获取与所述现实场景相对应的所述位置信息的方法包括但不限于：对该现实场景进行全球定位系统（GPS)定位、蜂窝基站定位或者位置服务器定位等方式。例如，在步骤S5’中，用户设备2通过GPS定位，获取某一场景的位置信息为“上海市徐汇区漕溪北路333号”，随后在步骤S2’中，用户设备2将包括该位置信息的访问请求发送给网络设备1，在步骤S3’中，网络设备I根据该位置信息匹配查询到与“徐家汇百脑汇”相对应的共享对象。本领域技术人员应能理解上述获取位置信息的方式仅为举例，其他现有的或今后可能出现的获取位置信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0094]	在一个优选实施例中（参见图4)，在步骤S6(未示出）中，网络设备I对所述场景图像进行图像识别处理，以获得与所述场景图像相对应的图像相关信息；其中，在步骤S3中，网络设备I根据所述场景图像与所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。具体地，在步骤S2中，网络设备I从用户设备2处获取与现实场景相对应的场景图像的访问请求后，网络设备I从中解析出场景图像，随后在步骤S6中，网络设备I对所述场景图像进行图像识别，包括但不限于对所述场景图像进行特征识别、文字识别或者边缘识别等，以获得与所述场景图像相对应的图像相关信息，例如图像的背景信息、描述信息等等。随后在步骤S3中，网络设备I根据该图像相关信息的内容，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。例如，若在步骤S6中，网络设备I识别出用户发送的场景图像是“百脑汇商场”，则在步骤S3中，网络设备I即可根据共享对象与场景标识的映射关系，在所述共享对象库中进行匹配查询，获得与“百脑汇商场”有映射关系的一个或多个共享对象。本领域技术人员应能理解上述获得图像相关信息的方式仅为举例，其他现有的或今后可能出现的获得图像相关信息的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0095]	更优选地，所述图像相关信息包括以下至少任一项：</p>
    <p>[0096]-所述场景图像所对应的背景信息；</p>
    <p>[0097]-所述场景图像所对应的对象信息；[0098]-所述场景图像所对应的关键词信息。</p>
    <p>[0099]	具体地，该图像识别过程包括但不限于对场景图像进行特征识别、文字识别或者边缘识别。以边缘识别和背景信息为例，若用户发送一张以“上海东方明珠”为背景的照片，则所述网络设备I在步骤S6中首先对该建筑物与其他背景间的交界线进行定位，随后判断出该边缘轮廓线条是3个大小不一但有排列有序的“球形”以及若干“圆柱体”的组合，从而得出该建筑是“上海东方明珠”的背景信息。以文字识别和对象信息为例，若用户发送了一张以“上海梅龙镇广场”招牌为拍摄对象的图片后，所述网络设备I在步骤S6中首先对照片中的文字进行剥离，随后通过文字识别辨认出“上”、“海”、“梅”、“龙”、“镇”、“广”、“场”，从而得出该场景是“上海梅龙镇广场”的对象信息。以特征识别和关键词信息为例，若用户发送了一张含有“徐家汇天主教堂”的图片，由于天主教堂相对于其他建筑物具有比较明显的特征，如尖顶，长线条，繁密排列，因此在步骤S6中，网络设备I可以通过这些特征识别出该场景是“徐家汇天主教堂”的特征信息。随后，在步骤S3中，网络设备I就可以根据获得的图像相关信息，如“上海东方明珠”、“上海梅龙镇广场”或“徐家汇天主教堂”，在所述共享 对象库中进行匹配查询，以获得所述一个或多个共享对象。本领域技术人员应能理解上述图像相关信息仅为举例，其他现有的或今后可能出现的图像相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0100]	更优选地（参见图5)，在步骤S3’中，网络设备I根据所述场景图像与所述场景相关信息，结合所述图像相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。具体地，在步骤S3’中，网络设备I根据在步骤S2中所获取的场景图像，与在步骤S5’中所获取的场景相关信息，如位置信息、描述信息、标志性信息，结合网络设备I在步骤S6中所获得的图像相关信息，如背景信息、对象信息、关键词信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。例如，在步骤S2’中，网络设备I除了获取自用户设备2在步骤SI中’所获取的场景图像之外，也获取来自于用户设备2在步骤S5’中所获取的场景相关信息，如通过GPS定位获取的位置信息“上海市徐汇区漕溪北路333号”，同时网络设备I在步骤S6中通过图像识别技术得出该场景图像的背景信息是“徐家汇百脑汇”，则网络设备I在步骤S3’中首先匹配位置信息，在位置信息与“徐家汇百脑汇商场”场景标识的位置信息匹配成功时，再匹配图像相关信息，对图像相关信息的匹配度允许一定的容错机制。例如，网络设备I可以设置如果位置信息完全相同，且图像相关信息中80%以上匹配，则获得与该场景标识相对应的共享对象。本领域技术人员应能理解上述获得共享对象的方式仅为举例，其他现有的或今后可能出现的获得共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0101]	在另一个优选实施例中（参见图4)，在步骤S4中，网络设备I根据所述一个或多个共享对象所对应的对象状态信息，将所述一个或多个共享对象提供给所述用户设2。具体地，在步骤S4中，网络设备I根据在步骤S3中所获得的一个或多个共享对象，结合所述一个或多个共享对象所对应的对象状态信息，例如所述共享对象的标签信息、类别信息、图层信息、属性信息、布局信息等，将所述一个或多个共享对象提供给所述用户设备2。例如，网络设备I可以根据大量用户对一个或多个现实场景的共享对象的对象共享操作，并结合所述共享对象的对象状态信息，建立或更新所述共享对象库。因此，在所述共享对象库中不仅存储了大量的共享对象，并且不同的共享对象还拥有各自不同的对象状态信息。具体地，所述网络设备2可根据共享对象的内容、类别不同，将不同的共享对象存储在不同的类别或标签中，故而，在步骤S4中，所述网络设备I可以根据不同的类别或标签中将一个或多个共享对象提供给用户。本领域技术人员应能理解上述提供共享对象的方式仅为举例，其他现有的或今后可能出现的提供共享对象的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0102]	优选地，所述对象状态信息包括以下至少任一项：</p>
    <p>[0103]-所述共享对象的标签信息；</p>
    <p>[0104]-所述共享对象的类别信息；</p>
    <p>[0105]-所述共享对象的图层信息；</p>
    <p>[0106]-所述共享对象的属性信息；</p>
    <p>[0107]-所述共享对象的布局信息。</p>
    <p>[0108]	其中，标签信息包括但不限于共享对象所映射的场景标识，如“打折信息a”的标签是“置地广场”，“打折信息b”的标签是“百脑汇商场”等等；类别信息包括但不限于共享对象的种类，如“商品信息”、“服务信息”、“交通信息”;图层信息包括但不限于共享对象在屏幕上的显示图层，例如，后台可以把不同类别的共享对象设置在不同图层上，接上例，假设屏幕初始显示的“百脑汇商场”的场景图像是第一图层，则“商品信息”类别的共享对象叠加显示在第一图层之上，即第二图层，“服务信息”显示在第三图层上，以此类推，方便用户筛选类别；属性信息包括但不限于共享对象的类型（如文本、图形或者图文结合）、共享对象的内容、大小、形状等等；布局信息包括但不限于共享对象显示在屏幕上的位置，例如，后台可以把不同类别的共享对象设置在屏幕上的不同位置上，接上例，假设屏幕初始显示的是“百脑汇商场”场景图像，则“商品信息”类别的共享对象显示在场景图像的上方，“服务信息”显示在场景图像的下方，以此类推，供用户加以区分。优选地，所述共享对象的对象状态信息既可以是网络设备I独立获取的，如后台根据图像识别、内容识别或者位置识别而自动设置的，也可以是接受来自用户设备2记录的，如由用户设置的，或者接受来自其他产品或第三方设备所获取的共享对象的对象状态信息。本领域技术人员应能理解上述对象状态信息仅为举例，其他现有的或今后可能出现的对象状态信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0109]	在又一个优选实施例中（参见图4)，在步骤S3中，网络设备I还可以根据所述场景图像，结合所述用户的用户相关信息，在所述共享对象库中进行匹配查询，以获得所述一个或多个共享对象。具体地，在步骤S3中，网络设备I根据在步骤SI中所获取的场景图像访问请求，从中解析出与所述现实场景相对应的场景图像，根据所述场景图像，结合所述用户的用户相关信息，例如所述用户的基本属性、地理位置、历史操作记录等，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，对男性、女性、儿童、老年人等，当其所提供的场景图像中包含“**商场”时，其实际需求区别较大，其中，男性用户可能对运动产品、男性服饰、电子产品更感兴趣、女性用户可能对护肤/化妆品、女性服饰更感兴趣，儿童用户可能对儿童服饰、儿童读物和卡通等更感兴趣，而老年用户可能对老年服饰、保养品更感兴趣。当然，用户的个人背景，如教育背景、生活背景、宗教 背景等也会成为影响获得共享对象的要素，例如拥有海外留学或生活背景的用户对于进口商品就会比一般用户更感兴趣。此外，用户以往的操作历史记录也可以成为确定共享对象的指示信息。在此，所述用户相关信息既可以是网络设备I独立获取的，也可以是接受来自用户设备2记录的，或者接受来自其他产品或第三方设备所获取的用户相关信息。本领域技术人员应能理解上述获得共享对象的方法仅为举例，其他现有的或今后可能出现的获得共享对象的的方法如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0110]	优选地，所述用户相关信息包括以下至少任一项：</p>
    <p>[0111]-所述用户的基本属性；</p>
    <p>[0112]-所述用户的地理位置；</p>
    <p>[0113]-所述用户的历史操作记录。 </p>
    <p>[0114]	其中，用户的基本属性包括但不限于用户预先输入的个人背景信息，例如性别、年龄、宗教、国籍、教育程度等，用户的喜好信息等等；用户的地理位置包括但不限于用户的绝对地理位置，例如经纬度，或者用户的相对地理位置，例如用户处于哪一区域和哪一区域的交界；用户的历史操作记录包括但不限于用户历史的购买记录、浏览记录等。在步骤S3中，网络设备I根据所述场景图像，结合所述用户的用户相关信息，在共享对象库中进行匹配查询，以获得与所述访问请求相对应的一个或多个共享对象。例如，用户扫描到家乐福超市的场景图像时，当用户的地理位置显示其位于五角场地区，并且用户年龄偏长、平时喜好购买打折商品，则在步骤S3中，网络设备I可以基于以上用户信息，获得五角场家乐福超市的优惠信息，当用户的地理位置显示其位于万里地区，并且用户年龄偏轻、具有居住在国外的经历，则在步骤S3中，网络设备I可以基于以上用户信息，获得万里家乐福超市的进口商品信息。本领域技术人员应能理解上述用户相关信息仅为举例，其他现有的或今后可能出现的用户相关信息如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0115]	在一个优选实施例中（参见图4)，在步骤S7(未示出）中，网络设备I还可以获取所述用户对所述一个或多个共享对象中至少一个的对象修改操作；根据所述对象修改操作，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。具体地，在步骤S7中，网络设备I根据与用户设备2及用户的交互，获取所述用户通过用户设备2接收到一个或多个共享对象后对其中至少一个的对象修改操作，如修改共享对象的内容、形状、图层等，并结合所述共享对象库中与所述对象修改操作相对应的场景标识，建立或更新所述共享对象库。例如，当用户通过拍摄并上传场景照片获得了对象数据库中的共享对象后，用户可以对所述共享对象进行修改，并且选择继续将其更新至共享对象库中。则之后的用户获得的共享对象就将是已经被改动过的共享对象。优选地，所述共享对象的修改权限可以由用户设置也可以是后台设置。更优选地，用户或后台在设置修改权限时可以限制修改共享对象的主体，比如只有自己可以修改，也可以限制可以被修改的共享对象状态信息，比如只有共享对象的图层信息可以被修改。本领域技术人员应能理解上述建立或更新共享对象库的方式仅为举例，其他现有的或今后可能出现的建立或更新共享对象库的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0116]	在另一个优选实施例中（参见图4)，在步骤S8(未示出）中，所述网络设备I还可以获取大量用户对一个或多个现实场景的共享对象的对象共享操作；根据所述对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，建立或更新所述共享对象库。具体地，在步骤S8中，网络设备I根据与用户设备2及用户的交互获取大量用户的对象共享操作，并结合所述共享对象库中与所述对象共享操作相对应的场景标识，例如用户输入的预设信息和场景标识，记录和更新对象数据库。因此，在所述共享对象库中不仅存储了大量的共享对象和场景标识，存储形式包括但不限于文字、文档、图片等，同时也存储了两者间的映射关系。优选地，所述映射关系的存储形式包括但不限于：a)作为独立的数据存储，b)将共享对象与场景标识做成相对应的表格存储，c)将所述场景标识作为所述共享对象的一个状态信息（如共享对象的标签）存储。例如，若某一用户事先想在某地预留一张虚拟便条，那他可以事先编辑好便条的内容和对应的地址，并将其存储在共享对象库中。本领域技术人员应能理解上述建立或更新共享对象库的方式仅为举例，其他现有的或今后可能出现的建立或更新共享对象库的方式如可适用于本发明，也应包含在本发明保护范围以内，并在此以引用方式包含于此。</p>
    <p>[0117]	对于本领域技术人员而言，显然本发明不限于上述示范性实施例的细节，而且在不背离本发明的精神或基本特征的情况下，能够以其他的具体形式实现本发明。因此，无论从哪一点来看，均应将实施例看作是示范性的，而且是非限制性的，本发明的范围由所附权 利要求而不是上述说明限定，因此旨在将落在权利要求的等同要件的含义和范围内的所有变化囊括在本发明内。不应将权利要求中的任何附图标记视为限制所涉及的权利要求。此夕卜，显然“包括” 一词不排除其他单元或步骤，单数不排除复数。系统权利要求中陈述的多个单元或装置也可以由一个单元或装置通过软件或者硬件来实现。第一，第二等词语用来表示名称，而并不表示任何特定的顺序。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101000623A?cl=zh">CN101000623A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年1月8日</td><td class="patent-data-table-td patent-date-value">2007年7月18日</td><td class="patent-data-table-td ">深圳市宜搜科技发展有限公司</td><td class="patent-data-table-td ">通过手机拍照进行图像识别搜索的方法及采用该方法的装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103002410A?cl=zh">CN103002410A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">北京百度网讯科技有限公司</td><td class="patent-data-table-td ">用于移动终端的增强现实方法、系统和移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103002410B?cl=zh">CN103002410B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td patent-date-value">2015年4月8日</td><td class="patent-data-table-td ">北京百度网讯科技有限公司</td><td class="patent-data-table-td ">用于移动终端的增强现实方法、系统和移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015192615A1?cl=zh">WO2015192615A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年12月9日</td><td class="patent-data-table-td patent-date-value">2015年12月23日</td><td class="patent-data-table-td ">西安中兴新软件有限责任公司</td><td class="patent-data-table-td ">一种图像文件共享方法、装置和计算机存储介质</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0029080000">H04L29/08</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30477">G06F17/30477</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=S1KlBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30047">G06F17/30047</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年9月26日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/ff377db3958a477d84aa/CN102694826A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E7%94%A8%E4%BA%8E%E8%8E%B7%E5%8F%96%E4%B8%8E%E7%8E%B0%E5%AE%9E%E5%9C%BA%E6%99%AF%E7%9B%B8%E5%85%B3.pdf?id=S1KlBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0x5ex5ub6ZEl8BsKB7SwgMVLzSjg"},"sample_url":"https://www.google.com/patents/reader?id=S1KlBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>