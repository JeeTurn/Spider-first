<!DOCTYPE html><html><head><title>专利 CN102592308A - 基于小波变换的单相机视频三维重建方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于小波变换的单相机视频三维重建方法"><meta name="DC.contributor" content="李坤" scheme="inventor"><meta name="DC.contributor" content="杨敬钰" scheme="inventor"><meta name="DC.contributor" content="江建民" scheme="inventor"><meta name="DC.contributor" content="天津大学" scheme="assignee"><meta name="DC.date" content="2011-11-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明属于计算机多媒体技术领域。为提供一种精确鲁棒的单相机视频三维重建方法，更加精确地重建非刚性物体形状和相机运动，本发明采取的技术方案是，一种基于小波变换的单相机视频三维重建方法，包括以下步骤：1)手持一台相机围绕一个运动物体运动，同时采集一段视频；2)采用KLT特征点跟踪方法计算每一帧图像的对应特征点；3)选取跟踪时间最长即所对应的帧图像最多的n个对应特征点；4)计算由步骤3)得到的的n个对应特征点所在的帧图像，并依照所含对应特征点多、图像之间间隔均匀的原则选取m幅帧图像；5)建立观测矩阵6)基于小波变换将观测矩阵W分解；7)计算各个时刻的三维点云。本发明主要应用于视频三维重建。"><meta name="DC.date" content="2012-7-18"><meta name="DC.relation" content="CN:101398886:A" scheme="references"><meta name="DC.relation" content="US:20040017952:A1" scheme="references"><meta name="citation_reference" content="历茂海，等: &quot;基于单目视觉的移动机器人全局定位&quot;, 《机器人》, vol. 29, no. 2, 31 March 2007 (2007-03-31)"><meta name="citation_reference" content="周佳立，等: &quot;基于双目被动立体视觉的三维人脸重构与识别&quot;, 《自动化学报》, vol. 35, no. 2, 28 February 2009 (2009-02-28), pages 123 - 131"><meta name="citation_reference" content="罗三定，等: &quot;基于SURF和KLT跟踪的图像拼接算法&quot;, 《计算机工程》, vol. 36, no. 1, 31 January 2010 (2010-01-31), pages 215 - 218"><meta name="citation_patent_publication_number" content="CN:102592308:A"><meta name="citation_patent_application_number" content="CN:201110390763"><link rel="canonical" href="https://www.google.com/patents/CN102592308A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102592308A?cl=zh"/><meta name="title" content="专利 CN102592308A - 基于小波变换的单相机视频三维重建方法"/><meta name="description" content="本发明属于计算机多媒体技术领域。为提供一种精确鲁棒的单相机视频三维重建方法，更加精确地重建非刚性物体形状和相机运动，本发明采取的技术方案是，一种基于小波变换的单相机视频三维重建方法，包括以下步骤：1)手持一台相机围绕一个运动物体运动，同时采集一段视频；2)采用KLT特征点跟踪方法计算每一帧图像的对应特征点；3)选取跟踪时间最长即所对应的帧图像最多的n个对应特征点；4)计算由步骤3)得到的的n个对应特征点所在的帧图像，并依照所含对应特征点多、图像之间间隔均匀的原则选取m幅帧图像；5)建立观测矩阵6)基于小波变换将观测矩阵W分解；7)计算各个时刻的三维点云。本发明主要应用于视频三维重建。"/><meta property="og:title" content="专利 CN102592308A - 基于小波变换的单相机视频三维重建方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102592308A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102592308A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=ZI-JBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102592308A&amp;usg=AFQjCNHZ9YjuD1T93ZxiHhtoPk4zDdILMg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/b04dff8d61c8eb72b3bd/CN102592308A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/b04dff8d61c8eb72b3bd/CN102592308A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102592308A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102592308A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102592308A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102592308B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102592308A?cl=zh" style="display:none"><span itemprop="description">本发明属于计算机多媒体技术领域。为提供一种精确鲁棒的单相机视频三维重建方法，更加精确地重建非刚性物体形状和相机运动，本发明采取的技术方案是，一种基于小波变换的单相机视频三维重建方法，包括以下步骤：1)手 ...</span><span itemprop="url">https://www.google.com/patents/CN102592308A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102592308A - 基于小波变换的单相机视频三维重建方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102592308A - 基于小波变换的单相机视频三维重建方法" title="专利 CN102592308A - 基于小波变换的单相机视频三维重建方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102592308 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110390763</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年7月18日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年11月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年11月30日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102592308B?hl=zh-CN&amp;cl=zh">CN102592308B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110390763.8, </span><span class="patent-bibdata-value">CN 102592308 A, </span><span class="patent-bibdata-value">CN 102592308A, </span><span class="patent-bibdata-value">CN 201110390763, </span><span class="patent-bibdata-value">CN-A-102592308, </span><span class="patent-bibdata-value">CN102592308 A, </span><span class="patent-bibdata-value">CN102592308A, </span><span class="patent-bibdata-value">CN201110390763, </span><span class="patent-bibdata-value">CN201110390763.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E5%9D%A4%22">李坤</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%A8%E6%95%AC%E9%92%B0%22">杨敬钰</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B1%9F%E5%BB%BA%E6%B0%91%22">江建民</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%22">天津大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102592308A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102592308A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102592308A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ZI-JBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110390763&amp;usg=AFQjCNH4KMlYccCtDpohajlKSHjIhr1JTQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ZI-JBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102592308A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFsmbSkGp5ES5UohtlTYqHRWt6ROQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114089184" lang="ZH" load-source="patent-office">基于小波变换的单相机视频三维重建方法</invention-title>
      </span><br><span class="patent-number">CN 102592308 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA98437285" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明属于计算机多媒体技术领域。为提供一种精确鲁棒的单相机视频三维重建方法，更加精确地重建非刚性物体形状和相机运动，本发明采取的技术方案是，一种基于小波变换的单相机视频三维重建方法，包括以下步骤：1)手持一台相机围绕一个运动物体运动，同时采集一段视频；2)采用KLT特征点跟踪方法计算每一帧图像的对应特征点；3)选取跟踪时间最长即所对应的帧图像最多的n个对应特征点；4)计算由步骤3)得到的的n个对应特征点所在的帧图像，并依照所含对应特征点多、图像之间间隔均匀的原则选取m幅帧图像；5)建立观测矩阵6)基于小波变换将观测矩阵W分解；7)计算各个时刻的三维点云。本发明主要应用于视频三维重建。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(2)</span></span></div><div class="patent-text"><div mxw-id="PCLM44434951" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种基于小波变换的单相机视频三维重建方法，其特征在于该方法包括以下步 骤：：1)手持一台相机围绕一个运动物体运动，同时米集一段视频；2)采用KLT特征点跟踪方法计算每一帧图像的对应特征点，KLT为 Kanade-Lucas-Tomasi 字头缩写；3)选取跟踪时间最长即所对应的帧图像最多的n个对应特征点；4)计算由步骤3)得到的的n个对应特征点所在的帧图像，并依照所含对应特征点多、 图像之间间隔均匀的原则选取m幅帧图像；5)建立观测矩阵Wej	其中矩阵每一列为一个对应特征点在m幅帧图像上的对应 像素位置，矩阵每两行为一幅帧图像上n个特征点对应的像素坐标（x，y)；6)基于小波变换将观测矩阵W分解为W	= MS + tF=D(QX&#174;I3)S + tF的形式，其中 Mg i 为运动矩阵,Sej 为形状基矩阵，r为形状基的个数,te丨2)"为1平均列向量， lei "为元素都为1的向量，Dei 2mx3m为对角矩阵，对角线元素为m个帧图像所对应视角的 2X3的旋转矩阵，Qei 为截断的小波基函数，d为截断后的小波基个数，Xq ~为形状 轨迹在小波基表示下的系数，13为3X3的单位矩阵表示矩阵的Kronecker乘法，（&#8226;）T 表示矩阵的转置；7)计算各个时刻的三维点云，即动态三维点云S'	= (QX&#174;I3)S。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求1所述方法，其特征是，基于小波变换分解观测矩阵的方法具体包括以 下步骤：6-1)计算观测矩阵W的平均列向量t ；6-2)迭代地采用PTA方法计算矩阵D，直到平均正交化误差没有变化为止，PTA是point trajectory approach	： <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00021.png"> <img id="icf0001" file="CN102592308AC00021.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00021.png" class="patent-full-image" alt="Figure CN102592308AC00021"> </a> </div>其中，Ri为第i帧图像所对应的2X3的旋转矩阵，12为2X2的单位矩阵，|| &#8226; | ^表 示矩阵的Frobenius范数；6-3)计算J级分解的Daubechies 10(dbl0)小波的基函数矩阵，即对mXm的单位矩阵 求反变换；6-4)对步骤6-2)得到的Daubechies 10小波基矩阵进行截断，即去掉最后的m_d列， 形成新的mXd的小波基矩阵Q ；6-5)初始化 <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00022.png"> <img id="icf0002" file="CN102592308AC00022.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00022.png" class="patent-full-image" alt="Figure CN102592308AC00022"> </a> </div>；6-6)采用Damped-Newton非线性优化方法求解以下优化问题： <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00023.png"> <img id="icf0003" file="CN102592308AC00023.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AC00023.png" class="patent-full-image" alt="Figure CN102592308AC00023"> </a> </div>其中，％为矩阵W的第j列，(^表示矩阵的伪逆；6-7)使用步骤 6-6)得至IJ的 X 求解 M 和 S :1^ = 0(11又013)，8 = 1\^(\&#165;-打0。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES50186198" lang="ZH" load-source="patent-office" class="description">
    <p>基于小波变换的单相机视频三维重建方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明属于计算机多媒体技术领域，具体讲，涉及小波变换及单相机视频三维重建方法。</p>
    <p>背景技术</p>
    <p>[0002]	为了给人们带来视觉上的沉浸感、立体感以及对对象的全方位认识（视角可变、 外部光照可变等），现有的场景捕获已经从原有的单视角采集方式发展到多视角采集方式。 多视角采集可以通过分布在不同位置上的多摄像机的同步采集来实现，国际上多所著名大学与研究机构如：斯坦福、麻省理工、卡奈基梅隆、萨里大学、三菱电子、微软研究院、马克斯-普朗克信息研究所都搭建了多摄像机采集系统。然而，多摄像机的采集方式存在成本高、校准复杂、系统维护困难、图像分辨率有限等问题。为了降低成本和复杂度、提高图像采集分辨率，另一种基于单相机视频的多视角采集方式越来越受到欢迎，并在广播电视、城市建设、等领域有着广泛的应用前景。该方法采用单个相机围绕场景拍摄一段视频，然后根据所拍摄的视频联合重建三维场景结构和相机的运动。这种方法对于刚性静态物体取得了很好的结果(J. Fortuna and A. M. Martinez, Rigid Structure from Motion from a Blind Source Separation Perspective,International Journal of Computer Vision,Vol. 88, No. 3，pp. 404-424,2010.)，但是对于非刚性运动物体，尤其是复杂的变形物体，仍然存在一定难度。一些研究人员&#37318;用DCT变换对物体形状轨迹进行建模来重建非刚性运动物体的形状和相机运动(I. Akhter, Y. A. Sheikh, S. Khan, and T. Kanade. Nonrigid structure from motion in trajectory space, in Neural Information Processing Systems, December 2008. P. F. U. Gotardo and A. M. Martinez. Computing smooth time-trajectories for camera and deformable shape in structure from motion with occlusion. IEEE Trans. PAMI，2011.)，但是DCT对于非平滑轨迹的描述能力有限，因而精度很难提高。</p>
    <p>发明内容</p>
    <p>[0003]	为克服现有技术的不足，提供一种精确鲁棒的单相机视频三维重建方法，更加精确地重建非刚性物体形状和相机运动，为达到上述目的，本发明采取的技术方案是，一种基于小波变换的单相机视频三维重建方法，包括以下步骤：</p>
    <p>[0004]	I)手持一台相机围绕一个运动物体运动，同时采集一段视频；</p>
    <p>[0005]	2)采用KLT特征点跟踪方法计算每一帧图像的对应特征点，KLT为 Kanade-Lucas-Tomasi 字头缩写；</p>
    <p>[0006]	3)选取跟踪时间最长即所对应的帧图像最多的η个对应特征点；</p>
    <p>[0007]	4)计算由步骤3)得到的的η个对应特征点所在的帧图像，并依照所含对应特征点多、图像之间间隔均匀的原则选取m幅帧图像；</p>
    <p>[0008]	5)建立观测矩阵We i 其中矩阵每一列为一个对应特征点在m幅帧图像上的对应像素位置，矩阵每两行为一幅帧图像上η个特征点对应的像素坐标（x，y)；[0009]	6)基于小波变换将观测矩阵W分解为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00041.png"> <img id="idf0001" file="CN102592308AD00041.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00041.png" class="patent-full-image" alt="Figure CN102592308AD00041"> </a> </div>
    <p>形式，其中Mei 为运动矩阵，Sei 为形状基矩阵，r为形状基的个数，tei 2；"为1平均列向量，Iei "为元素都为I的向量，Dei 2mx3m为对角矩阵，对角线元素为m个帧图像所对应视角的2X3的旋转矩阵，Qei mxd为截断的小波基函数，d为截断后的小波基个数，Xei d','r 为形状轨迹在小波基表示下的系数，I3为3X3的单位矩阵，&#174;表示矩阵的Kronecker乘法， (&#183;)τ表示矩阵的转置；</p>
    <p>[0010]	7)计算各个时刻的三维点云，即动态三维点云S、(nx&#174;l3)s。</p>
    <p>[0011]	基于小波变换分解观测矩阵的方法具体包括以下步骤：</p>
    <p>[0012]	6-1)计算观测矩阵W的平均列向量t ；</p>
    <p>[0013]	6-2)迭代地采用PTA方法计算矩阵D，直到平均正交化误差没有变化为止，PTA是 point trajectory approach 的字头缩写；</p>
    <p> [0014]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00042.png"> <img id="idf0002" file="CN102592308AD00042.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00042.png" class="patent-full-image" alt="Figure CN102592308AD00042"> </a> </div>
    <p>[0015]	其中，Ri为第i帧图像所对应的2X3的旋转矩阵，I2为2X2的单位矩阵，| | &#183; | |F 表示矩阵的Frobenius范数；</p>
    <p>[0016]	6-3)计算J级分解的Daubechies 10 (dblO)小波的基函数矩阵，即对mXm的单位矩阵求反变换；</p>
    <p>[0017]	6-4)对步骤6-2)得到的Daubechies 10小波基矩阵进行截断，即去掉最后的m_d 列，形成新的mXd的小波基矩阵Ω ；</p>
    <p>[0018]	6-5)初始化X= ^ ；</p>
    <p>[0019]	6-6)采用Damped-Newton非线性优化方法求解以下优化问题：</p>
    <p>[0020]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00043.png"> <img id="idf0003" file="CN102592308AD00043.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00043.png" class="patent-full-image" alt="Figure CN102592308AD00043"> </a> </div>
    <p>[0021]	其中，％为矩阵W的第j列，(丨表示矩阵的伪逆；</p>
    <p>[0022]	6-7)使用步骤 6-6)得到的 X 求解 M 和 S :M = D(QX&#174;I3)，S = M'W-tf )。</p>
    <p>[0023]	本发明的方法的特点及效果：</p>
    <p>[0024]	本发明方法避免了 DCT基函数对运动轨迹描述过于平滑等问题，利用小波基函数多分辨率分析的特点及其对细节描述的优越性，实现了由单相机视频的高精度的非刚性动态物体三维重建，在小波变换域对形状轨迹进行更好的描述，从而更加精确地重建非刚性物体形状和相机运动，具体具有以下特点：</p>
    <p>[0025]	I、程序简单，易于实现；</p>
    <p>[0026]	2、采用Daubechies 10小波基函数对形状运动轨迹进行精确描述和逼近；</p>
    <p>[0027]	3、可根据单相机拍摄的视频同时估计出相机的运动和所拍摄运动物体的动态形状；</p>
    <p>[0028]	4、重建的动态三维点云精度高、迭代次数少。</p>
    <p>[0029]	本发明可以采用单个相机实现动态场景的三维重建。所提出的方法具有很好的可扩展性：可以通过使用小波基函数对相机运动轨迹进行描述将本发明方法扩展到刚性静态物体的三维重建中。</p>
    <p>附图说明</p>
    <p>[0030]	本发明上述的和/或附加的方面和优点从下面结合附图对实施例的描述中将变得明显和容易理解，其中：</p>
    <p>[0031]	图I为本发明实施例的基于小波变换的单相机视频三维重建方法流程图；</p>
    <p>[0032]	图2为本发明实施例采用DCT基函数和小波基函数对Shark数据集重建的第I时刻的三维点云在三个视角下观看的结果。</p>
    <p>具体实施方式</p>
    <p>[0033]	本发明利用小波基函数多分辨率分析的特点及其对细节描述的优越性，对形状轨迹进行更好的描述，从而更加精确地重建非刚性动态物体的形状和相机的运动。所得结果具有效果好，精度高，迭代次数少的特点。</p>
    <p>[0034]	本发明的基于小波变换的单相机视频三维重建方法，其特征在于包括以下步骤：</p>
    <p>[0035]	I)手持一台相机围绕一个运动物体运动，同时采集一段视频；</p>
    <p>[0036]	2)采用Kanade-Lucas-Tomasi(KLT)特征点跟踪方法计算每一巾贞图像的特征点对应；</p>
    <p>[0037]	3)选取跟踪时间最长（所对应的帧图像最多)的η个特征点；</p>
    <p>[0038]	4)计算由步骤3)得到的的η个特征点所在的帧图像，并依照所含特征点多、图像之间间隔均匀的原则选取m幅帧图像；</p>
    <p>[0039]	5)建立观测矩阵W G j 2_，其中矩阵每一列为一个特征点在m幅帧图像上的对应像素位置，矩阵每两行为一幅帧图像上η个特征点对应的像素坐标（x，y)；</p>
    <p>[0040]	6)基于小波变换将观测矩阵W分解为W = MS + tf =D(QX&#174;I3)S + tF的形式， 其中Mei 为运动矩阵，Dei 2mx3m为对角矩阵，对角线元素为m个帧图像所对应视角的 2X3的旋转矩阵，Qei mxd为截断的小波基函数，Xei ^为形状轨迹在小波基表示下的系数，Sei 为形状基矩阵，r为形状基的个数，tei 2mSW平均列向量，Iei "为元素都为I 的向量，&#174;表示矩阵的Kronecker乘法。具体包括以下步骤：</p>
    <p>[0041 ] 6-1)计算观测矩阵W的平均列向量t ；</p>
    <p>[0042]	6-2)迭代地米用 PTA 方法（I. Akhter, Y. A. Sheikh, S. Khan, and T. Kanade. Nonrigid structure from motion in trajectory space, in Neural Information Processing Systems, December2008.)计算矩阵D，直到平均正交化误差没有变化为止：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00051.png"> <img id="idf0004" file="CN102592308AD00051.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00051.png" class="patent-full-image" alt="Figure CN102592308AD00051"> </a> </div>
    <p>[0044]	其中，Ri为第i帧图像所对应的2X3的旋转矩阵；</p>
    <p>[0045]	6-3)计算J级分解的Daubechies 10(dbl0)小波的基函数矩阵，即对mXm的单位矩阵求反变换；</p>
    <p>[0046]	6-4)对步骤6-2)得到的Daubechies 10小波基矩阵进行截断，即去掉最后的m_d列，形成新的mXd的小波基矩阵Ω ；</p>
    <p>[0047]	6-5)初始化 [0048]	6-6)采用Damped-Newton非线性优化方法求解以下优化问题：</p>
    <p>[0049]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00061.png"> <img id="idf0005" file="CN102592308AD00061.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00061.png" class="patent-full-image" alt="Figure CN102592308AD00061"> </a> </div>
    <p>[0050]	其中，Wj为矩阵W的第j列；</p>
    <p>[0051]	6-7)使用步骤 6-6)得到的 X 求解M和</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00062.png"> <img id="idf0006" file="CN102592308AD00062.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00062.png" class="patent-full-image" alt="Figure CN102592308AD00062"> </a> </div>
    <p>[0052]	7)计算各个时刻的三维点云，即动态三维点云Y = (nX&#174;I3)S。</p>
    <p>[0053]	本发明提出了一种基于小波变换的单相机视频三维重建方法，结合附图及实施例详细说明如下：</p>
    <p>[0054]	实现本发明方法的系统实施例结构如图I所示，为本发明实施例的基于小波变换的单相机视频三维重建方法流程图，包括以下步骤：</p>
    <p>[0055]	I)手持一台相机围绕一个运动物体运动，同时采集一段视频；</p>
    <p>[0056]	2)采用Kanade-Lucas-Tomasi(KLT)特征点跟踪方法计算每一巾贞图像的特征点对</p>
    <p>[0057]	3)选取跟踪时间最长（所对应的帧图像最多)的91个特征点；</p>
    <p>[0058]	4)计算由步骤3)得到的的91个特征点所在的帧图像，并依照所含特征点多、图像之间间隔均匀的原则选取240幅帧图像；</p>
    <p>[0059]	5)建立观测矩阵W e j 48_，其中矩阵每一列为一个特征点在240幅帧图像上的对应像素位置，矩阵每两行为一幅帧图像上91个特征点对应的像素坐标（x，y)；</p>
    <p>[0060]	6)基于小波变换将观测矩阵W分解为W = MS + tf =D(QX&#174;I3)S + tl#形式，其中形状基个数为3个，Mei 48°x9为运动矩阵，Dei 48°x72°为对角矩阵，对角线元素为240个帧图像所对应视角的2X3的旋转矩阵，Qei 24°x24为截断的小波基函数，Xei 24x3为形状轨迹在小波基表示下的系数，Sei 9x91为形状基矩阵，tej 48°为W平均列向量，Iei 91为元素都为I的向量，&#174;表示矩阵的Kronecker乘法，(&#183;)τ表示矩阵的转置，I3为3X3的单位矩阵。 具体包括以下步骤：</p>
    <p>[0061]	6-1)计算观测矩阵W的平均列向量t ；</p>
    <p>[0062]	6-2)迭代地米用 PTA 方法（I. Akhter, Y. A. Sheikh, S. Khan, and T. Kanade. Nonrigid structure from motion in trajectory space, in Neural Information Processing Systems, December 2008.)计算矩阵D，直到平均正交化误差没有变化为止：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00063.png"> <img id="idf0007" file="CN102592308AD00063.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00063.png" class="patent-full-image" alt="Figure CN102592308AD00063"> </a> </div>
    <p>[0064]	其中，Ri为第i帧图像所对应的2X3的旋转矩阵；</p>
    <p>[0065]	6-3)计算J级分解的Daubechies 10 (dblO)小波的基函数矩阵，即对240 X 240的</p>
    <p>单位矩阵求反变换；</p>
    <p>[0066]	6-4)对步骤6-2)得到的Daubechies 10小波基矩阵进行截断，即去掉最后的240-24列，形成新的240X24的小波基矩阵Ω ；</p>
    <p>[0067]	6-5)初始化X = 1J ；</p>
    <p>[0068]	6-6)采用Damped-Newton非线性优化方法求解以下优化问题：</p>
    <p>[0069]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00071.png"> <img id="idf0008" file="CN102592308AD00071.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00071.png" class="patent-full-image" alt="Figure CN102592308AD00071"> </a> </div>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00072.png"> <img id="idf0009" file="CN102592308AD00072.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00072.png" class="patent-full-image" alt="Figure CN102592308AD00072"> </a> </div>
    <p>[0070]	其中，Wj为矩阵W的第j列；</p>
    <p>[0071]	6-7)使用步骤 6-6)得到的 X 求解M和</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00073.png"> <img id="idf0010" file="CN102592308AD00073.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00073.png" class="patent-full-image" alt="Figure CN102592308AD00073"> </a> </div>
    <p>[0072]	7)计算各个时刻的三维点云，即动态三维点云S、(nX&#174;I3)S。</p>
    <p>[0073]	本实施例对Shark数据集重建的第I时刻的三维点云在三个视角下观看的结果及与采用DCT基函数表示的方法的比较如图2所示，其中（a)图为采用DCT基函数的方法 (P. F. U. Gotardo and A. M. Martinez. Computing smooth time-trajectories for camera and deformable shape in structure from motion with occlusion. IEEE Trans. PAMI, 2011.)得到的三维点云结果；(b)图为采用本发明方法得到的三维点云结果。黑色实点为真值，红色空圈为方法计算的结果。下表给出了采用DCT基函数和小波基函数对Shark数据集重建动态三维点云的方法性能比较表：</p>
    <p>[0074]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00074.png"> <img id="idf0011" file="CN102592308AD00074.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102592308A/CN102592308AD00074.png" class="patent-full-image" alt="Figure CN102592308AD00074"> </a> </div>
    <p>[0075]	其中RMSE(root-mean-square error)为恢复的观测矩阵与原始观测矩阵之间的均方根误差，最大误差为恢复的观测矩阵与原始观测矩阵对应元素的最大误差，点云误差为重建的三维点云与真值之间的平均欧氏距离。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101398886A?cl=zh">CN101398886A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年3月17日</td><td class="patent-data-table-td patent-date-value">2009年4月1日</td><td class="patent-data-table-td ">杭州大清智能技术开发有限公司</td><td class="patent-data-table-td ">一种基于双目被动立体视觉的快速三维人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040017952">US20040017952</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2002年7月25日</td><td class="patent-data-table-td patent-date-value">2004年1月29日</td><td class="patent-data-table-td ">Tinku Acharya</td><td class="patent-data-table-td ">Color video coding scheme</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">历茂海，等: "<a href='http://scholar.google.com/scholar?q="%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E7%9A%84%E7%A7%BB%E5%8A%A8%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%85%A8%E5%B1%80%E5%AE%9A%E4%BD%8D"'>基于单目视觉的移动机器人全局定位</a>", 《机器人》, vol. 29, no. 2, 31 March 2007 (2007-03-31)</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">周佳立，等: "<a href='http://scholar.google.com/scholar?q="%E5%9F%BA%E4%BA%8E%E5%8F%8C%E7%9B%AE%E8%A2%AB%E5%8A%A8%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E8%84%B8%E9%87%8D%E6%9E%84%E4%B8%8E%E8%AF%86%E5%88%AB"'>基于双目被动立体视觉的三维人脸重构与识别</a>", 《自动化学报》, vol. 35, no. 2, 28 February 2009 (2009-02-28), pages 123 - 131</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">罗三定，等: "<a href='http://scholar.google.com/scholar?q="%E5%9F%BA%E4%BA%8ESURF%E5%92%8CKLT%E8%B7%9F%E8%B8%AA%E7%9A%84%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5%E7%AE%97%E6%B3%95"'>基于SURF和KLT跟踪的图像拼接算法</a>", 《计算机工程》, vol. 36, no. 1, 31 January 2010 (2010-01-31), pages 215 - 218</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103885465A?cl=zh">CN103885465A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年4月2日</td><td class="patent-data-table-td patent-date-value">2014年6月25日</td><td class="patent-data-table-td ">中国电影器材有限责任公司</td><td class="patent-data-table-td ">一种基于视频处理生成动感座椅的动感数据的方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=ZI-JBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0017000000">G06T17/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年9月19日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月27日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/b04dff8d61c8eb72b3bd/CN102592308A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E7%9A%84%E5%8D%95%E7%9B%B8%E6%9C%BA%E8%A7%86%E9%A2%91%E4%B8%89.pdf?id=ZI-JBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2RmzhvPhtcT8NBB8eQA-y70tR1dw"},"sample_url":"https://www.google.com/patents/reader?id=ZI-JBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>