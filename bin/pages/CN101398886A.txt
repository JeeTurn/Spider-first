<!DOCTYPE html><html><head><title>专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种基于双目被动立体视觉的快速三维人脸识别方法"><meta name="DC.contributor" content="（请求不公开姓名）" scheme="inventor"><meta name="DC.contributor" content="杭州大清智能技术开发有限公司" scheme="assignee"><meta name="DC.date" content="2008-3-17" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于双目被动立体视觉的快速三维人脸识别方法，其步骤如下：1)运用两台高清晰数码照相机构建非接触式短轴平行双目立体视觉系统，2)系统标定完成后，对预览帧图像进行基于haar-AdaBoost分类器的人脸检测与采集，获得相应的上下立体视觉图对并估计视差，对人脸区域进行图像校正，获得区域内外极线垂直的上下立体视觉图对，3)运用Bayesian、haar-AdaBoost分类器以及点云三维信息获取眼睛与鼻尖的精确定位，构建基准三角形，4)运用基于复小波的相位相关算法金字塔形并行搜索立体图对中小区域的相应亚像素匹配，既而重建人脸密集三维点云信息，5)运用已构建的基准三角形，针对不同姿态下的人脸进行姿态归一与补洞，6)基于人脸表面测地距离不变性假设，对不同人脸进行表情归一化，7)利用算法对归一化后三维人脸进行识别。本发明有益的效果是：主要解决了被动立体视觉难以快速自动获得与识别不同姿态与表情下稠密精准人脸三维点云信息的问题，使三维人脸识别过程更快速、隐蔽、安全与可靠。"><meta name="DC.date" content="2009-4-1"><meta name="citation_patent_publication_number" content="CN:101398886:A"><meta name="citation_patent_application_number" content="CN:200810060166"><link rel="canonical" href="https://www.google.com/patents/CN101398886A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101398886A?cl=zh"/><meta name="title" content="专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法"/><meta name="description" content="本发明公开了一种基于双目被动立体视觉的快速三维人脸识别方法，其步骤如下：1)运用两台高清晰数码照相机构建非接触式短轴平行双目立体视觉系统，2)系统标定完成后，对预览帧图像进行基于haar-AdaBoost分类器的人脸检测与采集，获得相应的上下立体视觉图对并估计视差，对人脸区域进行图像校正，获得区域内外极线垂直的上下立体视觉图对，3)运用Bayesian、haar-AdaBoost分类器以及点云三维信息获取眼睛与鼻尖的精确定位，构建基准三角形，4)运用基于复小波的相位相关算法金字塔形并行搜索立体图对中小区域的相应亚像素匹配，既而重建人脸密集三维点云信息，5)运用已构建的基准三角形，针对不同姿态下的人脸进行姿态归一与补洞，6)基于人脸表面测地距离不变性假设，对不同人脸进行表情归一化，7)利用算法对归一化后三维人脸进行识别。本发明有益的效果是：主要解决了被动立体视觉难以快速自动获得与识别不同姿态与表情下稠密精准人脸三维点云信息的问题，使三维人脸识别过程更快速、隐蔽、安全与可靠。"/><meta property="og:title" content="专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101398886A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101398886A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101398886A&amp;usg=AFQjCNGokLOzfq2hjYl7PImHYIlKGQ0Pag" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/738f0e1a583f6ca42a3d/CN101398886A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/738f0e1a583f6ca42a3d/CN101398886A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101398886A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101398886A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101398886A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101398886B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101398886A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于双目被动立体视觉的快速三维人脸识别方法，其步骤如下：1)运用两台高清晰数码照相机构建非接触式短轴平行双目立体视觉系统，2)系统标定完成后，对预览帧图像进行基于haar-AdaBoost分类器的人脸检测与 ...</span><span itemprop="url">https://www.google.com/patents/CN101398886A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法" title="专利 CN101398886A - 一种基于双目被动立体视觉的快速三维人脸识别方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101398886 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200810060166</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2009年4月1日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2008年3月17日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2008年3月17日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101398886B?hl=zh-CN&amp;cl=zh">CN101398886B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200810060166.7, </span><span class="patent-bibdata-value">CN 101398886 A, </span><span class="patent-bibdata-value">CN 101398886A, </span><span class="patent-bibdata-value">CN 200810060166, </span><span class="patent-bibdata-value">CN-A-101398886, </span><span class="patent-bibdata-value">CN101398886 A, </span><span class="patent-bibdata-value">CN101398886A, </span><span class="patent-bibdata-value">CN200810060166, </span><span class="patent-bibdata-value">CN200810060166.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%EF%BC%88%E8%AF%B7%E6%B1%82%E4%B8%8D%E5%85%AC%E5%BC%80%E5%A7%93%E5%90%8D%EF%BC%89%22">（请求不公开姓名）</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%9D%AD%E5%B7%9E%E5%A4%A7%E6%B8%85%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">杭州大清智能技术开发有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101398886A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101398886A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101398886A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (16),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (4),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200810060166&amp;usg=AFQjCNEY3Zea4q2f2mapyJXZ9D3wfyVb1g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101398886A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGwwEiTYKTH0bSFD09-v75RlmyBHg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT75603011" lang="ZH" load-source="patent-office">一种基于双目被动立体视觉的快速三维人脸识别方法</invention-title>
    </span><br><span class="patent-number">CN 101398886 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA53358012" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于双目被动立体视觉的快速三维人脸识别方法，其步骤如下：1)运用两台高清晰数码照相机构建非接触式短轴平行双目立体视觉系统，2)系统标定完成后，对预览帧图像进行基于haar-AdaBoost分类器的人脸检测与采集，获得相应的上下立体视觉图对并估计视差，对人脸区域进行图像校正，获得区域内外极线垂直的上下立体视觉图对，3)运用Bayesian、haar-AdaBoost分类器以及点云三维信息获取眼睛与鼻尖的精确定位，构建基准三角形，4)运用基于复小波的相位相关算法金字塔形并行搜索立体图对中小区域的相应亚像素匹配，既而重建人脸密集三维点云信息，5)运用已构建的基准三角形，针对不同姿态下的人脸进行姿态归一与补洞，6)基于人脸表面测地距离不变性假设，对不同人脸进行表情归一化，7)利用算法对归一化后三维人脸进行识别。本发明有益的效果是：主要解决了被动立体视觉难以快速自动获得与识别不同姿态与表情下稠密精准人脸三维点云信息的问题，使三维人脸识别过程更快速、隐蔽、安全与可靠。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM13386717" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1、一种基于双目被动立体视觉的快速三维人脸识别方法，其特征在于包括如下步骤：1)运用两台高清晰数照码相机构建非接触式短轴平行双目立体视觉系统；2)对视觉系统的预览帧进行haar-AdaBoost方法的人脸检测与采集，获得相应的上下立体视觉图对并估计视差，对人脸区域进行图像校正，获得区域内外极线垂直的上下立体视觉图对；3)运用Bayesian、haar-AdaBoost分类器以及点云三维信息获取眼睛与鼻尖的精确定位，构建基准三角形；4)运用基于复小波的相位相关算法金字塔形并行快速搜索立体图对中小区域的相应亚像素匹配，既而重建人脸密集三维点云信息；5)运用已构建的基准三角形，针对不同姿态下的人脸进行姿态归一与补洞；6)基于人脸表面测地距离不变性假设，对不同人脸表情进行归一化；7)利用算法对归一化后三维人脸进行识别。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，所述的双 目立体视觉系统：由两台高&#28152;晰数码照相机平行紧靠安装，其光轴基本平打且基线长度尽可能短， 一股在 60mm左右。照相机通过usb接口连接到电脑，通过电脑，利用双线程同步技术控制两台照相机同时拍照， 并通过双目立体标定获得系统内外参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，所述的从 上下立体图对中获取人脸大致视差、对人脸区域校正并进行姿态估计：运用haar-AdaBoost分类器对照相 机预览图像进行人脸检测。当上下图中均有完整人脸时进行同步抓拍，对人脸区域进行图像对校正，获得 区域内外极线垂直的上下立体视觉图对。既而运用训练完成的Bayesian分类器，在已确定的人脸区域上半 部的左右侧分别进行左右瞳孔精确定位；下半部运用haar-AdaBoost分类器进行鼻子初步定位。对奥子周 围区域以及左右瞳孔进行亚像素级精确匹配，根据视差求出鼻尖以及左右瞳孔的三维深度信息，构建人脸 基准三角形，其确定的平面为基准平面。从鼻尖向左心瞳孔连线做垂线，垂足称为鼻基点，三等分鼻基 点到鼻尖线段，取靠近鼻尖的等分点为圆心，1.2倍瞳距为半径，在基准平面上做圆，通过该圆计算确定 上下视觉图中的人脸比对区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，所述的基 于复小波的相位相关算法金字塔形并行快速搜索立体图对中小区域的相应亚像素匹配.*采用基于复小波的 相位相关算法，对人脸比对区域每隔5像素点进行从粗到细的金字塔形搜索，获得上下视觉图的密集精确 匹配。具体公式如下：&lt;formula&gt;formula see original document page 2&lt;/formula&gt;（2} &lt;formula&gt;formula see original document page 2&lt;/formula&gt;（3)  &lt;formula&gt;formula see original document page 3&lt;/formula&gt;(8)&lt;formula&gt;formula see original document page 3&lt;/formula&gt;(9) &lt;formula&gt;formula see original document page 3&lt;/formula&gt; (10)&lt;formula&gt;formula see original document page 3&lt;/formula&gt; (11)&lt;formula&gt;formula see original document page 3&lt;/formula&gt; (12)</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5、 根据权利要求1或4所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，所述 的金字塔形搜索对图像进行5层复小波分解，在像素匹配阶段采用简化的算法：从最底层开始，只比对 Re[e(i^,n2)]中心附近的点，找出最大值，而由该最大值作为o的近似，其位置即为相应的视差估计，放大 后代入上一层作为新的初始估计，进行新的计算，直到最顶层为止。因此，在进行亚像素匹配时，视差估 计的误差应该小于1个像素。既而通过几次非线性最小二乘拟合迭代过程，获得最终的亚像素级视差估计。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6、 根据权利要求l所述的基于双目被动立体视觉的快速二维人脸识别方法，其特征在于，在每一层 的匹配过程中，都引入顺序匹配、连续性、相关性以及外极线等约^条件，作为对匹配关系的可信度评估。 所谓顺序匹配约束是指，对于上图中的两点，其下图中的匹配点应保持原来的顺序；而连续性是指，对于 上图中接近的两点，其相应视差也应该相似；相关性约汆可用O值来表示，当O值越人，说明这两点的匹配 相关性越大；而极线约束是指匹配点拥有基本相似的横坐标。整个匹配过程可改进为以下算法：第一步：对于每一层，匹配并估计每一未标记点的O值。如果O小亍某一阈值，则对该点进行标记并转 入第二步。否则，考虑其顺序约束，取与其同列并已匹配的最近未标记点，如果顺序匹配错误，则进行标记并转入第二步。否则，考虑其连续约束情况，取其附近5x5以内所有已匹配而未标记点，取其视差平均，比较与该点差的绝对值，如大于某一阈值，则对该点标记转入第二步。最后，如果匹配点偏离外极线过大，则标记该点并转入第二步；第二步：对于标记的点，考虑其附近5X5以内所有未标记点，取其关于CT值的相对加权平均作为该点 的初始估计，然后进行亚像素匹配，对其结果进行相应的约束检测。如仍被标记，则将初始估计作为其相 应视差。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，运用人脸 的对称性对遮挡或者纹理欠缺部分进行补洞：过鼻尖点，作垂直于基准二角形和左右瞳孔连线的平面，将 三维人脸点云对该平面作镜向，并运用ICP迭代算法进行人脸补洞。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，基于人脸 表面任意两点之间的测地线距离在表情变化下的不变性假设，用MDS(multidimensionalscarmg)方法，实现 从测地距离到欧氏直线距离间的等长映射（isometric m叩ping),实现表情归一。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9、 根据权利要求l所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，在识别过 程中，先比对两人脸的瞳距以及鼻尖到鼻基点的距离。如果在一定阈值范围内，则进一步比对，系统提供 两种比对方法-第一种，将归一化人脸点云投影到基准平面，对基准平面上的每一同定方格随机选取一点，对所有选 取的点，计算每两点之间的距离，画出基于半随机的统计特征图，通过比对不同人脸间的统计特征图即可 对人脸进行识别。第二种，将归一化人脸点云转化为高维矩的形式，然后再对其的主要部分向量进行相似度比较。定义:d,(S!,S2) = I]p+q+rsP((Xpqr(Xi) 一 Hpqr(X;))2.作为不同人脸Si,S2的相似度函数，其中Xi， X纟为其相应的归一化点云，npqr(X) = /x xPyqZrdxdydz.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10、 根据权利要求1或4所述的基于双目被动立体视觉的快速三维人脸识别方法，其特征在于，所有 点的匹配过程可并行计算，因此，在双核处理器中采用多线程的编程，可明显提高计算速度。对每张脸一 共计算大约5000个点。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES18773732" lang="ZH" load-source="patent-office" class="description">
    <p>一种基于双目被动立体视觉的快速三维人脸识别方法技术领域本发明涉及一种三维人脸识别方法，主要是一种以通过双目被动立体视觉快速自动获取人脸表面密集、 精确三维点云信息为基础的新思路来进行人脸三维重建，基于点云半随机统计特征和高维矩向量的表情无 关的三维人脸识别方法。背景技术人脸识别作为生物特征识别的一个重要方面，与指纹、虹膜、DNA识别等技术相比，其过程更加隐蔽、 友好和便捷，应用前景广阔。但在二维情况下，不可避免受到环境光线、背景、视角等以及人脸的姿态、 表情、遮挡等不利影响，因而其识别精度很难有进一步的提&#39641;。为了克服基于二维图像人脸识别技术的不足，有研究者已经开始转向二维人脸识别技术的研究。对三 维人脸识别技术而言，存在的最大困难是人脸三维点云数据的获得。近几年光学三维形貌测量技术有了很 大的进展，已发展出一些具有实用潜力的三维形貌测量技术，如结构光投影相移技术、结构光投影傅立叶 变换技术等，使得三维人脸的识别成为可能。但是，通过向人脸投射结构光事实上已经是一种接触式的识 别方法，对被识别者不够友好，会引起法律、公共次序等方面的争议，并且也失去了信息隐蔽采集的能力。 这样，在很大程度上减弱了较之指纹识别等的优势。因此，如何快速高效并且隐蔽的获取被识别者的密集 三维人脸信息引起了人们的重视。正如表情会影响2D人脸图像的表观(appearance),表情对3D人脸数据的影响是改变了人脸的3D形状， 不同程度的表情造成同一个人的不同采集视图形状差异很大，简单采用形状匹配时类内的模型相似度很低， 直接导致识别率下降。因此，寻求一种表情不变的人脸表征方法成为保证识别准确率的关键途径。在识别与信息存储方面，采集的人脸三维点云数据量通常十分庞大，不宜直接进行储存和识别比对， 传统的ICP方法，比对过程十分费时，并且归一化困难。因此，如何通过采集的二维点云信息，提取出易 于储存与识别比对的人脸特征将是人们亟待解决的重要问题。发明内容本发明的目的在于克服上述不足而提供一种基于双目被动立体视觉的快速三维人脸识别方法，主要解 决的是不同姿态与表情下的三维人脸快速识别问题。基于双目被动立体视觉的快速三维人脸识别方法包括如下步骤：1) 运用两台高清晰数照码相机构建非接触式短轴平行双目立体视觉系统；2) 对视觉系统的预览帧进行haar-AdaBoost方法的人脸检测与采集，获得相应的上下立体视觉图对 并估计视差，对人脸区域进行图像校正，获得区域内外极线垂直的上下立体视觉图对；3) 运用Bayesian、 haar-AdaBoost分类器以及点云三维信息获取眼睛与鼻尖的精确定位，构建基准二角形；4) 运用基于复小波的相位相关算法金字塔形并行快速搜索立体图对中小区域的相应亚像素匹配，既 而重建人脸密集三维点云信息；5) 运用已构建的基准三角形，针对不同姿态下的人脸进行姿态归一与补洞；6) 基于人脸表面测地距离不变性假设，对不同人脸表情进行归一化；7) 利用算法对归一化后ZI维人脸进行识别。所述的双目立体视觉系统：由两台高清晰数码照相机平行紧靠安装，其光轴基本平行且基线长度尽可 能短， 一般在60mm左右。照相机通过usb接口连接到电脑，通过屯脑，利用双线程同步技术控制两台照 相机同时拍照，并通过双目立体标定获得系统内外参数。对视觉系统所拍摄的上下立体图对进行校正，使 上下图外极线与y轴平行。所述的从上下立体图对中获取人脸大致视差与姿态估计：运用haar-AdaBoost分类器对照相机预览图 像进行人脸检测。当上下图中均有完整人脸时进行同步抓拍，既而运用训练完成的Bayesian分类器，在已 确定的人脸区域上平邻进行左右瞌孔精确定位：运HJ haar-AdaBoost分类器对下半部进行鼻孔初步定位。 对&#30064;孔周围区域以及左右瞳孔进行亚像素级精确匹配，根据视差求出鼻尖以及左右睡孔的二维深度信息， 构建人脸基准二角形，其确定的平面为基准平面。从鼻尖向左右瞳孔迕线做乖线，垂足称为舆基点，二 等分鼻基点到奥尖线段，取靠近彝尖的笱分点为圆心，1.2倍瞳距为半径，在基准平面上做圆，通过该圆 计算确定上下视觉图中的人脸比对区域。所述的基于复小波的相位相关算法金字塔形搜索立体图对中小区域的相应亚像素匹配：采用基于复小 波的相位相关算法，对人脸比对区域每隔5像素点进行从粗到细的金字塔形搜索，获得上'卜'视觉图的密集 精确匹配。具体公式如F，K0(b!,b2,a) laH眼"m,n)5(，,，). （2) (VV2)(bpb2,a,叫,W2) s (W々f氛b2,a,"2) &#8226; e-i"K). (8)C(WpW2) = (W^)(bpb2,a,oH,u)2) . (W,2)(b!,b2,a,w^). (9&gt; e(uh,u)2) = C("2)/IC(u^W2)1 &#171; e一). （10) 《ni,n2) - ^Sklk2e&#8222;.射&#8226; . ,2. (11)所述的金字塔形搜索对图像进行5层复小波分解，在像素匹配阶段采用简化的算法：从最底层&#24181;始，只比对Re["i^,n2)]中心附近的点，找出最人值，而由该最大值作为a的近似，其位置即为相应的视差估计，</p>
    <p>放大后代入上一层作为新的初始估计，进行新的计算，直到最顶层为.l卜.。因此，在进行亚像素匹配时，视 差估计的误差应该小于l个像素。既而通过几次t.线性最小二乘拟合迭代过程，获得最终的亚像素级视差 估计。所述的引入顺序匹配、连续性、相关性以及外极线等约束条件，作为对匹配关系的可信度评估：所谓 顺序匹配约束是指，对于上图中的两点，其下图中的匹配点应保持原来的顺序；而连续性是指，对于上图 中接近的两点，其相应视差也应该相似；相关性约束可ffla值来表示，当(T值越大，说明这两点的匹配相关 性越大；而极线约束是指匹配点拥有基本相似的横坐标。整个匹配过程可改进为以下算法：第一步：对于每一层，匹配并估计每一未标记点的ct值。如果ct小于某一阈值，则对该点进行标记并转 入第二步。否则，考虑其顺序约束，取与其同列并已匹配的最近未标记点，如果顺序匹配错误，则进行标记并转入第二步。否则，考虑其连续约束情况，取其附近5 x 5以内所有已匹配而未标记点，取其视差平均，比较与该点差的绝对值，如大于某一陶值，则对该点标记转入第二步。最后，如果匹配点偏离外极线过大，则标记该点并转入第二步：第二步：对于标记的点，考虑其附近Sx5以内所有未标记点，取其关丁'a值的相对加权平均作为该点 的初始估计，然后进行亚像素匹配，对其结果进行相应的约束检测。如仍被标记，则将初始估计作为其相 应视差，所述的运用人脸的对称性对遮挡或者纹理欠缺部分进行补洞：过舁尖点，作垂直于基准二角形和左右 瞳孔连线的平面，将二维人脸点云对该平面作镜向，并运用ICP迭代算法进行人脸补洞。所述的运用算法进行人脸识别：先比对两人脸的瞳距以及鼻尖到鼻基点的距离。如果在一定阈值范围 内，则进一步比对，系统提供两种比对方法：第一种，将人脸点云投影到基准平面，对基准平面上的每一同定方格随机选取一点，对所有选取的点， 计算每两点之间的欧氏距离，而实际上，这个距离在表情归一化时己经计算过，无需重复计算，画出基于 半随机的统计特征图，通过比对不同人脸间的统计特征图即可对人脸进行识别。第二种，运用Tal的基于点云高维矩的向量比对方法进行归一化后人脸比对过程。主要思想是，将归 一化人脸点云转化为高维矩的形式，然后再对其主耍部分向量进行相似度比较。定义：&lt;formula&gt;formula see original document page 7&lt;/formula&gt;作为不同人脸Si,S2的相似度函数，其中Xi, X'2为其相应的归一化点云，&lt;formula&gt;formula see original document page 7&lt;/formula&gt; 所有点的匹配过程可并行计算，W此对双核cpu采用多线程的编程，可明显提高计算速度。对每张脸 一共计算大约5000个点。本发明有益的效果是：所述的双目立体视觉系统：由两台高清晰数码照相机平行紧靠安装，其光轴基本平行且基线长度尽可能短，</p>
    <p>一般在60mm左右。照相机通过usb接口连接到电脑，通过电脑，利用双线程同步技术控制两台照相机同 时拍照，并通过双目立体标定获得系统内外参数。对视觉系统所拍摄的上下立体图对进行校正，使上下图 外极线与Y轴平行。</p>
    <p>(1) 构建基于两台平行光轴高清晰数码相机的短基线双目立体视觉系统，利用双线程同步技术，通过 电脑控制两台相机同时拍照，获得同一瞬间的高清晰人脸图像对，使后继的高精度匹配与重建过程得以实 现。(2) 提出考虑顺序匹配、连续性、相关性以及外极线等约束条件的基于复小波变换的相位相关算法从 粗到细地搜索匹配关系，自动获得稠密精准的人脸点云信息，使通过双目被动立体视觉系统对人脸进行快 速三维识别成为可能，识别过程更快速、隐蔽、安全与可靠；(3) 运用haar-AdaBoost与Bayesian分类器并结合二维深度信息的方法确定人脸基准三角形，通过该基 准三角形对特定人脸进行姿态归一化，结合人脸的对称性对遮挡部分进行补洞处理，效果良好；(4) 采用提取人脸半随机统计特征图的方法进行相似度比对，能很好地节约存储空间，并使比对过程 更加便捷与准确，识别鲁棒性强。</p>
    <p>附图说明：</p>
    <p>图l是基丁双目被动立体视觉的快速二维人脸识别方法流程示意图； 图2是本发明基于&#39641;&#28152;晰数码相机的双目被动立体系统； 图3是本发明以左右瞳孔中心以及鼻尖的空间位置构建的基准坐标系； 图4是本发明的不同人脸三维重建结果。</p>
    <p>具体实施方式</p>
    <p>&#8212;、本发明采用双目被动立体视觉的方法，对人脸进行检测与表面密集点云的快速二维重建，运用基准三角形对特定人脸进行姿态归一与补洞处理，对表情in&#8212;化后的人脸重建区域进行半随机统计特征图提 取，从而通过比对不同人脸的统计特征图实现人脸的&#39641;精度Q动识别。 为了实现发明目的，如图i所示，本方法采用如下的技术方案.-步骤1:运用两台高清晰数码照相机构建双目被动立体视觉系统： 对于平行光轴的双目系统，由于在光轴距离小的情况下，可以近似地将上下采集图中对应点为中心的小区 域视为相互的一个图像平移，因而可运用相位相关&#31591;法对对应点进行估计。冈此，希望它们的光轴距离（基 线距离）越短越好。然而，由亍对脸部&#37318;样的精确度以及点云密集程度的要求比较高，在对应点的匹配过 程中，就需要考虑更多的相邻像素区域，既而在更大的脸部表面区域进行匹配。然而，由丁-脸部表面并非 具有相同的深度，那么，我们没有理由相信其对应点附近较人的邻域仍然可以近似视为一个相互平移，这 一点反应在鼻梁区域尤为明显。所以，匹配算法的可信度将无法保证。而相反的，为了满足对应点邻近区</p>
    <p>域为相互平移的假设，而只考虑点周围很小的区域，算法精度将迅速下降。在匹配箅法中，调节小波基的 宽度，使得匹配点周围99X99的像素区域在窗口范围内时，才可获得可信度&#39641;的配准关系。为解决这样的 矛盾关系，使用&#39641;清晰的照相机取代摄像机作为新的双目组成视觉系统，如图2所示。这样，即使在很小 的表面区域内，仍然有足够多的纹理信息来保证匹配的效果。在系统中，基线距离即为照相机的宽度，取 61mm。这也正好是人双眼的大致距离，符合仿生学原理。双目系统通过USB接口与屯脑相连，运用双线 程同步技术，由电脑控制双目进行同时拍照。对构建完成的双目视觉系统进行立体标定，获得其内外参数信息。由于不可避免地受到镜头崎变等影 响，并且在实际应用中双S光轴往往难以达到精确平行要求，闪此外极线通常不垂直于图像x轴。通过校 正图像对可解决这一问题。因而，在后继的对应点匹配中，只需对y轴附近进行扫描即可。在新的系统中，由于采用了 1000万像素级的高分辨率照相机，因此，当上下图中的对应点匹配精度 达到0.1像素时，利用双目立体视觉原理可精确获得空间点的二维深度信息，误差不超过O.lmm。步骤2:对视觉系统的预览帧进行haar-AdaBoost方法人脸检测与采集，获得相应的上下立体视觉图对：在对应点匹配前，我们需耍检测预览帧中是否有完整的入脸，并了解人脸在图像中的大致区域与对应 视差。这样，匹配的搜索深度与范围将大大减少，既提高了效率又减少了匹配时的误判与拒判率。发明运 用Rainer Lienhart介绍的基于灰度图像中弱特征检测方法对预览视频流中每一帧进行实时人脸检测，对于 训练完成的多角度人脸AdaBoost分类器，单帧图像人脸检测准确率可达90%。当人脸图像进入视觉系统 中时，系统对每一帧图像进行检测，当检测结果符合人脸逻辑时由电脑控制双目进行同步抓拍获取清晰的 图像对，为后继的&#21304;维重建提供样本。这里所谓的符合逻辑是指，上下视频流中检测到的人脸区域的大小 与其中心x轴坐标都要基本一致，视差在一定的范围内，并且人脸区域耍整个地落在视频内。此时，对拍摄的图像对进行再一次的人脸检测，此次检测区域将只限定r预览帧所检测到的人脸区域附近，若此时，上下图对中都有完整的人脸并符合逻辑，则记录检测结果，并估计人脸视差。否则，需重新抓照。步骤3:对抓拍图像进行校正，使外极线垂直于图像x轴坐标。但由丁'校正过程较为耗时，丙此，可 只对人脸区域进行校正，这样，同时运用多线程技术，在主频为2.4GHz的双核处理器下，用时可控制在 0.75秒以内。步骤4:运用Bayesian、 AdaBoost分类器以及点云二维信息获取眼睛与彝尖的精确定位，构建基准二 角形，针对不同姿态下的人脸进行姿态!H&#8212;-根据步骤2的人脸检测结果，运用训练完成的Bayesian分类器，在已确定的人脸区域上半部的左右边 分别进行左右瞳孔精确定位；运用AdaBoost分类器对下半部进行鼻孔初步定位。运用发明步骤5将要介 绍的匹配算法对左右瞳孔中心进行亚像素精确视差估计，并对初步定位的鼻孔区域进行像素级匹配，通过 其各自视差计算H点的空间位置，过该二点确定初始参考平面，以远离人脸的方向为z轴正方向构建初始 坐标系。对鼻孔周围一定区域（本发明取卞.径为瞳距四分之一的圆）内每一点进行亚像素级精确匹配'继</p>
    <p>而求出各点在初始坐标系中的z坐标，取值最大的点作为鼻尖的估计。以左右瞳孔中心以及鼻尖的空间位 置构建人脸基准二角形，其确定的平面为基准平面，建立如图3所示的基准坐标系。从鼻尖向左右瞳孔连 线做垂线，称该垂足为鼻基点，二邻分鼻基点到鼻尖线段，取靠近弊尖的等分点为圆心，1.2倍瞳距为半 径，在基准平面上做圆，称该圆为特征圆，根据视差原理，反求出该圆的边界在上下图中的相应封闭曲线。 由于识别过程只考虑左右服能同时定位的情况，所以，我们总是假定鼻尖位置在该封闭曲线内。因此只需 考虑曲线内像素点的三维重建信息，将其作为后继识别匹配的人脸特征。 步骤5:基于复小波变换的相位相关算法以及在匹配过程中的具体运用；给定两幅大小均为（2M + 1) x (2N + 1)的灰度图fi(ni,n)、 f2(m,n)，定义它们在连续域中的对应函数 仍为fi(x,y)、 fz(x,y),为方便叙述，发明考虑连续函数的情况。假设f2为fi的平移，平移量为（5i， 62)， 则：f2(m,n) = fi(m &#8212; 6;!,n &#8212; 52). (1) 设4)为二维复小波基，那么对丁'连续域中的函数f" f2,在y(R)上的积分小波变换（iwr)分别定义为：(W^)(b"2,a) := |a|-U"m,n)不(，,呼). （2)(VV2)(^,b2,a) := lal&#8212;Emnf2(m,n)不(^,，). （3) 根据小波变换的平移性可知：(VV2)(、,b2，a) - - 、,b2 - 62,a). (4)需寻找这样的小波基，使得在频域中对（&amp;, 52)容易估计。在实际应用中，常用的小波基巾(x,y)多为变量可分离的一元凼数：cKx,y)-^(x〕小2(y),特别地，令 A-4V则巾(x,y)-^(x)巾i(y)。由于Morlet复小波采用时频窗面积最小的高斯窗函数，在时、频域都有较好的局部性，符合人眼的识 别规律。因此，令&amp;为Morlet复小波基：则：(5)lal一H2nmfi(m, n)'e&#8212;■当^《a， 52《a时1. (7)在实际匹配过程中，采用从粗到细的搜索策略，使得相对f给定的分辨率a， 6" 62总是很小，条件 (7)的估计是合适的。利用条件（7)，有：^、 f2的交叉能量谱C定义为：C(U^,W2) = (VVj(bi,b2,a,0^,W2) . (V^f2)(bhb2,a,U^,W2). (9) 其归一化后记为：对于一定范围的UH、 w2,进行2D离散,记A-glq(10&gt;&lt;formula&gt;formula see original document page 11&lt;/formula&gt;l,一M :S ki ^ M, &#8212;N :S ki S N,傅立叶反变换得:e"'"。 = ^klk2 &amp;々'&#8226;》1 '》2. (U&gt; 理论上，"ih,n2)的虚部应等于0，然而，实际应用中，通常只取其实部来ffl二维Dirichlet函数拟合：在理想情况，o = l。在实际应用中，由于存在噪声等的影响.a通常小丁l。运用Levenberg-Marquardt 算法对Re[e(&#12316;,n2)]中心5x5的整数点数值进行非线性最小一乘拟合，得到包括o, 62的参数估计。对人脸图像进行5层复小波分解，&#27598;隔10像素进行一次匹配。在像素匹配阶段&#37318;用简化的算法：从最底层开始，只比对Re[e(i^,n2)]中心附近的点，找出最大值，由该最人值作为o的近似，其位置即为相应的视差估计，放大后代入上一层作为新的初始估计.进行新的计算，直到最顶层为i卜.。ra此，在进行亚像素匹配时，视差估计的误差应该小于l个像素。既而通过儿次非线性最小二乘拟合迭代过程，获得最终的亚 像素级视差估计。这样的迭代过程进行两次就可收敛。根据以上的匹配方法，对丁大部分点都可fl动获得止确的视差估计，然而由丁'遮挡、噪声以及缺少纹 理等情况的影响，在由粗到细的金字塔匹配过程中，对某些点对将出现错误估计，进而导致亚像素匹配无 法收敛等情况的发生。不仅降低了自动配准的鲁棒性，而且在很大程度上减弱了三维重建的可靠性和精准 度。为克服以上问题，引入顺序匹配、连续性、相关性以及外极线等约束条件，作为对匹配关系的可信度 评估。所谓顺序匹配约束是指，对丁上图中的两点，其下图中的匹配点应保持原来的顺序；而连续性是指， 对于上图中接近的两点，其相应视差也应该相似；相关性约束可用o值来表示，当o值越大，说明这两点的 匹配相关性越大；而极线约束是指匹配点拥有基本相似的横坐标。因此，整个匹配过程可改进为以下算法：第一步：对于每一层，匹配并估计每一未标记点的a值。如果o小丁某一阈值，则对该点进行标记并转 入第二步。否则，考虑其顺序约束，取与其同列并已匹配的最近未标记点，如果顺序匹配错误，则进行标</p>
    <p>记并转入第二步。否则，考虑其连续约束情况，取其附近5 x 5以内所有已匹配而未标记点，取其视差平均， 比较与该点差的绝对值，如大于某一阈值，则对该点标记转入第&#8212;步。最后，如果匹配点偏离外极线过人， 则标记该点并转入第二步；第二步：对于标记的点，考虑其附近5x5以内所有未标记点，取其关于a值的相对加权平均作为该点 的初始估计，然后进行亚像素匹配，对其结果进行相应的约束检测。如仍被标记，则将初始估计作为其相 应视差。所有点的匹配过程可并行计算，因此在双核处理器下采用多线程编程，可明显提&#39641;计算速度。对每张 脸一共计算大约5000个点。不同人脸的三维重建结果请见图4。 步骤6:运用人脸的对称性对遮挡或者纹理欠缺部分进行补洞：当采集具有一定角度人脸图像时，归一化后只能得到大半边脸重建结果，并且由于鼻子对脸的遮挡等 情况，在需匹配区域出现洞，给识别过程带来困难。考虑到人脸具有很好的对称性，我们只需要过鼻尖点， 作垂直丁基准三角形和左右瞎孔连线的平面，将二维人脸点云对该平面作镜向，再将两幅点云进行ICP迭 代。这样，由于拍摄角度原因被棒子遮挡的脸颊部分以及脸的侧面被很好地恢复了。以上方法也被运用T 当人脸（特别是颧骨部分）皮肤过于细腻而缺少纹理出现人孔时的填补过程。步骤7:运用等长映射对3D人脸进行表情归一化：基于人脸表面任意两点之间的测地距离在表情变化下的不变性假设，运用fast Marching方法计算3D 人脸上每一对点之间的测地线距离（记录该测地距离，在步骤8中的半随机统计特征图提取时将再次用到）， 然后用MDS(咖ltidimensional scaling)方法，实现从测地距离到欧氏直线距离间的等长映射（isometric mapping)，实现表情归一。步骤8:运用算法对归一化后的人脸点云进行比对识别：先比对两人脸的瞳距以及鼻尖到鼻基点的距离。如果在一定阈值范围内，则进一步比对，系统提供两 种比对方法：第一种：将人脸点云投影到基准平面，对于基准平面上特征圆内的每一固定方格随机选取一点，对于 所有选取的点，计算每两点之间的欧氏距离（即表情归一化前的测地线距离，已在步骤7中计算过），画 出基于半随机的统计特征图，通过比对不同人脸间的统计特征图即可对人脸进行识别。假设对两人脸M、 N进行比对，分别获得函数fM与fN作为它们的半随机统计特征图，那么只需计算如下函数-S = Udx. (13)当S小丁给定阈值时，即可判定人脸M、 N属于同一个人。第二种，运用TSl的基丁-点云&#39641;维矩的向量比对方法进行归一化后人脸比对过程。主要步骤是，将表情 归一化人脸点云转化为高维矩的形式，然后再对其主要部分向量进行相似度比较。定义：d咖m(SpS2) = 5:p+q+rsP(Ppqr(Xi) _qr(X)2. (14)</p>
    <p>作为不同人脸Si,S2的相似度函数，其中Xi, X;为其相应的归一化点云，npqr(X) = /x XPyqzrdxdydz. 二、验证结果：为了验证该方法对人脸识别的效果，我们对10人在不同光照条件下进行多角度拍摄，每人拍3次， 对每组照片建立相应的归一化三维点云信息以及平.随机统计特征图.存入数据库中。本次实验比对该30 组数据中的任意两组，判断是否为同一人。运用第一种基丁统计图的判别方法，取阈值为150时，获得完全正确的识别效果。 运用第二种基于高维矩向量的方法，取阈值为200时，也获得了完全正确的识别效果。 实验表明，系统允许接受非正面的人脸采集图像，只要在该图像对中能方便地识别出基准三角形即可。 系统识别基本不受光照条件以及背景的影响，并且对不同面部表情也有较好的鲁棒性。在匹配算法中，每 &#8212;点都可并行计算，冈此在实际编程中，双核处理器采川多线程的方式可在很人程度上提高算法的速度。 本次实验，采用主频为2.4GHz的双核处理器，采ffl双线程，对每张脸计算5000个左右匹配点，数据库样本 大小为30,对单个人脸&#37318;样与比对过程用时约5秒，各项具体耗时如农l:</p>
    <p>表l单个人脸采集与比对过程的用时情况</p>
    <p>&lt;table&gt;table see original document page 13&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;</p>
    <p>整个过程基本达到实时化要求。</p>
    <p>王、实验结论-</p>
    <p>本发明公开了一种新的基于双目被动立体视觉采集人脸图像，运用复小波变换技术精确匹配对应点， 对重建二维点云进行特征提取与比对的三维人脸识别方法，与传统使用激光扫描仪或结构光等人脸信息&#37318; 集方法相比，由于使用了非俊入式的双目立体视觉系统，使采集过程更加友好、快捷，并可根据需要达到隐蔽&#37318;集的目的，得出以下结论：</p>
    <p>(1)运用基于复小波变换的相位相关算法可获得密集且满足识别精度要求的人脸二维点云信息。该算法对 背景无特别要求。{2)采用haar-AdaBoost和BaYesian分类器的方法，结合二维深度信息，确定人脸基准二角形，方便特定人 脸的姿态归一化。(3)提供基于统计图和基亍高维矩向量的两种不同的人脸比对方法，用户可根据实际情况进行选择。实验表明，该发明不仅对环境以及人脸位姿表情等鲁棒性强，识别准确率高，并且成本十分低廉，适合在 许多领域推广应用。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101833663A?cl=zh">CN101833663A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年4月21日</td><td class="patent-data-table-td patent-date-value">2010年9月15日</td><td class="patent-data-table-td ">北方工业大学</td><td class="patent-data-table-td ">一种双目电子阅读器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101833663B?cl=zh">CN101833663B</a></td><td class="patent-data-table-td patent-date-value">2010年4月21日</td><td class="patent-data-table-td patent-date-value">2012年10月10日</td><td class="patent-data-table-td ">北方工业大学</td><td class="patent-data-table-td ">一种双目电子阅读器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101887589A?cl=zh">CN101887589A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年6月13日</td><td class="patent-data-table-td patent-date-value">2010年11月17日</td><td class="patent-data-table-td ">东南大学</td><td class="patent-data-table-td ">一种基于立体视觉的实拍低纹理图像重建方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101887589B?cl=zh">CN101887589B</a></td><td class="patent-data-table-td patent-date-value">2010年6月13日</td><td class="patent-data-table-td patent-date-value">2012年5月2日</td><td class="patent-data-table-td ">东南大学</td><td class="patent-data-table-td ">一种基于立体视觉的实拍低纹理图像重建方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101894254A?cl=zh">CN101894254A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年6月13日</td><td class="patent-data-table-td patent-date-value">2010年11月24日</td><td class="patent-data-table-td ">南开大学</td><td class="patent-data-table-td ">一种基于等高线法的三维人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102122390A?cl=zh">CN102122390A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年1月25日</td><td class="patent-data-table-td patent-date-value">2011年7月13日</td><td class="patent-data-table-td ">于仕琪</td><td class="patent-data-table-td ">基于深度图像进行人体检测的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102122390B?cl=zh">CN102122390B</a></td><td class="patent-data-table-td patent-date-value">2011年1月25日</td><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td ">于仕琪</td><td class="patent-data-table-td ">基于深度图像进行人体检测的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102496138A?cl=zh">CN102496138A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月15日</td><td class="patent-data-table-td patent-date-value">2012年6月13日</td><td class="patent-data-table-td ">华东师范大学</td><td class="patent-data-table-td ">一种二维图像转换为三维图像的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102496138B?cl=zh">CN102496138B</a></td><td class="patent-data-table-td patent-date-value">2011年11月15日</td><td class="patent-data-table-td patent-date-value">2014年3月26日</td><td class="patent-data-table-td ">中能激光显示技术（上海）有限公司</td><td class="patent-data-table-td ">一种二维图像转换为三维图像的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102592308A?cl=zh">CN102592308A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月30日</td><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">天津大学</td><td class="patent-data-table-td ">基于小波变换的单相机视频三维重建方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102592308B?cl=zh">CN102592308B</a></td><td class="patent-data-table-td patent-date-value">2011年11月30日</td><td class="patent-data-table-td patent-date-value">2013年11月27日</td><td class="patent-data-table-td ">天津大学</td><td class="patent-data-table-td ">基于小波变换的单相机视频三维重建方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102609984A?cl=zh">CN102609984A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年2月2日</td><td class="patent-data-table-td patent-date-value">2012年7月25日</td><td class="patent-data-table-td ">西南交通大学</td><td class="patent-data-table-td ">基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102855496A?cl=zh">CN102855496A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月24日</td><td class="patent-data-table-td patent-date-value">2013年1月2日</td><td class="patent-data-table-td ">苏州大学</td><td class="patent-data-table-td ">遮挡人脸认证方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102915448A?cl=zh">CN102915448A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月24日</td><td class="patent-data-table-td patent-date-value">2013年2月6日</td><td class="patent-data-table-td ">西北工业大学</td><td class="patent-data-table-td ">一种基于AdaBoost的三维模型自动分类方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102999164A?cl=zh">CN102999164A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月30日</td><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种电子书翻页控制方法及智能终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103019561A?cl=zh">CN103019561A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td patent-date-value">2013年4月3日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种基于双摄像头的解锁方法及装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009620000">G06K9/62</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=E7NoBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00248">G06K9/00248</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06K9/00F1L</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2009年4月1日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年5月27日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年11月10日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/738f0e1a583f6ca42a3d/CN101398886A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8F%8C%E7%9B%AE%E8%A2%AB%E5%8A%A8%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89%E7%9A%84.pdf?id=E7NoBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0HHSC-NWhiaeD5EbkkT9ml5TN-rw"},"sample_url":"https://www.google.com/patents/reader?id=E7NoBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>