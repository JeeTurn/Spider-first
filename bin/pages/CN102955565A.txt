<!DOCTYPE html><html><head><title>专利 CN102955565A - 人机互动系统和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="人机互动系统和方法"><meta name="DC.contributor" content="吴冠廷" scheme="inventor"><meta name="DC.contributor" content="德信互动科技（北京）有限公司" scheme="assignee"><meta name="DC.date" content="2011-8-31" scheme="dateSubmitted"><meta name="DC.description" content="本发明是有关于一种人机互动系统和方法。其中的系统包括：视频捕捉装置和控制装置；视频捕捉装置用于实时摄取图像并输出；控制装置包括：接收模块，用于接收所述图像；面部表情提取模块，用于从所述图像中提取用户面部的热点区域信息，并根据热点区域信息确定用户的面部表情信息；存储模块，用于预先存储面部表情信息与控制命令的对应关系信息；控制模块，用于将上述确定出的面部表情信息在存储模块中存储的对应关系信息中进行匹配查找，以确定面部表情提取模块确定出的面部表情信息对应的控制命令；执行模块，用于执行所述控制模块确定出的控制命令。本发明提供的技术方案能够基于用户面部表情实现人机互动，从而使人机互动的实现方式多元化。"><meta name="DC.date" content="2013-3-6"><meta name="DC.relation" content="CN:101825947:A" scheme="references"><meta name="DC.relation" content="CN:102033696:A" scheme="references"><meta name="DC.relation" content="CN:102058983:A" scheme="references"><meta name="DC.relation" content="CN:102098567:A" scheme="references"><meta name="DC.relation" content="CN:102164541:A" scheme="references"><meta name="DC.relation" content="CN:201289739" scheme="references"><meta name="DC.relation" content="US:20110158546:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102955565:A"><meta name="citation_patent_application_number" content="CN:201110254702"><link rel="canonical" href="https://www.google.com/patents/CN102955565A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102955565A?cl=zh"/><meta name="title" content="专利 CN102955565A - 人机互动系统和方法"/><meta name="description" content="本发明是有关于一种人机互动系统和方法。其中的系统包括：视频捕捉装置和控制装置；视频捕捉装置用于实时摄取图像并输出；控制装置包括：接收模块，用于接收所述图像；面部表情提取模块，用于从所述图像中提取用户面部的热点区域信息，并根据热点区域信息确定用户的面部表情信息；存储模块，用于预先存储面部表情信息与控制命令的对应关系信息；控制模块，用于将上述确定出的面部表情信息在存储模块中存储的对应关系信息中进行匹配查找，以确定面部表情提取模块确定出的面部表情信息对应的控制命令；执行模块，用于执行所述控制模块确定出的控制命令。本发明提供的技术方案能够基于用户面部表情实现人机互动，从而使人机互动的实现方式多元化。"/><meta property="og:title" content="专利 CN102955565A - 人机互动系统和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102955565A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102955565A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=hPnQBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102955565A&amp;usg=AFQjCNH867o92AkPjx-BvHTK8pxCZG3f-Q" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/712309ba5c9a9e3793ab/CN102955565A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/712309ba5c9a9e3793ab/CN102955565A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102955565A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102955565A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102955565A?cl=zh" style="display:none"><span itemprop="description">本发明是有关于一种人机互动系统和方法。其中的系统包括：视频捕捉装置和控制装置；视频捕捉装置用于实时摄取图像并输出；控制装置包括：接收模块，用于接收所述图像；面部表情提取模块，用于从所述图像中提取用户面...</span><span itemprop="url">https://www.google.com/patents/CN102955565A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102955565A - 人机互动系统和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102955565A - 人机互动系统和方法" title="专利 CN102955565A - 人机互动系统和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102955565 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110254702</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年3月6日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年8月31日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年8月31日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110254702.9, </span><span class="patent-bibdata-value">CN 102955565 A, </span><span class="patent-bibdata-value">CN 102955565A, </span><span class="patent-bibdata-value">CN 201110254702, </span><span class="patent-bibdata-value">CN-A-102955565, </span><span class="patent-bibdata-value">CN102955565 A, </span><span class="patent-bibdata-value">CN102955565A, </span><span class="patent-bibdata-value">CN201110254702, </span><span class="patent-bibdata-value">CN201110254702.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%90%B4%E5%86%A0%E5%BB%B7%22">吴冠廷</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%BE%B7%E4%BF%A1%E4%BA%92%E5%8A%A8%E7%A7%91%E6%8A%80%EF%BC%88%E5%8C%97%E4%BA%AC%EF%BC%89%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">德信互动科技（北京）有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102955565A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102955565A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102955565A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (7),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=hPnQBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110254702&amp;usg=AFQjCNH5r7GdKC3EZ_0qSH2A3spyyZDSbg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=hPnQBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102955565A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGNny2ZnAsAOGuKUiaXj01ti6QbjA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT122502645" lang="ZH" load-source="patent-office">人机互动系统和方法</invention-title>
      </span><br><span class="patent-number">CN 102955565 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA109354994" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明是有关于一种人机互动系统和方法。其中的系统包括：视频捕捉装置和控制装置；视频捕捉装置用于实时摄取图像并输出；控制装置包括：接收模块，用于接收所述图像；面部表情提取模块，用于从所述图像中提取用户面部的热点区域信息，并根据热点区域信息确定用户的面部表情信息；存储模块，用于预先存储面部表情信息与控制命令的对应关系信息；控制模块，用于将上述确定出的面部表情信息在存储模块中存储的对应关系信息中进行匹配查找，以确定面部表情提取模块确定出的面部表情信息对应的控制命令；执行模块，用于执行所述控制模块确定出的控制命令。本发明提供的技术方案能够基于用户面部表情实现人机互动，从而使人机互动的实现方式多元化。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(6)</span></span></div><div class="patent-text"><div mxw-id="PCLM51773113" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种人机互动系统，其特征在于，所述系统包括：视频捕捉装置和控制装置；  所述视频捕捉装置，用于实时摄取图像，并输出；  所述控制装置包括：  接收模块，用于接收所述视频捕捉装置传输来的图像；  面部表情提取模块，用于从所述接收模块接收到的图像中提取用户面部的热点区域信息，并根据所述热点区域信息确定用户的面部表情信息；  存储模块，用于预先存储面部表情信息与控制命令的对应关系信息；  控制模块，用于将面部表情提取模块确定出的面部表情信息在所述存储模块中存储的对应关系信息中进行匹配查找，以确定面部表情提取模块确定出的面部表情信息对应的控制命令；  执行模块，用于执行所述控制模块确定出的控制命令。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求I所述的人机互动系统，其特征在于，所述视频捕捉装置与所述控制装置集成设置于同一电子设备中。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的人机互动系统，其特征在于，所述电子设备包括：计算机、游戏机、移动电话、平板电脑、机顶盒、电视机顶盒一体机或者电视机。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求I所述的人机互动系统，其特征在于，所述视频捕捉装置与所述控制装置独立分离设置，且所述视频捕捉装置与所述控制装置之间通过有线方式连接、或者通过无线方式连接。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求4所述的人机互动系统，其特征在于，所述控制装置设置于计算机、游戏机、移动电话、平板电脑、机顶盒、电视机顶盒一体机或者电视机中。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6.	一种人机互动方法，其特征在于，所述方法包括：  实时摄取图像；  从所述摄取的图像中提取用户面部的热点区域信息；  根据所述热点区域信息确定用户的面部表情信息； 将所述面部表情信息在预先存储的面部表情信息与控制命令的对应关系信息中匹配查找，以确定所述用户的面部表情信息对应的控制命令；  执行所述确定出的控制命令。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES58862511" lang="ZH" load-source="patent-office" class="description">
    <p>人机互动系统和方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及一种人机互动技术，特别是涉及一种人机互动系统和方法。</p>
    <p>背景技术 </p>
    <p>[0002]	人机互动技术已广泛应用于人们的日常生活和工作中。例如，体感游戏以及电器设备的控制等等。尤其是人机互动技术中的体感游戏由于其兼有健身和娱乐的目的而倍受人们的喜爱。</p>
    <p>[0003]目前现有的人机互动技术通常是基于控制设备来实现的，例如，体感游戏通常是通过计算机和体感控制装置来实现或者是通过电视机、机顶盒以及体感控制装置来实现。体感控制装置如游戏手柄等，体感控制装置通常会被用户单手或者双手握于手中，并进行控制操作。</p>
    <p>[0004]	发明人在实现本发明过程中发现：人机互动中的控制设备通常是一个物理实体设备，且通常由多个按键、摇杆、光源、重力加速度传感器以及小屏幕等元件组成。然而，目前人机互动技术已经可以不限于物理的实体设备来实现了，而且，现有的人机互动的实现方式有待于进一步的丰富。</p>
    <p>[0005]	有鉴于上述现有的人机互动技术存在的需求，本发明人基于从事此类产品设计制造多年丰富的实务经验及专业知识，并配合学理的运用，积极加以研究创新，以期创设一种新的人机互动系统和方法，能够满足现有的人机互动技术存在的需求，使其更具有实用性。经过不断的研究设计，并经过反复试作样品及改进后，终于创设出确具实用价值的本发明。</p>
    <p>发明内容</p>
    <p>[0006]	本发明的目的在于，满足人机互动技术存在的需求，而提供一种新的人机互动系统和方法，所要解决的技术问题是，使人机互动技术的实现方式多元化，非常适于实用。</p>
    <p>[0007]	本发明的目的以及解决其技术问题可以采用以下的技术方案来实现。</p>
    <p>[0008]	依据本发明提出的一种人机互动系统，所述人机互动系统包括：视频捕捉装置和控制装置；视频捕捉装置，用于实时摄取图像，并输出；所述控制装置包括：接收模块，用于接收所述视频捕捉装置传输来的图像；面部表情提取模块，用于从所述接收模块接收到的图像中提取用户面部的热点区域信息，并根据所述热点区域信息确定用户的面部表情信息；存储模块，用于预先存储面部表情信息与控制命令的对应关系信息；控制模块，用于将面部表情提取模块确定出的面部表情信息在所述存储模块中存储的对应关系信息中进行匹配查找，以确定面部表情提取模块确定出的面部表情信息对应的控制命令；执行模块，用于执行所述控制模块确定出的控制命令。</p>
    <p>[0009]	本发明的目的以及解决其技术问题还可以采用以下的技术措施来进一步实现。</p>
    <p>[0010]	较佳的，前述的人机互动系统，其中所述视频捕捉装置与所述控制装置集成设置于同一电子设备中。</p>
    <p>[0011]	较佳的，前述的人机互动系统，其中所述电子设备包括：计算机、游戏机、移动电话、平板电脑、机顶盒、电视机顶盒一体机或者电视机。</p>
    <p>[0012]	较佳的，前述的人机互动系统，其中所述视频捕捉装置与所述控制装置独立分离设置，且所述视频捕捉装置与所述控制装置之间通过有线方式连接、或者通过无线方式连接。</p>
    <p>[0013]	较佳的，前述的人机互动系统，其中所述控制装置设置于计算机、游戏机、移动电话、平板电脑、机顶盒、电视机顶盒一体机或者电视机中。</p>
    <p>[0014]	依据本发明提出的一种人机互动方法，包括：实时摄取图像；从所述摄取的图像中提取用户面部的热点区域信息；根据所述热点区域信息确定用户的 面部表情信息；将所述面部表情信息在预先存储的面部表情信息与控制命令的对应关系信息中匹配查找，以确定所述用户的面部表情信息对应的控制命令；执行所述确定出的控制命令。</p>
    <p>[0015]	借由上述技术方案，本发明的人机互动系统和方法至少具有下列优点及有益效果：本发明通过利用视频捕捉装置摄取图像、面部表情提取模块将摄取的图像中的用户面部的热点区域信息对应的面部表情信息提供给控制模块，使控制模块可以根据该面部表情信息和存储模块中存储的对应关系输出控制命令，以实现基于面部表情的人机互动，从而使人机互动的实现方式多元化，非常适于实用。</p>
    <p>[0016]	综上所述，本发明在技术上有显著的进步，具有明显的积极效果，诚为一新颖、进步、实用的新设计。</p>
    <p>[0017]	上述说明仅是本发明技术方案的概述，为了能够更清楚了解本发明的技术手段，而可依照说明书的内容予以实施，并且为了让本发明的上述和其他目的、特征和优点能够更明显易懂，以下特举较佳实施例，并配合附图详细说明如下。</p>
    <p>附图说明</p>
    <p>[0018]	图I为本发明的人机互动系统示意图；</p>
    <p>[0019]	图2为本发明的人机互动方法流程图。</p>
    <p>具体实施方式</p>
    <p>[0020]	为更进一步阐述本发明为达成预定发明目的所采取的技术手段及功效，以下结合附图及较佳实施例，对依据本发明提出的人机互动系统和方法其具体实施方式、结构、特征、流程及其功效，详细说明如后。</p>
    <p>[0021]	实施例一、人机互动系统。该系统如附图I所示。</p>
    <p>[0022]	图I示出的人机互动系统包括：视频捕捉装置I和控制装置2。其中的控制装置2包括：接收模块21、面部表情提取模块22、存储模块23、控制模块24以及执行模块25。接收模块21与面部表情提取模块22连接，控制模块24与面部表情提取模块22、存储模块23以及执行模块25均连接。</p>
    <p>[0023]	视频捕捉装置I主要用于实时摄取图像，并将其摄取到的图像向控制装置2发送。这里的实时摄取如视频捕捉装置I按照预定采样频率进行图像采样。该视频捕捉装置I可以与控制装置2集成设置，也可以与控制装置2相互分离独立设置。在视频捕捉装置I与控制装置2相互分离独立设置的情况下，视频捕捉装置I可以与控制装置2采用有线连接方式连接或者采用无线连接方式连接，即视频捕捉装置通过有线或者无线的方式将其摄取到的图像传输给控制装置2。</p>
    <p>[0024]	视频捕捉装置I可以采用现有的摄像头、以及摄像机等摄像设备，本发明不限制视频捕捉装置I的具体类型。</p>
    <p>[0025]	控制装置2主要用于根据视频捕捉装置I实时摄取的图像、以及其预先存储的用户的面部表情信息与控制命令的对应关系信息确定出摄取到的用户面部表情对应的控制命令，控制装置2通过执行其确定出的该控制命令，从而实现了基于面部表情的人机互动。 [0026]	由于本发明提供的人机互动系统仅仅是基于用户的面部表情来实现人机互动，因此，用户完全可以坐在桌前或者站在桌前或者位于其它近距离的地方来进行人机互动如体感游戏等，从而可以实现近距离体感游戏，并可以使用户在游戏过程中进行面部运动，增强用户对保健运动的兴趣。</p>
    <p>[0027]	控制装置2中的接收模块21主要用于接收视频捕捉装置I传输来的图像序列。在视频捕捉装置I与控制装置2独立分离设置的情况下，接收模块21可以通过有线或者无线方式接收到视频捕捉装置I传输来的图像。一个具体的例子：接收模块21可以通过蓝牙、</p>
    <p>2.	4GHz、WIFI、红外传输、以及USB等传输方式接收视频捕捉装置I传输来的图像，即接收模块21可以为蓝牙模块、2. 4GHz模块、WIFI模块、红外模块、或者USB模块。在视频捕捉装置I与控制装置2集成设置在同一电子设备的情况下，接收模块21可以为缓存介质。本发明不限制接收模块21的具体实现方式。</p>
    <p>[0028]	控制装置2中的面部表情提取模块22主要用于从接收模块21接收到的图像中提取用户面部的热点区域信息，并判断出该热点区域信息对应的面部表情信息，之后，面部表情提取模块22向控制模块24输出其确定出的面部表情信息。这里的热点区域如眉毛、眼睛、嘴巴、以及脸颊等。这里的面部表情信息如眉毛、眼睛、嘴巴以及脸颊等部位中的一个或多个部位的关键值，也可以为面部表情的索引值等。本发明不限制面部表情提取模块22输出的面部表情信息的具体表现形式。另外，本发明中的面部表情提取模块22可以采用现有的技术（如笑脸提取技术等）来提取用户面部的特定部位的热点区域信息。</p>
    <p>[0029]	需要说明的是，面部表情提取模块22在接收到视频捕捉装置I传输来的图像后，可以先对其接收到的图像进行优化处理操作，之后，再进行热点区域信息的提取及确定面部表情操作。上述对图像进行的优化处理操作可以包括：去除无效信息处理、去除干扰信息处理、去除红眼处理、纠正镜头畸变处理、以及增强有效信息处理等操作中的一个或者多个操作。</p>
    <p>[0030]	另外，面部表情提取模块22在提取热点区域信息的过程中，可以先将视频捕捉装置I传输来的图像转换为黑白图像，从而面部表情提取模块22可以根据黑白图像中的像素的灰度值，提取出用户面部的热点区域信息。</p>
    <p>[0031]	控制装置2中的存储模块23主要用于存储面部表情信息和控制命令之间的对应关系信息，例如，存储模块23中存储有面部表情的索引号与控制命令的对应关系信息；再例如，存储模块23中存储有面部表情的各关键值与控制命令之间的对应关系信息。上述关键值如眼睛的开合程度、眉毛的弯曲度、嘴巴开合程度、嘴巴的弯曲方向以及腮部的鼓出/凹陷程度等。上述控制命令可以称为针对设备的某具体应用的控制命令，例如，电视机换台、浏览照片翻页、关闭正在浏览的网页或者体感游戏中的游戏命令等等。</p>
    <p>[0032]	本发明可以动态的设置存储模块23中存储的对应关系信息，一个具体的例子：首先，开启视频捕捉装置1，视频捕捉装置I开始摄像操作，视频捕捉装置I摄取到的包含用户面部的图片被显示在控制装置2所在设备的显示屏上，控制装置2可以在显示屏上显示面部区域位置范围，用户可以通过调整其坐姿或者站位等使视频捕捉装置I摄取到的用户面部位于该面部区域位置范围内，之后，用户点击摄取图片对应的按键（该按键如计算机键盘上的回车键或者屏幕上显示的注册键或者遥控器上的确定键等）；控制装置2在监测到由该按键产生的摄取图片的命令之后，获取包含有用户面部区域的图片，该图片可以是黑白图片或者彩色图片，然后，控制装置2从该图片中获取热点区域图像信息，并通过分析该热点区域图像信息确定出面部表情索引值，之后，将该面部表情索引值和当前需要设置的控制命令以表中记录的形式对应存储到存储模块23中。</p>
    <p>[0033]	当然，本发明中的控制装置2也可以采用其它操作过程在存储模块23中存储面部表情信息和控制命令之间的对应关系信息，本发明不限制在存储模块23存储面部表情信息和控制命令之间的对应关系信息的具体实现方式。 [0034]	控制装置2中的控制模块24主要用于基于存储模块23中存储的对应关系信息将面部表情提取模块22传输来的面部表情信息转换为相应的控制命令，并将该控制命令提供给控制装置2中的执行模块，以实现人机交互如体感游戏等。一个具体的例子：控制模块24可以利用面部表情提取模块22输出的面部表情信息在存储模块23中存储的对应关系信息中进行匹配查找，匹配到的记录中的控制命令即为其接收到的面部表情信息对应的控制命令。</p>
    <p>[0035]	控制装置2还可以包括显示屏以及电源模块等元件。显示屏主要用于显示画面(如游戏画面、以及视频捕捉装置I摄取获得的图像等）。该显示屏可以为计算机的显示屏、移动电话的显示屏、电视机显示屏、平板电脑显示屏、或者游戏机显示屏等。电源模块主要用于为控制装置2中的各用电元件（如控制装置2中的各模块、或者视频捕捉装置I和控制装置2中的各模块等）提供电力资源，该电源模块可以为计算机、移动电话、电视机、平板电脑、或者游戏机等电子设备本身自带的电源模块，也可以为专为本发明中的人机互动系统设置的电源模块。</p>
    <p>[0036]	上述实施例中记载的人机互动系统的设置方式可以为如下两种形式：</p>
    <p>[0037]	第一种形式为：整个人机互动系统集成设置在同一个电子设备中，从而整个人机互动系统成为一个电子设备的一部分，该电子设备可以具体为计算机、移动电话、电视机、平板电脑、机顶盒、电视机机顶盒一体机或者游戏机等。一个具体的例子：在人机互动系统集成设置在计算机中的情况下，视频捕捉装置I集成设置在计算机显示屏的左上角，而控制装置2集成设置在计算机的主机的内部电路中。</p>
    <p>[0038]	第二种形式为：人机互动系统中的视频捕捉装置I与控制装置2独立分离设置，且视频捕捉装置I与控制装置2之间可以通过有线或者无线的方式连接。具体的，视频捕捉装置I可以为摄像头或者摄像机等独立的设备，控制装置2则可以集成设置在计算机、移动电话、电视机、平板电脑（PAD)、机顶盒、电视机机顶盒一体机或者游戏机等电子设备中。</p>
    <p>[0039]	实施例二、人机互动方法。该方法的流程如附图2所示。</p>
    <p>[0040]	图2中示出的人机互动方法包括如下步骤：</p>
    <p>[0041]	S200、实时摄取图像。具体的，可以按照预定采样频率进行图像采样。</p>
    <p>[0042]	S210、从实时摄取的图像中提取用户面部的热点区域信息。[0043]	具体的，上述热点区域如眉毛、眼睛、嘴巴、以及脸颊等。本发明中可以采用现有的技术（如笑脸提取技术等）来提取用户面部的特定部位的热点区域信息。本发明可以先对实时摄取的图像进行优化处理操作，之后再进行热点区域信息的提取操作。上述对图像进行的优化处理操作可以包括：去除无效信息处理、去除干扰信息处理、去除红眼处理、纠正镜头畸变处理、以及增强有效信息处理等操作中的一个或者多个操作。另外，在提取热点区域信息的过程中，可以先将摄取到的图像转换为黑白图像，从而根据黑白图像中的像素的灰度值，提取出用户面部的热点区域信息。</p>
    <p>[0044]	S220、根据热点区域信息确定用户的面部表情信息。</p>
    <p>[0045]	具体的，上述的面部表情信息如眉毛、眼睛、嘴巴以及脸颊等部位中的一个或多个部位的关键值，也可以为面部表情的索引值等。本发明不限制面部表情信息的具体表现形式。 [0046]	S230、将上述确定出的面部表情信息在预先存储的面部表情信息与控制命令的对应关系信息中匹配查找，以确定出用户的面部表情信息对应的控制命令。</p>
    <p>[0047]	具体的，本发明预先存储有面部表情信息和控制命令之间的对应关系信息，如预先存储有面部表情的索引号与控制命令的对应关系信息；再例如，预先存储有面部表情的各关键值与控制命令之间的对应关系信息。上述关键值如眼睛的开合程度、眉毛的弯曲度、嘴巴开合程度、嘴巴的弯曲方向以及腮部的鼓出/凹陷程度等。上述控制命令可以称为针对设备的某具体应用的控制命令，例如，电视机换台、计算机浏览图片前/后翻页、关闭正在浏览的网页或者体感游戏中的游戏命令等等。</p>
    <p>[0048]	本发明可以动态的设置预先存储的对应关系信息，例如：首先，开始执行摄像操作，摄取到的包含用户面部的图片被显示，本发明可以显示面部区域位置范围，用户可以通过调整其坐姿或者站位等使实时摄取到的用户面部位于该面部区域位置范围内，之后，用户点击摄取图片对应的按键（该按键如计算机键盘上的回车键或者屏幕上显示的注册键或者遥控器上的确定键等），从而获取包含有用户面部区域的图片，该图片可以是黑白图片或者彩色图片，然后，从该图片中获取热点区域图像信息，并通过分析该热点区域图像信息确定出面部表情索引值，之后，将该面部表情索引值和当前需要设置的控制命令以表中记录的形式对应存储起来。</p>
    <p>[0049]	当然，本发明也可以采用其它操作过程预先存储面部表情信息和控制命令之间的对应关系信息，本发明不限制预先存储面部表情信息和控制命令之间的对应关系信息的具体实现方式。</p>
    <p>[0050]	确定控制命令的一个具体的例子：利用前述步骤获得的面部表情信息在预先存储的对应关系信息中进行匹配查找，匹配到的记录中的控制命令即为上述确定出的面部表情信息对应的控制命令。</p>
    <p>[0051]	S240、执行上述确定出的控制命令。</p>
    <p>[0052]	以上所述仅是本发明的较佳实施例而已，并非对本发明作任何形式上的限制，虽然本发明已以较佳实施例揭露如上，然而并非用以限定本发明，任何熟悉本专业的技术人员在不脱离本发明技术方案范围内，当可利用上述揭示的技术内容作出些许更动或修饰为等同变化的等效实施例，但凡是未脱离本发明技术方案的内容，依据本发明的技术实质对以上实施例所作的任何简单修改、等同变化与修饰，均仍属于本发明技术方案的范围内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101825947A?cl=zh">CN101825947A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月4日</td><td class="patent-data-table-td patent-date-value">2010年9月8日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">智能控制移动终端的方法、装置及移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102033696A?cl=zh">CN102033696A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年9月17日</td><td class="patent-data-table-td patent-date-value">2011年4月27日</td><td class="patent-data-table-td ">株式会社泛泰</td><td class="patent-data-table-td ">图片控制装置和图片控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102058983A?cl=zh">CN102058983A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年11月10日</td><td class="patent-data-table-td patent-date-value">2011年5月18日</td><td class="patent-data-table-td ">无锡中星微电子有限公司</td><td class="patent-data-table-td ">基于视频分析的智能玩具</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102098567A?cl=zh">CN102098567A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年11月30日</td><td class="patent-data-table-td patent-date-value">2011年6月15日</td><td class="patent-data-table-td ">深圳创维－Rgb电子有限公司</td><td class="patent-data-table-td ">一种互动电视系统及其控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102164541A?cl=zh">CN102164541A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月2日</td><td class="patent-data-table-td patent-date-value">2011年8月24日</td><td class="patent-data-table-td ">爱信精机株式会社</td><td class="patent-data-table-td ">睁闭眼判别装置及程序</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201289739Y?cl=zh">CN201289739Y</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年11月18日</td><td class="patent-data-table-td patent-date-value">2009年8月12日</td><td class="patent-data-table-td ">天津三星电子有限公司</td><td class="patent-data-table-td ">自动表情识别遥控视频播放机</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110158546">US20110158546</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value">2011年6月30日</td><td class="patent-data-table-td ">Primax Electronics Ltd.</td><td class="patent-data-table-td ">System and method for generating control instruction by using image pickup device to recognize users posture</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103309450A?cl=zh">CN103309450A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年6月9日</td><td class="patent-data-table-td patent-date-value">2013年9月18日</td><td class="patent-data-table-td ">张家港市鸿嘉数字科技有限公司</td><td class="patent-data-table-td ">一种识别用户面部表情操作平板电脑的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103399630A?cl=zh">CN103399630A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月5日</td><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">北京百纳威尔科技有限公司</td><td class="patent-data-table-td ">表情录音方法和装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=hPnQBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=hPnQBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003010000">G06F3/01</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年3月6日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月6日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/712309ba5c9a9e3793ab/CN102955565A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BA%BA%E6%9C%BA%E4%BA%92%E5%8A%A8%E7%B3%BB%E7%BB%9F%E5%92%8C%E6%96%B9%E6%B3%95.pdf?id=hPnQBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2zFqCg85c7xcMUmEtqrH11ucbs2g"},"sample_url":"https://www.google.com/patents/reader?id=hPnQBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>