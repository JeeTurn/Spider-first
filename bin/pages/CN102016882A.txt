<!DOCTYPE html><html><head><title>专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="利用脸部签名来标识和共享数字图像的方法、系统和计算机程序"><meta name="DC.contributor" content="C&#183;斯图德霍尔梅" scheme="inventor"><meta name="DC.contributor" content="D&#183;C&#183;沃" scheme="inventor"><meta name="DC.contributor" content="K&#183;普拉塔尼奥蒂斯" scheme="inventor"><meta name="DC.contributor" content="R&#183;加农" scheme="inventor"><meta name="DC.contributor" content="鲁勇满" scheme="inventor"><meta name="DC.contributor" content="应用识别公司" scheme="assignee"><meta name="DC.date" content="2008-12-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明解决了在本地计算机存储设备(家庭计算机)上自动识别照片或视频中多个已知脸部的问题。其进一步允许基于已知脸部的图形化选择(通过选择人们的缩略图像)，对照片或视频进行复杂组织和呈现。其还解决了用于以自动方式在“好友”之间共享或分发照片或视频的问题，该好友也使用支持本发明的相同软件。其进一步解决了允许本发明的用户查看自动脸部检测、眼部检测和脸部识别方法的结果，并且修正自动过程产生的任何错误。"><meta name="DC.date" content="2011-4-13"><meta name="citation_patent_publication_number" content="CN:102016882:A"><meta name="citation_patent_application_number" content="CN:200880126543"><link rel="canonical" href="https://www.google.com/patents/CN102016882A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102016882A?cl=zh"/><meta name="title" content="专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序"/><meta name="description" content="本发明解决了在本地计算机存储设备(家庭计算机)上自动识别照片或视频中多个已知脸部的问题。其进一步允许基于已知脸部的图形化选择(通过选择人们的缩略图像)，对照片或视频进行复杂组织和呈现。其还解决了用于以自动方式在“好友”之间共享或分发照片或视频的问题，该好友也使用支持本发明的相同软件。其进一步解决了允许本发明的用户查看自动脸部检测、眼部检测和脸部识别方法的结果，并且修正自动过程产生的任何错误。"/><meta property="og:title" content="专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102016882A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102016882A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102016882A&amp;usg=AFQjCNHvacYlE1_yjbvPD8CyMK-SEYO6VA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/6228cc11be50803e1746/CN102016882A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/6228cc11be50803e1746/CN102016882A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102016882A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102016882A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102016882A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102016882B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102016882A?cl=zh" style="display:none"><span itemprop="description">本发明解决了在本地计算机存储设备(家庭计算机)上自动识别照片或视频中多个已知脸部的问题。其进一步允许基于已知脸部的图形化选择(通过选择人们的缩略图像)，对照片或视频进行复杂组织和呈现。其还解决了用于以自动 ...</span><span itemprop="url">https://www.google.com/patents/CN102016882A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序" title="专利 CN102016882A - 利用脸部签名来标识和共享数字图像的方法、系统和计算机程序"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102016882 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200880126543</td></tr><tr><td class="patent-bibdata-heading"> 专利合作条约 (PCT) 编号</td><td class="single-patent-bibdata">PCT/CA2008/002276</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年4月13日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2008年12月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年12月31日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2711143A1?hl=zh-CN&amp;cl=zh">CA2711143A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2711143C?hl=zh-CN&amp;cl=zh">CA2711143C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2897227A1?hl=zh-CN&amp;cl=zh">CA2897227A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102016882B?hl=zh-CN&amp;cl=zh">CN102016882B</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN104866553A?hl=zh-CN&amp;cl=zh">CN104866553A</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8750574?hl=zh-CN&amp;cl=zh">US8750574</a>, </span><span class="patent-bibdata-value"><a href="/patents/US9152849?hl=zh-CN&amp;cl=zh">US9152849</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100287053?hl=zh-CN&amp;cl=zh">US20100287053</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140161326?hl=zh-CN&amp;cl=zh">US20140161326</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20160086019?hl=zh-CN&amp;cl=zh">US20160086019</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2009082814A1?hl=zh-CN&amp;cl=zh">WO2009082814A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2009082814A8?hl=zh-CN&amp;cl=zh">WO2009082814A8</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200880126543.0, </span><span class="patent-bibdata-value">CN 102016882 A, </span><span class="patent-bibdata-value">CN 102016882A, </span><span class="patent-bibdata-value">CN 200880126543, </span><span class="patent-bibdata-value">CN-A-102016882, </span><span class="patent-bibdata-value">CN102016882 A, </span><span class="patent-bibdata-value">CN102016882A, </span><span class="patent-bibdata-value">CN200880126543, </span><span class="patent-bibdata-value">CN200880126543.0, </span><span class="patent-bibdata-value">PCT/2008/2276, </span><span class="patent-bibdata-value">PCT/CA/2008/002276, </span><span class="patent-bibdata-value">PCT/CA/2008/02276, </span><span class="patent-bibdata-value">PCT/CA/8/002276, </span><span class="patent-bibdata-value">PCT/CA/8/02276, </span><span class="patent-bibdata-value">PCT/CA2008/002276, </span><span class="patent-bibdata-value">PCT/CA2008/02276, </span><span class="patent-bibdata-value">PCT/CA2008002276, </span><span class="patent-bibdata-value">PCT/CA200802276, </span><span class="patent-bibdata-value">PCT/CA8/002276, </span><span class="patent-bibdata-value">PCT/CA8/02276, </span><span class="patent-bibdata-value">PCT/CA8002276, </span><span class="patent-bibdata-value">PCT/CA802276</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22C%C2%B7%E6%96%AF%E5%9B%BE%E5%BE%B7%E9%9C%8D%E5%B0%94%E6%A2%85%22">C&#183;斯图德霍尔梅</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22D%C2%B7C%C2%B7%E6%B2%83%22">D&#183;C&#183;沃</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22K%C2%B7%E6%99%AE%E6%8B%89%E5%A1%94%E5%B0%BC%E5%A5%A5%E8%92%82%E6%96%AF%22">K&#183;普拉塔尼奥蒂斯</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22R%C2%B7%E5%8A%A0%E5%86%9C%22">R&#183;加农</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%B2%81%E5%8B%87%E6%BB%A1%22">鲁勇满</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%BA%94%E7%94%A8%E8%AF%86%E5%88%AB%E5%85%AC%E5%8F%B8%22">应用识别公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102016882A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102016882A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102016882A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (24),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200880126543&amp;usg=AFQjCNFx8Btlj-OzQLQdcodadEV1NiXVwA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102016882A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEVltpllNrV9kI3WCy17XWLeoJpVQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT102452833" lang="ZH" load-source="patent-office">利用脸部签名来标识和共享数字图像的方法、系统和计算机程序</invention-title>
    </span><br><span class="patent-number">CN 102016882 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA84402227" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明解决了在本地计算机存储设备(家庭计算机)上自动识别照片或视频中多个已知脸部的问题。其进一步允许基于已知脸部的图形化选择(通过选择人们的缩略图像)，对照片或视频进行复杂组织和呈现。其还解决了用于以自动方式在“好友”之间共享或分发照片或视频的问题，该好友也使用支持本发明的相同软件。其进一步解决了允许本发明的用户查看自动脸部检测、眼部检测和脸部识别方法的结果，并且修正自动过程产生的任何错误。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM35567614" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种用于在数字图像中识别一个或多个脸部的方法，所述方法包括：a.生成与一个或多个脸部的一个或多个候选区域相对应的一个或多个脸部坐标；b.基于所述脸部坐标来生成眼部坐标；c.利用由所述脸部坐标和所述眼部坐标定义的一个或多个投影图像来检测每个脸 部；以及d.将每个投影图像与一个或多个已知投影图像进行比较，其中提供用于定义所述投 影图像与所述已知投影图像之间的最佳匹配的相似度阈值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征进一步在于，生成所述脸部坐标是通过：a.启动第一基于纹理的检测例程，以检测一个或多个候选脸部，每个候选脸部具有 脸部坐标；b.向所述一个或多个候选脸部应用肤色检测测试，以定义所述一个或多个候选脸部 的子集；c.将所述子集的脸部坐标所定义的大小缩小至预定大小，以定义脸部对象；d.对所述脸部对象启动第二基于纹理的检测例程，以定义真阳的脸部对象的集合和 不确定的脸部对象的集合；以及e.旋转所述不确定的脸部对象，以定义其他真阳的脸部对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其特征进一步在于，如果所述数字图像是彩色图像，则：a.在所述数字图像中检测肤色与非肤色的比率；以及b.如果所述比率超出了阈值，则确定所述数字图像不包括脸部。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求2所述的方法，其特征进一步在于，旋转由所述眼部坐标划界的每个 图像，以对应于所述不确定的脸部对象的旋转。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的方法，其特征进一步在于：a.裁剪与由每个眼部坐标划界的数字图像的部分相对应的眼部图像；b.可选地将所述眼部图像调整大小至预定大小；c.减小所述眼部图像中的反射光；以及d.隔离所述眼部图像中对应于所述眼部图像的深色位置的多个瞳孔。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的方法，其特征进一步在于，生成所述投影图像是通过：a.将所述候选区域转译、旋转和缩放至具有预定大小的正则化图像，其中将所述眼 部坐标链接至预定位置；b.对所述经正则化的图像进行蒙板，以定义经蒙板的图像，其中所述脸部被隔离；c.将直方图均衡应用于所述经蒙板的图像的灰度级描绘；以及d.利用主元分析来生成所述投影图像。</div>
    </div>
    </div> <div class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.	一种用于共享描绘一个或多个脸部的数字图像的方法，所述方法的特征在于：a.将多个计算机终端链接到计算机网络，每个计算机终端与个体相关联；b.将所述数字图像链接到至少一个所述计算机终端；c.允许至少一个所述计算机终端在所述数字图像上启动脸部识别例程，所述脸部识 别例程产生其脸部被描绘在所述数字图像中的一个或多个人的列表，至少一个人是所述 个体中的一个个体；以及d.允许至少一个所述计算机终端启动共享例程，以将所述数字图像传播到与所述一 个或多个人相关联的计算机终端。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的方法，其特征在于，每个计算机终端链接到处理引擎，其中 所述处理引擎：a.扫描一个或多个文件夹，使得所述处理引擎确定所述个体何时将所述数字图像链 接到所述文件夹中的一个文件夹；b.在所述数字图像上启动所述脸部识别例程；以及c.将所述脸部识别例程的结果链接到数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的方法，其特征在于，所述计算机终端还链接到用户接口，所 述用户接口允许所述个体将所述数字图像链接到所述文件夹中的一个文件夹。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的方法，其特征在于，所述用户接口从移动设备可访问。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求8所述的方法，其特征在于：所述用户接口使用户能够创建链接到 多个数字图像的一个或多个相册。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求7所述的方法，其特征进一步在于：a.将所述个体链接到一个或多个对等分组；以及b.仅将所述数字图像传播到这样的人，其链接到所述对等分组中的一个对等分组， 还链接到与链接到所述数字图像的计算机终端相关联的个体。</div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13.	&#8212;种用于提供安全目标广告的方法，其特征在于：a.追踪与注册到计算机程序的个体相关联的一个或多个人口统计属性；b.基于所述一个或多个人口统计属性，从第一源获取与一个或多个目标广告相关联 的广告指针列表；c.从第二源获取所述一个或多个广告；d.从所述第一源删除所述一个或多个人口统计属性；以及e.将所述广告呈现给所述个体。</div>
    </div>
    </div> <div class="claim"> <div num="14" class="claim">
      <div class="claim-text">14.	一种用于共享描绘一个或多个脸部的数字图像的系统，所述系统的特征在于：a.链接到计算机网络的多个计算机终端，每个计算机终端与个体相关联；b.可操作以链接到至少一个所述计算机终端的数字图像；c.可操作以由至少一个所述计算机终端启动的脸部识别例程，所述脸部识别例程产 生其脸部被描绘在所述数字图像中的一个或多个人的列表，至少一个人是所述个体中的 一个个体；以及d.可操作以由至少一个所述计算机终端启动的共享例程，所述共享例程将所述数字 图像传播到与所述一个或多个人相关联计算机终端。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES41360388" lang="ZH" load-source="patent-office" class="description">
    <p>利用脸部签名来标识和共享数字图像的方法、系统和计算</p>
    <p>机程序</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及将向目标个体分发图像。更具体地，本发明涉及数字图像中的脸部 检测和脸部识别，并且利用社交网络服务和对等网络将图像分发至出现在该图像中的个 体。</p>
    <p>背景技术</p>
    <p>[0002]	目前存在的社交网络是利用网站连接多个个体的工具。以下是PCMAG.COM&#8482; 百科对“社交网络”的定义：</p>
    <p>[0003]	由家庭、工作或爱好联系在一起的人的社团。该术语由J.A.BameS教授于20世 纪50年代首次创造，并将社交网络的大小定义为大约100到150人的团体。</p>
    <p>[0004]	以下是PCMAG.COM&#8482;百科对“社交网站”的定义：</p>
    <p>[0005]	向对特定对象感兴趣或只是一起“闲逛”的人们提供虚拟社区的Web站点。成 员通过语音、聊天、即时消息、视频会议和博客进行通信，并且该服务通常向成员提供 了联系其他成员的好友的方法。这种站点还可以用作亲自会面的媒介。“社交网站”是 针对“虚拟社区”（一群人使用因特网彼此之间就任何事乃至所有事进行通信）的21世 纪术语。</p>
    <p>[0006]	Friendster (www.friendster.com)是首个社交网站，其在 2002 年引入，而 MySpace(www.myspace.com)在一年后出现。从两个好友开始，MySpace变得非常流行， 并且其母公司（Intermix)在MySpace投放市场两年后被News Corporation以58亿美元收购。</p>
    <p>[0007]	Facebook(www.facebook.com)出现在2004年，最初定位于在校学生，但随后 欢迎所有人。 在 Facebook 之后是 TagWorld(www.tagworld.com)禾口 Tagged(www.tagged. com)。TagWorld引入了用于创建更加个性化Web页面的工具，而Tagged引入了为具有 相同兴趣的青少年建立职业摔角（tagteam)的概念。</p>
    <p>[0008]	社交网站对关注度的竞争与90年代中期因特网出现时的第一 Web门户网站之争 的场面非常相似。期望出现许多变化。</p>
    <p>[0009]	许多社交网站允许用户上传和共享照片。某些社交网站还包含用于给照片加标 签以标识照片中人（脸部）的姓名的特征（例如，FACEBOOK&#8482;提供了这一特征）。基 于用户调查，大多数回答者都表示加标签的工作是手动的并且非常耗时。此外，由于隐 私的原因，许多用户不会将他们所有的数字照片都上传到共享网站。而且，上传上千张 的照片是非常耗时和带宽敏感的。所以，尽管社交网站的用户在其本地计算机上可能有 10,000张数字照片时，但他们只会上传一两百张照片来与他们的好友共享。这基于2007 年9月AppliedRecognitionInc.执行的用户调查。</p>
    <p>[0010]	还有某些网站允许注册的用户上传数字照片和数字视频，并且将它们存储到以 共享为目的的网站上。这些网站是专用于此目的的。这些网站的示例包括FLICKR&#8482;和raOTOBUCKET&#8482;。这些网站的缺点在于：为了标识好友而给所有照片加标签的过程是 手动的并且非常耗时；raOTOBUCKET&#8482;不允许人们给照片加标签。对于FLICKR&#8482;， 如果平均每张照片包含两个人，那么针对每张照片可能要花费10-15秒来给照片中的人 加标签。当该时间乘以100或1000时，这会变得非常耗时，一般人也就不再执行加标签了。</p>
    <p>[0011]	如今，照相设备飞速发展，并且绝大部分现代蜂窝电话包含数字照相机。事实 上，如今经由蜂窝电话销售的照相机比所有专用数字照相机的总和还要多。这正在使上 传到和存储到家庭计算机的数字图像的数量激增。因为基于我们的调查数字图像的平均 数量超过了 1000张，因此对于大多数人而言，手动给照片加标签并对其正确地进行组织 的工作量是非常巨大的。</p>
    <p>[0012]	一家公司（RIYA&#8482;(www.riya.com))创建了一种基于web的、用于标识数字照片</p>
    <p>中脸部的产品。此产品涉及：在将这些照片上传到远程RIYA&#8482;基于web的服务器（在 那里将脸部与其他脸部进行比较以找到匹配）之前，下载用于标识用户本地计算机上照 片中脸部的软件模块。此产品是原型，因此不具有基于识别的自动照片共享特征。该产 品也不具有用于使用户能够修正发生在任何自动脸部检测和识别方法中不可避免的错误 的特征。</p>
    <p>发明内容</p>
    <p>[0013]	在本发明的一个方面中，提供了一种用于在数字图像中识别一个或多个脸部的 方法，该方法的特征在于：（a)生成与一个或多个脸部的一个或多个候选区域相对应的一 个或多个脸部坐标；（b)基于脸部坐标来生成眼部坐标；（c)利用由脸部坐标和眼部坐标 定义的一个或多个投影图像来检测每个脸部；以及（d)将每个投影图像与一个或多个已 知的投影图像进行比较，其中提供用于定义投影图像与已知投影图像之间的最佳匹配的 相似度阈值。</p>
    <p>[0014]	在本发明的另一方面中，提供了一种用于共享描绘一个或多个脸部的数字图像 的方法，该方法的特征在于：（a)将多个计算机终端链接到计算机网络，每个计算机终端 与个体相关联；（b)将数字图像链接到至少一个计算机终端；（c)允许至少一个计算机终 端在数字图像上启动脸部识别例程，该脸部识别例程产生其脸部被描绘在数字图像中的 一个或多个人的列表，至少一个人是个体之一；以及（d)允许至少一个计算机终端启动 用于将数字图像传播到与一个或多个人相关联的计算机终端的共享例程。</p>
    <p>[0015]	在本发明的另一方面中，提供了一种用于提供安全目标广告的方法，该方法的 特征在于：（a)追踪与注册到计算机程序的个体相关联的一个或多个人口统计属性；（b) 基于该一个或多个人口统计属性，从第一源获取与一个或多个目标广告相关联的广告指 针列表；（c)从第二源获取一个或多个广告；（d)从第一源删除该一个或多个人口统计属 性；以及（e)将广告呈现给个体。</p>
    <p>[0016]	在本发明的另一方面中，提供了一种用于在数字图像中识别一个或多个脸部的 系统，该系统的特征在于：（a)与一个或多个脸部的一个或多个候选区域相对应的一个 或多个脸部坐标；（b)基于脸部坐标而生成的眼部坐标；（c)由脸部坐标和眼部坐标定义 的一个或多个投影图像；以及（d)用于定义每个投影图像与一个或多个已知投影图像之间的最佳匹配的相似度阈值，该最佳匹配确定了对应于一个或多个脸部中每个脸部的身 份。</p>
    <p>[0017]	在本发明的另一方面中，提供了一种用于共享描绘一个或多个脸部的数字图像 的系统，该系统的特征在于：（a)链接到计算机网络的多个计算机终端，每个计算机终端 与个体相关联；（b)可操作以链接到至少一个计算机终端的数字图像；（c)可操作以由至 少一个计算机终端启动的脸部识别例程，该脸部识别例程产生其脸部被描绘在数字图像 中的一个或多个人的列表，至少一个人是个体之一；以及（d)可操作以由至少一个计算 机终端启动的共享例程，该共享例程将数字图像传播到与一个或多个人相关联的计算机 终端。</p>
    <p>[0018]	在本发明的另一方面中，提供了一种用于提供安全目标广告的系统，该系统的 特征在于：（a)与注册到计算机程序的个体相关联的一个或多个人口统计属性；（b)可操 作以基于该一个或多个人口统计属性来提供与一个或多个目标广告相关联的广告指针列 表的第一源；（c)可操作以提供一个或多个广告的第二源；（d)用于从第一源删除该一个 或多个人口统计属性的装置；以及（e)用于将广告呈现给个体的装置。</p>
    <p>[0019]	在本发明的另一方面中，提供了一种用于在数字图像中识别一个或多个脸部的 计算机程序产品，该计算机程序产品的特征在于：（a)包括软件指令的计算机可读介质； 以及（b)允许使计算机执行预定操作的软件指令，该预定操作包括步骤：⑴生成与一个 或多个脸部的一个或多个候选区域相对应的一个或多个脸部坐标；（ii)基于脸部坐标来 生成眼部坐标；（iii)利用由脸部坐标和眼部坐标定义的一个或多个投影图像来检测每个 脸部；以及（iv)将每个投影图像与一个或多个已知投影图像进行比较，其中提供用于定 义投影图像与已知投影图像之间的最佳匹配的相似度阈值。</p>
    <p>[0020]	在本发明的另一方面中，提供了一种用于共享描绘一个或多个脸部的数字图像 的计算机程序产品，该计算机程序产品的特征在于：（a)包括软件指令的计算机可读介 质；以及（b)用于允许计算机执行预定操作的软件指令，该预定操作包括步骤：⑴将 多个计算机终端链接到计算机网络，每个计算机终端与个体相关联；（ii)将数字图像链 接到至少一个计算机终端；（iii)允许至少一个计算机终端在数字图像上启动脸部识别例 程，该脸部识别例程产生其脸部被描绘在数字图像中的一个或多个人的列表，至少一个 人是个体中的一个；以及（iv)允许至少一个计算机终端启动用于将数字图像传播到与一 个或多个人相关联的计算机终端的共享例程。</p>
    <p>[0021]	在本发明的另一方面中，提供了一种用于提供安全目标广告的计算机程序产 品，该计算机程序产品的特征在于：（a)包括软件指令的计算机可读介质；以及（b)用 于使计算机能够执行预定操作的软件指令，该预定操作包括如下步骤：⑴追踪与注册到 计算机程序的个体相关联的一个或多个人口统计属性；（ii)基于一个或多个人口统计属 性，从第一源获取与一个或多个目标广告相关联的广告指针列表；（iii)从第二源获取一 个或多个广告；（iv)从第一源删除一个或多个人口统计属性；以及（v)将广告呈现给个 体。</p>
    <p>[0022]	就这一点，在详细阐述本发明的至少一个实施方式之前，应当理解，本发明不 将其应用限制于如下描述中阐明或附图中示出的构建细节以及组件安排。本发明能够通 过其他实施方式以各种方式来实践并完成。此外，应当理解，这里所采用的措辞和术语是为了描述的目的，因此不应理解为限制本发明。 附图说明</p>
    <p>[0023]	图1示出了并入用于执行照片目标分发的社交网络服务的本发明系统的特定实 施方式。</p>
    <p>[0024]	图2进一步示出了图1中所示的系统，其中用户添加随时间来自各种设备的新数</p>
    <p>字图像。</p>
    <p>[0025]	图3示出了本发明的脸部识别方法，在其中一方面，其用于生成可与已知人的 签名相比较的脸部“签名”。</p>
    <p>[0026]	图4示出了在本地计算机系统存储设备上的脸部数据库中链接脸部检测、眼部 检测和脸部识别技术的结果。</p>
    <p>[0027]	图5示出了对等（peer)分组如何随着已知人的列表的增长而随时间增长和演进。</p>
    <p>[0028]	图6示出了用于修正可能由自动脸部检测、眼部检测和脸部识别步骤产生的错 误的潜在方法。</p>
    <p>[0029]	图7示出了用于在相同端分组中本发明用户之间提供照片的自动选择性传播的 系统和方法。</p>
    <p>[0030]	图8示出了可以支持照片浏览以及由计算机程序管理的脸部数据库的图形化用 户接口的示例实施方式。</p>
    <p>[0031]	图9给出了已知人的脸部图像加上用于缩小照片的范围的布尔运算符。</p>
    <p>[0032]	图10示出了由GUI提供的可选广告显示能力。</p>
    <p>[0033]	图11示出了根据本发明其中一方面的基于纹理的脸部检测方法。</p>
    <p>[0034]	图12示出了根据本发明一方面的用于眼部检测的方法。</p>
    <p>[0035]	图13示出了根据本发明一方面的脸部识别方法。</p>
    <p>[0036]	图14示出了用于在照片中隔离眼部的方法。</p>
    <p>[0037]	图15示出了本发明系统的示例配置。</p>
    <p>[0038]	图16示出了用于允许用户确认出现在图像中的脸部身份的接口。</p>
    <p>[0039]	图17示出了用户可以用来删除图像中假阳（falsepositive)脸部检测的方式。</p>
    <p>[0040]	图18示出了用户可以为了提高检测算法的精确度的目的、重新调整对应于图像 中脸部的检测到的眼部坐标的装置。</p>
    <p>[0041]	图19示出了在图像中手动给脸部加标签的过程。</p>
    <p>[0042]	图20示出了视频扫描方法，由此视频中的帧被抽取出来并且在这些帧上执行脸 部检测。</p>
    <p>[0043]	图21示出了本发明的一个方面，其中远程web浏览器或移动设备能够支持访问 代理服务器，从而提供了到本发明功能的连接。</p>
    <p>[0044]	图22示出了假阳脸部检测错误的删除。</p>
    <p>具体实施方式</p>
    <p>[0045]	概述</p>
    <p>[0046]	本发明其中一个方面提供了支持图像自动分发的网络化计算机架构，该图像与在网络上操作计算机系统的多个个体有关。</p>
    <p>[0047]	本发明其中另一方面提供了可操作以支持每个个体与在此提供的用于共享包括 图像的信息的网络化计算机架构对接的计算机程序。该计算机程序使得个体能够上传图 像，包括具有一个或多个人的脸部描绘的图像。该计算机程序可以执行脸部检测技术， 用于检测图像中的一个或多个脸部，其可能会导致生成一个或多个脸部签名，每个脸部 签名对应于多个脸部中的一个。该计算机程序继而可以访问数据库，其中数据库将已知 人的列表与脸部签名链接，从而使每个已知人与一个或多个脸部签名相关联。可以将每 个检测到的脸部签名提供给与对应的已知人相关联的个体，或者在脸部签名不与任何已 知人相关联的情况下，信息可以由个体来提供。还可以向个体提供用于确认脸部签名与 已知人之间关联的装置。</p>
    <p>[0048]	本发明其中又一方面提供了用于基于图像中描绘的脸部来生成脸部签名的新方 法。还提供了用于减少在将识别的脸部签名与链接到数据库的一个或多个脸部签名相关 联过程中的错误率的装置。</p>
    <p>[0049]	本发明其中另一方面支持描绘脸部的图像的自动选择性分发。如果图像中检测 到的脸部和与这里提供的网络化计算机架构对接的人相关联，则这里提供的计算机程序 可以自动地将图像传输至那个人的计算机来向其呈现。应当注意，术语“照片”和“图 像”这里可以互换使用。</p>
    <p>[0050]	本发明其中又一方面提供了可以利用这里提供的网络化计算机架构操作的新的</p>
    <p>广告方法。</p>
    <p>[0051]	网络化计算机架构</p>
    <p>[0052]	本发明其中一个方面提供了支持图像自动分发的网络化计算机架构，该图像与 在网络上操作计算机系统的多个个体有关。图1示出了本发明的网络化计算机架构的示 例实现。多个个体中的每一个可以通过可操作访问因特网（11)的计算机终端连接到因特 网（11)。因特网（11)连接支持从连接到因特网的设备传输和接收数字数据，每个所述设 备可以如下面所提供的进行操作。</p>
    <p>[0053]	本发明其中另一个方面提供了可操作以允许每个个体与这里提供的网络化计算 机架构对接的计算机程序。图15示出了本发明系统的示例配置。本发明的用户（13)可 以注册、下载和安装该计算机程序到其计算机系统（15)。</p>
    <p>[0054]	计算机程序可以在其一个方面允许用户（13)邀请本发明的其他用户并且与其建 立关系。该计算机程序可以在其另一方面从将广告递送给计算机程序的广告web服务器 (23)集合请求广告，以用于在图形用户接口（ “GUI” )的各个部分显示给用户（13)。 计算机程序可以在其另一方面将照片和关于那些照片的元数据传输至其他用户或者第三 方网站（25)，诸如FLICKR&#8482;和FACEBOOK&#8482;。这些第三方网站（25)可以通过公开应 用编程接口（API)来支持从客户端软件或者其他基于web的应用连接到它们的服务，从 而鼓励使用它们的网站。</p>
    <p>[0055]	支持本发明实现的计算机程序的组件可以包括：</p>
    <p>[0056]	处理引擎，其可以在操作系统上作为后台进程来运行。该处理引擎可以扫描用 户向本地和/或远程计算机上的特定文件夹上传或拷贝的新数字照片，该特定文件夹针 对照片而被监测；或者当可移动介质（诸如，存储卡）插入计算机时，该处理引擎可以自</p>
    <p>8动地检测新照片。当检测到新的照片时，可以执行下文详述的脸部检测、眼部检测和脸 部识别步骤。其结果可以被存储到数据库中，诸如下文详述的数据库。应当注意，该处 理引擎可以在远程计算机上执行，诸如可以使用软件即服务模型将本发明的计算机程序 作为服务提供的计算机。</p>
    <p>[0057]	GUI,其可以向用户提供以下能力：导航照片、通过标识已知人来训练应用、 编辑和修正引擎的自动结果、基于搜索标准创建和修改相册、添加对等分组成员以及将 相册发送到第三方网站，每个此类动作将在下文详述。</p>
    <p>[0058]	数据库（例如，SQL数据库），其可以位于用户的计算机上，并且可以包含下面 描述的脸部检测、眼部检测和脸部识别步骤的结果。数据库还可以包含针对已知人与相 关联的脸部图像之间的关系以及照片和人的元数据。</p>
    <p>[0059]	GUI、处理引擎和数据库可以在一个或多个设备上提供。图21示出了本发明的 一个方面，其中远程web浏览器或移动设备（83)能够访问代理服务器（81)，从而提供到 本发明功能的连接。GUI可以被提供在诸如PDA或蜂窝电话的移动设备（83)上，并且 与运行在网站、服务器或者用户的桌上或膝上计算机上的远程引擎来回传输信息。在这 种实现中，PDA或蜂窝电话可以配有用于浏览图像的装置，和用于上传利用并入该设备 的照相机捕获的图像的装置。上传可以根据下面更加完整描述的一般性上传过程执行。</p>
    <p>[0060]	由利用计算机程序的用户执行的步骤可以包括： [0061 ] 指定文件夹以监测新的数字照片。</p>
    <p>[0062]	通过标识与数字照片中找到的脸部相关联的名称和元数据来训练应用。</p>
    <p>[0063]	修正由应用产生的错误；假阳和假阴（false negative)。</p>
    <p>[0064]	通过指定包括数据范围、已知人（经由脸部选择）的布尔组合、EXIF标签和通 用标签的搜索标准来创建相册（照片的集合）。可选地，用户可以将单个照片或照片分组 拖放到该相册。</p>
    <p>[0065]	一旦创建了相册，用户继而可以指定各种输出选项包括：</p>
    <p>[0066]	第三方网站，诸如Flickr&#8482;和Facebook&#8482;。</p>
    <p>[0067]幻灯片格式，诸如	Microsoft&#8482; Powerpoint&#8482; 文件。</p>
    <p>[0068]	文档格式，诸如Adobe&#8482; PDF&#8482;文件。</p>
    <p>[0069]	邀请其他应用用户加入到对等分组；指定关于对等分组中那些关系的选项；以 及接收加入另一用户的对等分组的邀请。</p>
    <p>[0070]	网络化计算机架构还可以包括一个或多个服务器用于支持这里所述的技术。例 如，这里提供的广告方法可以由服务器支持。可以在一个或多个服务器系统上提供的服 务器可以包括支持服务器功能的服务器程序，包括：</p>
    <p>[0071]	注册服务器，其具有数据库，该数据库支持电子邮件地址列表、相关联日期和 其他管理数据的关联。注册服务器可以向用户呈现诸如网页的接口，用于收集注册数据 继而将此数据写入到数据库。继而可以向用户给出用于安装上述计算机程序的装置，诸 如提供用于下载客户端软件的URL。</p>
    <p>[0072]	广告匹配服务器可以接受包含用户人口统计信息的加密请求。这种服务器也可 以通过多种格式（诸如JPG、.GIF、.SWF等）从广告者接收广告。对于提交到应用的 每个广告，还可以记录广告的目标人群。广告请求可以基于目标人群数据来与广告的库存进行匹配。可以返回指针（唯一 ID号的指针），用于将广告匹配于请求客户端软件。</p>
    <p>[0073]	广告递送服务器可以接受包含广告指针的加密请求。应用可以找到该指针所引 用的广告，并且将该广告返回给请求客户端软件。</p>
    <p>[0074]	对等分组</p>
    <p>[0075]	再次参考图1，本发明的第一用户（13)可以从网站下载计算机程序，或者配有 用于安装该计算机程序的任何其他安装手段。第一用户（13)可以安装计算机程序，该计 算机程序可以在他们运行操作系统（诸如，MICROSOFT&#8482; WINDOWS&#8482;、APPLE&#8482;、或 LINUX&#8482;操作系统）的膝上或桌上计算机系统（15)上支持本发明的系统。</p>
    <p>[0076]	第一用户（13)可以定义对等分组中的好友（17)，这通过向本发明指定他们的电 子邮件地址来实现。计算机程序随后可以发送电子邮件邀请，请求好友（17)也下载或以 其他方式支持该计算机程序安装。在安装之后，好友（17)的对应计算机程序可以向该好 友（17)呈现用于加入由第一用户（13)发起的对等分组的未决请求。可以要求现在可能 是第二用户（17)的好友（17)批准到对等分组的连接。一旦批准，第一用户（13)和第二 用户（17)运行的计算机程序现在可以根据这里所述的图像共享方法来交换照片以及关于 那些照片和关于已知人的元数据。</p>
    <p>[0077]	对等分组可以通过第一用户（13)或第二用户（17)邀请更多的人（19、21)加入 到对等分组得到扩充。第二用户（17)也可以创建没有第一用户（13)参与的新对等分组， 并且单独地对对等分组进行扩充。人与对等分组之间可能存在“多对多”的关系。因 此，第一用户（13)可以是多个对等分组的成员，第二用户（17)可以是多个对等分组的成 员。这使得与基于对等分组成员关系的其他用户共享照片变得容易。</p>
    <p>[0078]	如下面更加完整地描述，本发明其中一个方面支持已知人的列表。如上所述， 可以将已知人有选择地添加到一个或多个对等分组。</p>
    <p>[0079]	对等分组可以支持共享照片、关于照片的元数据和已知人。GUI可以支持用户 创建、修改和删除对等分组。GUI还可以支持将脸部图像或已知人的缩略图关联至现有 对等分组，例如，通过使用户能够将脸部图像或缩略图拖拽到接口的表示对等分组的区 域上，诸如区域或图标。</p>
    <p>[0080]	计算机程序每次可以生成一个邀请，用于将好友添加至对等分组。备选地，如 果被邀请者没在已知人的列表中，那么用户可以手动地将被邀请者的元数据添加至对等 分组。可以将对个体的邀请经由电子邮件发送至被邀请者。对于在他们的计算机系统上 已经安装了本发明的计算机程序的个体，一旦该电子邮件被接收，便提示被邀请者接受 邀请。可选地，要求个体将代码键入计算机程序来接受邀请。</p>
    <p>[0081]	如果好友还没有在他们的计算机上安装本发明的计算机程序，那么一旦该电子 邮件被接收，便可以包括下载链接或以其他方式允许该计算机程序的安装，并且可以提 供用于将其安装到计算机系统上的向导。在成功安装了计算机程序之后，可以向新用户 呈现邀请，并且新用户可以根据上所述步骤接受加入对等分组的邀请。</p>
    <p>[0082]	一旦被邀请者接受了邀请，便可以将被邀请者添加到对等分组。更新可以通过 网络化计算机架构进行传播，以使对应的对等分组信息能够在与该对等分组相关联的每 个人的计算机程序中得到更新。</p>
    <p>[0083]	根据如下所述的脸部检测技术，对等分组可以支持信息在网络化计算机架构之间的自动选择性传播。该传播技术在下面还进行了更加完整描述。</p>
    <p>[0084]	脸部检测</p>
    <p>[0085]	本发明其中一个方面提供了用于基于图像中描绘的脸部来生成脸部签名的新方 法。图3示出了根据本发明其中的一个方面的脸部识别方法。用户（13)可以将图像提 供给可操作来支持计算机程序执行的计算机系统（15)。计算机程序可以经由操作系统通 知来监测与计算机系统（15)相关联的文件夹，该操作系统通知可以在添加新文件或修改 现有文件时生成。当发现（28)新图像时，可以将这些图像排队（29)用于处理。</p>
    <p>[0086]	照片中的脸部可以通过使用多个技术中的任意一种技术进行定位（31)，这些技 术可以包括：生成脸部坐标，其可以定义脸部周围的包围盒；基于脸部坐标确定眼部坐 标；以及基于脸部和眼部坐标并且通过使用脸部签名技术来创建脸部的脸部签名（33)。 脸部签名技术可以是主元分析（PCA)，这对于本领域技术人员是已知的。可以将脸部签 名与已知的脸部签名进行比较（34)，并且可以将照片自动地且选择性地传播至其他用户 (36)。下面提供了本发明这些方面的进一步细节。</p>
    <p>[0087]	图4示出了在本地计算机系统存储设备上的脸部数据库中链接脸部检测、眼部 检测和脸部识别技术的结果。该结果可以是相关联对象的坐标。在脸部检测的情况下， 坐标可以利用左上、右上、左下和右下像素位置来在原始照片上定义脸部（37)的轮廓。 在眼部检测的情况下，坐标可以表示左眼和右眼的瞳孔位置（35)。在脸部识别的情况 下，其结果可以是脸部签名（42)。</p>
    <p>[0088]	本发明的图形用户接口（GUI)可以显示每张图像（35)上的脸部（37)和眼部（39) 的位置。如下面更加完整的描述，本发明在其中一个方面提供了已知人的列表。如果与 检测的脸部相对应的脸部签名（42)与已知人的列表中列出的人相关联，那么GUI可以使 用在图像上或周围的图形符号来向用户指出这种关联。否则，GUI可以使用在图像上或 周围的另一图形符号来向用户指出不存在这种关联。在图4描绘的示例中，已知的脸部 可以利用复选标记（41)标识，而未知脸部利用记号“X” (43)标识。</p>
    <p>[0089]	最初，所有的脸部对于系统可能都是未知的，直到用户“训练”本发明来识别 脸部。训练方法可以涉及用户。经由本发明的GUI，用户可以使用鼠标或其他输入设 备、通过点击脸部周围可视包围盒上的任何位置并且将脸部拖拽到人名（或代表该人的 图标）上，来标识属于指定人的脸部。备选地，用户可以将代表该人的图标拖拽到目标 脸部上。在另一备选中，用户可以点击可视包围盒上的任何位置并且选择用于标识先前 未知的脸部的功能，该功能可以使用户能够键入与该人有关的数据，诸如姓名、电子邮 件地址和其他细节，这可以统称为对应于该人的元数据。这种训练步骤可以为每个已知 人执行一次。为脸部创建的签名继而可以支持脸部数据库中所有未知的脸部签名与经标 识的人进行比较。下面更加完整地描述了用于比较的方法和用于脸部检测、眼部检测和 脸部识别的方法。</p>
    <p>[0090]	本发明其中又一方面通过对未知的脸部进行整理，使得用户可以标识最有可能 与单个个体相关联的经检测脸部的分组，而促进了最佳训练阶段。例如，可以使用算法 来基于脸部签名将相似的脸部聚集在一起。即便在脸部不与脸部数据库中的个体相关联 时，相似度仍可以基于他们脸部签名的某些方面。因此，用户可以标识属于特定已知人 的脸部簇，从而最佳地执行上文所述的训练方法。[0091]	脸部与已知人的关联</p>
    <p>[0092]	图16示出了用于允许用户确认出现在图像中的脸部身份的接口。图像中的脸部 签名针对与已知人相关联的脸部签名可以在相似度阈值中。在这种情况下，可以在检测 的脸部与已知人之间进行关联。下面更加完整地描述了一种用于比较脸部签名的方法。</p>
    <p>[0093]	如果脸部与已知人之间存在关联，那么可以在数据库中创建该脸部签名与已知 人之间进一步的关联。可以将针对每个已知人的每个先前标识的脸部与由系统处理的每 个新的脸部进行比较。当查看与特定的已知人有关的脸部时，可以显示由本发明生成的 任何猜测到的匹配，并且可以要求用户确认哪些匹配是正确的。</p>
    <p>[0094]	随着标识的脸部的数量随时间而增多，将新的脸部与正确的人相匹配的整体精 确度可以提高，因为通常将会存在具有每个新脸部的人的许多不同视图。根据这里提供 的用于比较脸部签名的方法，假阳的数量通常会随时间减少。</p>
    <p>[0095]	图5示出了对等分组如何随着已知人的列表增长而随时间增长和演进。由于用 户可以不断地将未知的脸部与已知人相关联，所以已知人的列表（101)随着用户使用本 发明而增长。</p>
    <p>[0096]	传播</p>
    <p>[0097]	本发明其中另一方面提供了一种可操作以允许每个个体与这里提供的、用于共 享图像的网络化计算机架构对接的计算机程序。图2进一步示出了本发明的系统。用户 (13)可以捕获数字图像并且周期地将它们从一个或多个图像设备存储系统（27)拷贝至计 算机系统（15)。用户（13)可以通过使用如上所述GUI将文件夹的名称输入到计算机程 序，来配置该计算机程序以针对新图像而监测计算机系统（15)上的特定文件夹。</p>
    <p>[0098]	根据本发明提供的用于脸部识别的新方法，本发明其中一个方面支持在对等分 组之间到其脸部在图像中描绘的用户的自动选择性传播。这在下面更加完整地进行描 述。</p>
    <p>[0099]	检测优化</p>
    <p>[0100]	本发明其中一个方面提供了用于根据本发明的其他方面优化脸部检测的新技 术。图6示出了用于修正可能从自动脸部检测、眼部检测和脸部识别步骤产生的错误的 潜在方法。本发明使用使用户通过GUI来修正这些不可避免的错误的新方法。</p>
    <p>[0101]	图17示出了用户可以用来删除图像中假阳脸部检测的方式。在脸部检测和眼部 检测阶段期间，可能存在假阳错误。在原始照片图像实际上没有脸部，而检测技术却确 定存在脸部时，可能出现这些错误。为了修正这些错误，GUI可以使用户能够通过使用 鼠标或其他输入设备将脸部（103)(该脸部由图像上的包围盒标识）移动到删除区域（其 可以由回收站或其他代表性图标表示）上、通过当该脸部高亮时按下键盘上的删除键、 或者通过选择与该脸部删除相对应的菜单选项（105)来删除假阳错误。</p>
    <p>[0102]	图18示出了用户可以为了提高检测算法的精确度的目的、重新调整对应于图像 中脸部的检测到的眼部坐标的装置。在脸部检测和眼部检测阶段期间，可能就眼部位置 坐标（107)存在错误。本发明的方法可以确定眼睛瞳孔位置，并且将眼部坐标（107)可视 地显示在图像上，但是生成的坐标可能不是最理想的，这是因为在某些情况下（例如， 有太阳眼镜的脸部）其可能是近似值。GUI可以允许用户手动地重新调整眼部坐标（107) 的位置，例如通过利用鼠标或其他输入设备来移动代表眼部位置的图标（109)。以这种方</p>
    <p>12式，可以提高本发明的精确度和性能，因为眼部坐标（107)通常用于生成针对脸部的脸 部签名。因此，眼部坐标（107)的改变可以带来脸部签名的改变，其可能对将签名与其 他已知的脸部相关联造成显著影响。</p>
    <p>[0103]	图22示出了假阳脸部检测错误的删除。在脸部识别阶段期间，可能存在关于脸 部与已知人的不正确关联的假阳错误。如果本发明将脸部签名匹配到已知人并且这不是 正确的关系，那么可能产生假阳错误。GUI可以允许用户将脸部图像（111)(缩略图）拖 拽到正确已知人（113)的脸部图像（缩略图）上。本发明继而可以修改数据库中的链接， 以给出脸部与已知人之间新的关系。还可以将旧的关系删除。</p>
    <p>[0104]	另一类错误是假阴。可能存在两种分类为假阴错误的情形，其在图6中示出：</p>
    <p>[0105]	1)在确实存在脸部（47)但系统没有在图像中检测到脸部的情况下，GUI可以 允许用户使用鼠标或其他输入装置在该脸部周围画出包围盒，继而通过利用代表眼部位 置的图标给出两只眼的位置。系统继而可以使用手动键入的信息来生成脸部签名，并且 执行这里所提供的脸部识别方法。备选地，系统可以允许用户手动地将标签与脸部相关 联，而不涉及脸部检测或识别过程。</p>
    <p>[0106]	2)在如下情况下也可能存在假阴错误，即，系统检测到脸部，但该脸部签名与 任何已知的脸部签名都不匹配，即便该脸部是已知人的脸部。如果脸部的签名与该特定 人的任何其他脸部签名之间的区别非常不同，那么可能会发生这种情况。在这种情况 下，系统可能不会自动地检测到该关系，并且脸部可能依然未知。在这种情况下，GUI 可以允许用户将脸部图像拖拽（49)到已知人的脸部图像上。通过这样做，系统可以将脸 部图像链接到数据库中已知人。通过来自用户的这种协助，系统现在具有了另一脸部签 名，其用于将来与新的或未知的脸部签名进行比较。这可以改进本发明的准确度。图19 进一步示出了在图像中手动给脸部加标签的过程。</p>
    <p>[0107]	图像的自动选择性传播</p>
    <p>[0108]	图7示出了用于在本发明的用户之间提供照片的自动选择性传播的系统和方 法。当作为对等分组成员的已知人的脸部在照片（53)中被识别出来时，可以对照片（53) 进行排队，以用安全的方式通过因特网（11)传输到该对等分组成员。例如，第一用户 (13)可以将包含了作为第二用户（17)(其也是对等分组成员）的已知人的脸部的照片上传 到其计算机系统（15)。在这种情况下，当系统确定脸部匹配时，可以将照片（53)排队以 便传输。在传输之前，可以将照片（53)缩小至较小版本，并且可以将元数据包括到数字 照片文件中。在大小上的相应减小可以优化带宽的使用。</p>
    <p>[0109]	第二用户（17)下次访问其计算机系统（51)上的计算机程序时，他可以接收示出 了原始照片的缩小图像和相关联的元数据的确认请求。可以向第二用户（17)提示其是否 愿意将照片（55)拷贝到其计算机系统（51)上。如果第二用户（17)的回答是肯定的，那 么系统可以将完全图像连同照片（55)的元数据以及来自该照片的已知的脸部和签名、通 过因特网从第一用户的计算机系统（15)拷贝到第二用户的计算机系统（55)。</p>
    <p>[0110]	本发明的另一新方面使用现有的社交网络服务和基于web的照片存储站点来与 对等分组成员共享照片。本发明可以将单个照片或照片分组传输到基于目标web的服 务。所传输的照片可能已经包含了来自本发明的、关于出现在照片中的人的元数据。例 如，社交网络站点FACEBOOK&#8482;提供了用于上传照片、共享照片以及手动给照片加标签来指示哪些好友出现在照片中的工具。加标签过程是手动的并且十分耗时。本发明可以 使这种上传过程自动化，并且消除手动给照片加标签的需求，从而向社交网络用户提供 了显著的益处。可以将本发明等同地适用于其他社交网络服务和基于web的照片存储站 点。如上所述，用户还可以通过因特网、直接从并入了照相机的移动设备上传照片。</p>
    <p>[0111]	本发明的另一新方面在于：已知人的初始列表可以从该用户的社交网络账户加 载，从而进一步节省了配置本发明提供的系统所需的时间。</p>
    <p>[0112]	图8示出了可以支持照片浏览以及由计算机程序管理的脸部数据库的GUI的示 例实施方式。在此示例中，示出了具有可以出售给广告者的可选横幅广告（57)的用户接 口。用户可以从相册（125)中选择照片（123)，并且GUI可以显示与照片（123)中找到 的已知人（117)相对应的缩略图（121)。还可以使用复选框（119)来指示已知人（117)在 照片（123)中的存在。</p>
    <p>[0113]	图9中描绘的示例示出了已知人的脸部图像，以及用于应用如下布尔搜索的复 选框，诸如与已知人的名称或关于图像的元数据相关联的“与”、“或”和“非”选 择。本发明的新特征在于：通过允许用户点击已知人（59)的脸部的缩略图，以及将布尔 运算（61)应用于由复选框支持的每个脸部，以可视的方式选择照片的能力。GUI的这个 方面通过组合针对全体照片和脸部数据库应用的各种搜索标准和过滤器来支持相册的创 建。</p>
    <p>[0114]	计算机程序提供的搜索标准可以包括：</p>
    <p>[0115]	文件夹选择（65)，指示照片图像在计算机存储设备上的文件夹位置或文件名 称；</p>
    <p>[0116]	已知人（67)，提供了与已知人的脸部相关联的布尔运算（“与”、“或”或 “非”）的选择；</p>
    <p>[0117]	日期范围（69)，提供了与要被包括到特定相册中的照片图像相对应的日期范围 的选择；</p>
    <p>[0118]	EXIF数据，提供了基于标准照片相关信息的选择装置，该相关信息通常在照片 拍摄过程期间由照相机附加到该照片。</p>
    <p>[0119]	为相册选择照片的备选方法可以向用户提供使用GUI将单个照片或照片分组拖 放到相册（63)的名称上，或者以其他方式使照片与相册（63)相关联的能力。</p>
    <p>[0120]	相册（63)可以是保存为该相册名称下的逻辑实体的照片集合。用户可以 经由GUI指定其想将相册发送到的各种目标文件类型或位置（71)，包括：幻灯片， MICROSOFT&#8482; POWERPOINT&#8482;或者其他呈现计算机程序；ADOBE&#8482; PDF&#8482;或其他文档 文件；基于web的共享站点，诸如FLICKR&#8482;或FACEBOOK&#8482;或者第三方印刷服务。广 告方法</p>
    <p>[0121]	本发明其中又一方面提供了可以与这里提供的网络化计算机架构一起操作的新</p>
    <p>广告方法。</p>
    <p>[0122]	图10示出了由GUI提供的可选广告显示能力。这是本发明的新特征，其提供了 用于基于用户人口统计定位广告同时维护用户隐私的安全方法。GUI可以向新用户（13) 提示：人口统计信息最少可以包括性别、年龄和位置数据。可以将此信息本地存储在运 行计算机程序的计算机系统（15)上。可以将请求周期地发送到基于web的服务器（73)，以返回广告指针列表。请求可以包含针对用户的人口统计数据的加密传输。请求也可以 使用由注册服务器（77)发布的证书进行签名。后一步骤可以验证请求的可靠性。基于 web的服务器（73)可以引导用于基于请求用户（13)特定的人口统计信息、将与目标人口 统计信息相关联的广告匹配给请求用户（13)的过程。可以将指针列表（即，针对存在于 不同广告服务器上的广告的引用）返回给请求用户的计算机系统（15)，并且传递至计算 机程序。计算机程序继而可以将另一请求发布到不同的基于web的服务器（75)，以下载 由指针引用的广告。基于web的服务器（73)继而可以丢弃人口统计数据，以保护个体用 户的隐私。</p>
    <p>[0123]	通过将用于执行广告匹配过程的基于web的服务器（73、77)与实际递送广告 的服务器（75)分离，以及通过不把用户的个人人口统计数据存储在基于web的服务器 (73，77)上，能使个人信息与其他方式相比变得更加安全。广告递送服务器（75)可以存 储关于广告的信息以用于计费目的，但是该数据中不包括个人信息。这是使用人口统计 数据、以安全方式将广告提供给任何web浏览器或软件程序的新实现。</p>
    <p>[0124]	其他实现</p>
    <p>[0125]	本发明的另一能力可以允许计算机程序从中央注册服务器接收数字脸部图像或 签名。例如，试图寻找个体（诸如丢失的儿童或通缉的罪犯）的组织可以张贴个体的脸 部数据。已经选择共享其脸部数据库的那些用户可以下载支持将该脸部数据与他们的脸 部数据库进行自动比较的数据。如果在目标个体与特定用户已知人之间找到匹配，那么 可以向该组织发出警报。这可以使该组织能够确定该个体的最近或当前位置。还可以使 该组织能够确定个体的姓名，这是因为个体的名称可能列在用户已知的一个或多个人的 列表中。</p>
    <p>[0126]	本发明提供的又一实施方式允许个体找到与他们自身有相似面部特征的其他 人。这种应用例如对于寻找其双胞胎之一的人很有用。在这个实施方式中，用户可以提 交包括其脸部的图像的照片，本发明可以从中生成脸部签名。继而可以将该脸部签名与 先前已经上传的其他个体的脸部签名进行比较。基于预定的相似度阈值，可以将一个或 多个相似脸部报告给其脸部匹配的一个或所有个体。根据此实施方式的系统可以提供供 用户批准与其他人联系的装置。如果匹配的个体批准了这种联系，那么其可以选择彼此 之间发送消息。可以部署相似的实施方式，作为约会服务的一部分，以基于相貌来匹配 人。</p>
    <p>[0127]	脸部检测、眼部检测和脸部识别</p>
    <p>[0128]	本发明其中另一方面提供了用于基于图像中描绘的脸部来生成脸部签名的新方 法。脸部签名可以通过使用包括了脸部检测、眼部检测和脸部识别的步骤的技术来生 成。</p>
    <p>[0129]	脸部检测</p>
    <p>[0130]	本发明其中一个方面提供了用于将基于纹理的脸部检测算法用作脸部检测基本 方法的方法。基于纹理的脸部检测算法的一个示例是已知为OPENCV&#8482;的例程的开源库。</p>
    <p>[0131]	基于纹理的脸部检测算法针对特定面部姿势（例如扭转（rolled)的正面脸部）可 能具有低真阳（truepositive)比率。这可能是由于训练纹理模式的正面脸部图像有别于普通数字照片中找到的变化的面部姿势。事实上，在用于训练脸部检测算法的纹理模式与 在其上应用该算法的目标照片中的姿势类型之间存在不匹配会导致较高的错误率。脸部 检测正面临两个众所周知挑战，包括：降低在扭转的正面脸部的情况下的假阴错误，以 及在不提高假阴错误的同时降低假阳错误。</p>
    <p>[0132]	本发明通过应用包括用以提高脸部检测过程的准确度的三个步骤的新技术而增 强了基于纹理的脸部检测。在第一步骤中，提供已知肤色比率测试在基于纹理的脸部检 测器上的新颖应用，用于改进该检测器的精度。在第二步骤中，通过将经检测的脸部对 象区域的大小缩小至预定大小来提供用于减小假阳脸部对象的新方法。在第三步骤中， 提供了新的脸部定向补偿方法。</p>
    <p>[0133]	图11示出了根据本发明其中一方面的基于纹理的脸部检测方法。</p>
    <p>[0134]	在基于纹理的脸部检测方法的一个特定实现中，在第一步骤中，基于纹理的脸 部检测器（131)最初可以设置有高目标真阳比率，该高目标真阳比率具有相应的高假阳 比率。基于纹理的脸部检测器将整个照片图像作为输入来运行。这种运行的结果可以给 出照片中潜在脸部对象的列表。对于彩色照片，可以在潜在脸部对象上执行肤色检测测 试（133)以降低假阳比率。这种肤色测试可以比较包含肤色的脸部对象区域与对象的全 部区域的比率。如果该比率没有超过预定阈值，那么可以跳过（135)该潜在脸部对象。</p>
    <p>[0135]	在第二步骤中，可以将从第一步骤产生的经检测的脸部对象区域缩小至预定大 小（诸如，44X44像素）。在这些经缩小的区域上，可以再次运行（137)基于纹理的脸 部检测器。这个步骤的目的是减少假阳脸部对象。通过在小尺寸（诸如44X44像素） 输入区域上运行，可以减少来自非脸部的不正确纹理模式的假阳错误同时可以保留真阳 纹理模式。这可以使得脸部检测的假阳比率减少，同时保留了真阳比率。在第二步骤中 被认为是脸部的脸部对象可以作为真脸部被接受（143)。那些没有通过第二步骤的脸部对 象可以被传递到第三步骤。</p>
    <p>[0136]	在第三步骤，提供脸部定向补偿方法。在上述第二步骤中，脸部检测在该图像 的较小区域上执行，可以降低在扭转脸部情况下的真阳比率。扭转的脸部中的纹理模式 可能由于第二步骤中应用的大小缩小而被脸部检测器认为是非脸部。为了保留在扭转的 脸部情况下的真阳比率，脸部定向补偿（139)可以与脸部检测一起执行。在这种方法 中，将本地图像区域以递增的角度进行旋转，并且每个角度实例可以通过脸部检测器来 运行。一个示例实现可以将从距纵轴-20度开始将图像旋转2度，并且重复旋转直到距 纵轴+20度。如果经旋转的脸部区域被识别并且存在于具有连续递增角度的实例中，那 么可以将该本地图像区域确定（141)为真脸部。</p>
    <p>[0137]	对基于纹理的脸部检测算法的这些修改可以显著地降低假阳错误比率。</p>
    <p>[0138]	眼部检测</p>
    <p>[0139]	图12示出了根据本发明的一个方面用于眼部检测的方法。该眼部检测方法应用 了新技术来提高在经检测脸部区域中检测瞳孔位置的准确度。第一步骤可以是将整个脸 部区域缩小至可能包含真实瞳孔/眼部位置的较小区域（“眼部图”）（145)。可以使用 公式来从眼部区域中裁剪出眼部图区域。例如，用于裁剪眼部图区域的公式可以是左边 移除.23w、右边移除.23w、底部移除.55h和顶部移除.30h;其中w是脸部区域的宽度， h是脸部区域的高度。图14A示出了用于从脸部区域裁剪眼部图区域的方法的特定实施方式。</p>
    <p>[0140]	此外，如果在特定角度实例上于脸部检测方法的第三步骤中检测到脸部，那么 可以将角度旋转应用（147)到眼部图区域来支持眼部位置的更加精确的选择。</p>
    <p>[0141]	图14B示出了可以改变用于裁剪眼部图区域的公式，以确保眼部图区域足够 大，从而确保良好的瞳孔检测结果。</p>
    <p>[0142]	一旦眼部图区域进行了裁剪，眼部图区域的大小继而可以重新调整至固定大小 (诸如80X80像素），使得可以应用固定的模板色差方法来确定候选眼部位置。这种方 法可以是基于瞳孔较之于眼部图区域周围的区域的较深浓度。</p>
    <p>[0143]	可以将色彩浓度图像的中间设置成浓度图中的零/黑（151)，以移除通常由于眼 镜的镜片和镜框反光所产生的潜在瞳孔候选。图14C示出了这种过程。</p>
    <p>[0144]	色差图像可以从色彩浓度图像中获得，继而可以通过阈值过滤器，使得只有小 部分眼部区域是白色的（例如，可以应用2%的阈值）（153)。接下来，可以应用“最适 合”方法来选择具有最高色差（左侧和右侧）浓度的眼部位置。可以将该最佳候选瞳孔 位置坐标传递（155)到本发明的脸部识别方法。</p>
    <p>[0145]	脸部识别</p>
    <p>[0146]	图13示出了本发明一个方面的脸部识别方法。脸部识别通常可以通过预处理 (157)、投影（159)、距离计算（163)和聚集（167)来执行。脸部识别方法可以采用主元 分析（PCA)。PCA是已知的方法，因为其是从混乱的数据集中抽取相关信息的简单、非 参数化方法，因此大量地用于各种形式的分析。</p>
    <p>[0147]	鉴于个人照片会因大多数主体可能倾向于直接看照相机而可能具有姿势上的略 微改变，本发明可以通过新的方式来采用PCA，该方式克服了其与对主体照明和姿势高 度敏感有关的传统问题。本发明可以利用描绘特定人的照片集可能以各种姿势和照明条 件进行拍摄这样的事实。本发明提供了用于聚集目标未知脸部和与每个已知的人相关联 的此多个脸部之间的比较的方法。</p>
    <p>[0148]	可以首先将预处理（157)应用于图像。可以将作为输入提供给脸部识别阶段的 脸部区域和眼部坐标用于正则化脸部区域。正则化过程可以包括转译、旋转和缩放脸部 区域至预定模板大小。正则化过程可以使用眼部坐标作为参考点，使得可调节脸部区域 图像以将眼部坐标置于特定的图像像素上。继而可以将标准固定的蒙板（mask)处理应用 到图像以过滤掉非脸部部分，该标准固定的蒙板处理潜在地将脸部区域限制到椭圆内的 区域。可以使用单调化（flattening)处理来确保像素浓度在图像上是空间均&#21243;的，该单调 化处理涉及在脸部区域中的像素浓度上运行二维线性回归。最后，可以在灰度级域中执 行直方图图像均衡化（图像处理方法对于本领域技术人员是已知的，由此图像的对比度 可以利用图像的直方图进行调节）。</p>
    <p>[0149]	继而可以将投影（159)应用于图像。正则化脸部区域的结果像素可以通过基于 PCA的公式，以创建由本发明用作脸部签名的PCA向量。PCA向量可以包括由从大量 一般图像中抽取的主元产生的投影图像。</p>
    <p>[0150]	根据这种方法创建的脸部签名可以是给定维数的实数的数组（来自PCA向量）。 虽然向量空间的精确维数可以适应性确定，其最大值设置为捕获例如输入图像能量的 95%的值，但是使用的默认值可以为50-100范围内的维数。</p>
    <p>17[0151]	最后，可以应用循环（161)来将已知人与未知脸部进行匹配。可以将每个脸部 签名（表示为数组）利用线性或非线性分类逻辑与任何其他脸部签名进行算术地比较，以 确定距离值（163)。例如，可以通过计算正则化内积距离来比较两个签名。</p>
    <p>[0152]	为了将脸部同与已知人相关联的所有脸部进行比较，可能会进行所有个体的一 对一比较，继而可以将所有结果用于接下来的步骤，或者可以使用通过与某些阈值比较 确定为最佳匹配的集合。选择的阈值可以被这样选择，以使得平均可以保留在将脸部与 不匹配的人进行比较时所获得距离的一半。</p>
    <p>[0153]	可以将某些形式的聚集用于结合在先前步骤中获得的距离值的集合来确定脸部 与已知人之间的距离。这种聚集可以是距离值（169)的几何平均的计算。几何平均可以 是类似于算术平均的求平均技术，但是几何平均可以通过将要平均的N个数相乘继而将 乘积的Nth方根作为期望的平均而计算。在脸部与每个已知人之间的最接近匹配可以通 过计算在该脸部与数据库中每个已知人之间的这种聚集距离（167)并且选择最小距离来 找到。</p>
    <p>[0154]	最后，可以将最接近的匹配距离与静态或动态确定的阈值相比较（171)，以降低 假阳匹配的比率。如果使用动态选择的阈值，那么此阈值可以这样确定：首先，假设在 将脸部与具有N个相关联的脸部的不匹配的人相比较时获得的聚集距离值是正态分布的 (对于N的每个可能值），继而使用逆累积正态分布函数来计算确保在平均上、未知脸部 的固定最大数目或固定比率错误地匹配到已知人的阈值。随着与每个人相关联的脸部数 目N的改变，此阈值因人而异。这种动态阈值计算的优势包括：可以将固定的最大数量 (或比率）保持尽可能小，以在为用户保留可接受的真阳匹配级时限制假阳匹配。</p>
    <p>[0155]	随着链接到本地脸部数据库中已知人的脸部签名数量的增长，可以提高本发明 在要处理的未来照片中自动检测已知人的准确性。这是本发明新的特征。</p>
    <p>[0156]	本发明可以通过确定针对来自已知人的分组中的先前标识的脸部的最接近匹配 来认识脸部。本发明的优势是：随着链接到本地脸部数据库中已知人的脸部签名数量的 增长，可以提高本发明在要处理的未来照片中自动检测认识的人的准确性。</p>
    <p>[0157]	视频扫描</p>
    <p>[0158]	图20示出了视频扫描方法，由此对视频中的帧进行抽取，并且在这些帧上执行 脸部检测。可以设置数量N(其中N是可调的），使得可以针对视频中作为个体照片图像 (183)的每N个帧（181)来扫描视频，其中可以应用先前提到的技术（185)来检测和识别 脸部和已知人。视频继而可以根据这里提供的技术进行传播。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102281140A?cl=zh">CN102281140A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2011年12月14日</td><td class="patent-data-table-td ">上海合合信息科技发展有限公司</td><td class="patent-data-table-td ">指定信息获取方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102281140B?cl=zh">CN102281140B</a></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2014年4月16日</td><td class="patent-data-table-td ">上海合合信息科技发展有限公司</td><td class="patent-data-table-td ">指定信息获取方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103365869A?cl=zh">CN103365869A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月29日</td><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">宏&#30849;股份有限公司</td><td class="patent-data-table-td ">照片管理方法与电子装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103491067A?cl=zh">CN103491067A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月29日</td><td class="patent-data-table-td patent-date-value">2014年1月1日</td><td class="patent-data-table-td ">广达电脑股份有限公司</td><td class="patent-data-table-td ">多媒体互动系统及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04W0004000000">H04W4/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009800000">G06K9/80</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0012160000">H04L12/16</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009680000">G06K9/68</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009360000">G06K9/36</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/4652">G06K9/4652</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30876">G06F17/30876</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q50/01">G06Q50/01</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30244">G06F17/30244</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00281">G06K9/00281</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30247">G06F17/30247</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00248">G06K9/00248</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/42">G06K9/42</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/02">G06Q30/02</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0269">G06Q30/0269</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00677">G06K9/00677</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F15/16">G06F15/16</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2FJyBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00288">G06K9/00288</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06F17/30M1</span>, <span class="nested-value">G06K9/42</span>, <span class="nested-value">G06K9/00F1L</span>, <span class="nested-value">G06K9/00F2L</span>, <span class="nested-value">G06Q30/02</span>, <span class="nested-value">G06Q30/0269</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年4月13日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年6月1日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年5月27日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/6228cc11be50803e1746/CN102016882A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%88%A9%E7%94%A8%E8%84%B8%E9%83%A8%E7%AD%BE%E5%90%8D%E6%9D%A5%E6%A0%87%E8%AF%86%E5%92%8C%E5%85%B1%E4%BA%AB%E6%95%B0.pdf?id=2FJyBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0Ud8NKZEn34fCPKB8NAPVJJ8gsBA"},"sample_url":"https://www.google.com/patents/reader?id=2FJyBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>