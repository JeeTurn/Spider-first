<!DOCTYPE html><html><head><title>专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="即时通讯工具中用户状态的设置方法及装置"><meta name="DC.contributor" content="党志立" scheme="inventor"><meta name="DC.contributor" content="北京百纳威尔科技有限公司" scheme="assignee"><meta name="DC.date" content="2013-7-10" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供一种即时通讯工具中用户状态的设置方法和装置，该方法包括：生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。本发明为即时通讯工具提供了一种新的用户状态设置方式，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。"><meta name="DC.date" content="2014-1-22"><meta name="DC.relation" content="CN:102710552:A" scheme="references"><meta name="DC.relation" content="CN:102790732:A" scheme="references"><meta name="DC.relation" content="CN:1620045:A" scheme="references"><meta name="DC.relation" content="WO:2003058478:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103532826:A"><meta name="citation_patent_application_number" content="CN:201310289126"><link rel="canonical" href="https://www.google.com/patents/CN103532826A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103532826A?cl=zh"/><meta name="title" content="专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置"/><meta name="description" content="本发明提供一种即时通讯工具中用户状态的设置方法和装置，该方法包括：生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。本发明为即时通讯工具提供了一种新的用户状态设置方式，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。"/><meta property="og:title" content="专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103532826A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103532826A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=R0TuCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103532826A&amp;usg=AFQjCNGO47Qq1txG1p3IXxbe36l5kSFuXA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/dc55f9b9ada65bd175d7/CN103532826A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/dc55f9b9ada65bd175d7/CN103532826A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103532826A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103532826A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103532826A?cl=zh" style="display:none"><span itemprop="description">本发明提供一种即时通讯工具中用户状态的设置方法和装置，该方法包括：生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应...</span><span itemprop="url">https://www.google.com/patents/CN103532826A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置" title="专利 CN103532826A - 即时通讯工具中用户状态的设置方法及装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103532826 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201310289126</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2014年1月22日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2013年7月10日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2013年7月10日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201310289126.0, </span><span class="patent-bibdata-value">CN 103532826 A, </span><span class="patent-bibdata-value">CN 103532826A, </span><span class="patent-bibdata-value">CN 201310289126, </span><span class="patent-bibdata-value">CN-A-103532826, </span><span class="patent-bibdata-value">CN103532826 A, </span><span class="patent-bibdata-value">CN103532826A, </span><span class="patent-bibdata-value">CN201310289126, </span><span class="patent-bibdata-value">CN201310289126.0</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%85%9A%E5%BF%97%E7%AB%8B%22">党志立</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E7%99%BE%E7%BA%B3%E5%A8%81%E5%B0%94%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京百纳威尔科技有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103532826A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103532826A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103532826A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=R0TuCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201310289126&amp;usg=AFQjCNG4AkTP_Gtm0q7rGp7J-eCyyAHrPg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=R0TuCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103532826A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNF_fzQg9krXayPXdFfzcAT08XMYMg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT132973054" lang="ZH" load-source="patent-office">即时通讯工具中用户状态的设置方法及装置</invention-title>
      </span><br><span class="patent-number">CN 103532826 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA129469099" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供一种即时通讯工具中用户状态的设置方法和装置，该方法包括：生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。本发明为即时通讯工具提供了一种新的用户状态设置方式，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(9)</span></span></div><div class="patent-text"><div mxw-id="PCLM58587474" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种即时通讯工具中用户状态的设置方法，其特征在于，包括:  生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；  根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；  根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，所述生成表情信息包括:  通过图像采集技术获取所述用户的面部图像；  根据所述面部图像通过图像识别处理技术获取所述用户的表情信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其特征在于，所述面部图像通过摄像头拍摄或扫描的方式获取。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1或2或3所述的方法，其特征在于，实时地或周期性地生成所述表情信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的方法，其特征在于，所述根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态包括:  判断使用所述即时通讯工具的所述用户当前的状态信息与所述获取的状态信息是否一致；  如果当前的状态信息与所述获取的状态信息不一致，则将使用所述即时通讯工具的所述用户的状态设置为所述获取的状态信息所反映的状态。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6.一种即时通讯工具中用户状态的设置装置，其特征在于，包括:  生成模块，用于生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；  获取模块，用于根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；  设置模块，用于根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的装置，其特征在于，所述生成模块包括:  图像采集单元，用于通过图像采集技术获取所述用户的面部图像；  图像识别单元，用于根据所述面部图像通过图像识别处理技术生成所述用户的表情信肩、O</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求6或7所述的装置，其特征在于，所述生成模块实时地或周期性地生成所述表情信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的装置，其特征在于，所述设置模块包括:  判断单元，用于判断使用所述即时通讯工具的所述用户当前的状态信息与所述获取的状态信息是否一致；  设置单元，用于在当前的状态信息与所述获取的状态信息不一致时，将使用所述即时通讯工具的所述用户的状态设置为所述获取的状态信息所反映的状态。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES64975036" lang="ZH" load-source="patent-office" class="description">
    <p>即时通讯工具中用户状态的设置方法及装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及即时通讯技术，尤其涉及一种即时通讯工具中用户状态的设置方法及</p>
    <p>&gt;J-U装直。</p>
    <p>背景技术</p>
    <p>[0002]	即时通讯工具是通过即时通讯技术实现在线聊天、交流的软件工具，例如，目前流行的腾讯QQ、微博和微信等。即时通讯是一种终端服务，可安装在各类终端机上，特别是现在广泛发展的各类移动终端设备(例如，手机、笔记本电脑、平板电脑等)上一般都可以安装即时通讯工具。</p>
    <p>[0003]	即时通讯工具中，一般可以设置不同的用户状态，例如，在线、隐身、忙碌、离线等。现有技术中，只能由用户手动设置即时通讯工具中的用户状态。但用户在不同情绪下可能希望处于不同的用户状态，而单一的手动设置方式无法及时将用户的情绪反映到即时通讯工具的用户状态上，从而无法满足用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>发明内容</p>
    <p>[0004]	本发明提供一种即时通讯工具中用户状态的设置方法及装置，为即时通讯工具提供了一种新的用户状态设置方式，以满足用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0005]	本发明提供一种即时通讯工具中用户状态的设置方法，包括:</p>
    <p>[0006]	生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；</p>
    <p>[0007]	根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；</p>
    <p>[0008]	根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</p>
    <p>[0009]	本发明还提供一种即时通讯工具中用户状态的设置装置，包括:</p>
    <p>[0010]	生成模块，用于生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；</p>
    <p>[0011]	获取模块，用于根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；</p>
    <p>[0012]	设置模块，用于根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</p>
    <p>[0013]	通过本发明提供的即时通讯工具中用户状态的设置方法和装置，在即时通讯工具的使用过程中，可以自动生成反映用户表情的表情信息，并根据该表情信息来自动设置即时通讯工具中的用户状态。因此，本发明为即时通讯工具提供了一种新的用户状态设置方式，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>附图说明</p>
    <p>[0014]	图1是本发明即时通讯工具中用户状态的设置方法的第一实施例的流程图；</p>
    <p>[0015]	图2是本发明实施例中生成表情信息的流程图；</p>
    <p>[0016]	图3是设置表情信息与面部特征信息以及表情信息与状态信息的对应关系的流程图；</p>
    <p>[0017]	图4是本发明即时通讯工具中用户状态的设置方法的第二实施例的流程图；</p>
    <p>[0018]	图5是本发明即时通讯工具中用户状态的设置装置的第一实施例的组成示意图；</p>
    <p>[0019]	图6是本发明实施例中生成模块的组成示意图；</p>
    <p>[0020]	图7是本发明即时通讯工具中用户状态的设置装置的第二实施例的组成示意图。具体实施方式</p>
    <p>[0021]	为使本发明实施例的目的、技术方案和优点更加清楚，下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。</p>
    <p>[0022]	本发明中，即时通讯工具指的是通过即时通讯技术实现在线聊天、交流的软件工具，例如，目前流行的腾讯QQ、微博和微信等。即时通讯工具可安装在各类终端机上，特别是现在广泛发展的各类移动终端设备(例如，手机、笔记本电脑、平板电脑等)上一般都可以安装即时通讯工具，因此，本发明提供的即时通讯工具中用户状态的设置方法和装置可以适用于安装在各类终端机上的即时通讯工具。</p>
    <p>[0023]	下面，将参照图1详细说明本发明的即时通讯工具中用户状态的设置方法的第一实施例，其包括以下步骤:</p>
    <p>[0024]	步骤1:生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情。</p>
    <p>[0025]	具体地，在用户使用即时通讯工具时，可以自动地生成反映出该用户表情的表情信息。</p>
    <p>[0026]	下文中将参照图2详细说明如何生成表情信息。</p>
    <p>[0027]	步骤2:根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态。</p>
    <p>[0028]	具体地，用户在不同情绪下，希望即时通讯工具中的用户状态不同。即时通讯工具中可以将用户状态设置成在线、隐身、忙碌、离线等各种不同情况，用相应的状态信息来反映这些用户状态。即时通讯工具可允许用户根据自身需要，预先设置用户在不同情绪下所对应的各种状态，由于用户的情绪可通过表情体现出来，因此也即预先设置反映用户表情的表情信息与反映用户状态的状态信息之间的对应关系，并将其进行存储。下文中将参照图3详细说明如何设置表情信息与状态信息的对应关系。</p>
    <p>[0029]	在步骤I中生成了表情信息后，根据已经预先设置并存储了的表情信息与状态信息的对应关系，可查询得到与步骤I中所生成的表情信息所对应的状态信息，该状态信息即为用户希望即时通讯工具中所设置的用户当前所处状态。通过预设的对应关系来获取与所述表情信息对应的状态信息的方法，对于本领域的技术人员来说是公知的，本文中不再赘述。</p>
    <p>[0030]	步骤3:根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</p>
    <p>[0031]	具体地，在步骤2中得到使用即时通讯工具的用户当前应所处的状态后，启动即时通讯工具的用户状态设置功能，将即时通讯工具中的当前用户状态设置为所述状态信息所表示的状态。</p>
    <p>[0032]	采用上述方法，在即时通讯工具的使用过程中，可以自动生成反映用户表情的表情信息，并根据该表情信息来自动设置即时通讯工具中的用户状态。因此，本发明的即时通讯工具中用户状态的设置方法为即时通讯工具提供了一种新的用户状态设置方式，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0033]	接下来，将详细说明如何生成表情信息。参照图2，作为优选实施例，其可以包括以下步骤:</p>
    <p>[0034]	步骤101:通过图像采集技术获取所述用户的面部图像。</p>
    <p>[0035]	在用户使用即时通讯工具时，可以启动面部图像采集功能，用来采集正在使用该即时通讯工具的用户的当前面部图像。例如，可以通过摄像头采集用户的面部图像，具体的可以为用户的面部彩色图像、灰度图像、二值图像等，具体的图像类型可以根据实际处理需求进行适应性调整，摄像头可以是固设在终端上的摄像头，也可以通过连接线与终端连接。可供选择地，还可以通过扫描的方式采集用户的面部图像。</p>
    <p>[0036]	步骤102:根据所述面部图像通过图像识别处理技术获取所述用户的表情信息。</p>
    <p>[0037]	优选地，可以通过计算机图像识别技术，从采集到的用户面部图像中识别提取人像特征点，例如眼睛、嘴巴、脸型等，从而得到对应所述面部图像的面部特征信息。</p>
    <p>[0038]	在本发明中，面部特征信息可以为用户面部中眼睛的位置信息、眼睛的形状信息、嘴巴的位置信息、嘴巴的形状信息、脸庞的位置信息、脸庞的形状信息中的一个，也可以是上述各信息的任意组合。本发明并不对此加以限制。在即时通讯工具的使用过程中，自动获取用上述任一种信息或其组合所表示的用户当前的面部特征信息。</p>
    <p>[0039]	在获取到用户的面部特征信息后，根据已经预先设置好的面部特征信息与表情信息的对应关系，可以查询得到与获取到的面部特征信息对应的表情信息。</p>
    <p>[0040]	例如，利用生物统计学原理预先建立一数学模板，即人脸情绪特征模板。根据预先建成的人脸情绪特征模板与获取到的面部特征信息进行特征分析，根据分析结果给出一个相似值。通过预先设置的面部特征信息与表情信息的对应关系，就可以确定上述相似值是否对应某一表情,也即得到与所述面部特征信息对应的表情信息。</p>
    <p>[0041]	上述预先设置的面部特征信息与表情信息的对应关系可以是系统自带的，也可以是由用户自行设置的。另外，如果某次得到的面部特征信息在对应关系中没有对应的表情信息，优选地，可以引导用户自行设置该面部特征信息所对应的表情信息，生成新的对应关系。[0042]	例如，用户在使用即时通讯工具时触发了摄像头的采集功能，摄像头采集到用户开心的面部图像，利用计算机图像识别技术从采集到的图像中提取得到面部特征信息，利用预设的面部特征信息与表情信息的对应关系，确定现在用户的表情为开心，因此将“开心”作为所述表情信息。</p>
    <p>[0043]	后面将参照图3详细说明如何设置面部特征信息与表情信息的对应关系。</p>
    <p>[0044]	除了通过采集用户面部图像的方式来得到表情信息，可供选择地，也可以通过采集音频数据信息的方式来得到表情信息，还可以通过预先设置表情选项，通过接收对表情选项的触发的方式来得到表情信息。总之，本领域的普通技术人员应熟知的是，用户表情信息的获取并不局限于上述几种方式，上述各种方式的等效替代方式以及其他的替代方式都可以实现本发明。</p>
    <p>[0045]	接下来，将详细说明如何设置表情信息与状态信息的对应关系以及如何设置面部特征信息与表情信息的对应关系。参照图3，作为优选实施例，其可以包括以下步骤:</p>
    <p>[0046]	步骤301:定义表情信息。</p>
    <p>[0047]	可以在第一次使用即时通讯工具之前引导用户设置有关的对应关系，也可以在即时通讯工具的使用过程中，随时设置或更改有关的对应关系。</p>
    <p>[0048]	在设置对应关系时，可以首先引导用户自己定义表情信息，也可以引导用户在已经设置的表情选项中选择感兴趣的或实际使用中可能需要的表情信息，比如开心、伤心、兴奋等，为每一种表情信息分配一个唯一的标识。</p>
    <p>[0049]	步骤302:获取与所述表情信息对应的面部特征信息，生成表情信息与面部特征信息的对应关系。</p>
    <p>[0050]	设置表情信息与面部特征信息的对应关系，是为了在实际使用过程中，在得到用户的当前面部特征信息后，可以相应地确定出与其对应的表情信息。而用户的面部表情可能多种多样，不同用户可能的面部表情与实际情绪之间也会有很大差异，因此用户的表情信息定义和面部特征识别有很多的复杂性和差异性。</p>
    <p>[0051]	面部图像采集和计算机图像识别技术在本领域均是公知的，本发明优选地采用如上面的步骤101和步骤102中的方法来获取用户面部特征信息，允许用户自己定义表情信息和通过采集面部图像而获取到的面部特征信息之间的对应关系，以此来提高个性表情的识别率。可供选择地，本发明也可以省去采集面部图像的步骤，直接允许用户自己定义表情信息和面部特征信息之间的对应关系。</p>
    <p>[0052]	步骤303:获取与所述表情信息对应的状态信息，生成表情信息与状态信息的对应关系。</p>
    <p>[0053]	设置表情信息与状态信息的对应关系，是为了在实际使用过程中，在生成了表情信息后，可以相应地确定出与其对应的状态信息。</p>
    <p>[0054]	同样，本发明也允许用户自己定义表情信息和状态信息之间的对应关系，以此来提高即时通讯工具的个性化设置。例如，表情信息为“开心”时，状态信息可以为“在线”，表情信息为“伤心”时，状态信息可以为“隐身”。</p>
    <p>[0055]	通过上述各步骤，在即时通讯工具中预先设置好了用户的表情信息与面部特征信息的对应关系，以及表情信息与状态信息的对应关系。用户在使用即时通讯工具时，能够根据获取到的用户面部特征信息，利用上述各对应关系，得到用户希望即时通讯工具中所设置的用户状态。由于可以根据用户的表情来自动设置即时通讯工具中的用户状态，因而满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0056]	如上面已经论述过的，由于除了通过获取用户面部图像的方式来得到表情信息，还可以通过采集音频数据信息的方式来得到表情信息，或者还可以通过预先设置表情选项，通过接收对表情选项的触发的方式来得到表情信息，因此，相应地，就需要预先设置好音频数据信息与表情信息的对应关系，或者不同表情选项与表情信息的对应关系等，具体的设置方式与上面的类似，此处就不再一一赘述。</p>
    <p>[0057]	此外，如上所述，在预先设置好表情信息与面部特征信息以及表情信息与状态信息的对应关系后，通过上面已经详细论述过的即时通讯工具中用户状态的设置方法，就可以最终得到使用即时通讯工具的用户的状态信息。</p>
    <p>[0058]	另外，上面已经提及，在生成表情信息的过程中，如果某次得到的面部特征信息在对应关系中没有对应的表情信息，优选地，可以引导用户自行设置该面部特征信息所对应的表情信息，生成新的对应关系。同理，由于没有对应的表情信息，也就不存在对应的状态信息，因此，在引导用户自行设置了该面部特征信息所对应的表情信息的基础上，还可以进一步引导用户自行设置该表情信息所对应的状态信息，以生成新的表情信息与状态信息的对应关系。</p>
    <p>[0059]	上面已经参照图1详细说明了本发明的即时通讯工具中用户状态的设置方法。在实际应用中，用户在使用即时通讯工具时，其表情会随着情绪等因素而随时发生变化。本发明提供的即时通讯工具中用户状态的设置方法可以及时地获取到用户表情的变化，根据用户的当前表情随时切换即时通讯工具中的用户状态。基于此，参照图4，作为第二实施例，本发明的即时通讯工具中用户状态的设置方法包括以下步骤:</p>
    <p>[0060]	步骤1001:实时地或周期性地生成表情信息。</p>
    <p>[0061]	具体地，在用户使用即时通讯工具的过程中，可以实时地生成表情信息，也可以设置一预定时间间隔，以此时间间隔周期性地生成表情信息，该时间间隔可以根据实际需要任意设置。</p>
    <p>[0062]	生成表情信息的方法与第一实施例相同，此处不再赘述。</p>
    <p>[0063]	步骤2000:根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息。</p>
    <p>[0064]	此步骤与第一实施例中的步骤2相同，此处不再赘述。</p>
    <p>[0065]	步骤3001:判断使用所述即时通讯工具的所述用户当前的状态信息与所述获取的状态信息是否一致。</p>
    <p>[0066]	步骤3002:如果当前的状态信息与所述获取的状态信息不一致，则将使用所述即时通讯工具的所述用户的状态设置为所述获取的状态信息所反映的状态。</p>
    <p>[0067]	用户的表情在一定时间段内可能会发生变化，也可能不会发生变化。因此，在实时地或周期性地生成表情信息时，前一次生成的表情信息可能与后一次生成的表情信息不一致，也即前一次得到的状态信息与后一次得到的状态信息不一致，此时就可以利用上述步骤3001和步骤3002，将即时通讯工具中当前的用户状态切换为后一次得到的状态信息所表不的状态。另外，也会出现前一次生成的表情信息与后一次生成的表情信息相同，甚至几次生成的表情信息都是相同的这种情况，此时就不需要重新设置即时通讯工具中的用户状态，仍保持其原状态即可。</p>
    <p>[0068]	采用上述各步骤，可以实现实时监测用户的面部表情，及时发现用户表情的变化，并可以根据得到的状态信息是否发生了变化，而相应地判断是否重新设置即时通讯工具中的用户状态，因此可以及时地自动调整即时通讯工具中的用户状态，进一步满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0069]	下面例举一个具体实施例，以便于理解上述发明。</p>
    <p>[0070]	例如，用户启动了即时通讯工具的设置功能，通过移动终端固设的摄像头拍摄了自己两个照片，分别定义为开心、伤心两个表情信息。利用计算机图像识别技术提取两张照片中的面部特征信息，比如眼睛的轮廓信息、嘴巴的轮廓信息、脸庞的轮廓信息等，设置好面部特征信息和表情信息的对应关系。</p>
    <p>[0071]	用户设置开心表情时即时通讯工具中的用户状态为在线，伤心表情时即时通讯工具中的用户状态为隐身。</p>
    <p>[0072]	当用户使用即时通讯工具时，通过固设的摄像头实时获取用户面部特征，与用户定义的两个表情信息相匹配，即可判定用户为哪个表情。如果用户是开心表情，自动设置即时通讯工具中的用户状态为在线；伤心表情时，自动设置即时通讯工具中的用户状态为隐身。因此，通过表情信息的变化即可自动改变即时通讯工具中的用户状态。</p>
    <p>[0073]	本领域普通技术人员可以理解:实现上述各方法实施例的全部或部分步骤可以通过程序指令相关的硬件来完成。前述的程序可以存储于一计算机可读取存储介质中。该程序在执行时，执行包括上述各方法实施例的步骤；而前述的存储介质包括:R0M、RAM、磁碟或者光盘等各种可以存储程序代码的介质。</p>
    <p>[0074]	图5为本发明即时通讯工具中用户状态的设置装置第一实施例的组成示意图。如图5所示，其包括生成模块10、获取模块20和设置模块30。</p>
    <p>[0075]	具体地，生成模块10用于生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；获取模块20用于根据存储的表情信息与状态信息之间的对应关系，获取所述表情信息所对应的状态信息，其中，所述状态信息用于反映使用所述即时通讯工具的所述用户的状态；设置模块30用于根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态。</p>
    <p>[0076]	另外，为了生成反映用户表情的表情信息，如图6所示，该装置中的生成模块10包括图像采集单元40，用于通过图像采集技术获取所述用户的面部图像；以及图像识别单元50，用于根据所述面部图像通过图像识别处理技术获取所述用户的表情信息。</p>
    <p>[0077]	上述即时通讯工具中用户状态的设置装置的功能和操作流程，可以参见前面的方法实施例，此处不再赘述。</p>
    <p>[0078]	采用上述装置，在即时通讯工具的使用过程中，可以自动生成反映用户表情的表情信息，并根据该表情信息来自动设置即时通讯工具中的用户状态。因此，本发明的即时通讯工具中用户状态的设置装置为即时通讯工具提供了一种新的用户状态设置装置，不需要用户手动设置，仅根据用户的表情就可以自动设置即时通讯工具中的用户状态，因而能够及时地将用户的情绪反映到用户状态中，满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0079]	图7为本发明即时通讯工具中用户状态的设置装置的第二实施例的组成示意图。如图7所示，其包括生成模块11、获取模块21和设置模块31，其中，设置模块31包括判断单元60和设置单元70。</p>
    <p>[0080]	具体地，生成模块11用于实时地或周期性地生成表情信息，所述表情信息用于反映使用所述即时通讯工具的用户的表情；获取模块21与第一实施例中的获取模块20相同；设置模块31用于根据获取的所述状态信息设置使用所述即时通讯工具的所述用户的当前状态，其中，判断单元60用于判断使用所述即时通讯工具的所述用户当前的状态信息与所述获取的状态信息是否一致，设置单元70用于在当前的状态信息与所述获取的状态信息不一致时，将使用所述即时通讯工具的所述用户的状态设置为所述获取的状态信息所反映的状态。</p>
    <p>[0081]	同样，该装置的功能和操作流程也可以参见前面的方法实施例，此处不再赘述。</p>
    <p>[0082]	采用上述装置，可以实现实时监测用户的面部表情，及时发现用户表情的变化，并可以根据得到的状态信息是否发生了变化，而相应地判断是否重新设置即时通讯工具中的用户状态，因此，可以及时地自动调整即时通讯工具中的用户状态，进一步满足了用户对即时通讯工具中用户状态设置的多样性需求。</p>
    <p>[0083]	最后应说明的是:以上各实施例仅用以说明本发明的技术方案，而非对其限制；尽管参照前述各实施例对本发明进行了详细的说明，本领域的普通技术人员应当理解:其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本发明各实施例技术方案的范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1620045A?cl=zh">CN1620045A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年8月17日</td><td class="patent-data-table-td patent-date-value">2005年5月25日</td><td class="patent-data-table-td ">罗技欧洲公司</td><td class="patent-data-table-td ">即时消息状况和身份管理</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102710552A?cl=zh">CN102710552A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月14日</td><td class="patent-data-table-td patent-date-value">2012年10月3日</td><td class="patent-data-table-td ">宇龙计算机通信科技(深圳)有限公司</td><td class="patent-data-table-td ">基于即时通信的用户状态显示方法和即时通信服务器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102790732A?cl=zh">CN102790732A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td ">上海量明科技发展有限公司</td><td class="patent-data-table-td ">即时通信中状态匹配的方法、客户端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2003058478A1?cl=zh">WO2003058478A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2002年12月17日</td><td class="patent-data-table-td patent-date-value">2003年7月17日</td><td class="patent-data-table-td ">Bellsouth Intellectual Property Corporation</td><td class="patent-data-table-td ">Remote presence recognition information delivery systems and methods</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=R0TuCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0012580000">H04L12/58</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=R0TuCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009600000">G06K9/60</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2014年1月22日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年2月26日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/dc55f9b9ada65bd175d7/CN103532826A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF%E5%B7%A5%E5%85%B7%E4%B8%AD%E7%94%A8%E6%88%B7%E7%8A%B6%E6%80%81%E7%9A%84%E8%AE%BE.pdf?id=R0TuCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1W7QZ5Qzy8BApX59D13cnGWPtkIA"},"sample_url":"https://www.google.com/patents/reader?id=R0TuCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>