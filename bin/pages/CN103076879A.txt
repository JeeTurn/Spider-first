<!DOCTYPE html><html><head><title>专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于人脸信息的多媒体交互方法及装置及终端"><meta name="DC.contributor" content="金骏" scheme="inventor"><meta name="DC.contributor" content="孙奥" scheme="inventor"><meta name="DC.contributor" content="中兴通讯股份有限公司" scheme="assignee"><meta name="DC.date" content="2012-12-28" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于生物特征信息的多媒体交互方法及装置及终端，其中方法包括：在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；本发明相比之前的交互方式，该方式简单、有效，界面友好，效率较高，大大提升了系统的友好性。"><meta name="DC.date" content="2013-5-1"><meta name="DC.relation" content="CN:101021899:A" scheme="references"><meta name="DC.relation" content="CN:101576810:A" scheme="references"><meta name="DC.relation" content="CN:101741973:A" scheme="references"><meta name="DC.relation" content="CN:102521619:A" scheme="references"><meta name="DC.relation" content="CN:102523213:A" scheme="references"><meta name="DC.relation" content="CN:1798189:A" scheme="references"><meta name="DC.relation" content="US:20110316666:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103076879:A"><meta name="citation_patent_application_number" content="CN:201210583452"><link rel="canonical" href="https://www.google.com/patents/CN103076879A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103076879A?cl=zh"/><meta name="title" content="专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端"/><meta name="description" content="本发明公开了一种基于生物特征信息的多媒体交互方法及装置及终端，其中方法包括：在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；本发明相比之前的交互方式，该方式简单、有效，界面友好，效率较高，大大提升了系统的友好性。"/><meta property="og:title" content="专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103076879A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103076879A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103076879A&amp;usg=AFQjCNHA-SAK4LT4GkOBSTpQcXUgwJsLpg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/b407dfd629ef452b993b/CN103076879A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/b407dfd629ef452b993b/CN103076879A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103076879A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103076879A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103076879A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于生物特征信息的多媒体交互方法及装置及终端，其中方法包括：在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；在当前多媒体资料中提取生物特征信息，并将提取到的生物特...</span><span itemprop="url">https://www.google.com/patents/CN103076879A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端" title="专利 CN103076879A - 基于人脸信息的多媒体交互方法及装置及终端"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103076879 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210583452</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年5月1日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年12月28日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年12月28日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/WO2013189317A1?hl=zh-CN&amp;cl=zh">WO2013189317A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210583452.8, </span><span class="patent-bibdata-value">CN 103076879 A, </span><span class="patent-bibdata-value">CN 103076879A, </span><span class="patent-bibdata-value">CN 201210583452, </span><span class="patent-bibdata-value">CN-A-103076879, </span><span class="patent-bibdata-value">CN103076879 A, </span><span class="patent-bibdata-value">CN103076879A, </span><span class="patent-bibdata-value">CN201210583452, </span><span class="patent-bibdata-value">CN201210583452.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%87%91%E9%AA%8F%22">金骏</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%99%E5%A5%A5%22">孙奥</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%85%B4%E9%80%9A%E8%AE%AF%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">中兴通讯股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103076879A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103076879A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103076879A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (7),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210583452&amp;usg=AFQjCNGJfngVZCRkjYFoxNiaAMeS12RIWQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103076879A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEHEkztCQSDkIfpHNx1QM-2-rfXQg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT124061315" lang="ZH" load-source="patent-office">基于人脸信息的多媒体交互方法及装置及终端</invention-title>
      </span><br><span class="patent-number">CN 103076879 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA111026520" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于生物特征信息的多媒体交互方法及装置及终端，其中方法包括：在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；本发明相比之前的交互方式，该方式简单、有效，界面友好，效率较高，大大提升了系统的友好性。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM52804517" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于生物特征信息的多媒体交互方法，其特征在于，包括:  在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；  在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，如果匹配失败，则根据该生物特征信息到本终端用户相关的网络社交媒体做进一步匹配或者直接请求终端进行存储处理。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2 所述的方法，其特征在于，在经过授权后访问与本终端用户相关的网络社交媒体，将提取到的生物特征信息与该网络社交媒体中存储的联系人的生物特征信息做进一步匹配，如果确定进一步匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；如果进一步匹配失败，则请求终端进行编辑存储处理。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求2或3所述的方法，其特征在于，所述请求终端进行编辑存储处理的步骤具体包括:  请求终端存储该生物特征信息和对应的已知的联系信息，并将该生物特征信息与已知的联系信息进行关联；如果当前不知道该生物特征信息对应的联系信息，则仅存储该生物特征信息作为储备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的方法，其特征在于，当匹配成功并调用与该生物特征信息对应的联系人的联系信息时，根据需要对该联系信息进行修改。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的方法，其特征在于，所述当前多媒体资料为终端中已有的多媒体资料，或者为终端实时拍摄的多媒体资料。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1、2、3或5所述的方法，其特征在于，所述生物特征信息为人脸信息。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.一种基于生物特征信息的多媒体交互装置，其特征在于，包括:  关联存储模块，用于在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储；  匹配交互模块，用在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的装置，其特征在于，所述匹配交互模块还用于，如果匹配失败，则对该生物特征信息到与本终端用户相关的网络社交媒体中做进一步匹配或者请求所述关联存储模块进行编辑存储处理。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.一种终端，其特征在于，至少包括权利要求8或9所述的基于生物特征信息的多媒体交互装置。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES59860677" lang="ZH" load-source="patent-office" class="description">
    <p>基于人脸信息的多媒体交互方法及装置及终端</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及通信技术领域，尤其涉及一种基于人脸信息的多媒体交互方法及装置及终端。</p>
    <p>背景技术</p>
    <p>[0002]	Human-ComputerInteraction Techniques (人机交互技术）是指通过计算机输入、输出设备，以有效的方式实现人与计算机对话的技术。</p>
    <p>[0003]	人机交互技术是随着计算机的出现应运而生的，从最初的手工作业阶段，到现在以虚拟现实技术为代表的人机交互技术，人机交互技术已经经历了很多阶段。人机交互的发展历史表明其由以计算机为中心的复杂交互逐渐向以人为中心的简单、自然的交互。目前的基于多媒体、多通道的人机交互技术已经取得了不少研究成果，比如在文字识别、手势识别、语音识别、语音合成等方面都有不少研究成果和产品问世。</p>
    <p>[0004]	随着电子技术的发展，手机、MP4、平板电脑、数码相机、数码摄像机等便携式终端设备的普及程度越来越高，人们使用这些设备的多媒体记录功能记录了大量的多媒体数据，包括照片、有声以及无声的视频录像等等。在记录的多媒体文件中，内容里有人参与的占有绝大一部分。随着时代的发展，技术的进步，人们生活水平的提高，个人拥有的类似的多媒体资料也越来越多。这些多媒体资料作为生活以及工作中记录或是记忆长期存在，人们在浏览这些资料时，只能从资料上被动的获得信息，而无法进一步与资料上的内容(主要是指资料中的人物）进行交互，使用者若需和多媒体资料上记录的人进行进一步的交流，必须手动借助于另一种资料，如通讯录、备忘录等，获得该联系人的联系方式，进而和该对象进行进一步的联系。</p>
    <p>[0005]	上述方法存在的弊端包括：交互过程不友好，与人机交互发展初期的手工操作基本相当，效率及其低下；当时间久远，已无法回忆出多媒体资料上人物的信息时，进一步的互动就将失败。</p>
    <p>发明内容</p>
    <p>[0006]	鉴于上述的分析，本发明旨在提供一种基于人脸信息的多媒体交互方法及装置及终端，用以解决现有技术中存在的人机交互不友好以及交互过程中存在的效率低或者互动失败的问题。</p>
    <p>[0007]	本发明的目的主要是通过以下技术方案实现的：</p>
    <p>[0008]	本发明提供了一种基于生物特征信息的多媒体交互方法，包括：</p>
    <p>[0009]	在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储，数据可以存储在本地或者服务器上；在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互。</p>
    <p>[0010]	进一步地，如果匹配失败，则根据该生物特征信息到本终端用户相关的网络社交媒体做进一步匹配或者直接请求终端进行存储处理。</p>
    <p>[0011]	进一步地，在经过授权后访问与本终端用户相关的网络社交媒体，将提取到的生物特征信息与该网络社交媒体中存储的联系人的生物特征信息做进一步匹配，如果确定进一步匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；如果进一步匹配失败，则请求终端进行编辑存储处理。</p>
    <p>[0012]	进一步地，所述请求终端进行编辑存储处理的步骤具体包括:</p>
    <p>[0013]	请求终端存储该生物特征信息和对应的已知的联系信息，并将该生物特征信息与已知的联系信息进行关联；如果当前不知道该生物特征信息对应的联系信息，则仅存储该生物特征信息作为储备。</p>
    <p>[0014]	进一步地，当匹配成功并调用与该生物特征信息对应的联系人的联系信息时，根据需要对该联系信息进行修改。</p>
    <p>[0015]	其中，所述当前多媒体资料为终端中已有的多媒体资料，或者为终端实时拍摄的多媒体资料。</p>
    <p>[0016]	所述生物特征信息为人脸信息。</p>
    <p>[0017]	本发明还提供了一种基于生物特征信息的多媒体交互装置，包括:</p>
    <p>[0018]	关联存储模块，用于在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储，存储位置可以在终端本地或者服务器上；</p>
    <p>[0019]	匹配交互模块，用在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互。</p>
    <p>[0020]	进一步地，所述匹配交互模块还用于，如果匹配失败，则对该生物特征信息到与本终端用户相关的网络社交媒体中做进一步匹配或者请求所述关联存储模块进行编辑存储处理。</p>
    <p>[0021]	本发明还提供了一种终端，至少包括上面所述的基于生物特征信息的多媒体交互装置。</p>
    <p>[0022]	本发明有益效果如下:</p>
    <p>[0023]	本发明更进一步的挖掘出图像中的信息，相比之前的交互方式，该方式简单、有效，界面友好，效率较高，大大提升了系统的友好性。</p>
    <p>[0024]	本发明的其他特征和优点将在随后的说明书中阐述，并且，部分的从说明书中变得显而易见，或者通过实施本发明而了解。本发明的目的和其他优点可通过在所写的说明书、权利要求书、以及附图中所特别指出的结构来实现和获得。</p>
    <p>附图说明</p>
    <p>[0025]	图1为本发明第一方法实施例的流程示意图；</p>
    <p>[0026]	图2为本发明第二方法实施例的流程示意图；</p>
    <p>[0027]	图3为本发明实施例所述装置的结构示意图；</p>
    <p>[0028]	图4为本发明实施例所述终端的结构示意图。</p>
    <p>具体实施方式[0029]	下面结合附图来具体描述本发明的优选实施例，其中，附图构成本申请一部分，并与本发明的实施例一起用于阐释本发明的原理。应当理解，此处所描述的具体实施例仅用以解释本发明，并不用于限定本发明。需要说明的是，在不冲突的情况下，本申请中的实施例及实施例中的特征可以相互任意组合。</p>
    <p>[0030]	首先，结合附图1和2对本发明所述方法实施例进行详细说明。</p>
    <p>[0031]	第一方法实施例</p>
    <p>[0032]	如图1所示，图1为本发明第一方法实施例的流程示意图，具体可以包括：</p>
    <p>[0033]	步骤101 :在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联，并将关联之后的数据进行存储，存储位置可以是终端本地或者服务器；</p>
    <p>[0034]	步骤102 :在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互。</p>
    <p>[0035]	本发明第一方法实施例通过自动检测多媒体资料中的生物特征信息，将识别到的生物特征信息提取出来与之前存储的生物特征信息进行匹配，从而调出将对应的联系人的联系信息，达到自动跟多媒体资料进行互动的目的。</p>
    <p>[0036]	第二方法实施例</p>
    <p>[0037]	如图2所示，图2为本发明第二方法实施例的流程示意图，具体可以包括如下步骤：</p>
    <p>[0038]	步骤200 :采集联系人的生物特征信息；采集方式可以有多种，例如可以通过终端实时采集，也可以通过电脑或网络下载到本终端；</p>
    <p>[0039]	步骤201 :在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储，存储位置可以是终端本地或者服务器；具体的说就是，用户将通过采集设备采集或者互联网或者电脑导入等方式得到的联系人的生物特征信息与该联系人的联系信息进行关联，关联时可以根据实际情况对联系信息进行编辑修改，例如增加新的联系信息或对已有联系信息进行修改等，关联之后进行存储；其中，该联系信息包括：联系人的姓名、职务、单位、电话号码、邮件地址、QQ号码、开心网账号等信息中的一个或多个；用户进行关联的时候可以基于终端原有的联系信息功能软件，例如，在通讯录软件中将联系人的生物特征信息与相应的电话号码进行关联；也可以建立一个总的联系信息数据库，将联系人的生物特征信息与其所有或部分联系信息进行关联；其中，使用者可以使用多种方法建立联系信息数据库，包括：（1)使用者可以在某一时间，根据当前拥有的、已经进行了标记的多媒体资料集中建立数据库；（2)采用功能一中的方法增量的建立数据库；（3)用户在浏览资料的同时标记个人信息，并将标记后的资料实时增量更新到数据库中；</p>
    <p>[0040]	步骤202 :用户阅读终端本地或者网络上或者终端实时拍摄的多媒体资料时，如果想跟多媒体资料上的人进行互动，则触发终端在当前多媒体资料中提取该联系人的生物特征信息，并将提取到的生物特征信息与之前预先存储的生物特征信息进行查找匹配；</p>
    <p>[0041]	步骤203 :判断匹配是否成功，如果是，执行步骤204 ;否则执行步骤207 ；</p>
    <p>[0042]	步骤204 :将匹配结果即该联系人的联系信息以互动的方式显示在用户界面上，例如，提示终端用户发消息给此人，或是发邮件给此人；</p>
    <p>[0043]	步骤205 :判断终端用户是否需要对该联系人的联系信息进行修改，如果不用修改，执行步骤206，否则转到步骤209 ；</p>
    <p>[0044]	步骤206:用户根据提示进行操作，进入相应的软件功能模块，例如短信处理软件模块；</p>
    <p>[0045]	步骤207:作为本发明优选的实施例，当根据该联系人的生物特征信息没有在终端匹配到与其对应的联系信息时，可以在经过用户授权后进一步到与终端用户有关的网络社交媒体中查找，即根据该联系人的生物特征信息进一步与网络社交媒体中的生物特征信息进行匹配；</p>
    <p>[0046]	需要说明的是，当根据该联系人的生物特征信息没有在终端匹配到与其对应的联系信息，也可以直接请求终端进行存储，即执行步骤209 ；</p>
    <p>[0047]	步骤208:判断进一步匹配是否成功，如果是，执行步骤204 ;否则执行步骤209 ；</p>
    <p>[0048]	步骤209:请求终端进行存储；具体的说就是，询问用户是否存储该联系人的生物特征信息并与对应的联系信息建立关联，如果是，请求终端存储该生物特征信息和当前已知的联系信息，并将该生物特征信息与联系信息进行关联；</p>
    <p>[0049]	如果当前不知道该生物特征信息对应的联系信息，则可以选择仅存储该生物特征信息作为储备，以便日后编辑使用；</p>
    <p>[0050]	步骤210:用户在完成记录后离线进行多媒体资料阅读，如果还有下个生物特征信息需要匹配，则转到步骤200，重复执行上述过程。</p>
    <p>[0051]	为了便于对本发明所述方法进行理解，以下将以人脸信息为例，给出几个典型的使用本本发明所述方法进行人机交互的使用场景，实际使用过程中包括但不限于这些场</p>
    <p>旦</p>
    <p>-5^ O</p>
    <p>[0052]	使用场景一:</p>
    <p>[0053]	用户A使用终端在进行本地图片的浏览，当用户正在浏览带有人物图像信息的图片时，用户可能想与照片中的人物进行互动。此时，使用人脸检测算法对图像进行人脸进行检测，进而在检测的基础上，对检测到的人脸进行识别和匹配。进行人脸识别的样本库用户A可以进行授权和配置，例如，用户A授权程序可以访问本地的联系人数据库，在这种情况下，程序根据检测到的人脸信息，和用户本地联系人中的头像信息进行匹配，进行当前图像中人物的识别。若识别成功，会在当前的图像浏览界面弹出提示框，给出用户A&#8212;些可以操作的选择，例如呼叫照片中的人物，或是发送消息给短消息中的人物。如果检索失败，也会在界面上有相应的提示，例如是否完善联系人信息，或是进一步请求用户的授权，确定是否可以扩大搜索范围，例如用户A可以给程序授权访问人人网主页，可以在用户的好友列表的图片以及头像信息里进一步的进行人物的识别。若识别成功，可以在界面上提示是否和该任务进一步交互，例如显示出该任务最近一段时间的状态更新情况。</p>
    <p>[0054]	使用场景二:</p>
    <p>[0055]用户A使用手持终端进行图像或者视频拍摄时，可以实时的对当前采集到的图像进行分析。和上一个使用场景类似，首先检测出人脸，并对检测到的人脸信息进行识别。若识别失败，则提示用户是否手动进行多媒体信息资料的标记，以便日后方便的与该多媒体资料进行交互。用户标记的用户信息作为本地人物样本库存在，这个也是用户日后进行图像交互时默认的图像检索 样本库。</p>
    <p>[0056]	以上结合附图1和2以及两个具体应用场景对于本发明实施例所述方法进行了详细说明，接下来将结合附图3对本发明实施例所述装置进行详细说明。</p>
    <p>[0057]	如图3所示，图3为本发明实施例所述装置的结构示意图，具体可以包括：关联存储模块和匹配交互模块，其中，</p>
    <p>[0058]	关联存储模块，主要负责在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储，存储位置可以是终端本地或者服务器；</p>
    <p>[0059]	匹配交互模块，主要负责在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；如果匹配失败，则对该生物特征信息到与本终端用户相关的网络社交媒体中做进一步匹配或者请求所述关联存储模块进行编辑存储处理。</p>
    <p>[0060]	需要说明的是，对于本发明实施例所述装置的具体实现流程，由于上述方法中已有详细说明，故此处不再赘述。</p>
    <p>[0061]	最后，结合附图4对本发明实施例所述终端进行详细说明。</p>
    <p>[0062]	如图4所示，图4为本发明实施例所述终端的结构示意图，该终端至少包括上述本发明实施例所述装置，该装置包括：关联存储模块和匹配交互模块，其中，</p>
    <p>[0063]	关联存储模块，主要负责在终端中预先将联系人的生物特征信息与该联系人的联系信息进行关联并存储，存储位置可以是终端本地或者服务器；</p>
    <p>[0064]	匹配交互模块，主要负责在当前多媒体资料中提取生物特征信息，并将提取到的生物特征信息与之前存储的生物特征信息进行匹配，如果确定匹配成功则调出与该生物特征信息对应的联系人的联系信息进行交互；如果匹配失败，则对该生物特征信息到与本终端用户相关的网络社交媒体中做进一步匹配或者请求所述关联存储模块进行编辑存储处理。</p>
    <p>[0065]	综上所述，本发明实施例提供了基于人脸信息的多媒体交互方法及装置及终端，与现有技术相比较，本发明更进一步的挖掘出图像中的信息，将一些需要人工干预的事情进行自动化的处理，用户只需要根据系统的输出信息做出选择即可。相比之前的交互方式，该方式简单、有效，界面友好，效率较高，大大提升了系统的友好性。</p>
    <p>[0066]	以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本发明揭露的技术范围内，可轻易想到的变化或替换，都应涵盖在本发明的保护范围之内。因此，本发明的保护范围应该以权利要求书的保护范围为准。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1798189A?cl=zh">CN1798189A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年10月28日</td><td class="patent-data-table-td patent-date-value">2006年7月5日</td><td class="patent-data-table-td ">Lg电子株式会社</td><td class="patent-data-table-td ">移动终端和用于在移动终端中将照片关联于电话号码的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101021899A?cl=zh">CN101021899A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年3月16日</td><td class="patent-data-table-td patent-date-value">2007年8月22日</td><td class="patent-data-table-td ">南京搜拍信息技术有限公司</td><td class="patent-data-table-td ">综合利用人脸及人体辅助信息的交互式人脸识别系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101576810A?cl=zh">CN101576810A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年5月9日</td><td class="patent-data-table-td patent-date-value">2009年11月11日</td><td class="patent-data-table-td ">杭州中正生物认证技术有限公司</td><td class="patent-data-table-td ">利用生物识别技术实现文件安全打印的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101741973A?cl=zh">CN101741973A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月7日</td><td class="patent-data-table-td patent-date-value">2010年6月16日</td><td class="patent-data-table-td ">深圳华为通信技术有限公司</td><td class="patent-data-table-td ">显示相关信息的方法及移动通信终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102521619A?cl=zh">CN102521619A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月22日</td><td class="patent-data-table-td patent-date-value">2012年6月27日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">基于人脸识别的信息呈现方法及装置和人脸识别打印系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102523213A?cl=zh">CN102523213A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月13日</td><td class="patent-data-table-td patent-date-value">2012年6月27日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">服务器、终端鉴权方法以及服务器、终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110316666">US20110316666</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value">2011年12月29日</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Information device, computer program product and method thereof</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103414815A?cl=zh">CN103414815A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月15日</td><td class="patent-data-table-td patent-date-value">2013年11月27日</td><td class="patent-data-table-td ">珠海市魅族科技有限公司</td><td class="patent-data-table-td ">联系人信息的显示方法和终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013189317A1?cl=zh">WO2013189317A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年8月2日</td><td class="patent-data-table-td patent-date-value">2013年12月27日</td><td class="patent-data-table-td ">Zte Corporation</td><td class="patent-data-table-td ">基于人脸信息的多媒体交互方法及装置及终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003048100">G06F3/0481</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003010000">G06F3/01</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=wIL2BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F21/32">G06F21/32</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年5月1日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年6月5日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/b407dfd629ef452b993b/CN103076879A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E8%84%B8%E4%BF%A1%E6%81%AF%E7%9A%84%E5%A4%9A%E5%AA%92%E4%BD%93%E4%BA%A4%E4%BA%92%E6%96%B9.pdf?id=wIL2BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1Xn68bp_r7wXeSk5D4GmkoZ0hs2Q"},"sample_url":"https://www.google.com/patents/reader?id=wIL2BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>