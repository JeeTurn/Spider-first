<!DOCTYPE html><html><head><title>专利 CN102609458A - 一种图片推荐方法和装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种图片推荐方法和装置"><meta name="DC.contributor" content="路晶" scheme="inventor"><meta name="DC.contributor" content="北京搜狗信息服务有限公司" scheme="assignee"><meta name="DC.contributor" content="北京搜狗科技发展有限公司" scheme="assignee"><meta name="DC.date" content="2012-1-12" scheme="dateSubmitted"><meta name="DC.description" content="本申请提供了一种图片推荐方法和装置，其中的方法具体包括：接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词。本申请能够提供契合用户个性化需求的图片，扩展用户感兴趣信息的获取渠道。"><meta name="DC.date" content="2012-7-25"><meta name="DC.relation" content="CN:101241512:A" scheme="references"><meta name="DC.relation" content="CN:102270234:A" scheme="references"><meta name="DC.relation" content="US:20040267740:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102609458:A"><meta name="citation_patent_application_number" content="CN:201210009043"><link rel="canonical" href="https://www.google.com/patents/CN102609458A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102609458A?cl=zh"/><meta name="title" content="专利 CN102609458A - 一种图片推荐方法和装置"/><meta name="description" content="本申请提供了一种图片推荐方法和装置，其中的方法具体包括：接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词。本申请能够提供契合用户个性化需求的图片，扩展用户感兴趣信息的获取渠道。"/><meta property="og:title" content="专利 CN102609458A - 一种图片推荐方法和装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102609458A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102609458A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=GC2PBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102609458A&amp;usg=AFQjCNEEoAKNIsk-l7g_0riCeEFlNXqSuw" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/4507eda69a1b119caabe/CN102609458A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/4507eda69a1b119caabe/CN102609458A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102609458A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102609458A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102609458A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102609458B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102609458A?cl=zh" style="display:none"><span itemprop="description">本申请提供了一种图片推荐方法和装置，其中的方法具体包括：接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；依据所述结果图片所在的网页文本，抽取描述图片语义特征...</span><span itemprop="url">https://www.google.com/patents/CN102609458A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102609458A - 一种图片推荐方法和装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102609458A - 一种图片推荐方法和装置" title="专利 CN102609458A - 一种图片推荐方法和装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102609458 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210009043</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年7月25日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年1月12日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年1月12日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102609458B?hl=zh-CN&amp;cl=zh">CN102609458B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210009043.7, </span><span class="patent-bibdata-value">CN 102609458 A, </span><span class="patent-bibdata-value">CN 102609458A, </span><span class="patent-bibdata-value">CN 201210009043, </span><span class="patent-bibdata-value">CN-A-102609458, </span><span class="patent-bibdata-value">CN102609458 A, </span><span class="patent-bibdata-value">CN102609458A, </span><span class="patent-bibdata-value">CN201210009043, </span><span class="patent-bibdata-value">CN201210009043.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B7%AF%E6%99%B6%22">路晶</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E6%90%9C%E7%8B%97%E4%BF%A1%E6%81%AF%E6%9C%8D%E5%8A%A1%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京搜狗信息服务有限公司</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E6%90%9C%E7%8B%97%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京搜狗科技发展有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102609458A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102609458A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102609458A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=GC2PBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210009043&amp;usg=AFQjCNHp-j9LiMqRc_v8uRtj7ilf7mkwlQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=GC2PBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102609458A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHEgBpyVi0ceNpO2OtqoTsVq5xkdA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114436639" lang="ZH" load-source="patent-office">一种图片推荐方法和装置</invention-title>
      </span><br><span class="patent-number">CN 102609458 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA99197776" lang="ZH" load-source="patent-office">
    <div class="abstract">本申请提供了一种图片推荐方法和装置，其中的方法具体包括：接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词。本申请能够提供契合用户个性化需求的图片，扩展用户感兴趣信息的获取渠道。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(16)</span></span></div><div class="patent-text"><div mxw-id="PCLM44627002" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种图片推荐方法，其特征在于，包括：接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求I所述的方法，其特征在于，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，包括：依据对所述网页文本进行聚类分析的结果，去除所述网页文本中孤立的网页文本，得到剩余文本；抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的方法，其特征在于，通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述词或短语；所述实体词库存储有具有实际意义的实体词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求2所述的方法，其特征在于，通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：依据词性抽取所述剩余文本中具有实际意义的词或短语，所述抽取过程包括：在所述剩余文本中的词或短语为叹词、代词或语气助词中的任一种时，丢弃所述词或短语。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求2所述的方法，其特征在于，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，还包括：依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求I至5中任一项所述的方法，其特征在于，所述方法还包括：在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；所述将与关键词匹配的相应目标图片推荐给用户的步骤为，将所述剩余图片推荐给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求I至5中任一项所述的方法，其特征在于，所述将与关键词匹配的相应目标图片推荐给用户的步骤，包括：依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；按照在线查询请求数目的降序将与关键词匹配的相应目标图片推荐给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求I至5中任一项所述的方法，其特征在于，该目标图片为与该查询请求对应的查询策略最匹配的图片；所述结果图片为除目标图片外大于匹配阈值的其他图片。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9.	一种图片推荐装置，其特征在于，包括：图片搜索模块，用于接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；关键词抽取模块，用于依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；匹配模块，用于在搜索日志中进行关键词的匹配；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词；及图片推荐模块，用于将与关键词匹配的相应目标图片推荐给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.如权利要求9所述的装置，其特征在于，所述关键词抽取模块包括：去除子模块，用于依据对所述网页文本进行聚类分析的结果，去除所述网页文本中孤立的网页文本，得到剩余文本；及抽取子模块，用于抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.如权利要求10所述的装置，其特征在于，还包括：第一实际意义抽取模块，用于调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述剩余文本中的词或短语；所述实体词库存储有具有实际意义的实体词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.如权利要求10所述的装置，其特征在于，还包括：第二实际意义抽取模块，用于依据词性抽取所述剩余文本中具有实际意义的词或短语，所述抽取过程包括：在所述剩余文本中的词或短语为叹词、代词或语气助词中的任一种时，丢弃所述剩余文本中的词或短语。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.如权利要求10所述的装置，其特征在于，所述关键词抽取模块还包括：边缘词统计子模块，用于依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.如权利要求9至13中任一项所述的装置，其特征在于，还包括：滤除模块，用于在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；所述图片推荐模块，具体用于将所述剩余图片推荐给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.如权利要求9至13中任一项所述的装置，其特征在于，所述图片推荐模块包括：数目统计子模块，用于依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；降序推荐子模块，用于按照在线查询请求数目的降序将相应与关键词匹配的相应目标图片推荐给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.如权利要求9至13中任一项所述的装置，其特征在于，该目标图片为与该查询请求对应的查询策略最匹配的图片；所述结果图片为除目标图片外大于匹配阈值的其他图片。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES50779729" lang="ZH" load-source="patent-office" class="description">
    <p>一种图片推荐方法和装置</p>
    <p>技术领域</p>
    <p>[0001]	本申请涉及图片处理技术领域，特别是涉及一种图片推荐方法和装置。</p>
    <p>背景技术</p>
    <p>[0002]目前随着网络技术的不断发展，用户对搜索引擎的要求已经不再满足于只是对文本的搜索，很多用户还希望可以通过搜索引擎对网络图片进行搜索。</p>
    <p>[0003]目前的图片搜索引擎大都采用基于文本的搜索技术，该技术将图片作为数据库存储的对象，用关键字对其进行描述。然而对于图片中包含的视觉特征，如颜色或形状等，无法用文本进行描述，这样，当需要根据图片中包含的视觉特征搜索图片时，基于文本的搜索技术将不再适用。例如，用户经常遇到这样的问题，在网站或电脑上看到一张包含物品的图片，但并不知道该图片中的物品是什么，故很难将该物品的视觉特征用语言描述出来，即便表达能力好的用户将其视觉特征描述出来了，也很难在现有的搜索引擎中找到与该图片相似的图片，导致搜索效率低下，使用网络流量较大。</p>
    <p>[0004]	针对上述搜索效率低下、使用网络流量较大的问题，一些图片搜索引擎提供以图搜图功能，该以图搜图功能将视觉内容一致的图片返回给用户，以满足用户的某些搜索需求。例如某些用户爱好搜集图片，最不能容忍的就是美图上面有水印，只要上传图片到图片搜索引擎，轻轻一点便能搜出不带水印的图片；又如，可以上传小图片，搜到这个小图片的各个版本，如清晰大图等。</p>
    <p>[0005]	还有一些图片搜索引擎在提供以图搜图功能的同时提供图片推荐功能，参照图1， 示出了现有技术一种图片搜索引擎中图片推荐方法的流程图，具体可以包括：</p>
    <p>[0006]	步骤101、用户提交查询图片；</p>
    <p>[0007]	步骤102、抽取查询图片的颜色、纹理、形状等视觉特征；</p>
    <p>[0008]	步骤103、将查询图片的视觉特征与数据库中图片的视觉特征进行相似性比对；</p>
    <p>[0009]	步骤104、将视觉相似图片推荐给用户。</p>
    <p>[0010]	由于图片推荐结果依据的颜色、纹理、形状等视觉特征比对得到，故这里的视觉相似主要指外观相似，例如用户上传妮可基德曼的图片，图片中妮可基德曼的头发颜色为金色，则图片搜索引擎可能会返回视觉相似的含有金色头发的图片，如金发女郎的图片，有时甚至会返回金毛犬的图片，等等。</p>
    <p>[0011]	但有些用户存在一些个性化需求，如用户上传刘德华的图片，还可能希望看到刘德华的电影海报、个人写真等图片。此时，现有技术中视觉内容一致的搜索结果和视觉相似的图片推荐结果均不能满足用户的个性化需求。</p>
    <p>[0012]	总之，需要本领域技术人员迫切解决的一个技术问题就是：如何能够提供契合用户个性化需求的图片。</p>
    <p>发明内容</p>
    <p>[0013]	本申请所要解决的技术问题是提供一种图片推荐方法和装置，能够提供契合用户个性化需求的图片，扩展用户感兴趣信息的获取渠道。</p>
    <p>[0014]	为了解决上述问题，本申请公开了一种图片推荐方法，包括：</p>
    <p>[0015]	接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；</p>
    <p>[0016]	依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；</p>
    <p>[0017]	在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词。</p>
    <p>[0018]	优选的，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，包括：</p>
    <p>[0019]	依据对所述网页文本进行聚类分析的结果，去除所述网页文本中孤立的网页文本，得到剩余文本；</p>
    <p>[0020]	抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</p>
    <p>[0021]	优选的，通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：</p>
    <p>[0022]	调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述词或短语；所述实体词库存储有具有实际意义的实体词。</p>
    <p>[0023]	优选的，通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：</p>
    <p>[0024]	依据词性抽取所述剩余文本中具有实际意义的词或短语，所述抽取过程包括：</p>
    <p>[0025]	在所述剩余文本中的词或短语为叹词、代词或语气助词中的任一种时，丢弃所述词或短语。</p>
    <p>[0026]	优选的，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，还包括：</p>
    <p>[0027]	依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键</p>
    <p>ο</p>
    <p>[0028]	优选的，所述方法还包括：</p>
    <p>[0029]	在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；</p>
    <p>[0030]	所述将与关键词匹配的相应目标图片推荐给用户的步骤为，将所述剩余图片推荐给用户。</p>
    <p>[0031]	优选的，所述将与关键词匹配的相应目标图片推荐给用户的步骤，包括：</p>
    <p>[0032]	依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；</p>
    <p>[0033]	按照在线查询请求数目的降序将与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0034]	优选的，该目标图片为与该查询请求对应的查询策略最匹配的图片；所述结果图片为除目标图片外大于匹配阈值的其他图片。</p>
    <p>[0035]	另一方面，本申请还公开了一种图片推荐装置，包括：</p>
    <p>[0036]图片搜索模块，用于接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；[0037]	关键词抽取模块，用于依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；</p>
    <p>[0038]	匹配模块，用于在搜索日志中进行关键词的匹配；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词；及</p>
    <p>[0039]	图片推荐模块，用于将与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0040]	优选的，所述关键词抽取模块包括：</p>
    <p>[0041]	去除子模块，用于依据对所述网页文本进行聚类分析的结果，去除所述网页文本中孤立的网页文本，得到剩余文本；及</p>
    <p>[0042]	抽取子模块，用于抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</p>
    <p>[0043]	优选的，所述装置还包括：</p>
    <p>[0044]	第一实际意义抽取模块，用于调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述剩余文本中的词或短语；所述实体词库存储有具有实际意义的实体词。</p>
    <p>[0045]	优选的，所述装置还包括：</p>
    <p>[0046]	第二实际意义抽取模块，用于依据词性抽取所述剩余文本中具有实际意义的词或短语，所述抽取过程包括：在所述剩余文本中的词或短语为叹词、代词或语气助词中的任一种时，丢弃所述剩余文本中的词或短语。</p>
    <p>[0047]	优选的，所述关键词抽取模块还包括：</p>
    <p>[0048]	边缘词统计子模块，用于依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键词。</p>
    <p>[0049]	优选的，所述装置还包括：</p>
    <p>[0050]	滤除模块，用于在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；</p>
    <p>[0051]	所述图片推荐模块，具体用于将所述剩余图片推荐给用户。</p>
    <p>[0052]	优选的，所述图片推荐模块包括：</p>
    <p>[0053]	数目统计子模块，用于依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；</p>
    <p>[0054]	降序推荐子模块，用于按照在线查询请求数目的降序将相应与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0055]	优选的，该目标图片为与该查询请求对应的查询策略最匹配的图片；所述结果图片为除目标图片外大于匹配阈值的其他图片。</p>
    <p>[0056]	与现有技术相比，本申请具有以下优点：</p>
    <p>[0057]	相对于现有技术采用视觉特征描述查询图片，本申请采用关键词描述查询图片的图片语义特征，并在搜索日志中记录全网在线查询请求对应的目标图片及相应的关键词； 由于关键词所描述的图片语义特征能够反映用户的兴趣爱好，这样，在一个用户提交查询请求时，本申请能够依据所得到目标图片的关键词和所述搜索日志中目标图片的关键词， 匹配得到具有相同兴趣爱好的其它用户查询请求对应的目标图片，也即与关键词匹配的相应目标图片能够契合用户的兴趣爱好，因此，将从搜索日志中提取出来的与关键词匹配的相应目标图片推荐给当前用户，提供了契合用户个性化需求的图片，扩展了用户感兴趣信息的获取渠道。</p>
    <p>附图说明</p>
    <p>[0058]	图I是现有技术一种图片搜索引擎中图片推荐方法的流程图；</p>
    <p>[0059]	图2是本申请一种图片推荐方法实施例的流程图；</p>
    <p>[0060]	图3是本申请一种图片推荐装置实施例的结构图。</p>
    <p>具体实施方式</p>
    <p>[0061]	为使本申请的上述目的、特征和优点能够更加明显易懂，下面结合附图和具体实施方式对本申请作进一步详细的说明。</p>
    <p>[0062]	用户个性化需求往往是源自用户的兴趣爱好的，例如，某用户有追星的爱好，其是刘德华的粉丝，则他在上传刘德华的图片时，很有可能还希望看到刘德华的电影海报、个人写真等图片；又如，另一用户是电影爱好者，其对《当幸福来敲门》这部电影有着由衷的爱好，则他在上传《当幸福来敲门》的电影海报时，很有可能还希望看到更多该电影的其它不同海报。现有技术视觉相似的搜索结果是无法满足在上述情形下的用户个性化需求。</p>
    <p>[0063]	本申请实施例的核心构思之一在于，根据当前用户输入图片的局部特征得到目标图片和与其特征内容相似或相同的多个结果图片，对结果图片所在页面分别进行分析，综合各页面中标题、文本等文字信息，得到的关键词与目标图片关联；由于关键词所描述的图片语义特征能够反映用户的兴趣爱好，这样，在一个用户提交查询请求时，本申请能够依据所得到目标图片的关键词和所述搜索日志中目标图片的关键词，匹配得到具有相同兴趣爱好的其它用户查询请求对应的对应目标图片，也即与关键词匹配的相应目标图片能够契合用户的兴趣爱好，因此，将与关键词匹配的相应目标图片推荐给用户能够提供契合用户个性化需求的图片，扩展用户感兴趣信息的获取渠道。</p>
    <p>[0064]	参照图2，示出了本申请一种图片推荐方法实施例的流程图，具体可以包括：</p>
    <p>[0065]	步骤201、接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；</p>
    <p>[0066]	本申请可以应用于图片搜索引擎中，用以扩充图片搜索引擎的功能，也即，使得图片搜索引擎具备原有的以图搜图功能，同时具备本申请的图片推荐功能。实际上，本申请还可以应用于其它搜索引擎或搜索装置，本申请对具体的应用环境不加以限制。</p>
    <p>[0067]	在实际中，用户可在浏览器中提交在线查询请求，这里的提交在线查询请求的方式可以包括直接上传本地图片，或者提供图片的网络地址，由服务器自动下载图片，本申请对具体的提交在线查询请求的方式不加以限制。也即，本申请实施例中，与该查询请求直接对应的图片可以包括用户直接上传的本地图片，也可以包括依据用户提供的图片的网络地址得到图片。</p>
    <p>[0068]	在具体实现中，服务器可根据该查询请求直接对应的图片的视觉内容，抽取出局部特征，然后进行图片搜索，与数据库中各图片的局部特征进行匹配，如果匹配率在一定阈值范围（如&gt;90%)内，可认为二者的视觉内容一致。[0069]	对于该查询请求直接对应的图片和匹配结果而言，二者仅有细微的差别，如是否带水印、小图片和大图片的差别等；刨除这些细微的差别，二者就是相同的图片。</p>
    <p>[0070]	考虑到该查询请求直接对应的图片可能为带水印的图片或者是小图片等质量不好的图片，如果将其作为搜索日志的存储对象，而最终向用户推荐的图片源自搜索日志，这样，向用户推荐带水印或小图片等质量不好的图片会影响用户的搜索体验。因此，在本申请的一种优选实施例中，将与查询请求对应的查询策略最匹配的图片作为目标图片，并将该目标图片作为搜索日志的存储对象。在实际中，匹配所用的数据库往往存储一些不带水印且尺寸较大的图片，这样，向用户推荐不带水印且尺寸较大的图片能够提高用户的搜索体验。</p>
    <p>[0071]	本申请的一种优选实施例中，结果图片为数据库中除目标图片外大于匹配阈值的其他图片，即结果图片与查询请求对应的查询策略的相符程度小于目标图片与查询请求对应的查询策略的相符程度。本实施例中，得到的目标图片和结果图片按匹配度进行排序，与查询请求最匹配的图片为目标图片，其余的图片作为结果图片按匹配度进行排序展示。在其他实施例中，用户的查询请求的对应结果可按图片大小或发布时间进行排序，将尺寸最大或最近发布的图片作为目标图片，其余的图片作为结果图片按尺寸由大至小或发布时间由近至远进行排序展示。在通常情况下，结果图片和目标图片仅有细微的差别，如是否带水印、小图片和大图片的差别等；刨除这些细微的差别，二者就是相同的图片。</p>
    <p>[0072]	可以理解，在本申请应用于图片搜索引擎时，服务器还可以将所述结果图片作为搜索结果返回给用户，以满足用户的某些搜索需求。例如某些用户爱好搜集图片，最不能容忍的就是美图上面有水印，只要上传图片到图片搜索引擎，轻轻一点便能搜出不带水印的图片；又如，可以上传小图片，搜到这个小图片的各个版本，如清晰大图等。</p>
    <p>[0073]	在本申请的一种应用示例中，所述根据该查询请求直接对应的图片的视觉内容， 抽取出局部特征的步骤具体可以包括：</p>
    <p>[0074]	首先，对该查询请求直接对应的图片的尺寸进行归一化，将尺寸过大或过小的图片变换为640*640&#12316;300*300之内；然后使用二维局部特征检测矩阵与归一化后的图片进行卷积操作；再者，在卷积后的图片中扫描定位出其中的局部极值（最大值与最小值）点的位置；最后，根据局部极值点附近区域的明暗对比，抽取该查询请求直接对应的图片的局部特征。需要说明的是，为了实现匹配目的，该查询请求直接对应的图片与数据库中具有与其相同原始尺寸的图片在归一化后的尺寸应一致，例如，同为300*300。</p>
    <p>[0075]	参照表1，示出了本申请一种归一化前后的图片尺寸示意。</p>
    <p>[0076]表	I[0077]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00091.png"> <img id="idf0001" file="CN102609458AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00091.png" class="patent-full-image" alt="Figure CN102609458AD00091"> </a> </div>
    <p>[0078]	在其他实施例中，所述结果图片也可以为对目标图片进行特征抽取，在数据库中进行搜索，与数据库中各图片的局部特征进行匹配所得到的图片。</p>
    <p>[0079]	步骤202、依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词， 作为该目标图片的关键词；</p>
    <p>[0080]	由于结果图片来自于网络，故搜索引擎或搜索装置的数据库中会记录有每一幅结果图片的网页文本，这些网页文本通常包括网页的文本信息，如页面标题，图片周边的描述文本等。</p>
    <p>[0081]	由于结果图片是与目标图片相同或近似的图片，在通常情况下，二者仅有细微的差别，如是否带水印、小图片和大图片的差别等；刨除这些细微的差别，二者就是相同的图片，也就是说，结果图片可以完全代表目标图片。</p>
    <p>[0082]	这样，依据结果图片的网页文本，抽取的关键词能够客观描述目标图片的图片语义特征，而目标图片的图片语义特征又能够在一定程度上反映用户的兴趣爱好，例如，用户搜索得到刘德华的图片，很有可能说明该用户是刘德华的粉丝，又如，用户搜索得到《当幸福来敲门》的电影海报，很有可能说明该用户是《当幸福来敲门》的爱好者等等。</p>
    <p>[0083]	在本申请的一种优选实施例中，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，可以进一步包括：</p>
    <p>[0084]	子步骤Al、对所述网页文本进行聚类分析；</p>
    <p>[0085]	子步骤A2、依据聚类分析结果，去除所述网页文本中孤立的网页文本，得到剩余文本；</p>
    <p>[0086]	在具体实现中，可将每幅结果图片的网页文本视为一个文档，对所有结果图片的网页文本进行聚类分析，将那些未聚集在一起的孤立文本视为噪音去除掉。聚类分析的原理是最近邻二叉树聚类，应用于网页文本时，其根据网页文本的重复程度，将重复最多的两份网页文本视为一个类进行合并，并将合并后的类视为一个网页文本，迭代重复下去，直至重复最多的两个网页文本之间的重复程度不能达到合并阈值为止。</p>
    <p>[0087]	参照表2和表3，分别示出了本申请一种原始网页文本和聚类分析后剩余文本的示例，其中，原始网页文本包括1-9九份网页对应的文本，聚类分析去除了其中的编号为2、</p>
    <p>4、9噪音文本，得到剩余文本。</p>
    <p>[0088]	表 2</p>
    <p>[0089]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00101.png"> <img id="idf0002" file="CN102609458AD00101.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00101.png" class="patent-full-image" alt="Figure CN102609458AD00101"> </a> </div>
    <p>[0090]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00111.png"> <img id="idf0003" file="CN102609458AD00111.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00111.png" class="patent-full-image" alt="Figure CN102609458AD00111"> </a> </div>
    <p>[0091]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00121.png"> <img id="idf0004" file="CN102609458AD00121.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00121.png" class="patent-full-image" alt="Figure CN102609458AD00121"> </a> </div>
    <p>[0092]表	3</p>
    <p>[0093]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00122.png"> <img id="idf0005" file="CN102609458AD00122.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00122.png" class="patent-full-image" alt="Figure CN102609458AD00122"> </a> </div>
    <p>[0094]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00131.png"> <img id="idf0006" file="CN102609458AD00131.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00131.png" class="patent-full-image" alt="Figure CN102609458AD00131"> </a> </div>
    <p>[0095]	在理想情况下，结果图片的网页文本能够真实准确地描述相应图片的语义内容， 但是，由于网页文本的质量参差不齐，在某些特殊情况下，网页文本与图片的语义内容并不相关。例如表2中原始网页文本的2，9。（文本4虽然与图片语义内容相关，但与其他文本的重复程度未达到合并阈值，因此也被去除了。）</p>
    <p>[0096]	在实际中，上述理想情况下的结果图片占大多数，特殊情况下的结果图片极为个别，这样，在聚类分析时理想情况下的结果图片的网页文本能够聚集在一起，而特殊情况下的结果图片的网页文本被孤立；因此，上述聚类分析能够将那些未聚集在一起的与目标图片中的物体或场景不相关的孤立文本视为噪音去除掉，以提高关键词抽取的准确性。</p>
    <p>[0097]	子步骤A3、抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</p>
    <p>[0098]	本申请可以提供如下抽取所述剩余文本中具有实际意义的词或短语的方案：</p>
    <p>[0099]方案一、</p>
    <p>[0100]	可以通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：</p>
    <p>[0101]	依据预先构造的实体词库，抽取所述剩余文本中具有实际意义的词或短语，所述实体词库存储有具有实际意义的实体词，所述抽取过程可以包括：</p>
    <p>[0102]	调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述剩余文本中的词或短语。</p>
    <p>[0103]	这里的实体词主要指表示单个或者多个实体概念的词语，其主要包括旧称名词， 如人名、电影名、物品名等。在实际中，可以搜集兴趣爱好类别下的实体词，并预先构造相应的实体词库，这里的兴趣爱好类别既可以包括；电影、电视、明星、音乐、动漫等娱乐类别，也可以图书、电子产品、服装、鞋帽等休闲类别等的。本申请对具体的兴趣爱好类别及实体词库的构造方式不加以限制。</p>
    <p>[0104]方案二、</p>
    <p>[0105]	可以通过以下步骤抽取所述剩余文本中具有实际意义的词或短语：</p>
    <p>[0106]	依据词性抽取所述剩余文本中具有实际意义的词或短语，所述抽取过程具体可以包括：</p>
    <p>[0107]	在所述剩余文本中的词或短语为叹词、代词或语气助词中的任一种时，丢弃所述剩余文本中的词或短语。</p>
    <p>[0108]	由于叹词、代词或语气助词等为常用词，通常没有实际意义，故在抽取时，可以对其进行丢弃处理。需要说明的是，除了叹词、代词或语气助词外，本方案还可以根据实际情况，丢弃所述剩余文本中其它词性的词或短语，如副词、介词、连词、结构助词、动态助词、拟声词中的任一种等等，本申请对具体丢弃的词性不加以限制。</p>
    <p>[0109]	需要说明的是，为了减轻抽取所述剩余文本中具有实际意义的词或短语的工作量，在本申请实施例中，优选的是，可以首先抽取所述剩余文本中词频最高的词或短语得到初步抽取结果，然后，从所述初步抽取结果中抽取具有实际意义的词或短语，得到最终抽取结果。当然，本领域技术人员也可以根据需要，首先抽取所述剩余文本中具有实际意义的词或短语，然后抽取词频最高的词或短语，本申请对具体的前后次序不加以限制。</p>
    <p>[0110]	另外，上述两种抽取所述剩余文本中具有实际意义的词或短语的方案可以单独使用或者结合使用，或者，本领域技术人员还可以根据实际需要，采用其他抽取所述剩余文本中具有实际意义的词或短语的方案，本申请对此不加以限制。</p>
    <p>[0111]	在本申请的另一种优选实施例中，所述依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词的步骤，还可以包括：</p>
    <p>[0112]	依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键</p>
    <p>ο</p>
    <p>[0113]	假设用户上传了刘德华的图片，且步骤201-203抽取得到描述图片语义特征的关键词&#8212;&#8212;“刘德华”；实际上该用户还希望看到刘德华的电影海报、个人写真等图片的，于是，可以“刘德华”为关键词，统计所述剩余文本中与“刘德华”相邻共现次数较多的其他词汇，如“电影”、“经典电影”、“写真”等，这样，最终得到的关键词可以包括：“刘德华电影”、 “刘德华经典电影”、“刘德华写真”等等。</p>
    <p>[0114]	步骤203、在搜索日志中进行关键词的匹配，并将与关键词匹配的相应目标图片推荐给用户；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键</p>
    <p>ο</p>
    <p>[0115]	网络操作系统通常设计有各种各样的日志文件，如应用程序日志，安全日志、系统日志等等，当用户在网络系统上进行一些操作时，这些日志文件通常会记录下操作的一些相关内容，如用户所用的IP(网络之间互连的协议，Internet Protocol)、时间、用户名等。</p>
    <p>[0116]	本申请的搜索日志是针对全网用户的在线查询请求而生成的，与已有技术不同的是，会在所述搜索日志中记录该在线查询请求对应的目标图片及相应的关键词，其中，所述关键词是通过执行步骤201-202而得到的。这里的全网用户可以包括互联网的用户，也即互联网的用户在搜索引擎或搜索装置中提交在线查询请求时，搜索引擎或搜索装置的服务器都可以生成相应的搜索日志，而本申请可以从互联网中所有搜索引擎或搜索装置的服务器收集搜索日志，得到搜索日志。本申请仅对搜索日志的存储内容进行了规定，而不会对具体的收集方式或者搜索日志的获取方式加以限制。</p>
    <p>[0117]	在具体实现中，匹配所依据的搜索日志应是全网用户的搜索日志，以查询到与该目标图片的关键词相匹配的其他用户查询得到对应的目标图片，这里的关键词匹配主要指搜索日志中记录的目标图片的关键词与当前目标图片的关键词相同、包含该目标图片的关键词，或彼此重置，等等。</p>
    <p>[0118]	本申请提供的图片推荐功能可以较好地满足用户个性化需求，因为本申请中关键词所描述的图片语义特征能够反映用户的兴趣爱好，这样，在一个用户提交查询请求时，本申请能够依据所得到目标图片的关键词和所述搜索日志中目标图片的关键词，匹配得到具有相同兴趣爱好的其它用户查询得到的对应目标图片，也即与关键词匹配的相应目标图片能够契合用户的兴趣爱好。</p>
    <p>[0119]	在本申请的一种优选实施例中，在将与关键词匹配的相应目标图片推荐给用户前，所述方法还可以包括：[0120]	在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；</p>
    <p>[0121]	所述将与关键词匹配的相应目标图片推荐给用户的步骤可以为，将所述剩余图片推荐给用户。</p>
    <p>[0122]	前面提到，在理想情况下，在与关键词对应的各目标图片中，相同或近似的两幅图片通常仅具有是否带水印、小图片和大图片的差别等细微差别相同或近似；另外，与关键词匹配的相应各目标图片是依据描述图片语义特征的关键词匹配得到的；因此，可以认为，与关键词匹配的相应各目标图片中如果存在两幅或两副以上相同或近似的图片，则没有推荐的意义，故对其进行滤除。</p>
    <p>[0123]	在本申请的另一种优选实施例中，所述将与关键词匹配的相应目标图片推荐给用户的步骤，可以进一步包括：</p>
    <p>[0124]	依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；</p>
    <p>[0125]	按照在线查询请求数目的降序将相应与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0126]	在某些情况下，所述与关键词匹配的相应各目标图片的数目可能为大数目，如100 幅以上，这些大数目的图片是否契合用户个性化需求难以预料，且需要分多页将这些大数目的图片在浏览器中显示，使用户需要从多页中提取自己所需要的内容。</p>
    <p>[0127]	本优选实施例按照在线查询请求数目的降序将相应与关键词匹配的相应目标图片推荐给用户，在线查询请求数目越多表明相应的图片越被具有相同兴趣爱好的用户所关注，也即，本申请能够优先推荐在线查询请求数目多关注度高的图片，因此，优先推荐的图片能够更好地契合用户个性化需求，增加用户的使用体验。</p>
    <p>[0128]	本申请可以提供如下场景中的应用示例：</p>
    <p>[0129]	应用示例I、</p>
    <p>[0130]	步骤BI、接收用户上传的刘德华的图片，并以该图片进行搜索得到该图片对应的目标图片和与目标图片相同或近似的结果图片；</p>
    <p>[0131]	步骤B2、依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为刘德华的图片的关键词，例如“刘德华电影”、“刘德华经典电影”、“刘德华写真”等；</p>
    <p>[0132]	步骤B3、在搜索日志中进行关键词的匹配，得到其他同样喜欢刘德华的用户上传的反映兴趣爱好对应的目标图片（如刘德华的电影海报、个人写真等更多的刘德华的相关图片），并推荐给用户。</p>
    <p>[0133]	应用示例2、</p>
    <p>[0134]	步骤Cl、接收用户上传的《失恋33天》电影海报；通过该电影海报搜索得到对应的目标图片和与目标图片相同或近似的结果图片；</p>
    <p>[0135]	步骤C2、依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词，如“失恋33天”等；</p>
    <p>[0136]	步骤C3、在搜索日志中进行关键词的匹配，得到其他喜欢《失恋33天》这部电影的用户上传的反映兴趣爱好对应的目标图片（例如该电影的不同海报），并推荐给用户。</p>
    <p>[0137]	为使本领域技术人员更好地理解本申请，以下提供本申请一种图片搜索引擎中推荐明星图片的方法示例的流程图，具体可以包括：</p>
    <p>[0138]	步骤I、接收用户上传的金发的妮可基德曼照片；[0139]	步骤2、从金发的妮可基德曼照片中抽取视觉特征，与数据库中图片的视觉特征进行比对，得到与金发的妮可基德曼照片的视觉内容一致的目标图片和结果图片；</p>
    <p>[0140]	步骤3、对结果图片的网页文本进行聚类分析，将那些未聚集在一起的孤立文本视为噪音去除掉，抽取剩余文本中词频最高并具有实际意义的词或短语，作为关键词；</p>
    <p>[0141]	例如,表4示出了本申请一种剩余文本中的词频示例。</p>
    <p>[0142]表	4</p>
    <p>[0143]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00161.png"> <img id="idf0007" file="CN102609458AD00161.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00161.png" class="patent-full-image" alt="Figure CN102609458AD00161"> </a> </div>
    <p>[0144]	其中，词频最高的“他们”没有实际意义，因此最终得到的关键词为“妮可基德曼”。</p>
    <p>[0145]	步骤4、图片搜索引擎的搜索日志中记录有全网用户提交的在线查询请求对应的目标图片及相应的关键词；</p>
    <p>[0146]	步骤5、抽取到目标图片的关键词后，通过关键词匹配（是否相同，互相包含或有所重叠），查询得到与各关键词有语义关联的目标图片；</p>
    <p>[0147]	步骤6、在滤除掉查询结果中与当前查询对应的目标图片相同或近似的目标图片后，统计搜索日志中剩余图片的在线查询请求数目，并将在线查询请求数目最多的部分图片推荐给用户。</p>
    <p>[0148]	例如，当关键词为“妮可基德曼”时，搜索日志中与“妮可基德曼”相关联的关键词及这些关键词对应图片的在线查询请求数目如表4所示，</p>
    <p>[0149]表	4</p>
    <p>[0150]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00162.png"> <img id="idf0008" file="CN102609458AD00162.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609458A/CN102609458AD00162.png" class="patent-full-image" alt="Figure CN102609458AD00162"> </a> </div>
    <p>[0151]</p>
    <p>[0152]	如果为用户推荐2幅图片，那么本申请将推荐图片a与图片b。[0153]	首先，上述方法示例能够通过图片搜索引擎抽取出关键词以描述目标图片的图片语义特征，如照片中明星的名字。</p>
    <p>[0154]	其次，上述方法示例能够为用户提供具有相同语义特征的图片作为推荐内容，也即能够提供契合用户个性化需求的图片素材。这样，当目标图片为金发的妮可基德曼照片时，可推荐关于该明星的不同图片，如该明星其他头发颜色的照片；而不是仅推荐视觉相似的图片。</p>
    <p>[0155]	与前述方法实施例相应，本申请还提供了一种图片推荐装置，参照图3，具体可以包括：</p>
    <p>[0156]	图片搜索模块301，用于接收用户的查询请求，并搜索得到与该查询请求对应的目标图片和与该目标图片相同或近似的结果图片；</p>
    <p>[0157]	关键词抽取模块302，用于依据所述结果图片所在的网页文本，抽取描述图片语义特征的关键词，作为该目标图片的关键词；</p>
    <p>[0158]	匹配模块303，用于在搜索日志中进行关键词的匹配；所述搜索日志记录有全网用户的在线查询请求对应的目标图片及相应的关键词；及</p>
    <p>[0159]	图片推荐模块304，用于将与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0160]	在本申请实施例中，优选的是，该目标图片为与该查询请求对应的查询策略最匹配的图片；所述结果图片为服务器端的数据库中除目标图片外大于匹配阈值的其他图片。</p>
    <p>[0161]	在本申请的一种优选实施例中，所述关键词抽取模块302可以进一步包括：</p>
    <p>[0162]	去除子模块，用于依据对所述网页文本进行聚类分析的结果，去除所述网页文本中孤立的网页文本，得到剩余文本；及</p>
    <p>[0163]	抽取子模块，用于抽取所述剩余文本中词频最高并具有实际意义的词或短语，作为描述图片语义特征的关键词。</p>
    <p>[0164]	在本申请的另一种优选实施例中，所述装置还可以包括：</p>
    <p>[0165]	第一实际意义抽取模块，用于依据预先构造的实体词库，抽取所述剩余文本中具有实际意义的词或短语，所述实体词库存储有具有实际意义的实体词，所述抽取过程包括: 在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述剩余文本中的词或短语。</p>
    <p>[0166]	在本申请的再一种优选实施例中，所述装置还可以包括：</p>
    <p>[0167]	第二实际意义抽取模块，用于调用预先构造的实体词库，在所述剩余文本中的词或短语与所述实体词库中的实体词相匹配时，保留所述剩余文本中的词或短语；所述实体词库存储有具有实际意义的实体词。</p>
    <p>[0168]	在本申请的一种优选实施例中，所述关键词抽取模块302还可以包括：</p>
    <p>[0169]	边缘词统计子模块，用于依据所述关键词与所述剩余文本中其他词汇的相邻共现频率，统计所述剩余文本中与所述关键词相邻的边缘词；将所述边缘词与关键词一起作为描述图片语义特征的关键词。</p>
    <p>[0170]	在本申请实施例中，优选的是，所述装置还可以包括：</p>
    <p>[0171]	滤除模块，用于在与关键词匹配的相应各目标图片中滤除相同或近似的图片，得到剩余图片；</p>
    <p>[0172]	此时，所述图片推荐模块304，可具体用于将所述剩余图片推荐给用户。[0173]	在本申请实施例中，优选的是，所述图片推荐模块304具体可以包括：</p>
    <p>[0174]	数目统计子模块，用于依据所述搜索日志，统计所述与关键词匹配的相应目标图片对应的在线查询请求数目；及</p>
    <p>[0175]	降序推荐子模块，用于按照在线查询请求数目的降序将相应与关键词匹配的相应目标图片推荐给用户。</p>
    <p>[0176]	对于装置实施例而言，由于其与方法实施例基本相似，所以描述的比较简单，相关之处参见方法实施例的部分说明即可。</p>
    <p>[0177]	本说明书中的各个实施例均采用递进的方式描述，每个实施例重点说明的都是与其他实施例的不同之处，各个实施例之间相同相似的部分互相参见即可。</p>
    <p>[0178]	以上对本申请所提供的一种图片推荐方法和装置，进行了详细介绍，本文中应用了具体个例对本申请的原理及实施方式进行了阐述，以上实施例的说明只是用于帮助理解本申请的方法及其核心思想；同时，对于本领域的一般技术人员，依据本申请的思想，在具体实施方式及应用范围上均会有改变之处，综上所述，本说明书内容不应理解为对本申请的限制。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101241512A?cl=zh">CN101241512A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年3月10日</td><td class="patent-data-table-td patent-date-value">2008年8月13日</td><td class="patent-data-table-td ">北京搜狗科技发展有限公司</td><td class="patent-data-table-td ">一种重新定义查询词的搜索方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102270234A?cl=zh">CN102270234A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年8月1日</td><td class="patent-data-table-td patent-date-value">2011年12月7日</td><td class="patent-data-table-td ">北京航空航天大学</td><td class="patent-data-table-td ">一种图像搜索方法及其搜索引擎</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040267740">US20040267740</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年7月28日</td><td class="patent-data-table-td patent-date-value">2004年12月30日</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Image retrieval systems and methods with semantic and feature based relevance feedback</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102831176A?cl=zh">CN102831176A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月30日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">东莞宇龙通信科技有限公司</td><td class="patent-data-table-td ">推荐好友的方法及服务器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103064903A?cl=zh">CN103064903A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月18日</td><td class="patent-data-table-td patent-date-value">2013年4月24日</td><td class="patent-data-table-td ">厦门市美亚柏科信息股份有限公司</td><td class="patent-data-table-td ">图片检索方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015139487A1?cl=zh">WO2015139487A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年12月10日</td><td class="patent-data-table-td patent-date-value">2015年9月24日</td><td class="patent-data-table-td ">百度在线网络技术（北京）有限公司</td><td class="patent-data-table-td ">搜索推荐方法和装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=GC2PBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年7月25日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年3月6日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年8月5日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/4507eda69a1b119caabe/CN102609458A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9B%BE%E7%89%87%E6%8E%A8%E8%8D%90%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE.pdf?id=GC2PBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U11PxvHzIUbodLWjSE8_0D2MP9wKA"},"sample_url":"https://www.google.com/patents/reader?id=GC2PBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>