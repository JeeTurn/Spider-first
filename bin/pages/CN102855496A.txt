<!DOCTYPE html><html><head><title>专利 CN102855496A - 遮挡人脸认证方法及系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="遮挡人脸认证方法及系统"><meta name="DC.contributor" content="徐汀荣" scheme="inventor"><meta name="DC.contributor" content="苏州大学" scheme="assignee"><meta name="DC.date" content="2012-8-24" scheme="dateSubmitted"><meta name="DC.description" content="本申请公开了一种遮挡人脸认证方法及系统，其中方法包括：S1、采集人脸视频图像；S2、对所采集的人脸视频图像进行预处理；S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监督1-NN近邻法的SVM二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。该遮挡人脸认证方法有效地提高局部遮挡人脸检测率和检测速度。"><meta name="DC.date" content="2013-1-2"><meta name="DC.relation" content="CN:101369310:A" scheme="references"><meta name="DC.relation" content="CN:101398886:A" scheme="references"><meta name="DC.relation" content="CN:101794385:A" scheme="references"><meta name="DC.relation" content="JP:2007304721" scheme="references"><meta name="citation_reference" content="曹红根，袁宝华，朱辉生: &quot;《结合对比度信息与LBP 的分块人脸识别》&quot;, 《山东大学学报( 工学版)》, vol. 42, no. 4, 20 August 2012 (2012-08-20)"><meta name="citation_patent_publication_number" content="CN:102855496:A"><meta name="citation_patent_application_number" content="CN:201210303885"><link rel="canonical" href="https://www.google.com/patents/CN102855496A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102855496A?cl=zh"/><meta name="title" content="专利 CN102855496A - 遮挡人脸认证方法及系统"/><meta name="description" content="本申请公开了一种遮挡人脸认证方法及系统，其中方法包括：S1、采集人脸视频图像；S2、对所采集的人脸视频图像进行预处理；S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监督1-NN近邻法的SVM二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。该遮挡人脸认证方法有效地提高局部遮挡人脸检测率和检测速度。"/><meta property="og:title" content="专利 CN102855496A - 遮挡人脸认证方法及系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102855496A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102855496A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=mwq3BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102855496A&amp;usg=AFQjCNHpzJyY70dO4qcW7WoICgybFqtTBQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/1cf3dcd03a02f6155ea6/CN102855496A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/1cf3dcd03a02f6155ea6/CN102855496A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102855496A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102855496A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102855496A?cl=zh" style="display:none"><span itemprop="description">本申请公开了一种遮挡人脸认证方法及系统，其中方法包括：S1、采集人脸视频图像；S2、对所采集的人脸视频图像进行预处理；S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计...</span><span itemprop="url">https://www.google.com/patents/CN102855496A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102855496A - 遮挡人脸认证方法及系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102855496A - 遮挡人脸认证方法及系统" title="专利 CN102855496A - 遮挡人脸认证方法及系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102855496 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210303885</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年1月2日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年8月24日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年8月24日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210303885.3, </span><span class="patent-bibdata-value">CN 102855496 A, </span><span class="patent-bibdata-value">CN 102855496A, </span><span class="patent-bibdata-value">CN 201210303885, </span><span class="patent-bibdata-value">CN-A-102855496, </span><span class="patent-bibdata-value">CN102855496 A, </span><span class="patent-bibdata-value">CN102855496A, </span><span class="patent-bibdata-value">CN201210303885, </span><span class="patent-bibdata-value">CN201210303885.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BE%90%E6%B1%80%E8%8D%A3%22">徐汀荣</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%8B%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%22">苏州大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102855496A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102855496A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102855496A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=mwq3BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210303885&amp;usg=AFQjCNGnDfDMBQHtJMeXSj6LxUtVBpSNng"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=mwq3BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102855496A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEM0DdrqmXWQLNQAJfF1_ccUL96Hw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT118432552" lang="ZH" load-source="patent-office">遮挡人脸认证方法及系统</invention-title>
      </span><br><span class="patent-number">CN 102855496 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA103873143" lang="ZH" load-source="patent-office">
    <div class="abstract">本申请公开了一种遮挡人脸认证方法及系统，其中方法包括：S1、采集人脸视频图像；S2、对所采集的人脸视频图像进行预处理；S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监督1-NN近邻法的SVM二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。该遮挡人脸认证方法有效地提高局部遮挡人脸检测率和检测速度。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM47941462" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种遮挡人脸认证方法，其特征在于，所述方法包括以下步骤：  S1、采集人脸视频图像；  S2、对所采集的人脸视频图像进行预处理，所述预处理包括：光照预处理、噪声滤波处理以及几何归�化和尺度归�化处理；  S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；  S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监瞀I-NN近邻法的SVM 二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的方法，其特征在于，所述步骤S3中的Adaboost算法进行进一步人脸位置的确认具体为：  S31、获取正负样本的特征，并用积分图的特征表示法进行计算；  S32、通过学习算法，为每个特征设计�个正确率高于50%的弱分类器；  S33、调整样本权值，多次循环提取错误率最低的弱分类器，构成强分类器；  S34、串联多个强分类器，构成级联分类器，进行人脸检&#28204;。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求I所述的方法，其特征在于，所述步骤S33中强分类器的算法具体为：    S331、给定的训练样本集：（X1,	Y1), (x2, y2), &#183;&#183;&#183;, (xm，ym),其中 Xi e X，yi e {-1,+1}；  S332、对样本权值进行初始化，对于非人脸样本：Dt(i)=l/2m，其中m为非人脸样本数目，对于人脸样本：Dt (i) =l/2n，其中η为人脸样本数目；  S333、经过T轮迭代后，可得T个弱分类器，循环&#912;=1，2&#183;&#183;&#183;，Τ	;  在当前样本权重分布Dt下，针对每个单个矩形特征训练�个弱分类器，并从中选取错误率最小的弱分类器ht;  对于选定的弱分类器ht，计算其加权错误率<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00021.png"> <img id="icf0001" file="CN102855496AC00021.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00021.png" class="patent-full-image" alt="Figure CN102855496AC00021"> </a> </div>  求解弱分类器ht的加权&#21443;数为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00022.png"> <img id="icf0002" file="CN102855496AC00022.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00022.png" class="patent-full-image" alt="Figure CN102855496AC00022"> </a> </div>  为下次循环更新样本权重，<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00023.png"> <img id="icf0003" file="CN102855496AC00023.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00023.png" class="patent-full-image" alt="Figure CN102855496AC00023"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00024.png"> <img id="icf0004" file="CN102855496AC00024.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00024.png" class="patent-full-image" alt="Figure CN102855496AC00024"> </a> </div>  S334、计算得最终强分类器为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00025.png"> <img id="icf0005" file="CN102855496AC00025.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00025.png" class="patent-full-image" alt="Figure CN102855496AC00025"> </a> </div>其中Th为手动设定满足正                                                              T样本错误率的阈值，进�步定义H(X)置信度为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00026.png"> <img id="icf0006" file="CN102855496AC00026.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00026.png" class="patent-full-image" alt="Figure CN102855496AC00026"> </a> </div>                                                                                                                           O</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3所述的方法，其特征在于，所述步骤S34中的级联分类器的算法具体为：  .5341、设定级联分类器每层强分类器的最小检测率Cli和最大误检率も； . 5342、设定级联分类器的目标误检率T，级联分类器检测率为Di,级联分类器的误检率为&amp;，其中i为级联分类器的层数；  .5343、给定人脸训练样本集合M和负训练样本集合N，并根据式<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00031.png"> <img id="icf0007" file="CN102855496AC00031.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00031.png" class="patent-full-image" alt="Figure CN102855496AC00031"> </a> </div>式与<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00032.png"> <img id="icf0008" file="CN102855496AC00032.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00032.png" class="patent-full-image" alt="Figure CN102855496AC00032"> </a> </div>ズ初                                      始化 Dtl=I, F0=I ；   .5344、初始化层数i=0	；  .5345、循环迭代，直至满足条件Fi≥T	;  采用Adaboost算法训练包含n1个Haar特征的第i层强分类器；  计算当前层强分类器的检测率Di和误检率Fi ；  调整第i层强分类器的阈值，使当前层的检测率满足DiMiXDg ；  .5346、若FiXT,则通过该层分类器对样本图像进行检测，将分类正确的负样本排除，将分类错误的负样本图像归入N。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的方法，其特征在于，所述步骤S3前还包括抽取关键样本，具体为：   给定标定的训练样本集：（X1, Yi)，(x2, y2)，…，(xm, ym)，其中 Xi e X&#187; Yi e H，+1}；给定关键样本集Xk= {xj，样本对应的权值集合W = {1,0,…，0}，wn e W，次要样本集Y= 0,定义d( &#183;)为向量间欧氏距离：   若Xi e X-XkAx' j e Xk时计算d(xi，x 'ふ定义<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00033.png"> <img id="icf0009" file="CN102855496AC00033.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00033.png" class="patent-full-image" alt="Figure CN102855496AC00033"> </a> </div>   判断是否满足d (Xi, χ ; η)&gt; α ,若满足,则X=X- {xj , Xe=Xe U {xj ,赋值wn = Wn+1 ;若不满足，再判断是否满足(Kxi, χ ' η)〈β ,若是,赋值wn = wn+l,若否,则X=X-{xJ, Y=Y U {xj ；    若 Xi e Y，在 χ ' j e Xe 时计算 d (Xi, χ ' p，定义<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00034.png"> <img id="icf0010" file="CN102855496AC00034.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00034.png" class="patent-full-image" alt="Figure CN102855496AC00034"> </a> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求4所述的方法，其特征在干，所述步骤S3对遮挡人脸进行检测具体为：  分别提取人的嘴巴、眼睛、鼻子的特征进行弱分类器的训练，生成三个独立的检测器，并与全脸的检测器并联一起，构成并行的多瀑布人脸检测器，使用多瀑布人脸检测器对遮挡人脸进行检&#28204;。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的方法，其特征在干，所述步骤S4对遮挡人脸进行计算具体为：  设置加速比&#21443;数α &gt;0，初始化扫描窗ロ大小，初始化窗ロ移动步长，初始检测框取训练样本图片大小；  采用并行级联分类器的前四层的遮挡估计器，对待检测区域图像进行固定步长扫描，并记录下每个位置的置信度val ； 计算所有位置的平均置信度&amp;，记下所有置信度大于的点为可能性较高的人脸位置，对可能存在人脸的位置采用自适应步长进行高分辨率扫描，自适应步长计算公式为<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00041.png"> <img id="icf0011" file="CN102855496AC00041.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00041.png" class="patent-full-image" alt="Figure CN102855496AC00041"> </a> </div> 其中，％为上次检测框中通过的强分类器数目，η为总共的强分类器数目，μ为调整因子；  判断是否已扫描完所有图像，若否则改变扫描窗ロ大小，继续扫描。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求I所述的方法，其特征在于，所述步骤S4中结合监瞀I-NN近邻法的SVM 二分算法具体为：  541、将人脸分块为6个可单独用于识别的区域，通过寻找最优主元重建样本，从而对人脸向量进行降&#32173;，经过降维处理后，每个分块均对应�个PCA降维向量，继而通过SVM分类器进行验证是否为遮挡人脸；<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00042.png"> <img id="icf0012" file="CN102855496AC00042.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00042.png" class="patent-full-image" alt="Figure CN102855496AC00042"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00043.png"> <img id="icf0013" file="CN102855496AC00043.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00043.png" class="patent-full-image" alt="Figure CN102855496AC00043"> </a> </div>542、定义训练样本集<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00044.png"> <img id="icf0014" file="CN102855496AC00044.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00044.png" class="patent-full-image" alt="Figure CN102855496AC00044"> </a> </div>计算h与L分类面的距离<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00045.png"> <img id="icf0015" file="CN102855496AC00045.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00045.png" class="patent-full-image" alt="Figure CN102855496AC00045"> </a> </div>若满足|f(Zj) I彡1，直接应用SVM分类器，若不满足|f(Zj) I彡1，则计算I Izj-XiI I，获取Zj附近最近的训练样本ζ' j，如果。j表示被遮挡，则Zj也被遮挡，如果z , j表示未被遮挡，再比较I I Zj-Xi I I与系统阈值的大小，若I Izj-XiI I小于系统阈值,则Zj未被遮挡,否则Zj被遮挡；  543、提取剩余人脸分块的LBP纹理特征，并对剩余人脸分块的分类能力进行分析，进行加权人脸识别，具体为分别计算6个区域的类间散度矩阵和类内散度矩阵 _ r'<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00046.png"> <img id="icf0016" file="CN102855496AC00046.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00046.png" class="patent-full-image" alt="Figure CN102855496AC00046"> </a> </div>块的类间类内散度矩阵进行权重估计，公式为：            <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00047.png"> <img id="icf0017" file="CN102855496AC00047.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00047.png" class="patent-full-image" alt="Figure CN102855496AC00047"> </a> </div>                                                                                                           O</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的方法，其特征在于，所述LBP特征向量之间相似度算法如下：  给定特征向量集It (t=l, 2，...，6)，分别属于C个人，其中t为人脸分块标签，&lt; e Rd%第i类的第m个LBP特征向量，每类特征向量子集可表示4 =W，4…&#20034;]&#183;Gram-Schmidt正交化姆类特征向量子集4，新特征向量子集表示为4 =[ζ“:&#943;，…，:U .给定测试特征向量Xtost，并在相对应特征向量子集4’的子空间以4')进行投影，得投影向量如<div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00048.png"> <img id="icf0018" file="CN102855496AC00048.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00048.png" class="patent-full-image" alt="Figure CN102855496AC00048"> </a> </div>                                                                                             5   计算对应人脸分块的相似度 <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00049.png"> <img id="icf0019" file="CN102855496AC00049.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AC00049.png" class="patent-full-image" alt="Figure CN102855496AC00049"> </a> </div>  类属"; = mp(ZH:./0其中Wt为分块权值。                                             5</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.	�种根据权利要求I所述的遮挡人脸认证系统，其特征在于，所述系统包括：  图像采集模块，用于捕获视频文件或者USB摄像头视频的视频帧，并保存捕获到的视频图像帧；图像预处理模块，用于完成图像的光照预处理、噪声滤波处理以及几何归�化和尺度归�化处理，消除包括光照、噪声、姿态对人脸后续处理的不利影响；  特征训练模块，用于完成对检测模块的Adaboost人脸检测器的Haar特征训练以及对人脸样本库分块LBP特征的提取，特征训练模块借助matlab图像处理和矩阵操作功能实现离线特征训练；   人脸检测和定位模块，用于对已经训练好的人脸Haar特征，包括整脸、眼睛、嘴巴、鼻子，对人脸进行自适应步长的多尺度&#25436;索，同时对于视频序列，在检测前通过视频序列间的运动信息对人脸位置进行预估计；  人脸识别模块，用于完成人脸图像特征的提取以及匹配，最&#32066;完成人脸识别，输出结果，人脸识别模块通过将目标人脸图像分块，剔除遮挡人脸分块，然后提取剩余人脸分块的LBP纹理特征，最后与人脸库中相对应的分块LBP纹理特征进行匹配识别。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES55032703" lang="ZH" load-source="patent-office" class="description">
    <p>遮挡人脸认证方法及系统</p>
    <p>技术领域</p>
    <p>[0001]	本申请涉及图像处理技术领域，尤其涉及一种遮挡人脸认证方法及系统。</p>
    <p>背景技术</p>
    <p>[0002]	随着科学技术的不断发展和IT产业的高速推进，社会各个领域对自动身份鉴别的要求日益突出，如何快速有效地对目标人物的身份进行识别已成为一个急需解决的热点问题。目前目标人物的身份鉴定仍然主要依靠公民身份证、工作证、个人密码等传统身份验证方式，这些方式存在着携带麻烦、易遗失和易伪造等弊端。随着光电技术、微计算机技术、图像处理技术与模式识别技术的发展，生物特征识别技术不断发展，逐步成为国内外热门的新兴学科。生物特征识别技术依据自动化测量身体特征，并将这些特征与数据库进行比较来实现目标鉴别，目前已经成为信息社会中不可缺少的身份识别方法。</p>
    <p>[0003]目前，常被用来鉴定身份的生物特征主要有指纹、人脸、虹膜、DNA等。这些特征为每个人体与生俱来的，具有唯一性和稳定性，不易伪造和复制。人脸特征用于身份鉴定的研究始于20世纪60年代中期，与上述其他生物特征相比较，虽然准确度不如指纹、虹膜等，但其具有简单经济的优点，整个鉴定过程中完全不需要接触目标，不易被目标人物察觉。人脸认证技术有以下几个优点：</p>
    <p>[0004]	(I)非接触式采集</p>
    <p>[0005]	人脸图像的获取不必与被监测人有任何身体接触，具有不被侵犯性、容易被接受等特点。人脸图像可通过各类摄像头进行采集，其操作不易被察觉，特别适用于监控特殊场合中的违法行为，而指纹采集、虹膜识别等却不易实现。</p>
    <p>[0006]	(2)设备简单且成本低</p>
    <p>[0007]	一般地，人脸监控识别系统只需要安装普通的摄像头或者摄像机即可。目前市场上这些设备的价格已经十分低廉。另外如今摄像头已经成为电子设备的标准外设，人脸认证技术的实用空间得到了极大的扩展。</p>
    <p>[0008]	(3)直观性</p>
    <p>[0009]	人脸认证技术的判定依据是人的面部信息，而人脸同时也是人眼进行身份判别的最直观的信息源。“以貌取人”与人类认知规律相符，相比虹膜识别、指纹识别更易于被人们所理解接受。人脸识别符合人类的识别习惯，更有利于改善人机交互界面。</p>
    <p>[0010]	(4)便于事后追踪</p>
    <p>[0011]	人脸认证系统在监控中的目标事件发生后，将目标人物的图像记录下来并存档，可供人工核实判断，方便于事后追踪。</p>
    <p>[0012]	人脸包含着丰富的细节信息，而人脸认证的本质是对三维柔性物体的二维投影图像进行匹配的问题，这一切使得人脸检测与识别成为极富挑战性的研究课题，归纳起来目前人脸监控识别系统存在的主要困难有：</p>
    <p>[0013]	(I)人脸柔性物体的不确定性，如姿态变化、表情变化、头部旋转等。</p>
    <p>[0014]	(2)人脸遮挡问题，如头发、饰物、胡须等遮挡。[0015]	(3)年龄因素，人脸某些局部特征会随着年龄增长而逐渐变化。</p>
    <p>[0016]	(4)图像成像环境，如光照问题、成像设备性能等。</p>
    <p>[0017]	对于人脸认证系统而言，遮挡是个不可避免的问题，特别是在安全领域中尤其突出。在实际应用中，比如智能门禁、视频监控、保安系统、罪犯识别等，基本均在非配合的环境下进行人脸图像的采集，易被其他人或者物所遮挡。造成遮挡的原因是多种多样，包括自身的墨镜、围巾等饰物的遮挡或者外景物的遮挡。这些干扰因素使得成像设备获取的人脸数据不完整，系统无法提取完整有效的人脸信息，影响了整个人脸认证系统检测和识别的准确率。如何有效去除遮挡物的影响，成为了人脸检测与识别技术中亟待解决的关键问题。</p>
    <p>[0018]	综上所述，有必要提供一种遮挡人脸认证方法及系统以解决上述问题。</p>
    <p>发明内容</p>
    <p>[0019]	有鉴于此，本发明提供一种遮挡人脸认证方法及系统，有效的提高了遮挡人脸认证中的检测率和检测速度。</p>
    <p>[0020]	为了实现上述目的，本申请实施例提供的技术方案如下：</p>
    <p>[0021]	一种遮挡人脸认证方法，所述方法包括以下步骤：</p>
    <p>[0022]	SI、采集人脸视频图像；</p>
    <p>[0023]	S2、对所采集的人脸视频图像进行预处理，所述预处理包括：光照预处理、噪声滤波处理以及几何归一化和尺度归一化处理；</p>
    <p>[0024]	S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；</p>
    <p>[0025]	S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监督I-NN近邻法的SVM 二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。</p>
    <p>[0026]	作为本发明的进一步改进，所述步骤S3中的Adaboost算法进行进一步人脸位置的确认具体为：</p>
    <p>[0027]	S31、获取正负样本的特征，并用积分图的特征表示法进行计算；</p>
    <p>[0028]	S32、通过学习算法，为每个特征设计一个正确率高于50%的弱分类器；</p>
    <p>[0029]	S33、调整样本权值，多次循环提取错误率最低的弱分类器，构成强分类器；</p>
    <p>[0030]	S34、串联多个强分类器，构成级联分类器，进行人脸检测。</p>
    <p>[0031]	作为本发明的进一步改进，所述步骤S33中强分类器的算法具体为：</p>
    <p>[0032]	S331、给定的训练样本集=(X1J1), (x2, J2),…，(xm, ym),其中 Xi G X,Ji G 1~1，+1};</p>
    <p>[0033]	S332、对样本权值进行初始化，对于非人脸样本：Dt(i)=l/2m，其中m为非人脸样本数目，对于人脸样本：Dt (i) =l/2n，其中n为人脸样本数目；</p>
    <p>[0034]	S333、经过T轮迭代后，可得T个弱分类器，循环t=l，2…，T ；</p>
    <p>[0035]	在当前样本权重分布Dt下，针对每个单个矩形特征训练一个弱分类器，并从中选取错误率最小的弱分类器ht;[0036]对于选定的弱分类器ht，计算其加权错误率=</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00081.png"> <img id="idf0001" file="CN102855496AD00081.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00081.png" class="patent-full-image" alt="Figure CN102855496AD00081"> </a> </div>
    <p>[0037]	求解弱分类器ht的加权参数为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00082.png"> <img id="idf0002" file="CN102855496AD00082.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00082.png" class="patent-full-image" alt="Figure CN102855496AD00082"> </a> </div>
    <p>                                                                                                ?</p>
    <p>[0038]	为下次循环更新样本权重，</p>
    <p>     [0039]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00083.png"> <img id="idf0003" file="CN102855496AD00083.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00083.png" class="patent-full-image" alt="Figure CN102855496AD00083"> </a> </div>
    <p>[0040]	S334、计算得最终强分类器为=</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00084.png"> <img id="idf0004" file="CN102855496AD00084.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00084.png" class="patent-full-image" alt="Figure CN102855496AD00084"> </a> </div>
    <p>其中Th为手动设定满</p>
    <p>                                                                                  T</p>
    <p>足正样本错误率的阈值，进一步定义H(X)置信度为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00085.png"> <img id="idf0005" file="CN102855496AD00085.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00085.png" class="patent-full-image" alt="Figure CN102855496AD00085"> </a> </div>
    <p>                                                                                                     T=I</p>
    <p>                                                                                                                                   o</p>
    <p>[0041]	作为本发明的进一步改进，所述步骤S34中的级联分类器的算法具体为：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00086.png"> <img id="idf0006" file="CN102855496AD00086.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00086.png" class="patent-full-image" alt="Figure CN102855496AD00086"> </a> </div>
    <p>[0042]	S341、设定级联分类器每层强分类器的最小检测率Cli和最大误检率&amp; ；</p>
    <p>[0043]	S342、设定级联分类器的目标误检率T，级联分类器检测率为Di,级联分类器的误检率为Fi，其中i为级联分类器的层数；</p>
    <p>[0044]	S343、给定人脸训练样本集合M和负训练样本集合N，并根据式D = I卜/,_与</p>
    <p>                                                                                                                                               /=1</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00087.png"> <img id="idf0007" file="CN102855496AD00087.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00087.png" class="patent-full-image" alt="Figure CN102855496AD00087"> </a> </div>
    <p>[0045]	S344、初始化层数i=0 ；</p>
    <p>[0046]	S345、循环迭代，直至满足条件Fi彡T ;</p>
    <p>[0047]	采用Adaboost算法训练包含Iii个Haar特征的第i层强分类器；</p>
    <p>[0048]	计算当前层强分类器的检测率Di和误检率Fi ；</p>
    <p>[0049]	调整第i层强分类器的阈值，使当前层的检测率满足DiMiXDp1 ；</p>
    <p>[0050]	S346、若FiXT,则通过该层分类器对样本图像进行检测，将分类正确的负样本排除，将分类错误的负样本图像归入N。</p>
    <p>[0051]	作为本发明的进一步改进，所述步骤S3前还包括抽取关键样本，具体为：</p>
    <p>[0052]给定标定的训练样本集:(X1,	Y1)，(x2, y2)，…，(xm, ym)，其中 Xi G X^i G {-I, +1}；</p>
    <p>[0053]	给定关键样本集Xk= IxJ，样本对应的权值集合W = {I, 0，…，0} ,wn G W，次要样本集Y=	0,定义(!（&#8226;）为向量间欧氏距离：</p>
    <p>[0054]若	Xi G X-Xe,在 X ' j G Xe 时计算 d (x,, x ' j),定义</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00088.png"> <img id="idf0008" file="CN102855496AD00088.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00088.png" class="patent-full-image" alt="Figure CN102855496AD00088"> </a> </div>
    <p>) &#8226;</p>
    <p>[0055]判断是否满足	d (Xi, x ' n) &gt; a，若满足，则 X=X- {xj，Xe=Xe U {xj，赋值 wn=wn+1 ;若不满足，再判断是否满足d (Xi, X ; n)〈 P ,若是，赋值wn = Wn+1 ,若否，贝IjX=X-{xj, Y=Y U {xj ；[0056]若	Xi e Y，在 X ' J G Xe 时计算 d(Xi, X ' P，定义</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00091.png"> <img id="idf0009" file="CN102855496AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00091.png" class="patent-full-image" alt="Figure CN102855496AD00091"> </a> </div>
    <p>                                                                                                                                      o</p>
    <p>[0057]	作为本发明的进一步改进，所述步骤S3对遮挡人脸进行检测具体为：</p>
    <p>[0058]	分别提取人的嘴巴、眼睛、鼻子的特征进行弱分类器的训练，生成三个独立的检测器，并与全脸的检测器并联一起，构成并行的多瀑布人脸检测器，使用多瀑布人脸检测器对遮挡人脸进行检测。</p>
    <p>[0059]	作为本发明的进一步改进，所述步骤S4对遮挡人脸进行计算具体为：</p>
    <p>[0060]	设置加速比参数a &gt; 0，初始化扫描窗口大小，初始化窗口移动步长，初始检测框取训练样本图片大小；</p>
    <p>[0061]	采用并行级联分类器的前四层的遮挡估计器，对待检测区域图像进行固定步长扫描，并记录下每个位置的置信度val ；</p>
    <p>[0062]	计算所有位置的平均置信度记下所有置信度大于的点为可能性较高的人脸位置，对可能存在人脸的位置采用自适应步长进行高分辨率扫描，自适应步长计算公</p>
    <p>式为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00092.png"> <img id="idf0010" file="CN102855496AD00092.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00092.png" class="patent-full-image" alt="Figure CN102855496AD00092"> </a> </div>
    <p>其中，％为上次检测框中通过的强分类器数目，n为总共的强</p>
    <p>                                                ，</p>
    <p>分类器数目，y为调整因子；</p>
    <p>[0063]	判断是否已扫描完所有图像，若否则改变扫描窗口大小，继续扫描。</p>
    <p>[0064]	作为本发明的进一步改进，所述步骤S4中结合监督I-NN近邻法的SVM 二分算法具体为：</p>
    <p>[0065]	S41、将人脸分块为6个可单独用于识别的区域，通过寻找最优主元重建样本，从而对人脸向量进行降维，经过降维处理后，每个分块均对应一个PCA降维向量，继而通过SVM分类器进行验证是否为遮挡人脸；</p>
    <p>[0066]	S42、定义训练样本集 TtrainIxi |i = 1，2，3-m}，测试样本集 Ttest Izj | j=l，2，3-n}；</p>
    <p>[0067]计算分类面的距离</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00093.png"> <img id="idf0011" file="CN102855496AD00093.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00093.png" class="patent-full-image" alt="Figure CN102855496AD00093"> </a> </div>
    <p>若满足|f(Zj) I彡1，直接</p>
    <p>应用SVM分类器，若不满足|f(zj }彡1，则计算I IzpciI |，获取\附近最近的训练样本z' j,如果z, j表示被遮挡，则Zj也被遮挡，如果z, j表示未被遮挡，再比较I I Zj-Xi I I与系统阈值的大小，若I Izj-XiI I小于系统阈值,则Zj未被遮挡,否则Zj被遮挡；</p>
    <p>[0068]	S43、提取剩余人脸分块的LBP纹理特征，并对剩余人脸分块的分类能力进行分析，进行加权人脸识别，具体为分别计算6个区域的类间散度矩阵和类内散度矩阵</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00094.png"> <img id="idf0012" file="CN102855496AD00094.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00094.png" class="patent-full-image" alt="Figure CN102855496AD00094"> </a> </div>
    <p>再通过每个人脸分</p>
    <p>块的类间类内散度矩阵进行权重估计，公式为：</p>
    <p>[0069]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00095.png"> <img id="idf0013" file="CN102855496AD00095.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00095.png" class="patent-full-image" alt="Figure CN102855496AD00095"> </a> </div>
    <p>为非遮挡区域</p>
    <p>                                                                                                       O</p>
    <p>[0070]	作为本发明的进一步改进，所述LBP特征向量之间相似度算法如下：[0071]	给定特征向量集It(t=l，2，. . .，6)，分别属于C个人，其中t为人脸分块标签，X1m e炉为第i类的第m个LBP特征向量，每类特征向量子集可表示4</p>
    <p>[0072]	Gram-Schmidt正交化每类特征向量子集&#28858;'，新特征向量子集表示为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00101.png"> <img id="idf0014" file="CN102855496AD00101.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00101.png" class="patent-full-image" alt="Figure CN102855496AD00101"> </a> </div>
    <p>[0073]	给定测试特征向量Xtest，并在相对应特征向量子集4'的子空间从</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00102.png"> <img id="idf0015" file="CN102855496AD00102.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00102.png" class="patent-full-image" alt="Figure CN102855496AD00102"> </a> </div>
    <p>进行投影，得投影向量如下</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00103.png"> <img id="idf0016" file="CN102855496AD00103.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00103.png" class="patent-full-image" alt="Figure CN102855496AD00103"> </a> </div>
    <p>[0074]	计算对应人脸分块的相似度</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00104.png"> <img id="idf0017" file="CN102855496AD00104.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00104.png" class="patent-full-image" alt="Figure CN102855496AD00104"> </a> </div>
    <p>[0075]	类属</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00105.png"> <img id="idf0018" file="CN102855496AD00105.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00105.png" class="patent-full-image" alt="Figure CN102855496AD00105"> </a> </div>
    <p>其中Wt为分块权值。</p>
    <p>                              [0076]	相应地，一种遮挡人脸认证系统，所述系统包括：</p>
    <p>[0077]	图像采集模块，用于捕获视频文件或者USB摄像头视频的视频帧，并保存捕获到的视频图像帧；</p>
    <p>[0078]	图像预处理模块，用于完成图像的光照预处理、噪声滤波处理以及几何归一化和尺度归一化处理，消除包括光照、噪声、姿态对人脸后续处理的不利影响；</p>
    <p>[0079]	特征训练模块，用于完成对检测模块的Adaboost人脸检测器的Haar特征训练以及对人脸样本库分块LBP特征的提取，特征训练模块借助matlab图像处理和矩阵操作功能实现离线特征训练；</p>
    <p>[0080]	人脸检测和定位模块，用于对已经训练好的人脸Haar特征，包括整脸、眼睛、嘴巴、鼻子，对人脸进行自适应步长的多尺度搜索，同时对于视频序列，在检测前通过视频序列间的运动信息对人脸位置进行预估计；</p>
    <p>[0081]	人脸识别模块，用于完成人脸图像特征的提取以及匹配，最终完成人脸识别，输出结果，人脸识别模块通过将目标人脸图像分块，剔除遮挡人脸分块，然后提取剩余人脸分块的LBP纹理特征，最后与人脸库中相对应的分块LBP纹理特征进行匹配识别。</p>
    <p>[0082]	由以上技术方案可以见，本发明提供的遮挡人脸认证方法及系统根据视频序列的运动信息，利用三帧差法对人脸图像的大致位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认。针对Adaboost特征训练时间过长问题，提出一种快速抽取样本算法，将训练时间缩短一半左右。针对局部遮挡情况下人脸检测率较低这一问题，提出了一种并行遮挡估计器结合自适应步长搜索的算法。有效提高局部遮挡人脸检测率和检测速度；</p>
    <p>[0083]	针对人脸局部遮挡情况下识别率较低这一问题，发明了一种基于MB-LBP特征的遮挡人脸识别算法。该算法首先将人脸样本分为六个分块，然后通过结合监督I-NN近邻法的SVM 二分算法对人脸分块进行遮挡判别。若分块被遮挡，则直接舍弃，若未遮挡则提取其相应的LBP纹理特征向量进行加权识别，然后用一种基于正交投影方法的分类器用来减少特征匹配次数。该算法有效提高局部遮挡人脸检测率和检测速度。</p>
    <p>附图说明</p>
    <p>[0084]	图I为本发明遮挡人脸认证方法的具体流程图；[0085]	图2为本发明遮挡人脸认证方法中矩形特征的特征值计算示意图；</p>
    <p>[0086]	图3为本发明遮挡人脸认证方法中级联分类器的结构示意图；</p>
    <p>[0087]	图4为本发明遮挡人脸认证方法中遮挡人脸的预估计示例示意图；</p>
    <p>[0088]	图5为本发明遮挡人脸认证方法中二分类的SVM算法示例示意图；</p>
    <p>[0089]	图6为本发明遮挡人脸认证系统的结构示意图；</p>
    <p>[0090]	图7为本发明一优选实施方式 中的正面人脸检测ROC曲线图；</p>
    <p>[0091]	图8为本发明一优选实施方式中的局部遮挡人脸检测ROC曲线图；</p>
    <p>[0092]	图9为本发明一优选实施方式中的不同人脸样本之间的欧氏距离曲线图；</p>
    <p>[0093]	图10为本发明一优选实施方式中的人脸分块区域示意图；</p>
    <p>[0094]	图11为本发明一优选实施方式中的不同条件下的识别率对比示意图。</p>
    <p>具体实施方式</p>
    <p>[0095]	为了使本技术领域的人员更好地理解本申请中的技术方案，下面将结合本申请实施例中的附图，对本申请实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本申请一部分实施例，而不是全部的实施例。基于本申请中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都应当属于本申请保护的范围。</p>
    <p>[0096]	参图I所示，本发明的一种遮挡人脸认证方法包括以下步骤：</p>
    <p>[0097]	SI、采集人脸视频图像；</p>
    <p>[0098]	S2、对所采集的人脸视频图像进行预处理，预处理包括：光照预处理、噪声滤波处理以及几何归一化和尺度归一化处理；</p>
    <p>[0099]	S3、对遮挡人脸进行检测计算，根据视频序列的运动信息，利用三帧差法对人脸图像的位置进行估计，然后通过Adaboost算法进行进一步人脸位置的确认；</p>
    <p>[0100]	S4、对遮挡人脸进行识别计算，将人脸样本分为若干分块，采用结合监督I-NN近邻法的SVM 二分算法对人脸分块进行遮挡判别，若分块被遮挡，则直接舍弃，若分块未被遮挡，则提取相应的LBP纹理特征向量进行加权识别，然后用基于正交投影方法的分类器用来减少特征匹配次数。</p>
    <p>[0101]	进一步地,步骤S3中的Adaboost算法进行进一步人脸位置的确认具体为：</p>
    <p>[0102]	S31、获取正负样本的特征，并用积分图的特征表示法进行计算；</p>
    <p>[0103]	S32、通过学习算法，为每个特征设计一个正确率高于50%的弱分类器；</p>
    <p>[0104]	S33、调整样本权值，多次循环提取错误率最低的弱分类器，构成强分类器；</p>
    <p>[0105]	S34、串联多个强分类器，构成级联分类器，进行人脸检测。</p>
    <p>[0106]	Adaboost算法是是基于统计的Boosting学习算法,其基本原理是通过对大量正负样本特征的学习，使得算法能够学习到区别正负样本的一些关键特征。Adaboost算法用于人脸检测时采用积分图的特征表示法，能够快速地计算出检测器所要用到的特征。Viola和Jones提出了一个基于级联结构的Adaboost分类器，分类器由多级构成，每一级的分类器均通过Adaboost算法进行训练。分类器级联是将单个的分类器串联成为一个具有更强分类能力的分类器，该方法首次实现了实时人脸检测的功能，其最大的优点在于快速稳定。</p>
    <p>[0107]	其中，在步骤S31中，Haar特征经过扩展之后，就可以通过平移、缩放、旋转等操作表示待检图像中不同尺度和偏移的人脸结构，但是Haar特征最大的缺点就是特征数量过多，仅一个24X24的区域就包含117941个位置大小不同的Haar特征。若通过传统方法计算区域间的特征值差异，其计算量相当庞大。为了加快特征训练速度，提出了积分图特征表示法的概念。</p>
    <p>[0108]	例如参图2所示，定义输入图像I，在像素点A(x，y)处的积分公式如下：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00121.png"> <img id="idf0019" file="CN102855496AD00121.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00121.png" class="patent-full-image" alt="Figure CN102855496AD00121"> </a> </div>
    <p>[0110]	逐点扫描待检图像I，得到其积分图像。设I(x，y)为点（x，y)的像素灰度值，S{x^y) = )是图像I中横轴坐标为x，纵轴坐标不超过y的所有像素点的灰度值之</p>
    <p>和，则图像I的积分图通过递归公式计算如下：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00122.png"> <img id="idf0020" file="CN102855496AD00122.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00122.png" class="patent-full-image" alt="Figure CN102855496AD00122"> </a> </div>
    <p>[0112]	在得到图像I的积分图像后，可以简单快速地计算出图像中任意矩形特征的特征值。以图中的第一个Haar特征为例，求此特征的特征值如下：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00123.png"> <img id="idf0021" file="CN102855496AD00123.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00123.png" class="patent-full-image" alt="Figure CN102855496AD00123"> </a> </div>
    <p>[0114]	从上式可以看出，要计算矩形特征的特征值，我们只需要计算其矩形特征顶点的积分图即可求得。在Adaboost算法训练时，每个Haar特征值的计算，至多只要从积分图像中取9个像素点的积分图做简单的加减法运算。另外，当对图像进行多尺度检测时，仍旧能够使用同一个的积分图像计算。正因为如此，整个图像的检测过程只需对原图扫描一次，便能够方便快捷地进行任意尺度的检测，极大地提高了检测的速度。</p>
    <p>[0115]	Adaboost算法的主要思想是通过建立多层次级联的筛选分类器，将候选检测窗口依次通过检测器，最终将人脸与非人脸分开。每一层都为一个强分类器，而每一个强分类器都是由若干个弱分类器构成。</p>
    <p>[0116]	一个弱分类器h(x，f，p，0)是由一个Haar特征值f，阈值0以及指示不等号方向的P组成：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00124.png"> <img id="idf0022" file="CN102855496AD00124.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00124.png" class="patent-full-image" alt="Figure CN102855496AD00124"> </a> </div>
    <p>[0118]	其中，f即为每一个Haar特征值，阈值0则是用来区分正负样本的临界值，方向指示符P用来调整不等号的方向。一个弱分类器单独用于区分人脸与非人脸，其正确率如果高于50%，则为有效弱分类器，而实验结果表明，人脸图像中绝大部分Haar特征对于识别人脸与非人脸的能力都很微弱。</p>
    <p>[0119]	Adaboost算法中，通过循环训练进行弱分类器的选择，每循环一次都在当前样本权重下选取一个最佳弱分类器，然后按照一定的方法提升为强分类器。对于每一个Haar特征，计算所有训练样本的该特征值，并按特征值从小到大的顺序依次排序，对排完序的每个特征值，计算如下四个值：</p>
    <p>[0120]	(a)所有样本的权重和T+;</p>
    <p>[0121]	(b)所有非人脸样本的权重和T-;[0122]	(c)在阈值之前的人脸样本权重和S+;</p>
    <p>[0123]	(d)在阈值之后的人脸样本权重和S-。</p>
    <p>[0124]	这样，将此弱分类器当前阈值之前的所有样本划分为人脸(或者非人脸)，将当前阈值之后的所有样本划分为非人脸(或者人脸)，计算弱分类器阈值分类误差为：</p>
    <p>[0125]	e=min (S++ (T--S-), S&gt; (T+-S+))。</p>
    <p>[0126]	从前至后完整扫描一遍所有特征值，选取加权分类误差最小的特征值作为阈值构成弱分类器。强分类器的学习则是通过多次迭代运算构成，经过T轮迭代后，可得T个弱分类器，串联叠加构成一个分类能力很强的强分类器。本发明中强分类器的算法具体为：</p>
    <p>[0127]	S331、给定的训练样本集=(X1J1), (x2, J2),…，(xm, ym),其中 Xi G X,Ji G 1~1，+1};</p>
    <p>[0128]	S332、对样本权值进行初始化，对于非人脸样本：Dt(i)=l/2m，其中m为非人脸样本数目，对于人脸样本：Dt (i) =l/2n，其中n为人脸样本数目；</p>
    <p>[0129]	S333、经过T轮迭代后，可得T个弱分类器，循环t=l，2…，T;</p>
    <p>[0130]	在当前样本权重分布Dt下，针对每个单个矩形特征训练一个弱分类器，并从中选取错误率最小的弱分类器ht;</p>
    <p>[0131]对于选定的弱分类器ht，计算其加权错误率</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00131.png"> <img id="idf0023" file="CN102855496AD00131.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00131.png" class="patent-full-image" alt="Figure CN102855496AD00131"> </a> </div>
    <p>[0132]	求解弱分类器ht的加权参数为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00132.png"> <img id="idf0024" file="CN102855496AD00132.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00132.png" class="patent-full-image" alt="Figure CN102855496AD00132"> </a> </div>
    <p>[0133]	为下次循环更新样本权重，</p>
    <p> [0134]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00133.png"> <img id="idf0025" file="CN102855496AD00133.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00133.png" class="patent-full-image" alt="Figure CN102855496AD00133"> </a> </div>
    <p>其中，Zt 是归一化</p>
    <p> 因子</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00134.png"> <img id="idf0026" file="CN102855496AD00134.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00134.png" class="patent-full-image" alt="Figure CN102855496AD00134"> </a> </div>
    <p>[0135]	S334、计算得最终强分类器为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00135.png"> <img id="idf0027" file="CN102855496AD00135.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00135.png" class="patent-full-image" alt="Figure CN102855496AD00135"> </a> </div>
    <p>其中Th为手动设定满</p>
    <p> 足正样本错误率的阈值，进一步定义H(X)置信度为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00136.png"> <img id="idf0028" file="CN102855496AD00136.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00136.png" class="patent-full-image" alt="Figure CN102855496AD00136"> </a> </div>
    <p>[0136]	由强分类器的学习算法可知，强分类器训练过程中不断地调整样本权值。当弱分类器对于样本分类错误时，权值不变，而对于样本分类正确时，权值减少。这样通过权值调整，以便算法下一轮训练更集中于分类错误的样本，使得强分类器的分类性能够得到进一步提高。当利用强分类器进行目标检测时，相当于使用该强分类器所有弱分类器对目标进行检测，每个弱分类的分类结果经过加权运算，得到最终的检测结果。</p>
    <p>[0137]	优选地，为了进一步的提高检测效率满足实时检测的要求，Viola等提出一种多层次级联的强分类器。级联强分类器是通过将分类正确率最高的N个的强分类器串联而形成的一种分类器，如图3所示。其中，每一层均是经过Adaboost算法训练出来的强分类器。待检测样本从左端第一层开始依次进入串联分类器，若是人脸则继续进入第二层强分类器，否则被认定为非人脸，直接淘汰，因此通过前面几个简单的强分类器就可以过滤掉大部分非人脸样本。级联分类器的特点是越往后的强分类器Haar特征越多，强分类器的结构也越复杂。但是通过前几层分类器的筛选，能够进入到后面几层分类器的待识别样本数目也大大减少，这样就可以在提高检测率的同时，也保证了检测速度。</p>
    <p>[0138]	本发明中的级联分类器的算法具体为：</p>
    <p>[0139]	S341、设定级联分类器每层强分类器的最小检测率Cli和最大误检率&amp; ；</p>
    <p>[0140]	S342、设定级联分类器的目标误检率T，级联分类器检测率为Di,级联分类器的误检率为Fi，其中i为级联分类器的层数； [0141]	S343、给定人脸训练样本集合M和负训练样本集合N，并根据式&#163;&gt; = 式与</p>
    <p>                                                                                                                                               1-1</p>
    <p>厂= 初始化 Dtl=I, Ftl=I ；</p>
    <p>[0142]	S344、初始化层数i=0 ；</p>
    <p>[0143]	S345、循环迭代，直至满足条件Fi彡T ;</p>
    <p>[0144]	采用Adaboost算法训练包含Iii个Haar特征的第i层强分类器；</p>
    <p>[0145]	计算当前层强分类器的检测率Di和误检率Fi ；</p>
    <p>[0146]	调整第i层强分类器的阈值，使当前层的检测率满足DiMiXDp1 ；</p>
    <p>[0147]	S346、若Fi &gt;TT，则通过该层分类器对样本图像进行检测，将分类正确的负样本排除，将分类错误的负样本图像归入N。</p>
    <p>[0148]	在本发明的其他实施方式中，为了加快算法训练速度，还提出一种根据初始样本间的差异度、抽取出关键样本进行样本的缩减、并同时初始化关键样本权值的方法。抽取关键样本方法具体为：</p>
    <p>[0149]给定标定的训练样本集：(X1,	Y1)，(X2, J2)，…，(Xm, ym)，其中 Xi G X7Yi G {-I, +1};</p>
    <p>[0150]	给定关键样本集Xk= IxJ，样本对应的权值集合W= {1，0，…，0}，Wn G W，次要样本集Y= 0,定义(!（&#8226;）为向量间欧氏距离：</p>
    <p>[0151]j	e Xk 时计算 d(xi，x ' p，定义《 = Srgmin^x,,'.).</p>
    <p>                '	5</p>
    <p>[0152]判断是否满足	d (Xi, X ; n) &gt; a，若满足，则 X=X- {xj，Xe=Xe U {xj，赋值 wn=wn+1 ;若不满足，再判断是否满足d (Xi, X ; n)〈 P ,若是，赋值wn = Wn+1 ,若否，贝IjX=X-{xj, Y=Y U {xj ；</p>
    <p>[0153]若	Xi G Y，在 x ' j G Xe 时计算 d (Xi, x ; j),定义” 二 arg &#8482;n d{'X'，X丨)</p>
    <p>                                                                                                                                      o</p>
    <p>[0154]	改进的样本训练算法采用了根据初始样本之间的差异度，通过调整参数a，@抽取关键样本，并初始化样本权值的方法。本发明的快速抽取训练样本的算法通过循环迭代，将初始训练样本中的关键样本抽取到关键样本集里。在进行强分类器训练时，则可以采用关键样本集代替原样本集直接进行训练，大大减少因为过多样本而带来的时间耗损。同时关键样本的权值代表了每个关键样本的重要程度，一定程度上提高了算法用于人脸检测的精度。</p>
    <p>[0155]	为解决人脸部分遮挡时漏检率较高这一问题，本发明采用多检测器并行的方法对人脸进行检测，分别提取人的嘴巴、眼睛、鼻子的特征进行弱分类器的训练，生成三个独立的检测器，并与全脸的检测器并联一起，构成并行的多瀑布人脸检测器，级联结构如图4所示。</p>
    <p>[0156]	在实时检测过程中往往需要用训练好的各个分类检测器扫描图像中所有可能的子窗口，但是这样做开销太大，为此本发明采用截取级联检测器的前m层作遮挡估计器，如图4中虚线框所示。每个检测器的前m层作为遮挡估计器，后n层进行进一步检测。待检测部分首先被送入遮挡估计器，通过图4中前m层粗线部分表示的并行检测部分，然后根据定义的强分类器置信度，对遮挡估计器的置信度进行仲裁：</p>
    <p>[0157]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00151.png"> <img id="idf0029" file="CN102855496AD00151.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00151.png" class="patent-full-image" alt="Figure CN102855496AD00151"> </a> </div>
    <p>[0158]	其中val为遮挡估计器置信度，conf为定义的强分类器置信度，i为级联检测器类别，j为瀑布型检测器层数。进行仲裁之后，记录置信度最高的级联分类器类别为k。同时为遮挡估计器设定置信度阈值threshold，若V alk大于阈值，则待检测样本进入第k类分类器的后n层判定，并结合先验知识进行最终人脸定位，反之则待检测图像被认定为非人脸，不再需要进行后面n层判定。</p>
    <p>[0159]多分辨率搜索的基本思想是将对图像的扫描分成两个步骤，按搜索步长的大小分为低分辨率和高分辨率进行。第一步，在低分辨率下扫描候选人脸区域，利用级联分类器前几层进行检测。第二步，在第一步中找到的可能的人脸区域附近，进行高分辨率下的人脸精确定位，本发明搜索算法如下：</p>
    <p>[0160]	设置加速比参数a &gt; 0，初始化扫描窗口大小，初始化窗口移动步长，初始检测框取训练样本图片大小；</p>
    <p>[0161]	采用并行级联分类器的前四层的遮挡估计器，对待检测区域图像进行固定步长扫描，并记录下每个位置的置信度val ；</p>
    <p>[0162]	计算所有位置的平均置信下所有置信度大于^的点为可能性较高的人脸位置，对可能存在人脸的位置采用自适应步长进行高分辨率扫描，自适应步长计算公</p>
    <p>式为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00152.png"> <img id="idf0030" file="CN102855496AD00152.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00152.png" class="patent-full-image" alt="Figure CN102855496AD00152"> </a> </div>
    <p>其中，nA为上次检测框中通过的强分类器数目，n为总共的强</p>
    <p>分类器数目，U为调整因子；</p>
    <p>[0163]	判断是否已扫描完所有图像，若否则改变扫描窗口大小，继续扫描。</p>
    <p>[0164]	本发明中，步骤S4具体为：</p>
    <p>[0165]	S41、将人脸分块为6个可单独用于识别的区域，通过寻找最优主元重建样本，从而对人脸向量进行降维，经过降维处理后，每个分块均对应一个PCA降维向量，继而通过SVM分类器进行验证是否为遮挡人脸；</p>
    <p>[0166]	S42、定义训练样本集TtrainIxi |i =。^…!^，测试样本集^上山=!，〗』…!!}；</p>
    <p>[0167]计算z^L分类面的距离</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00153.png"> <img id="idf0031" file="CN102855496AD00153.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00153.png" class="patent-full-image" alt="Figure CN102855496AD00153"> </a> </div>
    <p>若满足|f(Zj) I彡1，直</p>
    <p>                                                                                                                5</p>
    <p>接应用SVM分类器，若不满足|f(zj I彡1，则计算I IzpciI |，获取\附近最近的训练样本z' j,如果z, j表示被遮挡，则Zj也被遮挡，如果z, j表示未被遮挡，再比较I I Zj-Xi I I与系统阈值的大小，若I Izj-XiI I小于系统阈值,则Zj未被遮挡,否则Zj被遮挡；</p>
    <p>[0168]	S43、提取剩余人脸分块的LBP纹理特征，并对剩余人脸分块的分类能力进行分析，进行加权人脸识别，具体为分别计算6个区域的类间散度矩阵和类内散度矩阵</p>
    <p>c	c</p>
    <p>= [ [ (X-MiXx -TniY SI =么 N J &#8212; m ) (m . &#8212; m )1 再通过每个人脸分</p>
    <p> i=l 奸A	9	i-i	?</p>
    <p>块的类间类内散度矩阵进行权重估计，公式为：</p>
    <p>[0169]                 略+&#12316;.))为非遮挡区域</p>
    <p>          叫 HS;)</p>
    <p>、0,	n为遮挡区域</p>
    <p>                                                                                                           O</p>
    <p>[0170]	支持向量机是一种基于统计学习理论的VC维和结构风险最小化原理的理论,它通过有限的样本信息在训练模型的复杂度与学习机器学习能力之间寻求最佳折衷，得出最优分类面。目前已经在人脸识别领域等到了广泛的应用。</p>
    <p>[0171]	给定一个训练样本：</p>
    <p>[0172]	S={(x1, Y1), (xn, yn)} G RnX {-I, 1}</p>
    <p>[0173]	求解最优分类问题即为二重二次规划问题，相应的优化问题最终归结为：</p>
    <p>                   n ’	j n '</p>
    <p>[0174]	maxff f(a) =	，Xj)</p>
    <p>                    /=1 2 ij:\</p>
    <p>                                            ■ I	112</p>
    <p>[0175]其中：0	彡 a j ^	.v, = 0 k、x丨'-Y,) = exp(&#8212;~~)</p>
    <p>/-I	Z,(T</p>
    <p>    、 ?</p>
    <p>[0176]	a为Lagrange乘子，C&gt;0为正则化常数,决定了经验误差和复杂度的平衡点，并控制对错分样本的惩罚。{-1，1}为样本标签，-I表示人脸分块被遮挡，I表示人脸分块未被遮挡。SVM算法用于人脸块的最终分类函数如下：</p>
    <p>                      N</p>
    <p>[0177]	/(A) = s !'gft(hvrK (x,，Xj) + 办)</p>
    <p>   M	O</p>
    <p>[0178]	参图5所示，L是SVM算法所求得的最优分类面，L0为理想分类面，L1与L2为支持向量面，由图可知，L0是理想的分类面，可以毫无误差地将两类分开，但是通常情况下我们无法求出Ltl这一分类面。若测试样本落入L1与L2分类面之间，明显地，◎样本仍然可以得到正确地分类，但是O样本却被错误的划分了。为了提高二分类SVM算法的分类效果，本发明结合I-NN近邻法，提出步骤S42中的算法。</p>
    <p>[0179]	由上述算法可知，当测试样本落在L1的左边或者落在L2的右边时，直接应用SVM分类器，而当测试样本落在L1与L2之间时，则采用改进的监督I-NN算法进行分类。为了防止由于附近样本数过少出现误检测，算法中为I-NN算法设置阈值用来提高分类正确率。采用监督I-NN近邻法的SVM二分类算法，可以有效快速地提取出人脸分块中未被遮挡的部分。</p>
    <p>[0180]	为了进一步的提高人脸认证系统的识别速度，本发明结合正交分解理论，提出一种利用正交投影子空间计算LBP特征向量之间相似度的算法。算法首先提取每个训练样本各个分块的LBP特征向量，构成6个对应的LBP特征向量空间。然后将待测样本的LBP特征向量投影到对应的向量空间，计算其相似度，算法步骤如下：</p>
    <p>[0181]	给定特征向量集It(t=l，2,...,6),分别属于C个人，其中t为人脸分块标签，XleRd为第i类的第m个LBP特征向量，每类特征向量子集可表示</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00171.png"> <img id="idf0032" file="CN102855496AD00171.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00171.png" class="patent-full-image" alt="Figure CN102855496AD00171"> </a> </div>
    <p>[0182]	Gram-Schmidt正交化每类特征向量子集&#28858;\新特征向量子集表示为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00172.png"> <img id="idf0033" file="CN102855496AD00172.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00172.png" class="patent-full-image" alt="Figure CN102855496AD00172"> </a> </div>
    <p>[0183]	给定测试特征向量Xtest，并在相对应特征向量子集4'的子空间以4')进行投影，得投影向量如下：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00173.png"> <img id="idf0034" file="CN102855496AD00173.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00173.png" class="patent-full-image" alt="Figure CN102855496AD00173"> </a> </div>
    <p>[0184]	计算对应人脸分块的相似度力</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00174.png"> <img id="idf0035" file="CN102855496AD00174.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00174.png" class="patent-full-image" alt="Figure CN102855496AD00174"> </a> </div>
    <p>[0185]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00175.png"> <img id="idf0036" file="CN102855496AD00175.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00175.png" class="patent-full-image" alt="Figure CN102855496AD00175"> </a> </div>
    <p>其中 wt 为分块权值。</p>
    <p> [0186]	正交投影分类器构造的LBP特征向量空间随着训练样本的增多而趋至完善，不存在小样本问题。同时在识别过程中，待测样本与每类人脸只需比较一次，比较次数只与样本类别数目相关，而与每类样本的样本数无关。正交投影分类器大大减少了比较次数，一定程度上提高了识别速率。</p>
    <p>[0187]	相应地，参图6所示，本发明的一种遮挡人脸认证系统，包括：</p>
    <p>[0188]	图像采集模块10，用于捕获视频文件或者USB摄像头视频的视频帧，并保存捕获到的视频图像帧；</p>
    <p>[0189]	图像预处理模块20，用于完成图像的光照预处理、噪声滤波处理以及几何归一化和尺度归一化处理，消除包括光照、噪声、姿态对人脸后续处理的不利影响；</p>
    <p>[0190]	特征训练模块30，用于完成对检测模块的Adaboost人脸检测器的Haar特征训练以及对人脸样本库分块LBP特征的提取，特征训练模块借助matlab图像处理和矩阵操作功能实现离线特征训练；</p>
    <p>[0191]	人脸检测和定位模块40，用于对已经训练好的人脸Haar特征，包括整脸、眼睛、嘴巴、鼻子，对人脸进行自适应步长的多尺度搜索，同时对于视频序列，在检测前通过视频序列间的运动信息对人脸位置进行预估计；</p>
    <p>[0192]	人脸识别模块50，用于完成人脸图像特征的提取以及匹配，最终完成人脸识别，输出结果，人脸识别模块通过将目标人脸图像分块，剔除遮挡人脸分块，然后提取剩余人脸分块的LBP纹理特征，最后与人脸库中相对应的分块LBP纹理特征进行匹配识别。</p>
    <p>[0193]	本发明一优选实施例中人脸检测采用整脸、眼睛、嘴巴、鼻子四类弱分类器，训练提取250个Haar特征，四类Haar特征分别训练。传统Adaboost算法采用快速排序算法对每个特征进行阈值判断，并取最小错误率的特征作为当次循环的最佳弱分类器，每次训练一个弱分类器需要0. 5s左右。本实施例采用一种基于初始样本间的差异度，抽取出关键样本，减少训练样本数以提高样本训练速度。如表I所示,相比传统Adaboost训练算法，本发明训练算法时间缩短了近一半。算法中提取的关键样本数目通过调整a，^参数调整，参数值越高，则关键样本越少，训练时间越短，但弱分类器的错误率也随之上升。综合考虑训练时间与错误率，本优选实施例中，参数a取2. 7，参数P取1.3。</p>
    <p>[0194]	表I不同的弱分类器训练方法对比</p>
    <p>[0195]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00181.png"> <img id="idf0037" file="CN102855496AD00181.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00181.png" class="patent-full-image" alt="Figure CN102855496AD00181"> </a> </div>
    <p>[0196]	对于遮挡人脸检测，本实施例中设定初始检测窗口大小为19X19，按比例逐层缩小待检测图像。该方法采用三帧差法预估计人脸位置以及自适应步长搜索算法，扫描一幅320X240大小的图片只用时15ms。并行瀑布型检测器总共设有16层，前4层则设为遮挡估计器用于并行检测，共设有人的整脸、鼻子、眼睛和嘴巴等4类级联检测器，本发明通过4类级联检测器并联的方法，大大提高了人脸在遮挡情况下的检测正确率，同时本发明设计的遮挡估计器在没有引入任何额外开销的情况下，减少了由于并联多检测器过多而带来的时间耗损。本发明对不同遮挡程度下的人脸视频进行仿真实验对比，发现在正面非遮挡人脸的检测率约为95%左右的情况下，遮挡人脸的检测率也接近85%左右，对比传统Adaboost算法，正面遮挡人脸的检测率只有65%左右，ROC曲线见图7和图8。实验结果表明，本发明的方法在人脸局部遮挡的情况下，正确率明显好过传统Adaboost算法。</p>
    <p>[0197]	进行人脸识别之前，本实施例算法首先利用改进的SVM 二分类算法对人脸遮挡块进行预判定。SVM分类器的训练样本选用2000个遮挡人脸与2000个非遮挡人脸。每个人脸样本在通过SVM分类器进行遮挡判定之前，第一步是将人脸样本分成六个不相邻的人脸块；第二步是将每个人脸分块通过PCA算法进行降维，用降维后的PCA向量代替原人脸分块。</p>
    <p>[0198]	为了进一步提高SVM分类器二分算法的正确率，本发明结合监督I-NN近邻法对SVM分类器进行改进。为了验证I-NN近邻法的可行性，我们以六个人脸分块中的左眼分块为例，随机抽取训练样本中对应该分块的3个未遮挡PCA向量，分别计算这3个PCA向量与其他样本对应分块PCA向量的欧氏距离。如图9所示，三条曲线分别代表这3个未遮挡PCA向量与其他样本对应块PCA向量之间的欧氏距离。实验发现，图中三条曲线最高点，均为与被遮挡PCA向量之间的欧氏距离，且最高点的值明显高于周围。因此，设置合适阈值，采用I-NN近邻法确实可以在一定程度上区分遮挡分块与非遮挡分块。</p>
    <p>[0199]	为了可以更好地验证改进后SVM 二分类算法的正确率，我们从检测率、漏检率、拒绝率、误检率四个比率来对算法效果进行测试，四个比率的定义如表2所示。对于人脸遮挡块的检测，提高检测率与降低误检率是算法要实现的目标。</p>
    <p>[0200]	表2遮挡检测比率定义</p>
    <p>[0201]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00182.png"> <img id="idf0038" file="CN102855496AD00182.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00182.png" class="patent-full-image" alt="Figure CN102855496AD00182"> </a> </div>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00191.png"> <img id="idf0039" file="CN102855496AD00191.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00191.png" class="patent-full-image" alt="Figure CN102855496AD00191"> </a> </div>
    <p>[0202]	本发明主要针对人脸局部遮挡的情况进行识别，如图6-7所示，一般地，人脸局部遮挡主要遮挡物有墨镜和围巾口罩，遮挡区域为c、d、e、f，而通常人脸识别依靠的主要鉴别特征也是这四个区域的特征信息。因此本发明通过改进的SVM 二分算法分别对c、d、e、f&#8226;分块进行人脸遮挡分块判定实验，检测结果如表3所示。</p>
    <p>[0203]	表6-3遮挡人脸块检测结果</p>
    <p>[0204]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00192.png"> <img id="idf0040" file="CN102855496AD00192.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00192.png" class="patent-full-image" alt="Figure CN102855496AD00192"> </a> </div>
    <p>[0205]	表3中对比了传统K-NN算法、监督的1_NN算法、传统SVM算法以及本发明算法对遮挡人脸块的检测率和误检率。传统的K-NN算法依赖于训练样本的数目，当训练样本较少时，效果不是很理想。监督的I-NN近邻法通过设定一个合理的阈值，降低了算法对样本数目的要求，虽然检测率较高，但是同样误检率也很高，所以不能单独适用于人脸遮挡块的检测。通过结合监督I-NN近邻法的SVM 二分算法，与传统SVM分类法相比消除了最优超平面附近样本点的干扰，在检测率方面和误检率方面都取得了令人满意的效果。</p>
    <p>[0206]	本实施例中，选取ORL人脸库与AR人脸库中的部分人脸，ORL库中人脸的表情姿态变化较少，AR库中的人脸表情丰富并包含局部遮挡的情况。本发明根据每个人脸额头、眉毛、眼睛、鼻子、嘴巴、轮廓进行分块，提取其各自LBP特征向量，进行识别率对比实验。</p>
    <p>[0207]	表4人脸各部位识别率对比（％ )</p>
    <p>[0208]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00193.png"> <img id="idf0041" file="CN102855496AD00193.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00193.png" class="patent-full-image" alt="Figure CN102855496AD00193"> </a> </div>
    <p>[0209]	从表4的实验结果可以看出，在人脸表情和姿态变化微弱的ORL人脸库上，人脸各个部位的识别率为：眉毛 &gt; 眼镜 &gt; 嘴巴〉鼻子〉额头〉轮廓。在表情丰富以及局部遮挡的情况下，人脸各个部位的识别率为：眉毛 &gt; 嘴巴 &gt; 鼻子 &gt; 眼镜 &gt; 轮廓 &gt; 额头。由表4可知，人脸不同部位特征的识别能力并不相同，眉毛、嘴巴、眼睛等部位的特征明显好过鼻子、额头、轮廓等部位的特征。</p>
    <p>[0210]	为了更好地利用眉毛、眼睛、嘴巴等部位的特征，本发明对图10中的人脸分为六个分块，进行分类能力的定量研究。通过类间散度矩阵与类内散度矩阵依次求出各个分块的权重。如表5所示，我们可以看出包含眉毛、眼睛、嘴巴等部位的分块权重明显大于其他部位。</p>
    <p>[0211]	表5人脸分块区域权重统计</p>
    <p>[0212]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00201.png"> <img id="idf0042" file="CN102855496AD00201.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102855496A/CN102855496AD00201.png" class="patent-full-image" alt="Figure CN102855496AD00201"> </a> </div>
    <p>[0213]	因为传统的PCA方法与LBP方法均为全局方法，未对遮挡人脸做处理，为了更好地进行实验对比，我们将本发明的遮挡块判定算法与PCA相结合，遮挡人脸块通过改进SVM二分算法去除，剩余部分通过对应的分块的PCA向量进行识别，我们称之为LR-PCA(localrecognition PCA)。本发明对PCA方法、传统LBP方法、LR-PCA以及本发明方法，分别在未遮挡、墨镜遮挡、口罩遮挡三种情况下进行实验，并对比实验效果，如图11所示。在人脸未被遮挡的情况下，本发明方法与传统LBP方法识别率相近，但相对传统PCA方法与LR-PCA方法较高。而在人脸被遮挡的情况下，本发明的方法的识别率明显高于其他三种方法。对比传统LBP方法与LR-PCA方法，我们发现传统LBP方法在人脸遮挡情况下识别率仍然较高。因此可以得出，LBP纹理特征是对于局部遮挡鲁棒性较高的鉴别特征。另外对比墨镜遮挡与口罩遮挡这两种情况的识别率，可以发现墨镜遮挡相对口罩遮挡而言，对人脸识别结果的影响更大。</p>
    <p>[0214]	以上所述仅是本申请的优选实施方式，使本领域技术人员能够理解或实现本申请。对这些实施例的多种修改对本领域的技术人员来说将是显而易见的，本文中所定义的一般原理可以在不脱离本申请的精神或范围的情况下，在其它实施例中实现。因此，本申请将不会被限制于本文所示的这些实施例，而是要符合与本文所公开的原理和新颖特点相一致的最宽的范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101369310A?cl=zh">CN101369310A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年9月27日</td><td class="patent-data-table-td patent-date-value">2009年2月18日</td><td class="patent-data-table-td ">北京航空航天大学</td><td class="patent-data-table-td ">一种鲁棒的人脸表情识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101398886A?cl=zh">CN101398886A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年3月17日</td><td class="patent-data-table-td patent-date-value">2009年4月1日</td><td class="patent-data-table-td ">杭州大清智能技术开发有限公司</td><td class="patent-data-table-td ">一种基于双目被动立体视觉的快速三维人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101794385A?cl=zh">CN101794385A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年3月23日</td><td class="patent-data-table-td patent-date-value">2010年8月4日</td><td class="patent-data-table-td ">上海交通大学</td><td class="patent-data-table-td ">用于视频序列的多角度多目标快速人脸跟踪方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=mwq3BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2007304721A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGLARHYUzEKTDOaJH3lHMYhsSQq-Q">JP2007304721A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">曹红根，袁宝华，朱辉生: "<a href='http://scholar.google.com/scholar?q="%E3%80%8A%E7%BB%93%E5%90%88%E5%AF%B9%E6%AF%94%E5%BA%A6%E4%BF%A1%E6%81%AF%E4%B8%8ELBP+%E7%9A%84%E5%88%86%E5%9D%97%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%8B"'>《结合对比度信息与LBP 的分块人脸识别》</a>", 《山东大学学报( 工学版)》, vol. 42, no. 4, 20 August 2012 (2012-08-20)</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103310415A?cl=zh">CN103310415A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年3月15日</td><td class="patent-data-table-td patent-date-value">2013年9月18日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">基于人脸的图像缺损补绘方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103440475A?cl=zh">CN103440475A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年8月14日</td><td class="patent-data-table-td patent-date-value">2013年12月11日</td><td class="patent-data-table-td ">北京博思廷科技有限公司</td><td class="patent-data-table-td ">一种自动取款机使用者人脸可见性判断系统及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=mwq3BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009620000">G06K9/62</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年1月2日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年2月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/1cf3dcd03a02f6155ea6/CN102855496A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E9%81%AE%E6%8C%A1%E4%BA%BA%E8%84%B8%E8%AE%A4%E8%AF%81%E6%96%B9%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F.pdf?id=mwq3BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1zs6Jcx7dxpNOtVpNuFCG_oDIcIQ"},"sample_url":"https://www.google.com/patents/reader?id=mwq3BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>