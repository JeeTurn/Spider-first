<!DOCTYPE html><html><head><title>专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5115ea495017d9115e613207d3810e5a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5115ea495017d9115e613207d3810e5a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种基于信息融合的机读旅行证件识别方法"><meta name="DC.contributor" content="吴&#36985;" scheme="inventor"><meta name="DC.contributor" content="欧阳元新" scheme="inventor"><meta name="DC.contributor" content="薛玲" scheme="inventor"><meta name="DC.contributor" content="李超" scheme="inventor"><meta name="DC.contributor" content="盛浩" scheme="inventor"><meta name="DC.contributor" content="熊璋" scheme="inventor"><meta name="DC.contributor" content="北京航空航天大学" scheme="assignee"><meta name="DC.date" content="2007-1-10" scheme="dateSubmitted"><meta name="DC.description" content="一种基于信息融合的机读旅行证件识别方法：机读码信息提取：机读码信息提取主要包括：自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然后将此文本信息保存至数据库中；面部特征提取：检测证件图像中人脸图像位置，提取持证人面部特征，将此特征信息存入数据库中；身份比对：将文本特征和面部特征分别与重点人物数据库中的特征数据进行比对，判断持证人是否为重点人物数据库中的成员。本发明能够自动识别证件图像中的文本信息，同时自动提取证件中包含的持证人面部特征信息，并通过特征比对及结果融合准确地判断持证人是否为重点人物，提高了持证人身份对比的准确度。"><meta name="DC.date" content="2007-9-19"><meta name="citation_patent_publication_number" content="CN:101038686:A"><meta name="citation_patent_application_number" content="CN:200710063360"><link rel="canonical" href="https://www.google.com/patents/CN101038686A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101038686A?cl=zh"/><meta name="title" content="专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法"/><meta name="description" content="一种基于信息融合的机读旅行证件识别方法：机读码信息提取：机读码信息提取主要包括：自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然后将此文本信息保存至数据库中；面部特征提取：检测证件图像中人脸图像位置，提取持证人面部特征，将此特征信息存入数据库中；身份比对：将文本特征和面部特征分别与重点人物数据库中的特征数据进行比对，判断持证人是否为重点人物数据库中的成员。本发明能够自动识别证件图像中的文本信息，同时自动提取证件中包含的持证人面部特征信息，并通过特征比对及结果融合准确地判断持证人是否为重点人物，提高了持证人身份对比的准确度。"/><meta property="og:title" content="专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101038686A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101038686A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101038686A&amp;usg=AFQjCNFsGpqP_Ndw0f5jv6OLRMSS7_1YWA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/9b59901f1d58f4bb01ce/CN101038686A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/9b59901f1d58f4bb01ce/CN101038686A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101038686A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101038686A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101038686A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101038686B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101038686A?cl=zh" style="display:none"><span itemprop="description">一种基于信息融合的机读旅行证件识别方法：机读码信息提取：机读码信息提取主要包括：自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然...</span><span itemprop="url">https://www.google.com/patents/CN101038686A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法" title="专利 CN101038686A - 一种基于信息融合的机读旅行证件识别方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101038686 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200710063360</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2007年9月19日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2007年1月10日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年1月10日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101038686B?hl=zh-CN&amp;cl=zh">CN101038686B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200710063360.6, </span><span class="patent-bibdata-value">CN 101038686 A, </span><span class="patent-bibdata-value">CN 101038686A, </span><span class="patent-bibdata-value">CN 200710063360, </span><span class="patent-bibdata-value">CN-A-101038686, </span><span class="patent-bibdata-value">CN101038686 A, </span><span class="patent-bibdata-value">CN101038686A, </span><span class="patent-bibdata-value">CN200710063360, </span><span class="patent-bibdata-value">CN200710063360.6</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%90%B4%E9%81%B9%22">吴&#36985;</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%AC%A7%E9%98%B3%E5%85%83%E6%96%B0%22">欧阳元新</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%96%9B%E7%8E%B2%22">薛玲</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E8%B6%85%22">李超</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%9B%9B%E6%B5%A9%22">盛浩</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%86%8A%E7%92%8B%22">熊璋</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%A4%A7%E5%AD%A6%22">北京航空航天大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101038686A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101038686A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101038686A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (4)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200710063360&amp;usg=AFQjCNHYSTSICdQpmNzHpSsZ4ORVKOGFSg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101038686A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGqPo0kR3TqObkIjfmK_xO3P6knfQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT121964877" lang="ZH" load-source="patent-office">一种基于信息融合的机读旅行证件识别方法</invention-title>
      </span><br><span class="patent-number">CN 101038686 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA108198515" lang="ZH" load-source="patent-office">
    <div class="abstract">一种基于信息融合的机读旅行证件识别方法：机读码信息提取：机读码信息提取主要包括：自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然后将此文本信息保存至数据库中；面部特征提取：检测证件图像中人脸图像位置，提取持证人面部特征，将此特征信息存入数据库中；身份比对：将文本特征和面部特征分别与重点人物数据库中的特征数据进行比对，判断持证人是否为重点人物数据库中的成员。本发明能够自动识别证件图像中的文本信息，同时自动提取证件中包含的持证人面部特征信息，并通过特征比对及结果融合准确地判断持证人是否为重点人物，提高了持证人身份对比的准确度。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(5)</span></span></div><div class="patent-text"><div mxw-id="PCLM50786117" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于信息融合的机读旅行证件识别方法，其特征在于步骤如下：(1)机读码信息提取：包括自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然后将此文本信息保存至数据库中；(2)面部特征提取：检测证件图像中人脸图像位置，提取持证人面部特征，将此特征信息存入数据库中；(3)身份比对：将文本特征和面部特征分别与重点人物数据库中的特征数据进行比对，并对两类比对结果在决策级进行融合，判断持证人是否为重点人物数据库中的成员。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的基于信息融合的机读旅行证件识别方法，其特征在于：所述步骤(1)中的自动定位机读码区域的方法采用基于连通区域分析的方法，具体如下：(1)在HSI空间采用Thue＝Black对图像进行彩色滤波，滤除背景图像；(2)采用膨胀操作完成滤波后字符图像的笔画粘连，保证每个字符构成一个完整的连通区域；(3)分析图像连通区域得到每一个连通区域的外接矩形，剔除尺寸超过限定范围的矩形，得到矩形集合；(4)根据外接矩形集合划定机读码区域：即将外接矩形集合划分为若干不相交的子集，各子集同时满足(a)和(b)：(a)同一子集内的相邻矩形垂直位置相差较小；(b)同一子集内相邻矩形水平距离较小；(5)求出每个子集中所有矩形的最小外接矩形，长度超过图像长度3/4的矩形区域即为机读码字符区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的基于信息融合的机读旅行证件识别方法，其特征在于：所述步骤(1)中的自动字符识别方法如下：(1)采用最小二乘法对每一行机读码字符外接矩形左上角像素坐标进行线性拟合，根据拟合得到的直线倾斜角对图像进行旋转；(2)对旋转后的图像进行二值化操作，得到机读码图像二值图像；(3)对上述二值图像利用字符外接矩形信息完成对字符的分割，得到每一个机读码字符的图像；(4)利用OCR算法识别上述字符图像，得到文本信息，同时得出机读码区域各字符图像与字符模版的相似度向量序列VectorSeries＝{SimVectorn|1≤n≤N}，其中：N为机读码区域字符的个数，SimVectorn为第n个字符模版的相似度向量，表示为：SimVector＝{Simm|1≤m≤M}，其中M为字符模版的个数，Simm是这个字符与第m个字符模版的相似度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的基于信息融合的机读旅行证件识别方法，其特征在于：所述步骤(2)中的自动检测证件图像中人脸图像位置，提取持证人面部特征的方法步骤如下：(1)离线训练，利用Adaboost算法从一个大特征样本中选取若干最有效的特征，并为每个特征生成一个弱分类器，通过将这些分类器进行级联组合得到一个强学习算法；(2)在线检测，使用大小不同的窗口扫描图像，使用学习阶段得到的分类器检测窗口图像，若该窗口图像通过了所有的弱分类器，即认为该子窗口图像为人脸图像；(3)结合检测结果得到最终人脸位置；(4)对定位得到的人脸图像进行大小归一化、消除噪声、灰度归一化；(5)采用基于EHMM的特征算法为每一个人脸建立一个EHMM模型。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的一种基于信息融合的机读旅行证件识别方法，其特征在于：所述的步骤(3)中的在决策级进行融合的融合方法为基于模糊综合的融合算法，其步骤如下：(1)根据自动字符识别中得到的文本信息中‘＜’的位置将机读码字符分割成具有ICAO-9303标准所定义的语义字符串；(2)根据自动字符识别中所得到的相似度向量序列计算每个语义字符串与重点人物数据库中对应文本特征的相似度。得到待比对样本经过文本特征对比后的一组识别结果，表示为：Ψ1＝{(o1，ω1，1)，(o1，ω1，2)，...，(o1，ω1，i)，...，(o1，ω1，p)}。其中，ω1，i为文本特征与第i个样本oi的相似度；(3)采用EHMM模型的前向后向算法计算观察向量序列V与模型参数λ＝(π，A，Λ)的吻合概率p(V|λ)，得到待比对样本与重点人物数据库中所有面部特征EHMM模型的吻合概率序列，即待比对样本经面部特征比对的一组识别结果，表示为：Ψ2＝{(o1，ω2，1)，(o1，ω2，2)，...，(o1，ω2，i)，...，(o1，ω2，p)}，其中：ω2，i＝p(V|λ1)为待鉴别样本面部特征与第i个样本oi的相似度；(4)利用模糊集方法将文本特征比对和面部特征比对所得结果进行融合，模糊综合函数取：S(ω1，i，ω2，i)＝(ω1，i&#183;ω2，i)1/2或S(&amp;omega;1,i,&amp;omega;2,i)=&amp;omega;1,i+&amp;omega;2,i2;]]&gt;(5)若maxS(ω1，i，ω2，i)＞T，则该人员为第g个样本，否则该人员为非重点人物，其中T为相似度域值，g＝argimaxS(ω1，i，ω2，i)。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES57845456" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">一种基于信息融合的机读旅行证件识别方法</invention-title>
    <technical-field>
      <p>技术领域</p>
      <p>本发明涉及到一种机读旅行证件识别方法，特别是一种基于信息融合的机读旅行证件识别方法，用于快速通关工作。</p>
    </technical-field>
    <background-art>
      <p>背景技术</p>
      <p>随着国际交流合作的不断增加，快速通关已成为流动人口管理工作中的一个重要环节。其主要工作包括人员信息采集和重点人物审查。传统通关方法多采用人工方式进行信息采集和比对，效率低下浪费了大量人力资源。机读旅行证件的使用，使得自动采集和比对人员信息成为可能。机读旅行证件指符合国际民航组织推荐的ICAO-930关于机读旅行证件标准的适用于机器阅读的供国际旅行使用的各种证件，包括护照、签证、通行证和身份证等。</p>
      <p>目前部分流动人员管理单位已采用证件自动识别方法来代替手工操作。但现有的方法只能提取证件中的文本信息，在很大程度上影响了人员审查的准确率。其主要缺陷表现为：(1)只提取文本信息，人员身份审查的准确率直接依赖于对文本信息识别的准确率。然而由于各种因素的影响，识别错误在所难免，因此身份审查正确率不高；(2)存在一些不法分子企图使用伪造证件通关，证件中的文本信息与真实情况不符，因此仅通过文本信息进行身份审查将导致错误结果。</p>
    </background-art>
    <disclosure>
      <p>发明内容</p>
      <p>本发明解决的技术问题：克服现有技术的不足，提供一种基于信息融合的机读旅行证件识别方法，该方法不仅能够自动识别证件图像中的文本信息，同时自动提取证件中包含的持证人面部特征信息，并通过特征比对及结果融合准确地判断持证人是否为重点人物，满足了快速通关工作的需求，提高了持证人身份对比的准确度。</p>
      <p>本发明的技术解决方案：一种基于信息融合的机读旅行证件识别方法，其特点在于：综合利用旅行证件的文本信息及人脸信息，通过决策级融合提高识别的准确率，整个流程分为三部分：机读码信息提取，面部特征提取和身份比对。</p>
      <p>(1)机读码信息提取：机读码区域位于证件图像下部，包含持证人的基本信息，机读码信息提取的主要包括：自动定位机读码区域和自动字符识别，通过自动定位机读码区域确定机读码字符的区别，再通过自动字符识别得到持证人的文本信息，然后将此文本信息保存至数据库中；(2)面部特征提取：检测证件图像中人脸图像位置，提取持证人面部特征，将此特征信息存入数据库中；(3)身份比对：将文本特征和面部特征分别与重点人物数据库中的特征数据进行比对，并对两类比对结果在决策级进行融合，判断持证人是否为重点人物数据库中的成员。</p>
      <p>所述步骤(1)中的自动定位机读码区域的方法如下：(1)在HSI空间采用Thue＝Black对图像进行彩色滤波，滤除背景图像；(2)采用膨胀操作完成滤波后字符图像的笔画粘连，保证每个字符构成一个完整的连通区域；(3)利用连通区域分析算法得到每一个连通区域的外接矩形，剔除尺寸超过限定范围的矩形，得到矩形集合；(4)根据外接矩形划定机读码区域。将外接矩形集合划分为若干不相交的子集，各子集同时满足：(a)同一子集内的相邻矩形垂直位置相差较小；(b)同一子集内相邻矩形水平距离较小；(5)求出每个子集中所有矩形的最小外接矩形，外接矩形宽度超过图像宽度3/4的矩形区域即为机读码字符区域。</p>
      <p>所述步骤(1)中的自动字符识别方法如下：(1)采用最小二乘法对每一行机读码字符外接矩形左上角像素坐标进行线性拟合，根据拟合得到的直线倾斜角对图像进行旋转；(2)对旋转后的图像进行二值化操作，得到机读码图像二值图像；(3)对上述二值图像利用字符外接矩形信息完成对字符的分割，得到每一个机读码字符的图像；(4)利用OCR算法识别上述字符图像，得到文本信息。同时得出机读码区域各字符图像与字符模版的相似度向量序列VectorSeries＝{SimVectorn|1≤n≤N}，其中：N为机读码区域字符的个数，SimVectorn为第n个字符模版的相似度向量，表示为：SimVector＝{Simm|1≤m≤M}，其中M为字符模版的个数，Simm是这个字符与第m个字符模版的相似度。</p>
      <p>所述步骤(2)中的自动检测证件图像中人脸图像位置，提取持证人面部特征的方法步骤如下：(1)离线训练。利用Adaboost算法从一个大特征样本中选取若干最有效的特征，并为每个特征生成一个弱分类器，通过将这些分类器进行级联组合得到一个强学习算法；(2)在线检测。使用大小不同的窗口扫描图像，使用学习阶段得到的分类器检测窗口图像，若该窗口图像通过了所有的弱分类器，即认为该子窗口图像为人脸图像；(3)对定位得到的人脸图像进行大小归一化、消除噪声、灰度归一化；(4)采用基于EHMM的特征算法为每一个人脸建立一个EHMM模型。</p>
      <p>所述的步骤(3)中的在决策级进行融合的融合方法为基于模糊综合的融合算法，其步骤如下：(1)根据自动字符识别中得到的文本信息中‘＜’的位置将机读码字符分割成具有ICAO-9303标准所定义的语义字符串；(2)根据自动字符识别中所得到的相似度向量序列计算每个语义字符串与重点人物数据库中对应文本特征的相似度。得到待比对样本经过文本特征对比后的一组识别结果，表示为：Ψ1＝{(o1，ω1，1)，(o1，ω1，2)，...，(o1，ω1，i)，...，(o1，ω1，p)}。</p>
      <p>其中，ω1，i为文本特征与第i个样本oi的相似度；(3)采用EHMM模型的前向后向算法计算观察向量序列V与模型参数λ＝(π，A，Λ)的吻合概率p(V|λ)。从而得到待比对样本与重点人物数据库中所有面部特征EHMM模型的吻合概率序列，即待比对样本经面部特征比对的一组识别结果，表示为：Ψ2＝{(o1，ω2，1)，(o1，ω2，2)，...，(o1，ω2，1)，...，(o1，ω2，p)}。其中ω2，i＝p(V|λi)为待鉴别样本面部特征与第i个样本oi的相似度；(4)利用模糊集方法将文本特征比对和面部特征比对所得结果进行融合，模糊综合函数取：S(ω1，i，ω2，i)＝(ω1，i&#183;ω2，i)1/2或S(&amp;omega;1,i,&amp;omega;2,i)=&amp;omega;1,i+&amp;omega;2,i2;]]&gt;(5)若maxS(ω1，i，ω2，i)＞T则该人员为第g个样本，否则该人员为非重点人物，其中T为相似度域值，g＝argimaxS(ω1，i，ω2，i)。</p>
      <p>本发明与现有技术相比的优点在于：(1)可以自动识别证件图像中的文本信息，提高了人员信息采集的效率；(2)同时自动提取证件中包含的持证人面部特征信息，提高了机读旅行证件持证人的身份比对准确率；(3)提取人脸特征为涉外案件的侦察提供相应的依据。</p>
    </disclosure>
    <description-of-drawings>
      <p>附图说明</p>
      <p>图1为本发明的机读旅行证件自动识别方法工作流程图；图2为本发明的机读码区域图像；图3为本发明采用的人脸图像的EHMM；图4为本发明的基于融合算法的身份比对框图。</p>
    </description-of-drawings>
    <mode-for-invention>
      <p>具体实施方式</p>
      <p>如图1所示，本发明包括整个流程分为三部分：机读码信息提取，面部特征提取和身份比对。</p>
      <p>1.机读码信息提取方法：机读码信息提取分为两部分：机读码区域定位和机读码识别，前者完成对机读码图像定位，后者完成对机读码图像的预处理和识别。</p>
      <p>通过分析，发现机读码区域字符具有以下特点：(1)机读码区域字符尺寸一定；(2)所有字符均为黑色印刷体字符，采用OCR-B字体；(3)各字符笔画均相连。针对以上特点本方法采用基于连通区域分析的方法来定位机读码区域。</p>
      <p>由于机读码区域位置相对固定，为提高处理速度，仅在图像的下1/3区域内进行机读码区域提取，其方法步骤如下：(1)首先在HSI(Hue&#160;Saturation&#160;Intensity)空间对图像进行彩色滤波，保留所有满足Thue＝Black的像素点，滤除背景图像。</p>
      <p>(2)彩色滤波后，会出现笔画断裂影响连通区域分析，因此采用膨胀操作完成滤波后字符图像的笔画粘连，保证每个字符构成一个完整的连通区域。</p>
      <p>(3)利用文献(Yu&#160;and&#160;A.Jain.A&#160;generic&#160;system&#160;for&#160;form&#160;ropout.IEEETrans.Pattern&#160;Analysis&#160;and&#160;Machine&#160;Intelligent，1996，18：1127-1134.)中提出的连通区域分析算法得到上述图像中每一个连通区域的外接矩形。剔除尺寸超过限定范围的矩形，得到矩形集合。</p>
      <p>(4)最后，根据外接矩形集合划定机读码区域。分析机读码区域特点，并结合机读码字符国际标准，本方法提出以下假设：(a)同一行相邻字符的外接矩形在垂直位置上相差较小；(b)同一行相邻字符的水平距离较小；(c)一行机读码字符的长度大于图像长度的3/4，将外接矩形集合划分为若干不相交的子集，各子集同时满足假设(a)和(b)。</p>
      <p>(5)求出每个子集中所有矩形的最小外接矩形，外接矩形宽度超过图像宽度3/4的矩形区域即为机读码字符区域。</p>
      <p>机读码识别方法具体步骤如下：由于证件图像采集时，可能存在图像倾斜的情况，且字符识别算法只能处理单个文字的二值图像，因此在字符识别之前需进行倾斜校正、二值化以及字符分割等操作。</p>
      <p>针对图像采集过程中产生的图像倾斜，本方法采用最小二乘法对每一行机读码字符外接矩形的左上角像素坐标进行线性拟合。拟合得到的直线倾斜角度作为机读码区域的倾斜角度。</p>
      <p>对图像进行二值化得到机读码的二值图像，利用已得到的所有字符外接矩形，可直接完成对字符的分割。得到每机读码区域中每个字符的图像。</p>
      <p>利用OCR算法识别上述字符图像，得到文本信息。同时得出机读码区域各字符图像与字符模版的相似度向量序列VectorSeries＝{SimVectorn|1≤n≤N}。其中，N为机读码区域字符的个数，SimVectorn为第n个字符模版的相似度向量，表示为：SimVector＝{Simm|1≤m≤M}，其中M为字符种类的个数，即37。Simm是这个字符与所有字符种类中第m个字符的相似度。</p>
      <p>2.面部特征提取方法如下面部特征提取由两部分构成：人脸检测和人脸比对。人脸检测负责定位图像中的人脸位置。人脸比对负责提取人脸面部特征，与样本特征进行比对，得到相似度。</p>
      <p>本方法实现了一个正面人脸检测框架，该框架分为离线训练和在线检测两部分。离线训练从一个大特征样本中选取若干最有效的特征，并为每个特征生成一个弱分类器，通过将这些分类器进行级联组合得到一个强学习算法。分类器训练结束以后，即可应用于在线检测中。在线检测通过使用大小不同的窗口扫描图像，使用学习阶段得到的分类器检测窗口图像，若该窗口图像通过了所有的弱分类器，即认为该子窗口图像为人脸图像。对所有窗口图像进行检测之后，结合所有检测结果，得到最后的输出。</p>
      <p>人脸特征提取采用文献(AV&#160;Nefian&#160;and&#160;MH&#160;Hayes&#160;III：An&#160;embeddedHMM-based&#160;approach&#160;for&#160;face&#160;detection&#160;and&#160;recognition.In：IEEE&#160;Inter.Conf.on&#160;Acoustics，Speech&#160;and&#160;Signal&#160;Processing，IEEE&#160;Press，NewYork(1999)3553-3556)中提出的基于EHMM的特征提取算法，根据人脸五官特征，人脸图像的EHMM取5个超状态对应人脸的额头、眼睛、鼻子、嘴和下巴，分别描述和代表人脸的宏观特征，每个超状态内嵌入的状态分别描述人脸局部区域特征。人脸特征提取采用以下流程，由于特征提取和比对会受到诸如图像大小、亮度以及背景噪声等因素的影响，所以首先对对人脸图像进行大小归一化、消除噪声、灰度归一化等，以便在同一条件下完成训练和识别。然后建立人脸图像的EHMM。为了能够准确的表示人脸特征同时保证算法效率，每个超状态中的嵌入状态数取值为(3，6，6，6，3)。</p>
      <p>3.身份比对方法仅将某一种特征作决策依据不能充分的利用证件所提供的信息，难以保证身份比对的准确性，本方法采用基于决策级融合的身份比对综合考虑不同类型的特征，从而得到更可靠、全面、准确的比对结果。该方法通过文本特征比对和面部特征比对得到两组比对结果，并在决策级对两类结果进行融合，最终给出一个二类决策：该人员是否为样本集中的样本。</p>
      <p>在文本信息提取阶段，识别得到所有机读码区域字符，同时得到了一个相似度向量序列VectorSeries。本阶段采用以下步骤进行特征比对：根据ICAO-9303机读码标准，机读码字符中具有不同语义的字符被连续的‘＜’分割开。因此首先通过确定识别结果中‘＜’的位置将机读码字符分割成具有ICAO-9303所定义语义的字符串。</p>
      <p>利用相似度向量序列VectorSeries计算每个语义字符串与重点人物数据库中对应文本特征的相似度。例如，对于文本特征“ABC”，在VectorSeries中查找字符串首字符与A的相似度，第二个字符与B的相似度以及第三个字符与C的相似度，按照下式计算与这个文本特征的相似度即可：SimOfCluster=&amp;Sigma;i=1NSimi]]&gt;其中Simi为语义字符串中第i个字符与对应特征字符的相似度，N为字符串中的字符个数。将语义字符串的相似度进行加权平均，得到整个文本信息与重点人物数据库中文本信息的相似度。对于具有重要性较高语义的字符，赋给其较高的权值，而语义相对不重要的字符赋予其较低的权值，下式表示了本方法采用的相似度计算方法：&amp;mu;=&amp;Sigma;i=1M&amp;alpha;iSimOfClusteri&amp;Sigma;i=1M&amp;alpha;i.]]&gt;其中，αi为语义字符串的权值，以护照为例各字符的权值如表1所示。SimOfClusteri表示文本信息中第i个语义字符与比对样本中对应信息的相似度，M为文本语义字符串的个数。</p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>至此，能够得到待比对样本经过文本特征比对后的一组识别结果，表示为：Ψ1＝{(o1，ω1，1)，(o1，ω1，2)，...，(o1，ω1，i)，...，(o1，ω1，p)}，其中：ω1，i＝μi为文本特征与第i个样本oi的相似度。</p>
      <p>与文本特征比对相似，将前面得到的面部特征与样本空间中所有人脸特征进行比对得到相似度。本发明首先通过2D-DCT变换得到证件中人脸图像的观察向量序列V，采用EHMM模型的前向后向算法计算观察向量序列V与模型参数λ＝(π，A，Λ)的吻合概率p(V|λ)，从而得到待比对样本与重点人物数据库中所有面部特征EHMM模型的吻合概率序列，即待比对样本经“面部特征通道”的识别结果，表示为：Ψ2＝{(o1，ω2，1)，(o1，ω2，2)，...，(o1，ω2，i)，...，(o1，ω2，p)}，其中：ω2，i＝p(V|λi)为待鉴别样本面部特征与第i个样本oi的相似度。</p>
      <p>通过文本特征比对，获得了待比对样本文本特征与样本空间中各元素的相似度，可将其理解为样本经过“文本特征通道”得到的“模糊”判别结果。通过面部特征比对，得到了样本面部特征信息与样本空间各元素的相似度，可将其理解为样本经过“面部特征通道”的另一组“模糊”判别结果。利用模糊集方法将两个通道的结果进行融合，模糊综合函数取：S(ω1，i，ω2，i)＝(ω1，i&#183;ω2，i)1/2或S(&amp;omega;1,i,&amp;omega;2,i)=&amp;omega;1,i+&amp;omega;2,i2.]]&gt;最终的分类判据为，若maxS(ω1，i，ω2，i)＞T则该人员为第g个样本，否则该人员为非重点人物，其中T为相似度阈值，g＝argimaxS(ω1，i，ω2，i)。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102034099A?cl=zh">CN102034099A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月9日</td><td class="patent-data-table-td patent-date-value">2011年4月27日</td><td class="patent-data-table-td ">山东神思电子技术有限公司</td><td class="patent-data-table-td ">客户证件和现场信息鉴别比对留存系统及其工作方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102831425A?cl=zh">CN102831425A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月29日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">东南大学</td><td class="patent-data-table-td ">一种人脸图像快速特征提取方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102955941A?cl=zh">CN102955941A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年8月31日</td><td class="patent-data-table-td patent-date-value">2013年3月6日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">身份信息录入方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103503029A?cl=zh">CN103503029A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年4月11日</td><td class="patent-data-table-td patent-date-value">2014年1月8日</td><td class="patent-data-table-td ">英特尔公司</td><td class="patent-data-table-td ">检测面部特性的方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0007000000">G06K7/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=xGyHAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G07C0009000000">G07C9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2007年9月19日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2007年11月14日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年5月19日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年3月2日</td><td class="patent-data-table-td ">EXPY</td><td class="patent-data-table-td ">Termination of patent right or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/9b59901f1d58f4bb01ce/CN101038686A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5115ea495017d9115e613207d3810e5a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88%E7%9A%84%E6%9C%BA%E8%AF%BB%E6%97%85%E8%A1%8C.pdf?id=xGyHAAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3m7icBA8KZlBRZFoFxfiuWBfoUKQ"},"sample_url":"https://www.google.com/patents/reader?id=xGyHAAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>