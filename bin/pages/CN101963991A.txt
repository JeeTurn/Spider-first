<!DOCTYPE html><html><head><title>专利 CN101963991A - 图片准确搜索方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="图片准确搜索方法"><meta name="DC.contributor" content="辜进荣" scheme="inventor"><meta name="DC.contributor" content="辜进荣" scheme="assignee"><meta name="DC.date" content="2010-10-15" scheme="dateSubmitted"><meta name="DC.description" content="本发明是一种图片准确搜索方法，其方法是存在可以获取信息的第一图片，并且可以自第一图片中获得能够描述该图片的信息生成样本图片信息，将样本图片信息发送到网络或数据库，网络或数据库接受该样本图片信息并进行搜索，搜索到对应的其它类似图片，这个类似图片为第二图片，网络或数据库将所述搜索到的第二图片返回给用户端，也可再次自所获得的第二图片中提取第二样本图片信息，作为再次搜索的参考图片，其优点和效果：这种图片准确搜索方法，准确针对图片的具体内容，基于这种方式搜索出来的图片，无需与图片的关键字的内容相关联，而与用户真正想搜索的图片内容相符合，同时可以返回多个用户想要的结果，容易实现及操作。"><meta name="DC.date" content="2011-2-2"><meta name="DC.relation" content="CN:101211341:A" scheme="references"><meta name="DC.relation" content="CN:101216841:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:101963991:A"><meta name="citation_patent_application_number" content="CN:201010508187"><link rel="canonical" href="https://www.google.com/patents/CN101963991A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101963991A?cl=zh"/><meta name="title" content="专利 CN101963991A - 图片准确搜索方法"/><meta name="description" content="本发明是一种图片准确搜索方法，其方法是存在可以获取信息的第一图片，并且可以自第一图片中获得能够描述该图片的信息生成样本图片信息，将样本图片信息发送到网络或数据库，网络或数据库接受该样本图片信息并进行搜索，搜索到对应的其它类似图片，这个类似图片为第二图片，网络或数据库将所述搜索到的第二图片返回给用户端，也可再次自所获得的第二图片中提取第二样本图片信息，作为再次搜索的参考图片，其优点和效果：这种图片准确搜索方法，准确针对图片的具体内容，基于这种方式搜索出来的图片，无需与图片的关键字的内容相关联，而与用户真正想搜索的图片内容相符合，同时可以返回多个用户想要的结果，容易实现及操作。"/><meta property="og:title" content="专利 CN101963991A - 图片准确搜索方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101963991A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101963991A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=_iqOBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101963991A&amp;usg=AFQjCNGQH4sIGH84KZIy2ASnh5NC0qxLJw" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/786abd2c7827bb6d5643/CN101963991A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/786abd2c7827bb6d5643/CN101963991A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101963991A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101963991A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101963991A?cl=zh" style="display:none"><span itemprop="description">本发明是一种图片准确搜索方法，其方法是存在可以获取信息的第一图片，并且可以自第一图片中获得能够描述该图片的信息生成样本图片信息，将样本图片信息发送到网络或数据库，网络或数据库接受该样本图片信息并进行搜...</span><span itemprop="url">https://www.google.com/patents/CN101963991A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101963991A - 图片准确搜索方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101963991A - 图片准确搜索方法" title="专利 CN101963991A - 图片准确搜索方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101963991 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010508187</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年2月2日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年10月15日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年10月15日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010508187.8, </span><span class="patent-bibdata-value">CN 101963991 A, </span><span class="patent-bibdata-value">CN 101963991A, </span><span class="patent-bibdata-value">CN 201010508187, </span><span class="patent-bibdata-value">CN-A-101963991, </span><span class="patent-bibdata-value">CN101963991 A, </span><span class="patent-bibdata-value">CN101963991A, </span><span class="patent-bibdata-value">CN201010508187, </span><span class="patent-bibdata-value">CN201010508187.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%BE%9C%E8%BF%9B%E8%8D%A3%22">辜进荣</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%BE%9C%E8%BF%9B%E8%8D%A3%22">辜进荣</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101963991A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101963991A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101963991A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=_iqOBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010508187&amp;usg=AFQjCNGEQdNInjJftaRClxYy4_xuv6Sa3g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=_iqOBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101963991A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNE8rPMzjPz7SgISb581mz1NMlF8zw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT100746467" lang="ZH" load-source="patent-office">图片准确搜索方法</invention-title>
      </span><br><span class="patent-number">CN 101963991 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA83033166" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明是一种图片准确搜索方法，其方法是存在可以获取信息的第一图片，并且可以自第一图片中获得能够描述该图片的信息生成样本图片信息，将样本图片信息发送到网络或数据库，网络或数据库接受该样本图片信息并进行搜索，搜索到对应的其它类似图片，这个类似图片为第二图片，网络或数据库将所述搜索到的第二图片返回给用户端，也可再次自所获得的第二图片中提取第二样本图片信息，作为再次搜索的参考图片，其优点和效果：这种图片准确搜索方法，准确针对图片的具体内容，基于这种方式搜索出来的图片，无需与图片的关键字的内容相关联，而与用户真正想搜索的图片内容相符合，同时可以返回多个用户想要的结果，容易实现及操作。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><ol mxw-id="PCLM34912369" lang="ZH" load-source="patent-office" class="claims">
    <li class="claim"> <div num="1" class="claim">
      <div class="claim-text">一种图片准确搜索方法，其特征在于：包括：存在可以获取信息的第一图片；根据所述第一图片信息生成样本图片信息，样本图片信息是所述第一图片信息的一部分；将样本图片信息发送到网络或数据库；网络或数据库接受该样本图片信息并进行搜索，搜索到对应的其它类似图片，这个类似图片为第二图片；网络或数据库将所述搜索到的第二图片返回给用户端。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的图片准确搜索方法，其特征在于：所述的第一图片来自于区 域网络或用户本身，或互联网，并进行搜索。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的图片准确搜索方法，其特征在于：从第一图片中获得能够描述该图片的样本图片信息，是从第一图片可视界面中剪切其 中一部分，作为样本图片信息。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的图片准确搜索方法，其特征在于：从第一图片中获得能够描述该图片的样本图片信息，是从第一图片中以图像特征作为 依据选择其中一部分，作为样本图片信息。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的图片准确搜索方法，其特征在于：所述的从第一图片中选择 其中一部分作为样本图片信息，是采用的点选方式或圈选方式。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的图片准确搜索方法，其特征在于：所述的第二图片至少为一个。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1所述的图片准确搜索方法，其特征在于：所述第一图片信息生成样本图片信息是从互联网上获取已经存在的第一图片； 将获取到的所述第一图片的格式转换为点阵格式，以便从所述图片上获取到能够描述 该图片的样本图片信息。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求1所述的图片准确搜索方法，其特征在于：将所获得的第二图片中提 取第二样本图片信息，作为再次搜索的参考图片，进行再次搜索。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求1所述的图片准确搜索方法，其特征在于：第一图片信息生成样本图片信息，样本图片信息是所述第一图片信息的一部分； 所述第一图片信息能够描述该图片的颜色信息；根据所述颜色信息生成所述图片的样本图片信息，以便根据所述样本图片信息搜索到 对应的图片。在前所述的第一图片生成样本图片，样本图片信息是所述第一图片信息的一部分； 所述第一图片信息的指能够描述该图片的色彩及灰度信息；并根据所述色彩及灰度信息生成所述图片的样本图片信息，以便根据所述样本图片信 息搜索到对应的第二图片。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的方法，其特征在于：从第一图片信息获取到的样本图片中获 得能够描述该图片的色彩及灰度信息，具体过程包括：选择在第一图片区域内的有效指定区域作为样本图片的选择对象，采用可视界面的图 片剪切方式，生成一个样本图片区域；将所述样本图片区域内每个点的实际色彩表示成数值形式的色彩数据及灰度数据； 取得所述每个点的色彩及灰度数据，生成能够描述所述图片的色彩及灰度信息； 按照所述色彩及灰度信息中包含的实际色彩种类、特性、比例等特征分别建立与所述 样本图片信息。</div>
    </div>
  </li> </ol>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES40763108" lang="ZH" load-source="patent-office" class="description">
    <p>图片准确搜索方法</p>
    <p>技术领域 [0001]	本发明涉及到搜索技术领域，特别涉及到一种实现图片准确搜索的方法。 背景技术</p>
    <p>[0002]	随着社会和技术的进步，通讯技术和应用方式也越来越适应用户的需求，网络和 手机已经进入到了生活的方方面面，特别是随着宽带网络和宽带的推进和应用，而网络提 供的搜索服务也越来越多，例如除了关键字搜索以外，还有图片搜索等，可以通过图片搜索 程序，向用户提供网络或数据库上，特别是互联网上相关的图片资料，而现有技术中的图片 搜索，是由先给图片关联文字说明，与图片结合，而由用户在搜索框内输入搜索文字并提交 到网站的搜索引擎后，搜索引擎在网络机器人抓取到的海量配有文字的图片中，以用户所 提交的搜索文字作为关键字，来搜索附加在这些图片中匹配的文字的方式，常用的是搜索 图片所附加的文字，并将此图片返回用户，也就是说，这还是一种基于文字的图片搜索，而 不是准确针对图片的具体内容，这样，这种方式搜索出来的图片，往往是与所用的关键字的 内容相附，而与用户真正想搜索的图片内容不符，用户在返回的很多结果，得不到自己想要 找的内容，因此，目前的图片搜索方式还存在不足和需要完善的地方。</p>
    <p>发明内容</p>
    <p>[0003]	本发明的目的就是为了解决以上问题，提供一种不借助文字就可以准确进行图片 检索的方法。</p>
    <p>[0004]	本发明是通过这样的方法来实现的：</p>
    <p>[0005]	一种图片准确搜索方法，包括：存在可以获取信息的第一图片，并且可以自第一图 片中获得能够描述该图片的信息；</p>
    <p>[0006]	根据所述第一图片信息生成样本图片信息，样本图片信息是所述第一图片信息的 一部分；</p>
    <p>[0007]	将样本图片信息发送到网络或数据库；</p>
    <p>[0008]	网络或数据库接受该样本图片信息并进行搜索，搜索到对应的其它类似图片，这 个类似图片为第二图片；</p>
    <p>[0009]	网络或数据库将所述搜索到的第二图片返回给用户端。</p>
    <p>[0010]	进一步的，前述的第一图片来自于区域网络或用户本身，或互联网。</p>
    <p>[0011]	进一步的，从第一图片中获得能够描述该图片的样本图片信息，是从第一图片可 视界面中剪切其中一部分，作为样本图片信息。</p>
    <p>[0012]	进一步的，从第一图片中获得能够描述该图片的样本图片信息，是从第一图片中 以图像特征作为依据选择其中一部分，作为样本图片信息。</p>
    <p>[0013]	进一步的，所述的从第一图片中选择其中一部分作为样本图片信息，是采用的点 选或圈选方式。</p>
    <p>[0014]	进一步的，所述的第二图片至少为一个。[0015]	进一步的，所述第一图片信息生成样本图片信息是从互联网上获取已经存在的第 一图片，将获取到的所述第一图片的格式转换为点阵格式，以便从所述图片上获取到能够 描述该图片的样本图片信息。</p>
    <p>[0016]	进一步的，可再次自所获得的第二图片中提取第二样本图片信息，作为再次搜索 的参考图片，进行再次搜索。</p>
    <p>[0017]	进一步的，第一图片信息生成样本图片信息，样本图片信息是所述第一图片信息 的一部分；</p>
    <p>[0018]	所述第一图片信息能够描述该图片的色彩及灰度信息； </p>
    <p>[0019]	根据所述色彩及灰度信息生成所述图片的样本图片信息，以便根据所述样本图片 信息搜索到对应的第二图片。</p>
    <p>[0020]	进一步的，从第一图片信息获取到的样本图片中获得能够描述该图片的色彩及灰 度信息，具体过程包括：</p>
    <p>[0021]	选择在第一图片区域内的有效指定区域作为样本图片的选择对象，可以首先采用 可视界面的图片剪切方式，生成一个样本图片区域；</p>
    <p>[0022]	将所述样本图片区域内每个点的实际色彩表示成数值形式的色彩数据；</p>
    <p>[0023]	取得所述每个点的色彩数据，生成能够描述所述图片的色彩及灰度信息；</p>
    <p>[0024]	按照所述色彩及灰度信息中包含的实际色彩种类、特性、比例等特征分别建立与 所述样本图片信息。</p>
    <p>[0025]	本发明具有以下的优点和效果：</p>
    <p>[0026]	这种图片准确搜索方法，准确针对图片的具体内容，基于这种方式搜索出来的图 片，无需与图片的关键字的内容相关联，而与用户真正想搜索的图片内容相符合，同时可以 返回多个用户想要的结果，容易实现及操作。</p>
    <p>附图说明</p>
    <p>[0027]	图1是本发明所提出的图片准确搜索方法的原理框图；</p>
    <p>[0028]	图2是本发明所提出的图片准确搜索方法的搜索方法的获取样本图片示意图；</p>
    <p>[0029]	图3是本发明所提出的图片准确搜索方法的搜索方法所述的第二图片示意图；</p>
    <p>[0030]	图中说明：</p>
    <p>[0031]	1-用户终端显示屏，简称显示屏</p>
    <p>[0032]	2-第一图片</p>
    <p>[0033]	3-样本图片</p>
    <p>[0034]	4-第二图片（由第一图片获取)</p>
    <p>具体实施方式</p>
    <p>[0035]	下面结合附图对本发明的系统和方法进行进一步的说明。</p>
    <p>[0036]	为实现本发明的目的，本发明采用是这样的方法：</p>
    <p>[0037]	首先需要有一个用户终端，这个终端可以是电脑、电脑、手机等具有显示屏1以及 操作软件的信息设备，并且具有可以获取信息的第一图片2，这个可以直接显示在用户终端 的显示屏1上，而不仅仅只是一个或一段文字标识，这个图片可以是一个模型，如一个模型图片或与用户所要检索的目标图片最为接近的图片，并且从这个第一图片2中获得能够描 述该图片的信息，就是指这个图片是可以复制、剪切或是通过其它方式可获得其它像素或 图像信息的，是可以通过计算机的系统或应用程序获得该图片的像素的信息，而不是不可 复制或不可裁剪类的文件。</p>
    <p>[0038]	第一图片2来自于局域网络、互联网络或用户本身或自存文档。 [0039]	在上述条件的基础上，就要根据所述第一图片2信息生成样本图片3，如附 图2，所述的第一图片可视界面2中具有数字1234567890，也具有三角形图形，还具有 字母AB⑶EFGHIJK，用户想找到与字母AB⑶EFGHIJK最为接近的图片，那么就把字母 ABCDEFGHIJK区域的图片作为样本图片3，字母ABCDEFGHIJK区域的图片中的字母为宋体字 体，也就是说，样本图片3信息就是第一图片可视界面2上图片信息的一部分信息。</p>
    <p>[0040]	完成上述的步骤以后，将样本图片3信息发送到网络或数据库，网络或数据库接 受该样本图片3信息，并以此为参考图片进行搜索。</p>
    <p>[0041]	同样，搜索的范围也可以分别是局域网络、互联网络或用户本身或自存文档。</p>
    <p>[0042]	经过上述电脑或服务器、以及网络上的搜索，搜索到对应的其它类似图片，这个或 这些类似图片为第二图片4，如附图3所示，可以找到很多类似其它字体及形式的结果，以 及具有字母ABCDEFGHIJK中大部分字体的图片，也都可以作为搜索结果返回，实质上，第二 图片4就是第一图片2在网络上最接近或最类似的结果。</p>
    <p>[0043]	搜索出来以后，网络或数据库将所述搜索到的第二图片返回给用户端，就如同在 在附图3中所看到的结果。</p>
    <p>[0044]	在上述的第一图片2中获得能够描述该图片的样本图片3的方法，是从第一图片 2中剪切其中一部分，作为样本图片3，也可以是从第一图片2中选择其中一部分，作为样本 图片3，是采用的点选方式，或是采用的圈选方式，所述的点选或圈选的方式可以以所选择 的区域或点选的范围来确定。</p>
    <p>[0045]	另外，所述的第二图片4至少为一个搜索结果，一般为多个。</p>
    <p>[0046]	同时，也可从互联网上获取已经存在的第一图片2，将获取到的所述第一图片2的 格式转换为点阵格式，以便从所述图片上获取到能够描述该图片的样本图片3信息。</p>
    <p>[0047]	根据所述样本图片3信息在互联网内搜索，将与所述样本图片3信息搜索请求对 应的第二图片4或者与所述样本图片3信息搜索请求最接近的第二图片4发送给用户。</p>
    <p>[0048]	在上述的基础上，为了获得更准确的搜索结果，还可再次由所获得的第二图片4 中再提取第二样本图片3信息，作为再次搜索的参考图片，进行再一次的搜索，得到更附合 用户的需要。</p>
    <p>[0049]	同时，在前所述的第一图片2生成样本图片3，样本图片3信息是所述第一图片信 息的一部分，所述第一图片2信息的指能够描述该图片的色彩及灰度信息，并根据所述色 彩及灰度信息生成所述图片的样本图片3信息，以便根据所述样本图片3信息搜索到对应 的第二图片4。</p>
    <p>[0050]	从第一图片2信息获取到的样本图片3中获得能够描述该图片的色彩及灰度信 息，具体过程包括：选择在第一图片2区域内的有效指定区域作为样本图片3的选择对象， 可以首先采用在第一图片2可视界面的图片剪切方式，生成一个样本图片3区域；将所述样 本图片3区域内每个点的实际色彩表示成数值形式的色彩数据；取得所述每个点的色彩数据，生成能够描述所述图片的色彩及灰度信息；按照所述色彩及灰度信息中包含的实际色 彩种类、特性、比例等特征分别建立与所述样本图片3信息。</p>
    <p>[0051]	通过上述的方法和步骤，即可以准确针对图片的具体内容，并且基于这种方式搜 索出来的图片，无需与图片的关键字的内容相关联，而与用户真正想搜索的图片内容相符 合，同时可以返回多个用户想要的结果，容易实现及操作</p>
    <p>[0052]	虽然这里只说明了本发明的一个优选实施例，但其意并非限制本发明的范围、适 用性和配置。相反，对实施例的详细说明可使本领域技术人员得以实施。应能理解，在不偏 离所附权利要求书确定的本发明精神和范围情况下，可对一些细节做适当变更和修改。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101211341A?cl=zh">CN101211341A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年12月29日</td><td class="patent-data-table-td patent-date-value">2008年7月2日</td><td class="patent-data-table-td ">上海芯盛电子科技有限公司</td><td class="patent-data-table-td ">图像智能模式识别搜索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101216841A?cl=zh">CN101216841A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年1月14日</td><td class="patent-data-table-td patent-date-value">2008年7月9日</td><td class="patent-data-table-td ">南京搜拍信息技术有限公司</td><td class="patent-data-table-td ">交互式图像搜索系统和方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103064972A?cl=zh">CN103064972A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月8日</td><td class="patent-data-table-td patent-date-value">2013年4月24日</td><td class="patent-data-table-td ">深圳市中兴移动通信有限公司</td><td class="patent-data-table-td ">移动终端图像检索的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103176996A?cl=zh">CN103176996A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月21日</td><td class="patent-data-table-td patent-date-value">2013年6月26日</td><td class="patent-data-table-td ">阿里巴巴集团控股有限公司</td><td class="patent-data-table-td ">基于图片特征信息的图片搜索方法及图片搜索引擎服务器</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=_iqOBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年2月2日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年3月23日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td ">C12</td><td class="patent-data-table-td ">Rejection of an application for a patent</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/786abd2c7827bb6d5643/CN101963991A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9B%BE%E7%89%87%E5%87%86%E7%A1%AE%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95.pdf?id=_iqOBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U01EBKL6pS_5_xUBRcQSDKrIlz2ew"},"sample_url":"https://www.google.com/patents/reader?id=_iqOBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>