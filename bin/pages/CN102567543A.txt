<!DOCTYPE html><html><head><title>专利 CN102567543A - 一种服装图片的搜索方法和装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种服装图片的搜索方法和装置"><meta name="DC.contributor" content="路晶" scheme="inventor"><meta name="DC.contributor" content="北京搜狗信息服务有限公司" scheme="assignee"><meta name="DC.contributor" content="北京搜狗科技发展有限公司" scheme="assignee"><meta name="DC.date" content="2012-1-12" scheme="dateSubmitted"><meta name="DC.description" content="本申请提供了一种服装图片的搜索方法和装置，其中的搜索方法具体包括：依据接收到的服装图片，抽取相应的服装本体局部特征；依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；将匹配查询得到的模特着装图片返回给用户。本申请能够为用户提供服装商品的着装效果，提高搜索效率。"><meta name="DC.date" content="2012-7-11"><meta name="DC.relation" content="CN:101042705:A" scheme="references"><meta name="DC.relation" content="CN:101206749:A" scheme="references"><meta name="DC.relation" content="CN:101853299:A" scheme="references"><meta name="DC.relation" content="CN:101872352:A" scheme="references"><meta name="DC.relation" content="CN:102016918:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:102567543:A"><meta name="citation_patent_application_number" content="CN:201210008780"><link rel="canonical" href="https://www.google.com/patents/CN102567543A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102567543A?cl=zh"/><meta name="title" content="专利 CN102567543A - 一种服装图片的搜索方法和装置"/><meta name="description" content="本申请提供了一种服装图片的搜索方法和装置，其中的搜索方法具体包括：依据接收到的服装图片，抽取相应的服装本体局部特征；依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；将匹配查询得到的模特着装图片返回给用户。本申请能够为用户提供服装商品的着装效果，提高搜索效率。"/><meta property="og:title" content="专利 CN102567543A - 一种服装图片的搜索方法和装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102567543A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102567543A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=jpeDBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102567543A&amp;usg=AFQjCNEUrEPeNV6TI9lm4MUo4vZSR-VNmA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/deba97fb5c3b26452219/CN102567543A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/deba97fb5c3b26452219/CN102567543A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102567543A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102567543A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102567543A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102567543B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102567543A?cl=zh" style="display:none"><span itemprop="description">本申请提供了一种服装图片的搜索方法和装置，其中的搜索方法具体包括：依据接收到的服装图片，抽取相应的服装本体局部特征；依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中...</span><span itemprop="url">https://www.google.com/patents/CN102567543A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102567543A - 一种服装图片的搜索方法和装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102567543A - 一种服装图片的搜索方法和装置" title="专利 CN102567543A - 一种服装图片的搜索方法和装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102567543 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210008780</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年7月11日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年1月12日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年1月12日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102567543B?hl=zh-CN&amp;cl=zh">CN102567543B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210008780.5, </span><span class="patent-bibdata-value">CN 102567543 A, </span><span class="patent-bibdata-value">CN 102567543A, </span><span class="patent-bibdata-value">CN 201210008780, </span><span class="patent-bibdata-value">CN-A-102567543, </span><span class="patent-bibdata-value">CN102567543 A, </span><span class="patent-bibdata-value">CN102567543A, </span><span class="patent-bibdata-value">CN201210008780, </span><span class="patent-bibdata-value">CN201210008780.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B7%AF%E6%99%B6%22">路晶</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E6%90%9C%E7%8B%97%E4%BF%A1%E6%81%AF%E6%9C%8D%E5%8A%A1%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京搜狗信息服务有限公司</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E6%90%9C%E7%8B%97%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京搜狗科技发展有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102567543A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102567543A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102567543A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=jpeDBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210008780&amp;usg=AFQjCNGcxTV8xzRGjkWFiXLa9YG0IANQHw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=jpeDBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102567543A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGy9mGiy50TRrQ8QG63MtTUTCEUZg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114036189" lang="ZH" load-source="patent-office">一种服装图片的搜索方法和装置</invention-title>
      </span><br><span class="patent-number">CN 102567543 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA98384290" lang="ZH" load-source="patent-office">
    <div class="abstract">本申请提供了一种服装图片的搜索方法和装置，其中的搜索方法具体包括：依据接收到的服装图片，抽取相应的服装本体局部特征；依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；将匹配查询得到的模特着装图片返回给用户。本申请能够为用户提供服装商品的着装效果，提高搜索效率。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(22)</span></span></div><div class="patent-text"><div mxw-id="PCLM44208068" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	�种服装图片的&#25436;索方法，其特征在干，包括：依据接收到的服装图片，抽取相应的服装本体局部特征；依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；将匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求1所述的方法，其特征在干，所述方法还包括：依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的方法，其特征在干，所述依据该服装图片的服装本体局部特征， 在图片数据库中进行服装本体局部特征的匹配查询的步骤具体为，依据该服装图片的服装本体局部特征，结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行联合匹配查询；其中，所述图片数据库中还存储有辅助图片对应的服装局部辅助特征；所述将匹配查询得到的模特着装图片返回给用户的步骤为，将联合匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求2所述的方法，其特征在干，所述方法还包括：依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中还存储有辅助图片对应的辅助信息；根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模特着装图片和相应的服装本体局部特征存储至所述图片数据库中。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求4所述的方法，其特征在干，所述依据该服装图片的服装本体局部特征， 在图片数据库中进行服装本体局部特征的匹配查询的步骤具体为，依据该服装图片的服装本体局部特征，在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求5所述的方法，其特征在干，所述网站中服装的各品牌模特着装图片还包括：对网站中对应的视频文件采集数据帧所得的静态图片；所述将匹配查询得到的模特着装图片返回给用户的步骤具体为：将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户；所述方法还包括：将所述静态图片对应的视频文件返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求1至6中任�权利要求所述的方法，其特征在干，所述方法还包括：对该服装图片进行方位模式处理，所述方位模式处理过程包括：对该服装图片进行方位变换，在服装图片中按各方位比例分别进行像素拉伸，得到服装图片对应的各方位视图；所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体为，依据服装图片对应的方位视图，抽取相应的服装本体局部特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求1至6中任�权利要求所述的方法，其特征在于，该服装图片为非穿着状态服装的图片时，所述方法还包括：对该服装图片进行模拟着装处理，所述模拟着装处理过程包括：对该服装图片中服装区域的左右边缘进行裁剪处理；按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染，得到模拟着装处理后的服装图片；所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体为，依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.如权利要求1至6中任�权利要求所述的方法，其特征在干，所述方法还包括：接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；依据该特定区域的视觉内容，抽取相应的服装本体局部特征；依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；将特定区域匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.如权利要求1至6中任�权利要求所述的方法，其特征在于，该服装图片为使用带有网络接入的移动设备拍摄的服装和/或配饰的图片。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.如权利要求2至6中任一项所述的方法，其特征在干，所述辅助图片包括服装标牌图片，辅助图片中的辅助信息包括服装品牌和/或服装型号信息。</div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12.	�种服装图片的&#25436;索装置，其特征在干，包括：第一抽取模块，用于依据接收到的服装图片，抽取相应的服装本体局部特征；第一匹配查询模块，用于依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；及第一结果返回模块，用于将匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.如权利要求12所述的装置，其特征在于，还包括：第二抽取模块，用于依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.如权利要求13所述的装置，其特征在干，所述第一匹配查询模块，具体用于依据该服装图片的服装本体局部特征，结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行联合匹配查询；其中，所述图片数据库中还存储有辅助图片对应的服装局部辅助特征；所述第一结果返回模块，具体用于将联合匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.如权利要求13所述的装置，其特征在于，还包括：第二匹配查询模块，用于依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中还存储有辅助图片对应的辅助信息；存储模块，用于根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模特着装图片和相应的服装本体局部特征存储至所述图片数据库中。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.如权利要求15所述的装置，其特征在干，所述第一匹配查询模块，具体用于依据该服装图片的服装本体局部特征，在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.如权利要求16所述的装置，其特征在干，所述网站中服装的各品牌模特着装图片还包括：对网站中对应的视频文件采集数据帧所得的静态图片；所述第一结果返回模块，具体用于将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户；所述装置还包括：第二结果返回模块，用于将所述静态图片对应的视频文件返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.如权利要求12至17中任一项所述的装置，其特征在于，还包括：方位模式处理模块，用于对该服装图片进行方位模式处理，所述方位模式处理模块包括：方位变换子模块，用于对该服装图片进行方位变换，在服装图片中按各方位比例分&#21029;进行像素拉伸，得到服装图片对应的各方位视图；所述第一抽取模块，具体用于依据服装图片对应的方位视图，抽取相应的服装本体局部特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.如权利要求12至17中任一项所述的装置，其特征在于，该服装图片为非穿着状态服装的图片时，所述装置还包括：模拟着装处理模块，用于对该服装图片进行模拟着装处理； 所述模拟着装处理模块包括：裁剪处理子模块，用于对该服装图片中服装区域的左右边缘进行裁剪处理；及渲染子模块，用于按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染，得到模拟着装处理后的服装图片；相应地，所述第一抽取模块，具体用于依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.如权利要求12至17中任一项所述的装置，其特征在于，还包括：第四接ロ模块，用于接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；第三抽取模块，用于依据该特定区域的视觉内容，抽取相应的服装本体局部特征； 第三匹配模块，用于依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；第三结果返回模块，用于将特定区域匹配查询得到的模特着装图片返回给用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21.如权利要求12至17中任一项所述的装置，其特征在于，该服装图片为使用带有网络接入的移动设备拍摄的服装和/或配饰的图片。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22.如权利要求13至17中任一项所述的装置，其特征在干，所述辅助图片包括服装标牌图片，辅助图片中的辅助信息包括服装品牌和/或服装型号信息。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES49829748" lang="ZH" load-source="patent-office" class="description">
    <p>�种服装图片的&#25436;索方法和装置</p>
    <p>技术领域</p>
    <p>[0001]	本申请涉及信息&#25436;索技术领域，特&#21029;是涉及�种服装图片的&#25436;索方法和装置。 背景技术</p>
    <p>[0002]	随着人们生活水平的不断提高，逛街购物成了不少时尚人士的选择，在逛街选购服装&#21515;，人们遇到喜爱的服装而实体商店又没有模特试穿&#21515;，看不到具体的着装效果，往往只能通过亲身试穿的方式判断这件服装是否合适自己，不免需要经过繁琐的试换、比照，花费了大量的时间和精力，常常让人感到筋疲力尽。</p>
    <p>[0003]	无论在实体商店还是网络商店中购物，用户都存在货比三家的消费心理，也即，在一家网店看中一件商品&#21515;，希望将其跟别的网店的相似商品去比较，以核实商品价格、质量是否合意。为了增加网上购物的便利性，现有�些图片购物搜索网站可以根据用户提供的商品图片，&#25436;索到指定类型的外观相似的商品。具体而言，用户提交商品图片，圈定图片中的商品范围，并指定商品的类型就可以搜索到外观最相似的商品图片及相关的商品信息， 如商品价格、商品介绍、商家信息等等。</p>
    <p>[0004]	但是，现有以图片进行购物搜索的网站目前仅仅针对网上购物的用户，其所用数据库的图片往往来源于网络商店，这样，在用户提交的图片为网络商店中某个流行商品的图片&#21515;，其能够搜索到外观最相似的商品图片；而在用户向网络商店提交稀缺商品的图片或者非该网络商店的商品（例如用户在实体商店中看到的商品）的图片&#21515;，很难搜索到外观最相似的商品图片，而且即使能够搜索到，仍不能为用户展示具体的着装效果。</p>
    <p>[0005]	一些网络商店能够提供商品&#25436;索功能，也即用户通过浏览器输入商品名称，&#25436;索引擎根据所输入的商品名称在网络中查找相关商品的信息，如商品价格、商品介绍、商家信息等，并显示给用户。但是，上述商品&#25436;索功能只允许用户输入描述性文本，这就对用户描述服装的能力提出了较高的要求，例如，需要用户将实体商店中服装的颜色、款式、类别等特征用语言准确描述出来，描述过程需要花费大量的时间，而且，即便表达能力好的用户将其服装特征描述出来了，也很难在现有的搜索引擎中找到与该服装相似的商品，导致搜索效率低下，使用网络流量较大。</p>
    <p>[0006]	总之，需要本领域技术人员迫切解决的�个技术问题就是：如何能够为用户提供服装商品的着装效果。</p>
    <p>发明内容</p>
    <p>[0007]	本申请所要解决的技术问题是提供�种服装图片的&#25436;索方法和装置，能够为用户提供服装商品的着装效果，提高搜索效率。</p>
    <p>[0008]	为了解决上述问题，本申请公开了�种服装图片的&#25436;索方法，包括：</p>
    <p>[0009]	依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0010]	依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；[0011]	将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0012]	优选的，所述方法还包括：</p>
    <p>[0013]	依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征。</p>
    <p>[0014]	优选的，</p>
    <p>[0015]	所述依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询的步骤具体为，依据该服装图片的服装本体局部特征，结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行联合匹配查询；所述图片数据库中还存储有辅助图片对应的服装局部辅助特征；</p>
    <p>[0016]	所述将匹配查询得到的模特着装图片返回给用户的步骤为，将联合匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0017]	优选的，所述方法还包括：</p>
    <p>[0018]	依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中还存储有辅助图片对应的辅助信息；</p>
    <p>[0019]	根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模特着装图片和相应的服装本体局部特征存储至所述图片数据库中。</p>
    <p>[0020]	优选的，所述依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询的步骤具体为，依据该服装图片的服装本体局部特征，在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询。</p>
    <p>[0021]	优选的，所述网站中服装的各品牌模特着装图片还包括：对网站中对应的视频文件采集数据帧所得的静态图片；</p>
    <p>[0022]	所述将匹配查询得到的模特着装图片返回给用户的步骤具体为：将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户；</p>
    <p>[0023]	所述方法还包括：将所述静态图片对应的视频文件返回给用户。</p>
    <p>[0024]	优选的，所述方法还包括：</p>
    <p>[0025]	对该服装图片进行方位模式处理，所述方位模式处理过程包括：</p>
    <p>[0026]	对该服装图片进行方位变换，在服装图片中按各方位比例分别进行像素拉伸，得到服装图片对应的各方位视图；</p>
    <p>[0027]	所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体为，依据服装图片对应的方位视图，抽取相应的服装本体局部特征。</p>
    <p>[0028]	优选的，该服装图片为非穿着状态服装的图片时，所述方法还包括：</p>
    <p>[0029]	对该服装图片进行模拟着装处理，所述模拟着装处理过程包括：</p>
    <p>[0030]	对该服装图片中服装区域的左右边缘进行裁剪处理；</p>
    <p>[0031]	按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染，得到模拟着装处理后的服装图片；</p>
    <p>[0032]	所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体为，依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</p>
    <p>[0033]	优选的，所述方法还包括：</p>
    <p>[0034]	接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；</p>
    <p>[0035]	依据该特定区域的视觉内容，抽取相应的服装本体局部特征；</p>
    <p>[0036]	依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；</p>
    <p>[0037]	将特定区域匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0038]	优选的，该服装图片为使用带有网络接入的移动设备拍摄的服装和/或配饰的图片。</p>
    <p>[0039]	优选的，所述辅助图片包括服装标牌图片，辅助图片中的辅助信息包括服装品牌和/或服装型号信息。</p>
    <p>[0040]	另�方面，本申请还公开了�种服装图片的&#25436;索装置，包括：</p>
    <p>[0041]	第一抽取模块，用于依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0042]	第一匹配查询模块，用于依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；及</p>
    <p>[0043]	第一结果返回模块，用于将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0044]	优选的，所述装置还包括：</p>
    <p>[0045]	第二抽取模块，用于依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征。</p>
    <p>[0046]	优选的，所述第一匹配查询模块，具体用于依据该服装图片的服装本体局部特征， 结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行联合匹配查询；其中，所述图片数据库中还存储有辅助图片对应的服装局部辅助特征；</p>
    <p>[0047]	所述第一结果返回模块，具体用于将联合匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0048]	优选的，所述装置还包括：</p>
    <p>[0049]	第二匹配查询模块，用于依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中还存储有辅助图片对应的辅助信息；</p>
    <p>[0050]	存储模块，用于根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模特着装图片和相应的服装本体局部特征存储至所述图片数据库中。</p>
    <p>[0051]	优选的，所述第一匹配查询模块，具体用于依据该服装图片的服装本体局部特征， 在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询。</p>
    <p>[0052]	优选的，所述网站中服装的各品牌模特着装图片还包括：对网站中对应的视频文件采集数据帧所得的静态图片；</p>
    <p>[0053]	所述第一结果返回模块，具体用于将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户；</p>
    <p>[0054]	所述装置还包括：第二结果返回模块，用于将所述静态图片对应的视频文件返回给用户。</p>
    <p>[0055]	优选的，所述装置还包括：[0056]	方位模式处理模块，用于对该服装图片进行方位模式处理，所述方位模式处理模块包括：</p>
    <p>[0057]	方位变换子模块，用于对该服装图片进行方位变换，在服装图片中按各方位比例分别进行像素拉伸，得到服装图片对应的各方位视图；</p>
    <p>[0058]	所述第一抽取模块，具体用于依据服装图片对应的方位视图，抽取相应的服装本体局部特征。</p>
    <p>[0059]	优选的，该服装图片为非穿着状态服装的图片时，所述装置还包括：</p>
    <p>[0060]	模拟着装处理模块，用于对该服装图片进行模拟着装处理； [0061 ] 所述模拟着装处理模块包括：</p>
    <p>[0062]	裁剪处理子模块，用于对该服装图片中服装区域的左右边缘进行裁剪处理；及</p>
    <p>[0063]	渲染子模块，用于按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染， 得到模拟着装处理后的服装图片；</p>
    <p>[0064]	相应地，所述第一抽取模块，具体用于依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</p>
    <p>[0065]	优选的，所述装置还包括：</p>
    <p>[0066]	第四接ロ模块，用于接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；</p>
    <p>[0067]	第三抽取模块，用于依据该特定区域的视觉内容，抽取相应的服装本体局部特征；</p>
    <p>[0068]	第三匹配模块，用于依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；</p>
    <p>[0069]	第三结果返回模块，用于将特定区域匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0070]	优选的，该服装图片为使用带有网络接入的移动设备拍摄的服装和/或配饰的图片。</p>
    <p>[0071]	优选的，所述辅助图片包括服装标牌图片，辅助图片中的辅助信息包括服装品牌和/或服装型号信息。</p>
    <p>[0072]	与现有技术相比，本申请具有以下优点：</p>
    <p>[0073]	本申请无需用户输入服装的颜色、款式、类别等查询文本，只需提交服装图片，即能够为用户提供服装的模特着装图片，以便用户在不用亲自试穿的情况下判断着装效果， 因此，本申请能够提供给用户更准确更具体的着装信息；同&#21515;，由于本申请能够提供更准确的&#25436;索&#32080;果，因此能够减少搜索次数，提高搜索效率。</p>
    <p>[0074]	另外，本申请还可以依据服装图片和辅助图片的特征在图片数据库中进行服装本体局部特征和服装局部辅助特征的联合查询，所述服装图片和辅助图片通常源于同一服装，由于匹配查询过程中考虑了更多关于服装的信息，故能够提高服装图片和模特着装图片的匹配度，从而最终返回给用户的与服装标牌信息匹配的模特着装图片，能够提供给用户更准确更具体的着装信息，从而能够进一&#27497;提高搜索结果的准确性，进�步减少搜索次数，提高搜索效率。</p>
    <p>附图说明[0075]	图1是本申请�种服装图片的&#25436;索方法实施例1的流程图；</p>
    <p>[0076]	图2是本申请�种方位模式处理前后的服装图片对照；</p>
    <p>[0077]	图3是本申请�种服装图片的&#25436;索方法实施例2的流程图；</p>
    <p>[0078]	图4是本申请�种服装图片的&#25436;索方法实施例3的流程图；</p>
    <p>[0079]	图5是本申请�种服装图片的&#25436;索方法实施例4的流程图；</p>
    <p>[0080]	图6是本申请�种服装图片的&#25436;索方法实施例5的流程图；</p>
    <p>[0081]	图7是本申请�种服装图片的&#25436;索装置实施例的结构图。</p>
    <p>具体实施方式</p>
    <p>[0082]	为使本申请的上述目的、特征和优点能够更加明显易懂，下面结合附图和具体实施方式对本申请作进一步详细的说明。</p>
    <p>[0083]	本申请在接收用户上传的服装图片后，抽取出该服装图片的服装本体局部特征， 通过图片数据库匹配查询得到与该服装图片的服装本体局部特征相同或相似的模特着装图片，并返回给用户；由于模特着装图片为穿着状态的服装图片，其能够展示对应服装图片的着装效果，这样，用户无需亲自试穿，就可以快速查看该服装图片的着装效果。</p>
    <p>[0084]	&#21443;照图1，示出了本申请�种服装图片的&#25436;索方法实施例1的流程图，具体可以包括：</p>
    <p>[0085]	步骤101、依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0086]	本申请可以应用于各种搜索引擎或搜索装置，用于依据用户上传的服装图片，返回相应的模特着装图片。</p>
    <p>[0087]	下面例举�些具体的应用场景：</p>
    <p>[0088]	应用场景1、</p>
    <p>[0089]	用户在实体商店选购服装&#21515;，遇到喜爱的服装而实体商店又没有模特试穿&#21515;，看不到具体的着装效果，但亲自试穿会浪费时间和精力；于是使用移动设备拍摄该服装的图片，并使用移动设备上传该服装的图片，这里的上传可以为在移动设备的浏览器中上传该服装的图片，由本申请对该服装的图片进行分析处理，并通过浏览器返回展示着装效果的模特着装图片；用户在查看模特着装图片所展示的着装效果后，就可判定该服装是不是适合自己，从而进一&#27497;确定是否购买该服装。</p>
    <p>[0090]	这里的移动设备主要指可以在移动中使用的设备，广义的讲可以包括数码相机、 手机、笔记本、平板电脑。在实际中，用户可以使用智能手机拍照，然后使用同一智能手机上传拍摄的图片；或者，使用数码相机拍照，然后输入笔记本，最后通过笔记本上传拍摄的图片，等等，本申请对具体的移动设备及移动设备的使用方式不加以限制。</p>
    <p>[0091]	现有图片购物搜索网站是不支持移动平台的，�个主要的原因是现有图片购物搜索网站使用了 flash(动画）播放器，例如其在上传图片时使用了 flash播放器，而支持 flash的操作系统有限，例如，Windows, Android 2. 2版等少数操作系统支持flash，苹果、 塞班等多数操作系统不支持flash，于是，现有图片购物&#25436;索网站很难应用和普及到移动平</p>
    <p>I=I O</p>
    <p>[0092]	针对上述情形，在具体实现中，本申请可以采用表单来实现上传图片的功能。作为表单中的�个重要元素，表单域可以进一&#27497;包含文本框、密码框、隐藏域、多行文本框、复选框、单选框、下拉选择框和文件上传框等。文件上传框看上去和其它文本域差不多，只是它还包含了�个浏览按钮；用户可以通过输入需要上传的图片的路径或者点击浏览按钮选择需要上传的图片。</p>
    <p>[0093]	或者，本申请还可以采用ASP (动态服务器页面，Active Server Page)来实现上传图片的功能。例如，可以采用SA-FileUp组件、LyfUpload组件、动网上传组件、IronSoft 系列组件或《3. Upload组件接收用户上传的图片，必要&#21515;，还可以采用图像处理组件、 w3. image组件、xxiyy图形组件、IronSoft图形组件、Flash截图组件或ASPJpeg组件对用户上传的图片进行处理等。</p>
    <p>[0094]	总之，本申请可以采用表&#21336;、ASP等方式实现图片上传功能以支持移动平台，甚至在支持flash的操作系统中使用flash播放器等等，本申请对具体的实现图片上传的方式不加以限制。</p>
    <p>[0095]	应用场景2、</p>
    <p>[0096]	用户在实体商店看上一件服装，而实体商店没有模特试穿导致看不到具体的着装效果，而且，实体商店的价格偏高使得用户有去网络商店购物的打算；于是用户当场使用移动设备拍摄该服装的图片，并在回家后使用计算机上传拍摄的图片，这里的上传可以为在计算机的浏览器中上传该服装的图片，由本申请对该服装的图片进行分析处理，并通过浏览器返回展示着装效果的服装的图片对应的模特着装图片；用户在查看模特着装图片所展示的着装效果后，就可判定该服装是不是适合自己，从而进一&#27497;确定是否购买该服装。</p>
    <p>[0097]	应用场景3、</p>
    <p>[0098]	用户在网络商店看上一件服装，而网络商店仅有该服装的图片，看不到具体的着装效果；并且，用户在现有图片购物&#25436;索网站中也仅能搜索到外观最相似该服装的图片，仍然看不到具体的着装效果；于是，用户在计算机的浏览器中上传该服装的图片，由本申请对该服装的图片进行分析处理，并通过浏览器返回展示着装效果的模特着装图片；用户在查看模特着装图片所展示的着装效果后，就可判定该服装是不是适合自己，从而进一步确定是否购买该服装。</p>
    <p>[0099]	总之，对于用户而言，其上传的服装图片可以是使用移动设备拍摄的服装和/或配饰的图片，或以其他方式保存的服装和/或配饰的图片，如商品网站上已有的服装和/或配饰的图片或服装和/或配饰的图片对应的链接等。上述使用移动设备拍摄或以其他方式保存的服装图片可由用户通过移动设备或计算机上传至服务器。本申请对服装图片的具体获取方式、上传工具或上传途径不加以限制。</p>
    <p>[0100]	本申请实施例中，局部特征主要用于描述该服装图片局部亮度的明暗变化。</p>
    <p>[0101]	在具体实现中，可以采用具有尺度不变性的局部特征抽取算法来抽取服装图片的局部特征。例如，所述具有尺度不变性的局部特征抽取算法可以包括基于Linderberg尺度不变理论的特征检测子以及David Lowe的类SIFT的高维描述子的算法，这些抽取算法可以自动换取图像结构的尺度，并在该尺度上计算具有一定抗尺度变化、光照变化、角度变化、旋转变化等不同变化的局部图像特征。在获取图像特征之后，一幅图片可能被表示为数百个局部特征，该局部特征可用矢量来表示。总之，本领域技术人员可以采用任意一种抽取算法得到局部特征，本申请对具体的抽取算法不加以限制。</p>
    <p>[0102]	在本申请的�种应用示例中，所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体可以包括：</p>
    <p>[0103]	首先，对该服装图片的尺寸进行归一化，将尺寸过大或过小的该服装图片变换为 640*640&#12316;300*300之内；然后使用ニ维局部特征检测矩阵与归�化后的该服装图片进行卷积操作；再者，在卷积后的图片中扫描定位出其中的局部极值（最大值与最小值）点的位置；最后，根据局部极值点附近区域的明暗对比，抽取该服装图片的局部特征，即局部极值点的位置。</p>
    <p>[0104]	&#21443;照表1，示出了本申请�种归�化前后的图片尺寸示意。</p>
    <p>[0105]	表 1</p>
    <p>原始图片尺寸	归�化后的图片尺寸&gt;640*640	按原始长宽比例缩小，最长边为640&lt;=640*640 且&gt;=300*300	尺寸不变&lt;300*300	按原始长宽比例放大，最小边为300</p>
    <p>[0107]	步骤102、依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；</p>
    <p>[0108]	在具体实现中，服务器可将该服装图片的服装本体局部特征与图片数据库中模特着装图片的服装本体局部特征进行比对，如果匹配率在一定阈值范围（如&gt;90%)内，可认为二者的视觉内容一致，于是将视觉内容一致的图片作为匹配查询得到的模特着装图片。</p>
    <p>[0109]	需要说明的是，为了实现比对目的，该服装图片与图片数据库中具有与其相同原始尺寸的图片在归�化后的尺寸应一致，例如，同为300*300。</p>
    <p>[0110]	步骤103、将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0111]	总之，本申请无需用户输入服装的颜色、款式、类别等查询文本，只需提交服装图片，即能够为用户提供服装的模特着装图片，以便用户在不用亲自试穿的情况下判断着装效果，因此，本申请能够提供给用户更准确更具体的着装信息。</p>
    <p>[0112]	在本申请的�种优选实施例中，所述方法还可以包括：</p>
    <p>[0113]	依据接收到的辅助图片，抽取相应的服装局部辅助特征。</p>
    <p>[0114]	这里的辅助图片可以包括服装标牌图片，对于依据辅助图片抽取相应的服装局部辅助特征的过程，由于其与依据服装图片抽取相应的服装本体局部特征的过程类似，故在此不作赘述，相互&#21443;照即可。</p>
    <p>[0115]	在本申请的�种优选实施例中，该服装图片为非穿着状态服装的图片时，所述方法还可以包括：</p>
    <p>[0116]	对该服装图片进行模拟着装处理，所述模拟着装处理过程具体可以包括：</p>
    <p>[0117]	步骤Al、对该服装图片中服装区域的左右边缘进行裁剪处理；[0118]	步骤A2、按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染，得到模拟着装处理后的服装图片。</p>
    <p>[0119]	此时，所述依据该服装图片，抽取相应的服装本体局部特征的步骤具体可以为，依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</p>
    <p>[0120]	由于模特着装图片中的服装均为穿着状态，而服装图片在拍摄时，很大部分对应着由衣架悬挂时所呈的非穿着状态。为提高服装图片与图片数据库中模特着装图片的匹配度，本优选实施例对服装图片进行模拟着装处理，将服装图片中服装区域的左右边缘进行裁剪，并按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染，由于能够自动模拟服装图片中对应服装的穿着状态，故能够提高服装图片与模特着装图片的匹配度。</p>
    <p>[0121]	在本申请的另一优选实施例中，该服装图片为用户在任意方向拍摄的图片，即由于拍照角度的原因，用户在拍摄服装时没有正对待拍摄服装，所得到的服装图片往往与服装本身包含服装本体局部特征的�侧成一定角度，故需要将服装图片进行方位模式处理， 将未正对待拍摄服装拍摄时得到的服装图片转换为对应的各方位视图。</p>
    <p>[0122]	对该服装图片进行方位变换，在服装图片中按各方位比例分别进行像素拉伸，得到服装图片对应的各方位视图；所述方位比例为设定的服装长宽比例。例如，如图2所示， 服装图片为用户竖直持移动设备对平铺于身前桌子上的一件裤子拍摄所得的图片，将图片在竖直方位上进行像素拉伸，拉伸的方位比例为设定的裤子的比例1. 8&#12316;2. 0，即将图片在竖直方向上拉伸至1. 5&#12316;2. 0，形成服装图片对应的方位视图，对方位视图抽取相应的服装本体局部特征，得到被拉伸后的裤子的局部特征，并在图片数据库中进行匹配查询，可匹配到穿着用户所拍摄裤子的真人模特图片。在其他实施例中，服装图片为用户成45度角对面前假人模特穿着服装拍摄所得的图片，将图片在水平方位上进行像素拉伸，拉伸的方位比例随着用户的触发进行调整，即将图片在水平方向上拉伸至用户满意的比例，形成图片在侧向和正向的方位视图，对方位视图抽取相应的服装本体局部特征，并在图片数据库中进行匹配查询，可匹配到穿着用户所拍摄的服装对应模特的侧向图片和正向图片，从而使用户更好地查看该服装的穿着状态。</p>
    <p>[0123]	在本申请的又一种优选实施例中，所述方法还可以包括：</p>
    <p>[0124]	步骤Bi、接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；</p>
    <p>[0125]	步骤B2、依据该特定区域的视觉内容，抽取相应的服装本体局部特征；</p>
    <p>[0126]	步骤B3、依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；</p>
    <p>[0127]	步骤B4、将特定区域匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0128]	本优选实施例允许用户对服装图片进行框选，将依据框选得到的特定区域的视觉内容，抽取相应的服装本体局部特征，由于用户框选的特定区域往往为用户所关注的，且易于进行区&#21029;的区域，故本优选实施例能够在考虑用户关注度和个性化需求的情况下，更好地为用户提供服装的模特着装图片。</p>
    <p>[0129]	例如，用户拍摄的服装图片中对应服装为一件卫衣，其中含有�个大头娃娃的图案，那么，用户可以框选服装图片中的“大头娃娃”，并将依据对应的特定区域抽取得到的服装本体局部特征与图片数据库中各模特着装图片的服装本体局部特征进行比对，由于对应的“大头娃娃”图案特征明显，则很容易得到穿着“大头娃娃”服装的模特着装图片，从而能够在考虑用户关注度和个性化需求的情况下，提高服装图片与模特着装图片的匹配度。</p>
    <p>[0130]	需要说明的是，本优选实施例提供的特定区域匹配查询可以在上述匹配查询后执行，例如，如果用户对第一次返回的模特着装效果不满意，则可以针对服装图片执行框选操作以触发特定区域匹配查询，此时，特定区域匹配查询可以看作服装本体局部特征的二次匹配查询。或者，用户可以在上传服装图片后，直接针对服装图片执行框选操作以触发特定区域匹配查询，此时，特定区域匹配查询可以看作服装本体局部特征的一次匹配查询。总之，本领域技术人员可以依据用户操作执行本申请的匹配查询或特定区域匹配查询，本申请对具体的执行时机不加以限制。</p>
    <p>[0131]	可以理解，如果本申请返回的模特着装图片未满足用户需求，则允许用户多次上传不同拍摄角度的服装图片进行后续的匹配查询，本申请对此不加以限制。</p>
    <p>[0132]	&#21443;照图3，示出了本申请�种服装图片的&#25436;索方法实施例2的流程图，具体可以包括：</p>
    <p>[0133]	步骤301、依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0134]	步骤302、依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征；</p>
    <p>[0135]	步骤303、依据该服装图片的服装本体局部特征，结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行服装本体局部特征和服装局部辅助特征的联合匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征和辅助图片对应的服装局部辅助特征；</p>
    <p>[0136]	步骤304、将联合匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0137]	所述联合匹配查询可以包括：首先依据该服装图片的服装本体局部特征在所述图片数据库中进行服装本体局部特征的第一查询，然后依据所述辅助图片对应的服装局部辅助特征在与第一查询结果相应的数据集中进行服装局部辅助特征的查询，得到最终的查询&#32080;果；或者，首先依据所述辅助图片对应的服装局部辅助特征在与所述图片数据库中进行服装局部辅助特征的第二查询，然后该服装图片的服装本体局部特征在与第二查询结果相应的数据集中进行服装本体局部特征的查询，得到最终的查询&#32080;果。</p>
    <p>[0138]	相对于实施例1，本实施例依据服装图片和辅助图片的特征在图片数据库中进行服装本体局部特征和服装局部辅助特征的联合查询，所述服装图片和辅助图片通常源于同一服装，由于匹配查询过程中考虑了更多关于服装的信息，因此，相对于实施例1，能够提供给用户更准确更具体的着装信息；同&#21515;，能够进一&#27497;提高搜索结果的准确性，因此能够进� 步减少&#25436;索次数，提高搜索效率。</p>
    <p>[0139]	在本申请的�种优选实施例中，所述辅助图片可以包括服装标牌图片，辅助图片中的辅助信息为服装标牌信息。此时，&#21443;照图4，示出了本申请�种服装图片的&#25436;索方法实施例3的流程图，具体可以包括：</p>
    <p>[0140]	步骤401、依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0141]	步骤402、依据接收到的所述服装图片对应的服装标牌图片，抽取相应的服装局部辅助特征，该服装标牌图片和该服装图片源自同一服装；</p>
    <p>[0142]	步骤403、在图片数据库中进行服装局部辅助特征的匹配查询，过滤与所述服装局部辅助特征不匹配的模特着装图片，&#21104;余的模特着装图片组成候选图片数据库；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征和服装局部辅助特征；</p>
    <p>[0143]	步骤404、依据该服装图片的服装本体局部特征，在所述候选图片数据库中进行服装本体局部特征的匹配查询；</p>
    <p>[0144]	步骤405、将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0145]	与实体商店中服装相比，网络商店中往往存在款式、&#38996;色相似的服装，故实施例1 返回的模特着装图片，能够在用户不用亲自试穿的情况下提供给用户更准确更具体的着装</p>
    <p>イロ‘ &gt;Ε、。</p>
    <p>[0146]	但是，在某些特殊情况下，即使款式、颜色相似的两件服装，着装效果也会有差异。 例如，有些服装品牌的风格相似，但是着装效果会有差异。另外，有些用户还存在品牌消费心理，也即，只购买认可品牌的服装。</p>
    <p>[0147]	针对上述情形，本实施例依据用户上传的服装标牌图片获取服装局部辅助特征， 并依据服装局部辅助特征在所述图片数据库中过滤与匹配查询得到的服装标牌信息不匹配的模特着装图片，由于用户提交的服装标牌图片和服装图片源自同一服装，故能够提高服装图片和模特着装图片的匹配度，从而最终返回给用户的与服装局部辅助特征匹配的模特着装图片能够提供给用户更准确更具体的着装信息，满足了用户的品牌消费心理。</p>
    <p>[0148]	在本申请的�种优选实施例中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征和服装局部辅助特征对应的服装标牌信息，此时，所述在图片数据库中进行服装局部辅助特征的匹配查询的步骤可以为，在所述图片数据库中过滤与所述服装标牌信息不匹配的模特着装图片。</p>
    <p>[0149]	在实际中，所述服装标牌信息具体可以包括服装品牌和/或服装型号信息等，例如，服装品牌可以为阿迪达斯，服装型号可以为175/92A等。</p>
    <p>[0150]	在本申请的�些实施例中，可以依据OCR(光学字符识&#21029;，Optical Character Recognition)原理识别出服装标牌图片对应的商品文本信息，这些商品文本信息具体可以包括服装品牌和服装型号等信息。</p>
    <p>[0151]	在本申请实施例中，优选的是，所述在图片数据库中进行服装局部辅助特征的匹配查询的步骤可以进一&#27497;包括：</p>
    <p>[0152]	子步骤Bi、依据该服装标牌图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片的辅助信息，即服装标牌信息；其中，所述图片数据库中存储有辅助图片对应的服装局部辅助特征和辅助信息；</p>
    <p>[0153]	子步骤B2、在所述图片数据库中过滤与所述辅助信息不匹配的模特着装图片，剩余的模特着装图片组成候选图片数据库；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征和对应的辅助信息。</p>
    <p>[0154]	为使本领域技术人员更好地理解本申请，以下提供本申请�种运动上衣图片的搜索方法示例，本示例中，辅助图片为服装标牌图片，辅助图片中的辅助信息包括服装品牌和 /或服装型号信息。具体可以包括：</p>
    <p>[0155]	步骤1、用户使用智能手机拍摄服装标牌，并使用智能手机将拍摄的服装标牌图片上传至服务器，服装标牌图片涉及的服装标牌可以包括运动品牌“阿迪达斯”的标牌等；</p>
    <p>[0156]	步骤2、对服装标牌图片的尺寸做归�化，将尺寸过大或过小的图片通过上采样或下采样的方式变换到640*640&#12316;300*300之内；然后，使用ニ维局部特征检测矩阵与归�化后的服装标牌图片进行卷积操作，在卷积后的服装标牌图片中，通过扫描，定位出其中的局部极值（最大值与最小值）点的位置；最后，根据局部极值点附近区域的明暗对比，抽取服装标牌图片的服装局部辅助特征，即局部极值点的位置；</p>
    <p>[0157]	步骤3、将服装局部辅助特征与图片数据库中存储的服装标牌图片的服装局部辅助特征进行比对，得到匹配率最大的服装标牌图片对应的辅助信息；</p>
    <p>[0158]	&#21443;照表2，示出了本申请�种图片数据库的示意，其具体存储服装局部辅助特征、 服装品牌和服装型号三个字段的内容。结合图片数据库，本步骤实现服装标牌图片对应服装标牌信息的&#25436;索功能，如根据输入的“阿迪达斯”的标牌图片，可&#25436;索到“阿迪达斯”、 “180/100A”的服装标牌信息。</p>
    <p>[0159]表	2</p>
    <p>[0160]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102567543A/CN102567543AD00151.png"> <img id="idf0001" file="CN102567543AD00151.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102567543A/CN102567543AD00151.png" class="patent-full-image" alt="Figure CN102567543AD00151"> </a> </div>
    <p>[0161]	步骤4、在图片数据库中过滤与匹配查询得到的服装标牌信息不匹配的模特着装图片，&#21104;余的模特着装图片组成候选图片数据库；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征和对应的服装标牌信息；</p>
    <p>[0162]	例如，表3示出了本申请�种图片数据库的示意图，其具体存储服装品牌和服装型号、模特着装图片、价格、商品描述、买家信息等字段的内容。</p>
    <p>[0163]表	3</p>
    <p>[0164]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102567543A/CN102567543AD00161.png"> <img id="idf0002" file="CN102567543AD00161.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102567543A/CN102567543AD00161.png" class="patent-full-image" alt="Figure CN102567543AD00161"> </a> </div>
    <p>[0165]	当步骤3获取的服装标牌信息为“阿迪达斯”、“180/100A”&#21515;，得到的候选图片数据库中包括有“模特着装图片d、e、f”。</p>
    <p>[0166]	步骤5、将用户上传的服装图片保存到服务器，如上传的服装图片为男款白色上衣图片，其中，该服装图片可使用移动设备进行拍摄并上传；</p>
    <p>[0167]	步骤6、依据该服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0168]	步骤7、依据该服装图片的服装本体局部特征，在所述候选图片数据库中进行服装本体局部特征的匹配查询；可获得与该款式服装特征相同或相似的模特着装图片及其对应的商品信息；</p>
    <p>[0169]	步骤8、将匹配查询得到的模特着装图片及其对应的商品信息返回给用户。</p>
    <p>[0170]	如根据男款白色上衣图片，&#25436;索到与该图片匹配度最高的一男模特穿着白色上衣的模特图片“着装图片d”和“着装图片f”，则步骤8可以分别按匹配度从高到低的顺序显示“着装图片d”和“着装图片f”，并在用户触发下根据“着装图片d”和“着装图片f”调用</p>
    <p>对应的与该图图片相关的信息“360元、白色男款运动上装.......”、“510元、白色男款运</p>
    <p>动上装.......”等商品信息。</p>
    <p>[0171]	&#21443;照图5，示出了本申请�种服装图片的&#25436;索方法实施例4的流程图，具体可以包括：</p>
    <p>[0172]	步骤501、依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0173]	步骤502、依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征；</p>
    <p>[0174]	步骤503、依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中存储有辅助图片对应的辅助信息；</p>
    <p>[0175]	步骤504、根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模</p>
    <p>特着装图片和相应的服装本体局部特征存储至所述图片数据库中；[0176]	步骤505、依据该服装图片的服装本体局部特征，在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询；</p>
    <p>[0177]	步骤506、将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0178]	在本申请实施例中，优选的是，所述辅助图片具体可以包括服装标牌图片，辅助图片中的辅助信息具体可以包括服装品牌和/或服装型号信息。</p>
    <p>[0179]	在本申请的�种优选实施例中，所述步骤504可以进一&#27497;包括：</p>
    <p>[0180]	步骤Cl、依据所述服装标牌信息中的服装品牌信息，获取该服装品牌信息对应的网络商店信息；</p>
    <p>[0181]	步骤C2、依据该网络商店信息，获取对应网络商店中服装的各品牌模特着装图片；</p>
    <p>[0182]	子步骤C3、依据该品牌模特着装图片的视觉内容，抽取相应的服装本体局部特征， 并将该品牌模特着装图片和相应的服装本体局部特征保存至图片数据库；使各品牌模特着装图片和相应的服装本体局部特征存储于所述图片数据库中。</p>
    <p>[0183]	&#21443;照图6，示出了本申请�种服装图片的&#25436;索方法实施例5的流程图，具体可以包括：</p>
    <p>[0184]	步骤601、依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0185]	步骤602、依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征；</p>
    <p>[0186]	步骤603、依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中存储有辅助图片对应的辅助信息；</p>
    <p>[0187]	步骤604、根据辅助图片中的辅助信息获取对应的网站，将服装图片与网站中对应的视频文件进行匹配查询；</p>
    <p>[0188]	从所述视频文件中采集数据帧，得到对应的静态图片；视频文件可以为网站中固定位置上的广告、服装介绍等播放资源，也可以为网站的页面中弹出的播放窗口中的媒体内容。将视频文件从网站中抓取后采集图像帧，可以仅抓取该视频文件的预览帧，也可以按设定好的时间间隔或是图像分析算法分析图像内容选取的图像帧，从而使视频文件中分割出静态图片。将静态图片存储至图片数据库中，依据服装图片的服装本体局部特征，将接收到的服装图片与所述静态图片的图像特征进行匹配查询。</p>
    <p>[0189]	步骤605、将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户。其他实施例中还包括：将所述静态图片对应的视频文件返回给用户，这样，用户可以通过视频播放的形式查看模特的着装效果。</p>
    <p>[0190]	本优选实施例依据所述服装标牌信息中的服装品牌信息，直接转到对应品牌的门户网店的子站，以便于在子站中包括的图片中进行搜索识别。</p>
    <p>[0191]	与前述方法实施例相应，本申请还公开了�种服装图片的&#25436;索装置，&#21443;照图7，具体可以包括：</p>
    <p>[0192]	第一抽取模块701，用于依据接收到的服装图片，抽取相应的服装本体局部特征；</p>
    <p>[0193]	第一匹配查询模块702，用于依据该服装图片的服装本体局部特征，在图片数据库中进行服装本体局部特征的匹配查询；其中，所述图片数据库中存储有模特着装图片及对应的服装本体局部特征；及</p>
    <p>[0194]	第一结果返回模块703，用于将匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0195]	在本申请的�种优选实施例中，所述装置还可以包括：</p>
    <p>[0196]	第二抽取模块，用于依据接收到的所述服装图片对应的辅助图片，抽取相应的服装局部辅助特征。</p>
    <p>[0197]	在本申请的另一种优选实施例中，所述图片数据库中还存储有辅助图片及对应的服装局部辅助特征；</p>
    <p>[0198]	此时，所述第一匹配查询模块702，可具体用于依据该服装图片的服装本体局部特征，结合所述辅助图片对应的服装局部辅助特征，在所述图片数据库中进行服装本体局部特征和服装局部辅助特征的联合匹配查询；</p>
    <p>[0199]	所述第一结果返回模块，具体用于将联合匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0200]	在本申请的再一种优选实施例中，所述装置还可以包括：</p>
    <p>[0201]	第二匹配查询模块，用于依据该辅助图片的服装局部辅助特征，在图片数据库中进行服装局部辅助特征的匹配查询，得到该辅助图片对应的辅助信息；其中，所述图片数据库中存储有辅助图片对应的服装局部辅助特征和辅助信息。</p>
    <p>[0202]	存储模块，用于根据辅助图片中的辅助信息获取对应的网站，将网站中服装的各品牌模特着装图片和相应的服装本体局部特征存储至所述图片数据库中。</p>
    <p>[0203]	在本申请的�种优选实施例中，所述网站中服装的各品牌模特着装图片还包括： 对网站中对应的视频文件采集数据帧所得的静态图片；</p>
    <p>[0204]	所述第一结果返回模块703，具体用于将匹配查询得到的网站中对应的视频文件采集数据帧所得的静态图片返回给用户；</p>
    <p>[0205]	所述装置还包括：第二结果返回模块，用于将所述静态图片对应的视频文件返回给用户。</p>
    <p>[0206]	在本申请的�种优选实施例中，所述第一匹配查询模块702，可具体用于依据该服装图片的服装本体局部特征，在所述各品牌模特着装图片和相应的服装本体局部特征中进行服装本体局部特征的匹配查询。</p>
    <p>[0207]	在本申请的另一种优选实施例中，所述装置还可以包括：</p>
    <p>[0208]	方位模式处理模块，用于对该服装图片进行方位模式处理，所述方位模式处理模块包括：</p>
    <p>[0209]	方位变换子模块，用于对该服装图片进行方位变换，在服装图片中按各方位比例分别进行像素拉伸，得到服装图片对应的各方位视图；</p>
    <p>[0210]	此时，所述第一抽取模块701，可具体用于依据服装图片对应的方位视图，抽取相应的服装本体局部特征。</p>
    <p>[0211]	在本申请的再一种优选实施例中，该服装图片为非穿着状态服装的图片时，所述装置还可以包括：</p>
    <p>[0212]	模拟着装处理模块，用于对该服装图片进行模拟着装处理；</p>
    <p>[0213]	所述模拟着装处理模块具体可以包括：</p>
    <p>[0214]	裁剪处理子模块，用于对该服装图片中服装区域的左右边缘进行裁剪处理；及[0215]	渲染子模块，用于按正态分布对裁剪处理后服装区域的亮度和对比度进行渲染， 得到模拟着装处理后的服装图片；</p>
    <p>[0216]	相应地，所述第一抽取模块，具体用于依据模拟着装处理后的服装图片的视觉内容，抽取相应的服装本体局部特征。</p>
    <p>[0217]	在本申请的�种优选实施例中，所述装置还可以包括：</p>
    <p>[0218]	第四接ロ模块，用于接收用户针对该服装图片的框选操作，并依据该框选操作得到相应的该服装图片中的特定区域；</p>
    <p>[0219]	第三抽取模块，用于依据该特定区域的视觉内容，抽取相应的服装本体局部特征；</p>
    <p>[0220]	第三匹配模块，用于依据该特定区域的服装本体局部特征，在所述图片数据库中进行服装本体局部特征的特定区域匹配查询；</p>
    <p>[0221]	第三结果返回模块，用于将特定区域匹配查询得到的模特着装图片返回给用户。</p>
    <p>[0222]	在本申请的�种优选实施例中，该服装图片为使用带有网络接入的移动设备拍摄的服装和/或配饰的图片。</p>
    <p>[0223]	在本申请的�种优选实施例中，所述辅助图片具体可以包括服装标牌图片，辅助图片中的辅助信息具体可以包括服装品牌和/或服装型号信息。</p>
    <p>[0224]	对于装置实施例而言，由于其与方法实施例基本相似，所以描述的比较简单，相关之处&#21443;见方法实施例的部分说明即可。</p>
    <p>[0225]	本说明书中的各个实施例均采用递进的方式描述，每个实施例重点说明的都是与其他实施例的不同之处，各个实施例之间相同相似的部分互相&#21443;见即可。</p>
    <p>[0226]	以上对本申请所提供的�种服装图片的&#25436;索方法和装置，进行了详细介绍，本文中应用了具体个例对本申请的原理及实施方式进行了阐述，以上实施例的说明只是用于帮助理解本申请的方法及其核心思想；同时，对于本领域的一般技术人员，依据本申请的思想，在具体实施方式及应用范围上均会有改变之处，综上所述，本说明书内容不应理解为对本申请的限制。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101042705A?cl=zh">CN101042705A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年3月22日</td><td class="patent-data-table-td patent-date-value">2007年9月26日</td><td class="patent-data-table-td ">王克继</td><td class="patent-data-table-td ">使用标准化服装数据格式的服装开发和生产系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101206749A?cl=zh">CN101206749A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年5月16日</td><td class="patent-data-table-td patent-date-value">2008年6月25日</td><td class="patent-data-table-td ">株式会社G&amp;G贸易公司</td><td class="patent-data-table-td ">使用多路图像检索模块推荐产品的方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101853299A?cl=zh">CN101853299A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月31日</td><td class="patent-data-table-td patent-date-value">2010年10月6日</td><td class="patent-data-table-td ">杭州淘淘搜科技有限公司</td><td class="patent-data-table-td ">一种基于感性认知的图像检索结果排序方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101872352A?cl=zh">CN101872352A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年7月30日</td><td class="patent-data-table-td patent-date-value">2010年10月27日</td><td class="patent-data-table-td ">万信电子科技有限公司</td><td class="patent-data-table-td ">服装试穿系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102016918A?cl=zh">CN102016918A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年4月27日</td><td class="patent-data-table-td patent-date-value">2011年4月13日</td><td class="patent-data-table-td ">公立大学法人大阪府立大学</td><td class="patent-data-table-td ">物体识别用图像数据库的制作方法、处理装置以及处理用程序</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103500172A?cl=zh">CN103500172A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年9月4日</td><td class="patent-data-table-td patent-date-value">2014年1月8日</td><td class="patent-data-table-td ">苏州荣越网络技术有限公司</td><td class="patent-data-table-td ">一种图片搜索系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104036009A?cl=zh">CN104036009A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年6月24日</td><td class="patent-data-table-td patent-date-value">2014年9月10日</td><td class="patent-data-table-td ">北京奇虎科技有限公司</td><td class="patent-data-table-td ">一种搜索匹配图片的方法、图片搜索方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104036281A?cl=zh">CN104036281A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年6月24日</td><td class="patent-data-table-td patent-date-value">2014年9月10日</td><td class="patent-data-table-td ">北京奇虎科技有限公司</td><td class="patent-data-table-td ">一种图片的匹配方法、搜索方法及其装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=jpeDBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年7月11日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年11月7日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年2月18日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/deba97fb5c3b26452219/CN102567543A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E6%9C%8D%E8%A3%85%E5%9B%BE%E7%89%87%E7%9A%84%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85.pdf?id=jpeDBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0umBWedzGkHa-5pg4bh6u2aWYKEQ"},"sample_url":"https://www.google.com/patents/reader?id=jpeDBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>