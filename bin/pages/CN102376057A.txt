<!DOCTYPE html><html><head><title>专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5115ea495017d9115e613207d3810e5a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5115ea495017d9115e613207d3810e5a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="对消费者生成媒体信息进行处理的方法和装置"><meta name="DC.contributor" content="于浩" scheme="inventor"><meta name="DC.contributor" content="何楠" scheme="inventor"><meta name="DC.contributor" content="王主龙" scheme="inventor"><meta name="DC.contributor" content="王新文" scheme="inventor"><meta name="DC.contributor" content="葛付江" scheme="inventor"><meta name="DC.contributor" content="贾文杰" scheme="inventor"><meta name="DC.contributor" content="贾晓建" scheme="inventor"><meta name="DC.contributor" content="富士通株式会社" scheme="assignee"><meta name="DC.date" content="2010-8-16" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开一种对消费者生成媒体信息进行处理的方法和装置。所述方法包括：从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及可视化地呈现所述定制的消费者生成媒体信息，其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。"><meta name="DC.date" content="2012-3-14"><meta name="DC.relation" content="CN:101477554:A" scheme="references"><meta name="DC.relation" content="CN:101551825:A" scheme="references"><meta name="DC.relation" content="CN:101630315:A" scheme="references"><meta name="DC.relation" content="CN:101639841:A" scheme="references"><meta name="DC.relation" content="CN:101719145:A" scheme="references"><meta name="DC.relation" content="CN:1659531:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:102376057:A"><meta name="citation_patent_application_number" content="CN:201010257490"><link rel="canonical" href="https://www.google.com/patents/CN102376057A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102376057A?cl=zh"/><meta name="title" content="专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置"/><meta name="description" content="本发明公开一种对消费者生成媒体信息进行处理的方法和装置。所述方法包括：从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及可视化地呈现所述定制的消费者生成媒体信息，其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。"/><meta property="og:title" content="专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102376057A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102376057A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=bimHBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102376057A&amp;usg=AFQjCNE_OzBXpM8Pfzh-4IFMzoDBU7Rxww" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/ce47a3723baaa535aca8/CN102376057A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/ce47a3723baaa535aca8/CN102376057A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102376057A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102376057A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102376057A?cl=zh" style="display:none"><span itemprop="description">本发明公开一种对消费者生成媒体信息进行处理的方法和装置。所述方法包括：从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生...</span><span itemprop="url">https://www.google.com/patents/CN102376057A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置" title="专利 CN102376057A - 对消费者生成媒体信息进行处理的方法和装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102376057 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010257490</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年3月14日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年8月16日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年8月16日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010257490.5, </span><span class="patent-bibdata-value">CN 102376057 A, </span><span class="patent-bibdata-value">CN 102376057A, </span><span class="patent-bibdata-value">CN 201010257490, </span><span class="patent-bibdata-value">CN-A-102376057, </span><span class="patent-bibdata-value">CN102376057 A, </span><span class="patent-bibdata-value">CN102376057A, </span><span class="patent-bibdata-value">CN201010257490, </span><span class="patent-bibdata-value">CN201010257490.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E4%BA%8E%E6%B5%A9%22">于浩</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E4%BD%95%E6%A5%A0%22">何楠</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E4%B8%BB%E9%BE%99%22">王主龙</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E6%96%B0%E6%96%87%22">王新文</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%91%9B%E4%BB%98%E6%B1%9F%22">葛付江</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B4%BE%E6%96%87%E6%9D%B0%22">贾文杰</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B4%BE%E6%99%93%E5%BB%BA%22">贾晓建</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%AF%8C%E5%A3%AB%E9%80%9A%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE%22">富士通株式会社</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102376057A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102376057A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102376057A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=bimHBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010257490&amp;usg=AFQjCNEG24tMw6lCs_q3EvRXRxOPcPpetA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=bimHBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102376057A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFdt15g8dH70LOOZIc6uXRmmQwPRw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT112053895" lang="ZH" load-source="patent-office">对消费者生成媒体信息进行处理的方法和装置</invention-title>
      </span><br><span class="patent-number">CN 102376057 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA95506476" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开一种对消费者生成媒体信息进行处理的方法和装置。所述方法包括：从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及可视化地呈现所述定制的消费者生成媒体信息，其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM40859553" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种对消费者生成媒体信息进行处理的方法，包括： 从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及可视化地呈现所述定制的消费者生成媒体信息，其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1的方法，其中，基于前次更新的用户模型来进行本次收集和过滤中的至少一个。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1或2的方法，其中，所述更新所述用户模型包括： 记录所述用户对所呈现的消费者生成媒体信息的反馈动作；抽取与所述反馈动作相关联的消费者生成媒体信息的特征；以及基于所记录的反馈动作和所抽取的特征来更新所述用户模型。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3的方法，其中，在所述收集和过滤中的所述至少一个中，对符合所述用户模型中的所抽取的特征的消费者生成媒体信息进行与所记录的反馈动作相对应的处理。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求3的方法，还包括：在所述整合之前基于所述用户模型对经所述过滤得到的与预定主题相关的消费者生成媒体信息进行情感分析，或者在所述整合之后基于所述用户模型对所述定制的消费者生成媒体信息进行情感分析，以便对接受情感分析的消费者生成媒体信息赋予相应的评价值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5的方法，其中，所述记录反馈动作包括：记录所述用户对所呈现的消费者生成媒体信息中的一部分或全部的评价值进行修改的动作；以及所述情感分析包括：对经所述过滤得到的或经所述整合得到的消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息的评价值赋予在所述反馈动作中修改后的评价值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求5的方法，其中，所述情感分析还包括：基于所述用户模型，将评价值落入预定阈值范围的所述消费者生成媒体信息确定为关键事件，并将所述关键事件报告给所述用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7的方法，其中，所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的关键事件标记为非关键事件的动作；以及所述情感分析还包括：将所述消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为非关键事件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求7的方法，其中，所述方法还包括：接收所述用户对关键事件的报告规则的定义；以及所述报告关键事件包括：根据所述用户定义的报告规则来将所确定的关键事件报告给所述用户。</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10.	一种对消费者生成媒体信息进行处理的装置，包括：收集和抽取单元，被配置成从信息供应源收集并抽取消费者生成媒体信息； 过滤单元，被配置成基于预定主题对通过所述收集和抽取单元得到的消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；整合单元，被配置成基于用户定制的规则来对通过所述过滤单元得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及呈现单元，被配置成可视化地呈现通过所述整合单元得到的消费者生成媒体信息， 其中，所述收集和抽取单元和所述过滤单元中的至少一个还被配置成基于用户模型来进行收集和过滤中的相应至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且其中，所述装置还包括用户模型更新单元，所述用户模型更新单元被配置成根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES46321947" lang="ZH" load-source="patent-office" class="description">
    <p>对消费者生成媒体信息进行处理的方法和装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明总体上涉及信息处理的技术领域，更具体而言，涉及一种对消费者生成媒体信息进行处理的方法和装置。</p>
    <p>背景技术</p>
    <p>[0002]	消费者生成媒体（Consumer-generated Media, CGM)指任何人（不必然是专业的媒体工作者）都可以在网上创建的内容，其可通过数字技术被其他消费者使用。CGM可包括网络日志或“博客（Blog)”、移动电话博客或“mo-blog”、论坛（BBS)、电子讨论消息、新闻组、留言板（messageboard)、BBS模拟服务（BBS emulating services)、产品预览和讨论网站、支持消费者意见的在线零售站点、社会网络、媒体库、以及数字图书馆等。可见，CGM信息一般是指在CGM网站上或者网页上包括的各种内容，例如，博文、消费者留言、消费者的发帖（post)等。CGM信息通常是文本，但是也包括音频文件和流式视频文件（MP3、网络广播等）、动画（flash等），以及任何其他形式的多媒体。博文、消费者留言、消费者的发帖等是典型的CGM信息的例子，当然，CGM网站或者网页本身也可被视为一种CGM信息。因而， 从广义上讲，CGM信息包括所有与CGM相关的内容和信息。此外，在本说明书的上下文中， “消费者”泛指网络这种信息创建和传播工具的消费和使用者，而不仅仅是指通常意义上的某种具体商品的消费者。</p>
    <p>[0003]	随着计算机及网络技术的迅猛发展，个人空间的需求、网站创建的简单化、通过网络进行交互的快速和便捷等多种因素推动了 CGM在类型和数量两个方面的极大发展，随之而来的是海量的CGM信息。面对种类和数量日益增多的CGM，已提出了根据实际需要有效地收集CGM信息的各种方法和系统。例如，Scout Labs公司(见http://www. scoutlabs. com/)和Radian6技术公司（见http ： //www. radian6. com/)均提供了各自的CGM收集管理产品和服务。</p>
    <p>[0004]	现有技术的CGM收集管理方法和系统通常由用户提出需求，由系统管理员制定相应策略并进行CGM收集。然而，这种方式往往不能准确反映用户的需求，并且不能根据用户对CGM信息的偏好来提供个性化的CGM收集管理服务。</p>
    <p>发明内容</p>
    <p>[0005]	在下文中给出了关于本发明的简要概述，以便提供关于本发明的某些方面的基本理解。应当理解，这个概述并不是关于本发明的穷举性概述。它并不是意图确定本发明的关键或重要部分，也不是意图限定本发明的范围。其目的仅仅是以简化的形式给出某些概念，以此作为稍后论述的更详细描述的前序。</p>
    <p>[0006]	本发明的目的是针对现有技术的上述问题，提供一种个性化的对消费者生成媒体信息进行处理的方法和装置。</p>
    <p>[0007]	根据本发明的一个方面，提供了一种对消费者生成媒体信息进行处理的方法。所述方法包括：从信息供应源收集并抽取消费者生成媒体信息；基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及可视化地呈现所述定制的消费者生成媒体信息。其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息。并且，其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</p>
    <p>[0008]	其中，可以基于前次更新的用户模型来进行本次收集和过滤中的至少一个。</p>
    <p>[0009]	根据本发明的另一方面，提供了一种对消费者生成媒体信息进行处理的装置。所述装置包括：收集和抽取单元，被配置成从信息供应源收集并抽取消费者生成媒体信息； 过滤单元，被配置成基于预定主题对通过所述收集和抽取单元得到的消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；整合单元，被配置成基于用户定制的规则来对通过所述过滤单元得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及呈现单元，被配置成可视化地呈现通过所述整合单元得到的消费者生成媒体信息。其中，所述收集和抽取单元和所述过滤单元中的至少一个还被配置成基于用户模型来进行收集和过滤中的相应至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息。并且，其中，所述装置还包括用户模型更新单元，所述用户模型更新单元被配置成根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</p>
    <p>[0010]	另外，根据本发明的其它方面，还提供了相应的计算机可读存储介质和计算机程</p>
    <p>序广品。</p>
    <p>[0011]	在根据本发明的上述方面的方法和装置中，基于用户模型来进行收集和过滤中的至少一个，并根据用户对CGM信息的反馈来更新用户模型，从而准确地反映用户对CGM信息的偏好，为用户提供个性化的CGM信息处理。</p>
    <p>附图说明</p>
    <p>[0012]	本发明可以通过参考下文中结合附图所给出的描述而得到更好的理解，其中在所有附图中使用了相同或相似的附图标记来表示相同或者相似的部件。所述附图连同下面的详细说明一起包含在本说明书中并且形成本说明书的一部分，而且用来进一步举例说明本发明的优选实施例和解释本发明的原理和优点。在附图中：</p>
    <p>[0013]	图1示出根据本发明的第一实施例的对CGM信息进行处理的方法的示意性流程图。</p>
    <p>[0014]	图2示出根据本发明实施例的更新用户模型的步骤的示意性流程图。</p>
    <p>[0015]	图3示出根据本发明实施例的CGM信息收集过程的示例图。</p>
    <p>[0016]	图4示出根据本发明实施例的CGM信息过滤过程的示例图。</p>
    <p>[0017]	图5示出根据本发明的第二实施例的对CGM信息进行处理的方法的示意性流程图。</p>
    <p>[0018]	图6示出根据本发明的第三实施例的对CGM信息进行处理的方法的示意性流程图。</p>
    <p>[0019]	图7示出根据本发明的一个实施例的对CGM信息进行处理的装置的示意性框图。[0020]	图8示出根据本发明的另一个实施例的对CGM信息进行处理的装置的示意性框图。</p>
    <p>[0021]	图9示出可用于实施根据本发明实施例的方法和装置的计算机的示意性框图。 具体实施方式</p>
    <p>[0022]	下面参照附图来说明本发明的实施例。在本发明的一个附图或一种实施方式中描述的元素和特征可与一个或更多个其它附图或实施方式中示出的元素和特征相结合。应当注意，为了清楚起见，附图和说明中省略了与本发明无关的、本领域普通技术人员已知的部件和处理的表示和描述。</p>
    <p>[0023]	图1示出根据本发明的第一实施例的对消费者生成媒体（CGM)信息进行处理的方法的示意性流程图。如图所示，在步骤SllO中，从信息供应源收集并抽取CGM信息。接着， 在步骤S120中，基于预定主题对抽取出的CGM信息进行过滤，以获得与预定主题相关的CGM 信息。所示预定主题可以由例如用户或系统管理员预先确定。然后，在步骤S130中，基于用户定制的规则来对过滤得到的CGM信息进行整合，以便获得定制的CGM信息。然后，在步骤S140中，可视化地呈现所定制的CGM信息。</p>
    <p>[0024]	在本实施例中，可以基于用户模型来进行收集和过滤中的至少一个。所述用户模型包括关于用户对CGM信息的偏好的信息。本领域技术人员可以理解，用户模型有多种表示形式，如加权关键词矢量、加权语义网、分类模型、规则等。可以用各种现有技术的方法来生成用户模型。另一方面，用户模型可以根据用户的初始需求而预先生成，或者也可以根据用户对所呈现的CGM信息的反馈动作而生成。例如，抽取出与用户的反馈动作相关联的CGM 信息的特征例如来源、标题、正文等，并利用这些特征来产生用户模型。在首次生成用户模型后，在以后的处理中就可根据用户对所呈现的可视化CGM信息的反馈动作而更新用户模型。本领域技术人员可以根据用户模型的表示形式不同而选择适合的用户模型更新方法， 这里不再赘述。</p>
    <p>[0025]	另外，为了不断跟踪用户对CGM信息的最新偏好，可以根据所述用户对所呈现的 CGM信息的反馈来更新用户模型，如步骤S150所示。</p>
    <p>[0026]	可以理解，本次更新的用户模型将对下一次收集或过滤起作用。换句话说，可以基于前次更新的用户模型来进行本次收集和过滤中的至少一个。</p>
    <p>[0027]	这样，根据本发明实施例的CGM信息处理方法可以是一种在线的处理方法，能够随时根据用户的反馈来更新用户模型，以使处理后的CGM信息不断贴近用户的实际需求。</p>
    <p>[0028]	图2示出上述方法中的更新用户模型的步骤S150的一个示例。如图所示，在步骤 S210中，记录用户对所呈现的CGM信息的反馈动作。接着，在步骤S220中，抽取与所述反馈动作相关联的CGM信息的特征。然后，在步骤S230中，基于所记录的反馈动作和所抽取的特征来更新所述用户模型。例如，用户将某条CGM删除（例如认为该信息与用户关心主题不相关），则该CGM信息的特征例如来源、标题、正文等将被抽出，并用于更新用户模型。</p>
    <p>[0029]	根据本发明的一个实施例，在收集或过滤中，可以对符合用户模型中的所抽取的特征的CGM信息进行与所记录的反馈动作相对应的处理。</p>
    <p>[0030]	下面将结合图3和4，通过举例的方式对根据本发明的第一实施例的对CGM信息进行处理的方法中的收集和过滤过程进行详细描述。[0031]	图3示出根据本发明实施例的CGM信息收集过程的具体示例。如图3所示，可以从各种信息供应源310收集CGM信息。这些信息供应源310包括但不限于RSS/AT0M 源（Feed)311、论坛312、搜索引擎313和用户定义的URLs(统一资源定位符）/Site(网站）314。下面逐一描述从这些信息供应源收集和抽取CGM信息的处理。</p>
    <p>[0032]	RSS为Really Simple Syndication(简易供稿)的缩写，原意是把网站内容如标题、链接、部分内文甚至全文转换为可扩展标记语言（XML extensible Markup Language) 的格式，以向其它网站供稿。ATOM是RSS的继承者，其在处理!^eed中提供的所有内容方面被设计得更加容易。博客、新闻等通常来自RSS/AT0M源311，如上所述的，这些信息的组织性较强，例如一般采用XML格式，因此在收集和抽取处理320中可通过例如i^eed Fetcher 等工具来对其进行收集处理。Feed Fetcher是Google的Reader和Google个性主页订阅器的Robot (机器人），或者说Crawler (爬行器）。从i^ed Fetcher获得的内容中抽取得到XML格式的数据，并存储到数据库330中。当然，本领域技术人员容易理解，这里使用的 Feed Fetcher只是一个例子，还可以使用任何其他合适的信息获取工具来实现从RSS/AT0M 源（Feed) 311收集XML格式的数据。</p>
    <p>[0033]	论坛312通常包括一系列URL。因此，可以通过例如Gecko (参见http ：// en. wikipedia. org/wiki/Gecko_% 281ayout_engine % 29)以及其他工具（参见 http:// en. wikipedia. org/wiki/List_of_layout_engines)等来通过 URL 收集得到相应网页的内容。所获得的来自论坛312的CGM信息（例如论坛页面）绝大多数基于各种模板组织，具有规则的组织形式。因此，通过预先对构成CGM信息的网页收集分析可以预定义一些模板。在 322的抽取处理中首先进行模板检测。如果从网页信息中检测到预定义的模板，则在323的抽取处理中利用预定义的包装器中所包含的这些预定义的模板的来对收集得到的CGM信息进行匹配，以便根据模板的结构而抽取预定格式的数据，例如XML格式的数据。如果未检测到预定义的模板，则在3M中生成新的模板，并在325中根据检测到的模板生成新的包装器，然后通过利用新生成的包装器完成匹配，以便从收集得到的CGM信息中抽取相应信息。 另外，在324中新生成的模板将反馈到模板检测322中，以在后续的模板检测322中作为预定义模板使用。现有技术中已有多种模板检测和包装器生成等方法，这里不再赘述。</p>
    <p>[0034]	作为一种信息供应源的搜索引擎313通常包括搜索引擎列表以及关键词，其中关键词可以是用户自定义的或者系统的缺省设置。为收集特定的CGM信息，可以为搜索引擎 313设置预定的主题。每一个主题包括描述以及一个或者多个用户自定义的或系统缺省设置的关键字和关键短语。对于关键词在搜索引擎中得到的查询结果，可通过上述Gecko等工具获取查询结果页面的网页内容。由于从搜索引擎313得到的内容的数据量有限而形式多样，所以首先可以根据实际需要判断是否存在不需要收集的信息。例如，如果需要收集对于某种商品的文字评论，则基本上可将搜索引擎313返回的图片、音乐等内容判断为与此无关因而不进行收集处理。对于收集得到的网页内容（即CGM信息），例如可在3&#190;通过利用预先定义的包装器来进行信息抽取处理，与323的处理类似。将经过收集和抽取处理得到的XML格式的数据也存储到数据库330中。</p>
    <p>[0035]	对于用户定义的URLs/网站314，例如可在327利用“网络蜘蛛（Spider) ” (也可直接称为蜘蛛）等工具来进行动态网页下载，通过指定的URL来获取站点中网页的内容。 例如，Google的蜘蛛程序Spider对网页数据的抓取是通过读取网页文本内容，并顺着页面中的链接层层深入，从而获得对全站内容的抓取。在327从用户定义的URLs/网站314获取CGM信息，例如获取动态网页的内容之后，在3&#190;使用各种适当的工具，如预定义的包装器等，进行信息抽取。同样地，将经过收集和抽取处理得到的XML格式的数据存储到数据库 330中，以供后续处理之用。</p>
    <p>[0036]	根据本发明的实施例，可以基于用户模型来进行上述收集。</p>
    <p>[0037]	例如，可以记录所述用户将所呈现的CGM信息中的一部分或全部标记为与预定主题不相关的动作，作为用户对所呈现的CGM信息的反馈动作，以更新用户模型。</p>
    <p>[0038]	在进行CGM信息收集时，例如在将收集到的CGM信息保存到数据库330中之前，可以通过更新过的用户模型判断CGM信息与预定主题的相关性，对相关性小于预定义阈值的 CGM信息予以舍弃。换句话说，可以将收集到的CGM信息中符合用户模型中的所抽取的特征的CGM信息确定为与预定主题不相关。</p>
    <p>[0039]	再例如，可以在327中，根据用户模型来改变网络蜘蛛的抓取策略。例如，可以将用户确定为与用户模型中的反馈动作所涉及的预定主题不相关的网页集所链向的网页认定为网络蜘蛛不再抓取的网页。可以在抓取网页时，当通过用户模型确定网页中的锚文本 (anchor text)与用户反馈动作相关联的预定主题不相关、或者锚文本所在的源网页与所述预定主题不相关时，将该锚文本所指向的网页视为与所示预定主题不相关，不对该锚文本所指向的网页进行抓取。关于根据预定主题的改变来改变网络蜘蛛的抓取策略的技术， 还可以参考相关的文献：刘金红、陆余良的“主题网络爬虫研究综述”，计算机应用研究，第 24卷第10期，2007年10月。</p>
    <p>[0040]	又例如，某些RSS源用于记录更新信息的XML文件中不包含对应源网页的全文，但往往包含URL和标题。通过用户模型判断标题与预定主题的相关性，可以对相关性小于预定义阈值的信息条目予以舍弃。</p>
    <p>[0041]	另外，多数论坛包含一个或多个列表页，每个列表页包含若干帖子的标题和URL 等信息，以起到快速浏览和导航的作用。例如通过用户模型判断帖子标题与预定主题的相关性，可以对相关性小于预定义阈值的帖子不予下载，也不存入数据库。</p>
    <p>[0042]	同样，也可以记录所述用户将所呈现的CGM信息中的一部分或全部标记为与预定主题相关的动作，作为用户对所呈现的CGM信息的反馈动作，以更新用户模型。</p>
    <p>[0043]	在将收集到的CGM信息保存到数据库330中之前，可以将CGM信息中符合用户模型中的所抽取的特征的CGM信息确定为与所述预定主题相关，继而保存到数据库330中。</p>
    <p>[0044]	或者，可以在判断网页与预定主题的相关性之后，将用户调整为高相关度的网页集链向的网页认定为网络蜘蛛要优先抓取的网页。</p>
    <p>[0045]	或者，可以将含有网页集中关键词的锚文本所指向的网页认定为网络蜘蛛要优先抓取的网页。</p>
    <p>[0046]	需要注意，虽然在图3所示出的信息收集和抽取处理的具体实例中通过信息抽取处理获得的是XML格式的数据，但是，本领域技术人员应当理解，在此XML格式的数据实际上只是CGM信息的结构化表现形式的一种具体例子，也可以使用能够标识出所收集的CGM信息的各个部分的组成结构及其内容的其他任何数据格式，例如JSON(JavaScript ObjectNotation)数据格式是另外一个选择。此外，数据库330除了存储通过信息抽取处理获得的XML格式的数据以外，也可以存储通过收集处理得到的各种CGM信息。此外，用于存储XML格式的数据以及存储所收集的CGM信息的数据库也可以是不同的数据库。</p>
    <p>[0047]	图4示出根据本发明实施例的CGM信息过滤过程的示例图。如图4所示，以数据库330中存储的数据作为输入在410-440中进行CGM信息过滤。首先，在410中判断网页的类型。具有不同网页类型的不同的网页不仅在信息如何发布以及如何显示方面不同，而且在内容方面也有所不同。在本说明书的上下文中，“网页类型”包括但不限于BBS、博客、 新闻、SNS (Social Network Site，社交网站）、新闻组、产品预览和讨论网站、支持消费者意见的在线零售站点，等等。可以进行网页类型判断处理，以便对不同类型的网页应用不同的过滤策略。</p>
    <p>[0048]	在网页类型判断处理中，如果在410判断网页类型为BBS/博客/其他，则在420继续执行Spam(兜售信息）过滤处理。“兜售信息”是指未经索要而主动提供的信息，基本属于一种垃圾信息，所以需要过滤掉。可以通过现有技术的方法来进行兜售信息的过滤。随后，在430对经过Spam过滤的信息进行相关性判断处理。</p>
    <p>[0049]	相关性判断是指确定网页与某个主题之间的相关性。作为相关性判断的前提，需要设定一个或者多个主题，其中每一个主题包括描述以及一个或者多个关键字和关键短语。主题可以由用户或系统管理员预先设定。这里的主题可以是图3中所示的主题。</p>
    <p>[0050]	可通过各种合适的方法来实现相关性判断处理。例如，可以根据网页与预定主题的相关性程度是否超过预定阈值来判断该网页与预定主题是否相关。或者，也可以直接根据网页中是否包含预定主题中的一个或多个关键字来判断该网页与预定主题是否相关。</p>
    <p>[0051]	如果在410判断网页类型为新闻，则在440中对网页进行相关性判断。440的相关性判断方法可以与430的相关性判断方法相同。</p>
    <p>[0052]	经判断为与预定主题相关的网页将存储到数据库450中。</p>
    <p>[0053]	根据本发明的实施例，可以基于用户模型来进行上述过滤。</p>
    <p>[0054]	例如，可以记录用户将所呈现的CGM信息中的一部分或全部标记为垃圾信息如兜售信息的动作，作为用户对所呈现的CGM信息的反馈动作，以更新用户模型。在此情况下， 在420中，将抽取出的CGM信息中符合所述用户模型中的所抽取的特征的CGM信息确定为垃圾信息并过滤掉。</p>
    <p>[0055]	再例如，可以记录用户将所呈现的CGM信息中的一部分或全部标记为与预定主题不相关的动作，作为用户对所呈现的CGM信息的反馈动作，以更新用户模型。在此情况下， 在430和440中，将所收集的CGM信息中符合所述用户模型中的所抽取的特征的CGM信息确定为与所述预定主题不相关并过滤掉。</p>
    <p>[0056]	在收集和过滤之后，可以基于用户定制的规则对得到的CGM信息进行整合，以获得定制的CGM信息。</p>
    <p>[0057]	整合处理的一个例子是将内容相似的网页聚合在一起，即聚类处理。可以使用任何已知的聚类方法来进行聚类处理。通过整合处理，将具有某种共性或者一致性的CGM信息进行关联。这种共性是由用户定制的整合规则所决定的。例如，以网页作为待整合的CGM 信息的示例，如果将创建时间作为整合规则，则创建时间相同或者相近的网页可认为具有共性或者一致性。类似地，如果将作者作为整合规则，则作者相同的网页可认为具有共性或者一致性。或者，如果将主题内容作为整合规则，则主题相同或相近的网页可认为具有共性或者一致性，等等。[0058]	根据本发明实施例的方法可以提供在线进行的CGM信息处理。CGM信息经过前面的收集和抽取、过滤等处理以连续不间断的形式提供。因此优选地，这种聚类处理方式以增量的方式进行，即，只判断重新进入的网页是否归属于前面已存在的网页所属的类，而不是每进入一个新网页就将全部网页重新再进行一次聚类处理。</p>
    <p>[0059]	整合处理的另一个例子是基于用户定制的规则对CGM信息进行分类。例如，可以基于CGM信息的内容或属性（例如创建时间、作者、来源等）来进行分类处理。通过分类， 将CGM信息确定为预先规定的不同类别。</p>
    <p>[0060]	经过整合处理之后所获得的定制的CGM信息例如可以通过视觉化的方式呈现给用户。视觉化可通过各种合适的显示手段来实现。例如，可通过显示屏等显示装置实现这种呈现。</p>
    <p>[0061]	用户对所呈现的CGM信息的反馈，可以通过用户接口例如鼠标、键盘、触摸屏等来实现。系统将记录并保存用户的各种反馈动作以及与反馈动作相关联的CGM信息的特征， 以更新用户模型。</p>
    <p>[0062]	图5示出根据本发明的第二实施例的对CGM信息进行处理的方法的示意性流程图。与图1所示的根据本发明的第一实施例的方法相比，在根据本发明的第二实施例的方法中，新增了一种对CGM信息的处理步骤S560，即基于用户模型的情感分析（sentimental analysis)。其他步骤如 S510、S520、S530、S540 等，与图 1 所示的步骤 S110、S120、S130、 S140等基本类似，这里不再赘述。</p>
    <p>[0063]	通过情感分析，对CGM信息赋予相应的评价值，该评价值可以表示情感的倾向性及其程度。例如，可以用评价值的正/负来代表CGM信息中的意见的正面/负面性，并且正 /负评价值的分值越高，表示正面/负面的情感倾向程度越大。</p>
    <p>[0064]	情感分析可以依据不同的情感评价规则而进行。例如，对于网页上的发帖，可以根据发帖中主体内容的正面和负面性来进行情感分析，可以根据发帖人的重要性级别来进行情感分析，或者可以根据发帖的时间来进行情感分析。情感评价规则可以由用户预先定义。</p>
    <p>[0065]	可以利用现有技术的方法进行情感分析处理，这里不再赘述。</p>
    <p>[0066]	在图5中所示的例子中，在整合之前进行情感分析。尽管未示出，但是应当理解， 也可以在整合之后对定制的CGM信息进行情感分析。</p>
    <p>[0067]	根据本实施例，上述情感分析过程的过程基于用户模型来进行。例如，可以记录用户对所呈现的CGM信息中的一部分或全部的评价值进行修改的动作，以更新用户模型。在此情况下，可以在所述情感分析过程中，对经过滤得到的或经整合得到的CGM信息中符合用户模型中的所抽取的特征的CGM信息的评价值赋予在所述反馈动作中修改后的评价值。</p>
    <p>[0068]	将用户的情感分析纳入用户模型，提高了 CGM信息处理的个性化程度，更加贴合用户的实际需求。</p>
    <p>[0069]	图6示出根据本发明的第三实施例的对CGM信息进行处理的方法的示意性流程图。与图5所示的根据本发明的第二实施例的方法相比，在根据本发明的第二实施例的方法中，新增了对CGM信息的处理步骤S670和S680，即基于用户模型来确定关键事件，以及将关键事件上报给用户。其他步骤如S610、S620、S630、S640、S660等，与图5所示的步骤 S510、S520、S530、S540、S560等基本类似，这里不再赘述。</p>
    <p>[0070]	所谓“关键事件”是指用户比较关注的事件，这种事件可以与具有负面情感倾向性的信息有关，也可以与具有正面情感倾向性的信息有关，可根据实际需要进行设定。可以在 S670中将情感分析所得到的评价值与预定的阈值进行比较。如果评价值超过阈值，则确定被赋予该评价值的网页构成关键事件，并在步骤S680中向用户报告关键事件。在此，预定阈值也可以是一个预定的阈值范围，并规定在评价值落入该预定阈值范围的情况下确定出现关键事件。</p>
    <p>[0071]	根据本实施例，可以基于用户模型来进行关键事件的确定。</p>
    <p>[0072]	例如，可以记录用户将所呈现的CGM信息中的关键事件标记为非关键事件的动作，以更新用户模型。在此情况下，可以在所述关键事件的确定步骤S670中，将经过情感分析的CGM信息中符合所述用户模型中的所抽取的特征的CGM信息确定为非关键事件。例如，如果用户将所呈现的创建时间在1980年以前的关键事件标记为非关键事件，则在后续的关键事件确定过程中，将符合该特征的CGM信息，即创建时间在1980年以前的CGM信息， 确定为非关键事件。</p>
    <p>[0073]	再例如，可以记录用户将所呈现的CGM信息中的非关键事件标记为关键事件的动作，以更新用户模型。在此情况下，可以在所述关键事件的确定步骤S670中，将经过情感分析的CGM信息中符合所述用户模型中的所抽取的特征的CGM信息确定为关键事件。</p>
    <p>[0074]	另外，还可以接收用户对用于确定关键事件的所述阈值范围的修改，并根据修改后的阈值范围来确定关键事件。</p>
    <p>[0075]	根据本发明的另一实施例，所述CGM信息处理方法还可以包括接收用户对关键事件的报告规则的定义。例如，用户可以通过用户接口等来配置关于关键事件的报告规则。所述报告规则可以是各种数据形式，例如，可以是配置文件、规则树等等。在步骤S680中，可以根据用户定义的报告规则来将所确定的关键事件报告给用户。这样，可以避免大量未经筛选的关键事件涌向用户，而只将用户需要的关键事件报告给用户。</p>
    <p>[0076]	基于用户模型进行关键事件的确定并上报关键事件，使得用户能够及时了解到可能需要处理的CGM信息，从而提供更好的用户体验。</p>
    <p>[0077]	图7示出根据本发明的一个实施例的对CGM信息进行处理的装置的示意性框图。 如图7所示，对CGM信息进行处理的装置700包括收集和抽取单元710、过滤单元720、整合单元730、呈现单元740和用户模型更新单元750。其中，收集和抽取单元710被配置成从信息供应源收集并抽取CGM信息。过滤单元720被配置成基于预定主题对通过所述收集和抽取单元710得到的CGM信息进行过滤，以获得与所述预定主题相关的CGM信息。整合单元 730被配置成基于用户定制的规则来对通过所述过滤单元720得到的CGM信息进行整合，以便获得定制的CGM信息。呈现单元740被配置成可视化地呈现通过所述整合单元730得到的CGM信息。用户模型更新单元750被配置成根据用户对所呈现的CGM信息的反馈来更新用户模型。其中，收集和抽取单元710与过滤单元720中的至少一个还被配置成基于所述用户模型来进行收集和过滤中的相应至少一个。所述用户模型包括关于用户对CGM信息的偏好的信息。</p>
    <p>[0078]	根据本发明的另一实施例，用户模型更新单元750可以进一步被配置成：记录用户对通过呈现单元740呈现的CGM信息的反馈动作；抽取与所述反馈动作相关联的CGM信息的特征；以及基于所记录的反馈动作和所抽取的特征来更新所述用户模型。</p>
    <p>[0079]	根据本发明的另一实施例，收集和抽取单元710可以进一步被配置成对符合所述用户模型中的所抽取的特征的CGM信息进行与所记录的反馈动作相对应的处理。</p>
    <p>[0080]	根据本发明的另一实施例，过滤单元720可以进一步被配置成对符合所述用户模型中的所抽取的特征的CGM信息进行与所记录的反馈动作相对应的处理。</p>
    <p>[0081]	图8示出根据本发明的另一个实施例的对CGM信息进行处理的装置的示意性框图。在该实施例中，除了具有与图7中的装置700的单元710-750类似的单元810-850之外，装置800还可以包括情感分析单元860。所述情感分析单元860被配置成基于用户模型对通过过滤单元820得到的或通过整合单元830得到的CGM信息进行情感分析，以便对接受情感分析的CGM信息赋予相应的评价值。</p>
    <p>[0082]	根据本发明的另一实施例，情感分析单元860还可以被配置成基于用户模型，将评价值落入预定阈值范围的CGM信息确定为关键事件，并将所述关键事件报告给用户。</p>
    <p>[0083]	根据本发明的另一实施例，用户模型更新单元850还可以被配置成接收用户对关键事件的报告规则的定义。情感分析单元860还可以被配置成根据所述用户定义的报告规则来将所确定的关键事件报告给用户。</p>
    <p>[0084]	关于上述装置和单元的操作细节，可以参考以上相应方法的各个实施例，这里不再详细描述。</p>
    <p>[0085]	另外，上述装置中各个组成模块、单元可以通过软件、固件、硬件或其组合的方式进行配置。配置可使用的具体手段或方式为本领域技术人员所熟知，在此不再赘述。在通过软件或固件实现的情况下，从存储介质或网络向具有专用硬件结构的计算机安装构成该软件的程序，该计算机在安装有各种程序时，能够执行各种功能等。</p>
    <p>[0086]	在根据本发明的实施例的方法和装置中，基于用户模型来进行收集和过滤中的至少一个，并根据用户对CGM信息的反馈来更新用户模型，从而准确地反映用户对CGM信息的偏好，为用户提供个性化的CGM信息处理。</p>
    <p>[0087]	图9示出了可用于实施根据本发明实施例的方法和装置的计算机的示意性框图。 在图9中，中央处理单元（CPU)901根据只读存储器（ROM)902中存储的程序或从存储部分 908加载到随机存取存储器（RAM) 903的程序执行各种处理。在RAM 903中，还根据需要存储当CPU901执行各种处理等等时所需的数据。CPU 90UROM 902和RAM 903经由总线904 彼此连接。输入/输出接口 905也连接到总线904。</p>
    <p>[0088]	下述部件连接到输入/输出接口 905 ：输入部分906(包括键盘、鼠标等等）、输出部分907(包括显示器，比如阴极射线管（CRT)、液晶显示器（LCD)等，和扬声器等）、存储部分908(包括硬盘等)、通信部分909(包括网络接口卡比如LAN卡、调制解调器等)。通信部分909经由网络比如因特网执行通信处理。根据需要，驱动器910也可连接到输入/输出接口 905。可拆卸介质911比如磁盘、光盘、磁光盘、半导体存储器等等可以根据需要被安装在驱动器910上，使得从中读出的计算机程序根据需要被安装到存储部分908中。</p>
    <p>[0089]	在通过软件实现上述系列处理的情况下，从网络比如因特网或存储介质比如可拆卸介质911安装构成软件的程序。</p>
    <p>[0090]	本领域的技术人员应当理解，这种存储介质不局限于图9所示的其中存储有程序、与设备相分离地分发以向用户提供程序的可拆卸介质911。可拆卸介质911的例子包含磁盘（包含软盘（注册商标））、光盘（包含光盘只读存储器（⑶-ROM)和数字通用盘 (DVD))、磁光盘（包含迷你盘（MD)(注册商标））和半导体存储器。或者，存储介质可以是</p>
    <p>1ROM 902、存储部分908中包含的硬盘等等，其中存有程序，并且与包含它们的设备一起被分发给用户。</p>
    <p>[0091]	本发明还提出一种存储有机器可读取的指令代码的程序产品。所述指令代码由机器读取并执行时，可执行上述根据本发明实施例的方法。</p>
    <p>[0092]	相应地，用于承载上述存储有机器可读取的指令代码的程序产品的存储介质也包括在本发明的公开中。所述存储介质包括但不限于软盘、光盘、磁光盘、存储卡、存储棒等寸。</p>
    <p>[0093]	在上面对本发明具体实施例的描述中，针对一种实施方式描述和/或示出的特征可以以相同或类似的方式在一个或更多个其它实施方式中使用，与其它实施方式中的特征相组合，或替代其它实施方式中的特征。</p>
    <p>[0094]	应该强调，术语“包括/包含”在本文使用时指特征、要素、步骤或组件的存在，但并不排除一个或更多个其它特征、要素、步骤或组件的存在或附加。</p>
    <p>[0095]	此外，本发明的方法不限于按照说明书中描述的时间顺序来执行，也可以按照其他的时间顺序地、并行地或独立地执行。因此，本说明书中描述的方法的执行顺序不对本发明的技术范围构成限制。</p>
    <p>[0096]	尽管上面已经通过对本发明的具体实施例的描述对本发明进行了披露，但是，应该理解，上述的所有实施例和示例均是示例性的，而非限制性的。本领域的技术人员可在所附权利要求的精神和范围内设计对本发明的各种修改、改进或者等同物。这些修改、改进或者等同物也应当被认为包括在本发明的保护范围内。</p>
    <p>[0097]	Mid</p>
    <p>[0098]	附记1. 一种对消费者生成媒体信息进行处理的方法，包括：</p>
    <p>[0099]	从信息供应源收集并抽取消费者生成媒体信息；</p>
    <p>[0100]	基于预定主题对抽取出的所述消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；</p>
    <p>[0101]	基于用户定制的规则来对过滤得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及</p>
    <p>[0102]	可视化地呈现所述定制的消费者生成媒体信息，</p>
    <p>[0103]	其中，基于用户模型来进行所述收集和过滤中的至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且</p>
    <p>[0104]	其中，所述方法还包括：根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</p>
    <p>[0105]	附记2.根据附记1的方法，其中，基于前次更新的用户模型来进行本次收集和过滤中的至少一个。</p>
    <p>[0106]	附记3.根据附记1或2的方法，其中，所述更新所述用户模型包括：</p>
    <p>[0107]	记录所述用户对所呈现的消费者生成媒体信息的反馈动作；</p>
    <p>[0108]	抽取与所述反馈动作相关联的消费者生成媒体信息的特征；以及</p>
    <p>[0109]	基于所记录的反馈动作和所抽取的特征来更新所述用户模型。</p>
    <p>[0110]	附记4.根据附记3的方法，其中，在所述收集和过滤中的所述至少一个中，对符合所述用户模型中的所抽取的特征的消费者生成媒体信息进行与所记录的反馈动作相对应的处理。</p>
    <p>[0111]	附记5.根据附记3的方法，其中，</p>
    <p>[0112]	所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的一部分或全部标记为与所述预定主题不相关的动作；以及</p>
    <p>[0113]	所述收集包括：将来自所述信息供应源的消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为与所述预定主题不相关。</p>
    <p>[0114]	附记6.根据附记3的方法，其中，</p>
    <p>[0115]	所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的一部分或全部标记为垃圾信息的动作；以及</p>
    <p>[0116]	所述过滤包括：将抽取出的消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为垃圾信息并过滤掉。</p>
    <p>[0117]	附记7.根据附记3的方法，其中，</p>
    <p>[0118]	所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的一部分或全部标记为与所述预定主题不相关的动作；以及</p>
    <p>[0119]	所述过滤包括：将所收集的消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为与所述预定主题不相关并过滤掉。</p>
    <p>[0120]	附记8.根据附记3的方法，还包括：</p>
    <p>[0121]	在所述整合之前基于所述用户模型对经所述过滤得到的与预定主题相关的消费者生成媒体信息进行情感分析，或者在所述整合之后基于所述用户模型对所述定制的消费者生成媒体信息进行情感分析，以便对接受情感分析的消费者生成媒体信息赋予相应的评价值。</p>
    <p>[0122]	附记9.根据附记8的方法，其中，</p>
    <p>[0123]	所述记录反馈动作包括：记录所述用户对所呈现的消费者生成媒体信息中的一部分或全部的评价值进行修改的动作；以及</p>
    <p>[0124]	所述情感分析包括：对经所述过滤得到的或经所述整合得到的消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息的评价值赋予在所述反馈动作中修改后的评价值。</p>
    <p>[0125]	附记10.根据附记8的方法，其中，所述情感分析还包括：</p>
    <p>[0126]	基于所述用户模型，将评价值落入预定阈值范围的所述消费者生成媒体信息确定为关键事件，并将所述关键事件报告给所述用户。</p>
    <p>[0127]	附记11.根据附记10的方法，其中，</p>
    <p>[0128]	所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的关键事件标记为非关键事件的动作；以及</p>
    <p>[0129]	所述情感分析还包括：将所述消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为非关键事件。</p>
    <p>[0130]	附记12.根据附记10的方法，其中，</p>
    <p>[0131]	所述记录反馈动作包括：记录所述用户将所呈现的消费者生成媒体信息中的非关键事件标记为关键事件的动作；以及</p>
    <p>[0132]	所述情感分析还包括：将所述消费者生成媒体信息中符合所述用户模型中的所抽取的特征的消费者生成媒体信息确定为关键事件。</p>
    <p>[0133]	附记13.根据附记10的方法，其中，</p>
    <p>[0134]	所述方法还包括：接收所述用户对关键事件的报告规则的定义；以及</p>
    <p>[0135]	所述报告关键事件包括：根据所述用户定义的报告规则来将所确定的关键事件报告给所述用户。</p>
    <p>[0136]	附记14.根据附记10的方法，还包括：接收所述用户对所述阈值范围的修改，并根据修改后的所述阈值范围来确定所述关键事件。</p>
    <p>[0137]	附记15. &#8212;种对消费者生成媒体信息进行处理的装置，包括：</p>
    <p>[0138]	收集和抽取单元，被配置成从信息供应源收集并抽取消费者生成媒体信息；</p>
    <p>[0139]	过滤单元，被配置成基于预定主题对通过所述收集和抽取单元得到的消费者生成媒体信息进行过滤，以获得与所述预定主题相关的消费者生成媒体信息；</p>
    <p>[0140]	整合单元，被配置成基于用户定制的规则来对通过所述过滤单元得到的消费者生成媒体信息进行整合，以便获得定制的消费者生成媒体信息；以及</p>
    <p>[0141]	呈现单元，被配置成可视化地呈现通过所述整合单元得到的消费者生成媒体信息&#938;</p>
    <p>[0142]	其中，所述收集和抽取单元和所述过滤单元中的至少一个还被配置成基于用户模型来进行收集和过滤中的相应至少一个，所述用户模型包括关于用户对消费者生成媒体信息的偏好的信息；并且</p>
    <p>[0143]	其中，所述装置还包括用户模型更新单元，所述用户模型更新单元被配置成根据所述用户对所呈现的消费者生成媒体信息的反馈来更新所述用户模型。</p>
    <p>[0144]	附记16.根据附记15的装置，其中，所述用户模型更新单元进一步被配置成：</p>
    <p>[0145]	记录所述用户对通过所述呈现单元呈现的消费者生成媒体信息的反馈动作；</p>
    <p>[0146]	抽取与所述反馈动作相关联的消费者生成媒体信息的特征；以及</p>
    <p>[0147]	基于所记录的反馈动作和所抽取的特征来更新所述用户模型。</p>
    <p>[0148]	附记17.根据附记16的装置，其中，所述收集和抽取单元和所述过滤单元中的所述至少一个进一步被配置成对符合所述用户模型中的所抽取的特征的消费者生成媒体信息进行与所记录的反馈动作相对应的处理。</p>
    <p>[0149]	附记18.根据附记16的装置，还包括情感分析单元，所述情感分析单元被配置成基于所述用户模型对通过所述过滤单元得到的或通过所述整合单元得到的消费者生成媒体信息进行情感分析，以便对接受情感分析的消费者生成媒体信息赋予相应的评价值。</p>
    <p>[0150]	附记19.根据附记16的装置，其中，所述情感分析单元还被配置成基于所述用户模型，将评价值落入预定阈值范围的所述消费者生成媒体信息确定为关键事件，并将所述关键事件报告给所述用户。</p>
    <p>[0151]	附记20.根据附记19的装置，其中，</p>
    <p>[0152]	所述用户模型更新单元还被配置成接收所述用户对关键事件的报告规则的定义； 以及</p>
    <p>[0153]	所述情感分析单元还被配置成根据所述用户定义的报告规则来将所确定的关键事件报告给所述用户。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1659531A?cl=zh">CN1659531A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2003年4月4日</td><td class="patent-data-table-td patent-date-value">2005年8月24日</td><td class="patent-data-table-td ">索尼电子有限公司</td><td class="patent-data-table-td ">使用学习机制对内容进行过滤</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101477554A?cl=zh">CN101477554A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年1月16日</td><td class="patent-data-table-td patent-date-value">2009年7月8日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于用户兴趣的个性化元搜索引擎及搜索结果处理方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101551825A?cl=zh">CN101551825A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年5月15日</td><td class="patent-data-table-td patent-date-value">2009年10月7日</td><td class="patent-data-table-td ">中国科学技术大学</td><td class="patent-data-table-td ">基于属性描述的个性化影片推荐系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101630315A?cl=zh">CN101630315A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年7月16日</td><td class="patent-data-table-td patent-date-value">2010年1月20日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">一种快速检索方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101639841A?cl=zh">CN101639841A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年7月30日</td><td class="patent-data-table-td patent-date-value">2010年2月3日</td><td class="patent-data-table-td ">深圳市九洲电器有限公司</td><td class="patent-data-table-td ">一种提供多媒体数据搜索和查询服务的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101719145A?cl=zh">CN101719145A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年11月17日</td><td class="patent-data-table-td patent-date-value">2010年6月2日</td><td class="patent-data-table-td ">北京大学</td><td class="patent-data-table-td ">基于图书领域本体的个性化搜索方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=bimHBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06Q0030020000">G06Q30/02</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=bimHBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年3月14日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年4月25日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年12月23日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/ce47a3723baaa535aca8/CN102376057A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5115ea495017d9115e613207d3810e5a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%AF%B9%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E6%88%90%E5%AA%92%E4%BD%93%E4%BF%A1%E6%81%AF%E8%BF%9B%E8%A1%8C%E5%A4%84.pdf?id=bimHBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3QUKoGWXHaYruH_oqO-_SQBJF_ow"},"sample_url":"https://www.google.com/patents/reader?id=bimHBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>