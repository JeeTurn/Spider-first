<!DOCTYPE html><html><head><title>专利 CN102456019A - 检索方法及装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="检索方法及装置"><meta name="DC.contributor" content="孙良" scheme="inventor"><meta name="DC.contributor" content="腾讯科技（深圳）有限公司" scheme="assignee"><meta name="DC.date" content="2010-10-18" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种检索方法及装置，属于检索技术领域。所述方法包括：接收用户输入的检索词；获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；根据所述检索词及情景数据在检索数据库中进行检索。本发明通过获取与用户相匹配的情景数据，并根据用户输入的检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。"><meta name="DC.date" content="2012-5-16"><meta name="DC.relation" content="CN:101105795:A" scheme="references"><meta name="DC.relation" content="CN:101373486:A" scheme="references"><meta name="DC.relation" content="CN:101719145:A" scheme="references"><meta name="DC.relation" content="CN:1758248:A" scheme="references"><meta name="DC.relation" content="EP:1708105:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102456019:A"><meta name="citation_patent_application_number" content="CN:201010519681"><link rel="canonical" href="https://www.google.com/patents/CN102456019A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102456019A?cl=zh"/><meta name="title" content="专利 CN102456019A - 检索方法及装置"/><meta name="description" content="本发明公开了一种检索方法及装置，属于检索技术领域。所述方法包括：接收用户输入的检索词；获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；根据所述检索词及情景数据在检索数据库中进行检索。本发明通过获取与用户相匹配的情景数据，并根据用户输入的检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。"/><meta property="og:title" content="专利 CN102456019A - 检索方法及装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102456019A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102456019A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=2MhwBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102456019A&amp;usg=AFQjCNF1w9GiZRjZX6wa4rUJe9z9GTO-Xg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/c9471cee6b2556629526/CN102456019A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/c9471cee6b2556629526/CN102456019A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102456019A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102456019A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102456019A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种检索方法及装置，属于检索技术领域。所述方法包括：接收用户输入的检索词；获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；根据所述检索词及情景数据在检索数...</span><span itemprop="url">https://www.google.com/patents/CN102456019A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102456019A - 检索方法及装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102456019A - 检索方法及装置" title="专利 CN102456019A - 检索方法及装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102456019 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010519681</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年5月16日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年10月18日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年10月18日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010519681.4, </span><span class="patent-bibdata-value">CN 102456019 A, </span><span class="patent-bibdata-value">CN 102456019A, </span><span class="patent-bibdata-value">CN 201010519681, </span><span class="patent-bibdata-value">CN-A-102456019, </span><span class="patent-bibdata-value">CN102456019 A, </span><span class="patent-bibdata-value">CN102456019A, </span><span class="patent-bibdata-value">CN201010519681, </span><span class="patent-bibdata-value">CN201010519681.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%99%E8%89%AF%22">孙良</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%85%BE%E8%AE%AF%E7%A7%91%E6%8A%80%EF%BC%88%E6%B7%B1%E5%9C%B3%EF%BC%89%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">腾讯科技（深圳）有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102456019A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102456019A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102456019A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2MhwBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010519681&amp;usg=AFQjCNHmE78I33vlVaMtIXC8Prfpx2C86A"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2MhwBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102456019A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGPwciaaAUSo4l0i7TiZIjtz8PW0A"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT112428794" lang="ZH" load-source="patent-office">检索方法及装置</invention-title>
      </span><br><span class="patent-number">CN 102456019 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA95935387" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种检索方法及装置，属于检索技术领域。所述方法包括：接收用户输入的检索词；获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；根据所述检索词及情景数据在检索数据库中进行检索。本发明通过获取与用户相匹配的情景数据，并根据用户输入的检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM41301079" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种检索方法，其特征在于，所述方法包括： 接收用户输入的检索词；获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；根据所述检索词及情景数据在检索数据库中进行检索。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，所述接收用户输入的检索词之前，还包括：获取文档数据，并根据所述文档数据构造检索数据库；所述根据所述检索词及情景数据在检索数据库中进行检索，具体包括：根据所述检索词及情景数据在所述构造的检索数据库中进行检索。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其特征在于，所述获取文档数据，具体包括：抓取网页数据和/或接收推送的网页数据，并对所述网页数据进行文本解析，得到文档数据；所述根据所述文档数据构造检索数据库，具体包括：对获取到的所述文档数据进行分类、主题抽取和词关系分析处理，并将处理后的文档数据进行数据索引，得到检索数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的方法，其特征在于，所述获取所述用户的相关信息，具体包括：获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志信息；所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体包括： 根据所述网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；根据统计的关系以及确定的检索行为特征得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的方法，其特征在于，所述获取所述用户的相关信息，具体包括：获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体包括： 根据获取到的所述用户信息分析得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的方法，其特征在于，所述获取所述用户的相关信息，具体包括：获取所述用户的日志信息和用户信息，所述日志信息至少包括网页点击的日志信息及会话日志信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体包括： 根据所述网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；根据统计的关系、确定的检索行为特征以及获取到的所述用户信息得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
    </div> <div class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.	一种检索装置，其特征在于，所述装置包括： 接收模块，用于接收用户输入的检索词；第一获取模块，用于获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；检索模块，用于根据所述接收模块接收到的检索词及所述第一获取模块获取到的情景数据在检索数据库中进行检索。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的装置，其特征在于，所述第一获取模块，具体包括：第一获取单元，用于获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志信息；第二获取单元，用于根据所述第一获取单元获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；第三获取单元，用于根据所述第二获取单元统计的关系以及确定的检索行为特征得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求7所述的装置，其特征在于，所述第一获取模块，具体包括：第四获取单元，用于获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；第五获取单元，用于根据所述第四获取单元获取到的所述用户信息分析得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求7所述的装置，其特征在于，所述第一获取模块，具体包括：第一获取单元，用于获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志信息；第二获取单元，用于根据所述第一获取单元获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；第四获取单元，用于获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；第六获取单元，用于根据所述第二获取单元统计的关系、确定的检索行为特征和第四获取单元获取到的所述用户信息得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES46749489" lang="ZH" load-source="patent-office" class="description">
    <p>检索方法及装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及检索技术领域，特别涉及一种检索方法及装置。 背景技术</p>
    <p>[0002]	互联网的迅速普及已经成为信息时代的重要标志，任何人在任何时间、任何地点都可以通过网络发布信息。在庞大的信息库里面快速有效地查找到用户需要的信息，使搜索引擎成为了寻找信息的好帮手。</p>
    <p>[0003]	现有搜索引擎在检索时，当用户输入检索词之后，需要用户在检索结果中反复查找所需信息，或在整个检索过程中，需要用户反复的修改检索词，并反复在检索结果中筛选对自己有用的信息。</p>
    <p>[0004]	现有技术至少存在以下缺点：</p>
    <p>[0005]	现有搜索引擎在实现检索时，同样的检索词会得到同样的检索结果，也就是说，现有检索方式对于所有用户都通用，导致检索结果没有针对性，准确性也不高。</p>
    <p>发明内容</p>
    <p>[0006]	本发明实施例提供了一种检索方法及装置，其能解决现有检索方式中检索结果没有针对性，准确性也不高的问题。所述技术方案如下：</p>
    <p>[0007]	&#8212;方面，提供了一种检索方法，所述方法包括：</p>
    <p>[0008]	接收用户输入的检索词；</p>
    <p>[0009]	获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；</p>
    <p>[0010]	根据所述检索词及情景数据在检索数据库中进行检索。</p>
    <p>[0011]	其中，所述接收用户输入的检索词之前，还包括：</p>
    <p>[0012]	获取文档数据，并根据所述文档数据构造检索数据库；</p>
    <p>[0013]	所述根据所述检索词及情景数据在检索数据库中进行检索，具体包括：包括：</p>
    <p>[0014]	根据所述网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；</p>
    <p>[0015]	根据统计的关系、确定的检索行为特征以及获取到的所述用户信息得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0016]	另一方面，还提供了一种检索装置，所述装置包括：</p>
    <p>[0017]	接收模块，用于接收用户输入的检索词；</p>
    <p>[0018]	第一获取模块，用于获取所述用户的相关信息，并对所述相关信息进行分析，得到与所述用户相匹配的情景数据；</p>
    <p>[0019]	检索模块，用于根据所述接收模块接收到的检索词及所述第一获取模块获取到的情景数据在检索数据库中进行检索。[0020] 其中，所述第一获取模块，具体包括：</p>
    <p>[0021 ] 第一获取单元，用于获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志信息；</p>
    <p>[0022]	第二获取单元，用于根据所述第一获取单元获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；</p>
    <p>[0023]	第三获取单元，用于根据所述第二获取单元统计的关系以及确定的检索行为特征得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0024]	可选地，所述第一获取模块，具体包括：</p>
    <p>[0025]	第四获取单元，用于获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0026]	第五获取单元，用于根据所述第四获取单元获取到的所述用户信息分析得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0027]	可选地，所述第一获取模块，具体包括：</p>
    <p>[0028]	第一获取单元，用于获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志信息；</p>
    <p>[0029]	根据所述检索词及情景数据在所述构造的检索数据库中进行检索。</p>
    <p>[0030]	所述获取文档数据，具体包括：</p>
    <p>[0031]	抓取网页数据和/或接收推送的网页数据，并对所述网页数据进行文本解析，得到文档数据。</p>
    <p>[0032]	所述根据所述文档数据构造检索数据库，具体包括：</p>
    <p>[0033]	对获取到的所述文档数据进行分类、主题抽取和词关系分析处理，并将处理后的文档数据进行数据索引，得到检索数据库。</p>
    <p>[0034]	所述获取所述用户的相关信息，具体包括：</p>
    <p>[0035]	获取所述用户的日志信息，所述日志信息至少包括网页点击的日志信息及会话日志fn息；</p>
    <p>[0036]	所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体包括：</p>
    <p>[0037]	根据所述网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；</p>
    <p>[0038]	根据统计的关系以及确定的检索行为特征得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0039]	可选地，所述获取所述用户的相关信息，具体包括：</p>
    <p>[0040]	获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0041]	所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体包括：</p>
    <p>[0042]	根据获取到的所述用户信息分析得到包括用户个人信息、检索原因信息、检索时</p>
    <p>5间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0043]	可选地，所述获取所述用户的相关信息，具体包括：</p>
    <p>[0044]	获取所述用户的日志信息和用户信息，所述日志信息至少包括网页点击的日志信息及会话日志信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0045]	所述对所述相关信息进行分析，得到与所述用户相匹配的情景数据，具体</p>
    <p>[0046]	第二获取单元，用于根据所述第一获取单元获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据所述会话日志信息确定所述用户的检索行为特征；</p>
    <p>[0047]	第四获取单元，用于获取所述用户的用户信息，所述用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0048]	第六获取单元，用于根据所述第二获取单元统计的关系、确定的检索行为特征和第四获取单元获取到的所述用户信息得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0049]	本发明实施例提供的技术方案的有益效果是：</p>
    <p>[0050]	通过获取与用户相匹配的情景数据，并根据检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。</p>
    <p>附图说明</p>
    <p>[0051]	为了更清楚地说明本发明实施例中的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。</p>
    <p>[0052]	图1是本发明实施例一提供的检索方法流程图；</p>
    <p>[0053]	图2是本发明实施例二提供的检索方法流程图；</p>
    <p>[0054]	图3是本发明实施例三提供的检索装置结构示意图；</p>
    <p>[0055]	图4是本发明实施例三提供的检索装置的另一种结构示意图；</p>
    <p>[0056]	图5是本发明实施例三提供的第一获取模块结构示意图；</p>
    <p>[0057]	图6是本发明实施例三提供的第一获取模块的另一种结构示意图；</p>
    <p>[0058]	图7是本发明实施例三提供的第一获取模块的又一种结构示意图。</p>
    <p>具体实施方式</p>
    <p>[0059]	为使本发明的目的、技术方案和优点更加清楚，下面将结合附图对本发明实施方式作进一步地详细描述。</p>
    <p>[0060]	实施例一</p>
    <p>[0061]	参见图1，本实施例提供了一种检索方法，该检索方法流程具体如下：</p>
    <p>[0062]	101 ：接收用户输入的检索词；[0063]	102:获取用户的相关信息，并对相关信息进行分析，得到与用户相匹配的情景数据；</p>
    <p>[0064]	103 ：根据检索词及情景数据在检索数据库中进行检索。</p>
    <p>[0065]	本实施例提供的方法，通过获取与用户相匹配的情景数据，并根据检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。</p>
    <p>[0066]	实施例二</p>
    <p>[0067]	本实施例提供了一种检索方法，该方法通过获取用户的相关信息，根据用户的相关信息获取与用户相匹配的情景数据，并在检索过程中考虑到用户的情景数据，从而提高检索结果的针对性及准确性。其中，用户的相关信息包括用户的日志信息和/或用户信息。 为了便于说明，本实施例以用户的相关信息同时包括用户的日志信息及用户信息为例，对本实施例提供的方法进行详细描述。参见图2，本实施例提供的方法流程具体如下：</p>
    <p>[0068]	201 ：获取文档数据，并根据文档数据构造检索数据库；</p>
    <p>[0069]	其中，检索数据库是检索技术中必不可少的，现有技术中也存在多种构造检索数据库的方式。在本实施例中，仅以根据获取到的文档数据构造检索数据库为例。</p>
    <p>[0070]	对于如何获取文档数据，本实施例同样不作具体限定，保证获取到更全面的数据即可。本实施例采取的获取文档数据的方式包括但不限于抓取网页数据和/或接收推送的网页数据，并对网页数据进行文本解析，得到文档数据。其中，本实施例不对抓取到的网页数据和接收推送的网页数据进行限定，为了构造出覆盖范围较广且实用的检索数据库，抓取或接收的网页数据内容应尽量丰富。在根据获取到的文档数据构造检索数据库时，为了便于后续检索，需要对获取到的文档数据进行分类、主题抽取和词关系分析等处理，并将处理后的文档数据进行数据索引，得到检索数据库。</p>
    <p>[0071]	202 ：对用户输入的检索词进行分词处理，得到分词结果；</p>
    <p>[0072]	针对该步骤，当用户输入检索词触发检索操作后，对用户输入的检索词进行分词处理已是较为成熟的现有技术，对于相同的检索词，采用不同的分词处理方式，得到的分词结果也可能不同，本实施例不对分词处理的方式进行具体限定。例如，在对用户输入的检索词“沈届大运会”进行分词处理时，可将语言学上有意义的词识别出来，得到包括“26”、“届” 和“大运会”这3个词单元的分词结果。</p>
    <p>[0073]	203:获取用户的日志信息和用户信息，并对用户的日志信息和用户信息进行分析，得到与用户相匹配的情景数据；</p>
    <p>[0074]	具体地，由于用户的日志信息和用户信息能够反应一个用户的多种信息，为了充分挖掘用户的检索意图，本实施例采取了获取用户的日志信息和用户信息的方式，通过对获取到的日志信息和用户信息进行分析，进而得出与用户相匹配的情景数据，通过情景数据反应用户的检索意图，进而为用户提供更具针对性的检索服务。</p>
    <p>[0075]	其中，用户的日志信息包括但不限于网页点击的日志信息及会话日志信息，例如， 用户在一段时间内曾输入过的检索词，以及根据选择的检索结果而点击的网页等等，则在对用户的日志信息进行分析时，可以根据网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据会话日志信息确定用户的检索行为特征。该用户的检索行为特征可以反应用户的检索意愿，例如，用户检索的目的是为了查看新闻，或是为了获取信息等</p>
    <p>7等。</p>
    <p>[0076]	用户的用户信息包括但不限于用户浏览网页的信息、文件信息、互动平台信息，例如，用户浏览过哪些类型的网页，网页的内容等等，互动平台可以是聊天工具，论坛等，互动平台信息可以是用户在注册或登录互动平台时填写的个人信息，或是互动内容信息等等。</p>
    <p>[0077]	在获取了用户的日志信息和用户信息等相关信息之后，通过对获取到的信息进行分析，即可得到包括用户个人信息（Who)、检索原因信息（Why)、检索时间信息（When)、检索位置信息（Where)、检索词信息（What)、检索目的信息（Want)和检索行为信息（How)中的至少一种信息，由于该类信息是根据用户的日志信息和用户信息等相关信息得到的，因而本实施例将该类信息作为用户检索行为的7要素，统称为与用户相匹配的情景数据，不同用户对应不同的情景数据，本实施例不对情景数据的具体内容进行限定，实际应用过程中， 情景数据既可以包括7要素中的一个或多个要素，也可以包括全部要素，还可以在这7个要素的基础上增加其他要素，从而有助于更准确地挖掘出用户的检索意图。</p>
    <p>[0078]	204 ：根据分词结果及情景数据在检索数据库中进行检索。</p>
    <p>[0079]	针对该步骤，在数据库中检索是很常见的现有技术，但在本实施例中，检索过程中，还要考虑与用户相匹配的情景数据，即根据用户检索意图进行检索，从而能够返回用户期望得到的检索结果，例如，用户输入的检索词为“苹果”，由于该词的含义较多，不仅代表水果，还具有软件、网站、电影名称等多层含义，用户输入该检索词时可能只是为了获取其中的一种含义对应的相关信息，如果仅根据该检索词进行检索，则得到的检索结果会很多， 不仅数量多，内容也会多种多样，即使对检索结果有一定的排序方式，也很难直接将用户期望得到的检索结果显示给用户，常常无法避免地需要用户在多个检索结果中筛选期望的检索结果。</p>
    <p>[0080]	而对于本实施例提供的方法，由于通过获取用户的日志信息和用户信息，得到了与用户相匹配的情景数据，而该情景数据又能够反应出用户的搜索意图，例如，情景数据中给出了用户的检索意图为软件，则在检索时，可将相关的软件信息检索出来提供给用户，从而减少用户反复筛选检索结果。</p>
    <p>[0081]	需要说明的是，本实施例提供的方法，还可以省略对检索词进行分词处理的步骤， 即在接收到用户输入的检索词，并得到与用户相匹配的情景数据之后，直接根据检索词及情景数据在检索数据库中进行检索，本实施例对此不作具体限定。</p>
    <p>[0082]	本实施例提供的方法，通过获取与用户相匹配的情景数据，并根据用户输入的检索词的分词结果及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。</p>
    <p>[0083]	实施例三</p>
    <p>[0084]	参见图3，本实施例提供了一种检索装置，该装置包括：</p>
    <p>[0085]	接收模块301，用于接收用户输入的检索词；</p>
    <p>[0086]	第一获取模块302，用于获取用户的相关信息，并对相关信息进行分析，得到与用户相匹配的情景数据；</p>
    <p>[0087]	检索模块303，用于根据接收模块301接收到的检索词及第一获取模块302获取到的情景数据在检索数据库中进行检索。</p>
    <p>[0088]	参见图4，该检索装置还包括：[0089]	第二获取模块304，用于获取文档数据；</p>
    <p>[0090]	构造模块305，用于根据第二获取模块304获取到的文档数据构造检索数据库；</p>
    <p>[0091]	相应地，检索模块303，具体用于根据接收模块301接收到的检索词及第一获取模块302获取到的情景数据在构造模块305构造的检索数据库中进行检索。</p>
    <p>[0092]	其中，第二获取模块304，具体用于抓取网页数据和/或接收推送的网页数据，并对网页数据进行文本解析，得到文档数据。</p>
    <p>[0093]	构造模块305，具体用于对第二获取模块304获取到的文档数据进行分类、主题抽取和词关系分析处理，并将处理后的文档数据进行数据索引，得到检索数据库。</p>
    <p>[0094]	参见图5，第一获取模块302，具体包括：</p>
    <p>[0095]	第一获取单元30加，用于获取用户的日志信息，日志信息至少包括网页点击的日志信息及会话日志信息；</p>
    <p>[0096]	第二获取单元302b，用于根据第一获取单元30&#190;获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据会话日志信息确定用户的检索行为特征；</p>
    <p>[0097]	第三获取单元302c，用于根据第二获取单元302b统计的关系以及确定的检索行为特征得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、 检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0098]	可选地，参见图6，第一获取模块302，具体包括：</p>
    <p>[0099]	第四获取单元302d，用于获取用户的用户信息，用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0100]	第五获取单元30&#190;，用于根据第四获取单元302d获取到的用户信息分析得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0101]	可选地，参见图7，第一获取模块302，具体包括：</p>
    <p>[0102]	第一获取单元30加，用于获取用户的日志信息，日志信息至少包括网页点击的日志信息及会话日志信息；</p>
    <p>[0103]	第二获取单元302b，用于根据第一获取单元30&#190;获取到的网页点击的日志信息统计用户输入过的检索词和被点击网页的关系，并根据会话日志信息确定用户的检索行为特征；</p>
    <p>[0104]	第四获取单元302d，用于获取用户的用户信息，用户信息至少包括用户浏览网页的信息、文件信息、互动平台信息中的一种信息；</p>
    <p>[0105]	第六获取单元302f，用于根据第二获取单元302b统计的关系、确定的检索行为特征和第四获取单元302d获取到的用户信息得到包括用户个人信息、检索原因信息、检索时间信息、检索位置信息、检索词信息、检索目的信息和检索行为信息中至少一种信息的情景数据。</p>
    <p>[0106]	其中，接收模块301，还用于对接收到的检索词进行分词处理，得到分词结果；</p>
    <p>[0107]	检索模块303，还用于根据接收模块301得到的分词结果及第一获取模块302获取到的情景数据在检索数据库中进行检索。</p>
    <p>[0108]	综上所述，本实施例提供的装置，通过获取与用户相匹配的情景数据，并根据用户</p>
    <p>9输入的检索词及情景数据进行检索，从而可以按照用户的检索意愿进行检索，使得到的检索结果更具针对性及准确性。</p>
    <p>[0109]	需要说明的是：上述实施例提供的检索装置在进行检索时，仅以上述各功能模块的划分进行举例说明，实际应用中，可以根据需要而将上述功能分配由不同的功能模块完成，即将装置的内部结构划分成不同的功能模块，以完成以上描述的全部或者部分功能。另夕卜，上述实施例提供的检索装置与检索方法实施例属于同一构思，其具体实现过程详见方法实施例，这里不再赘述。</p>
    <p>[0110]	上述本发明实施例序号仅仅为了描述，不代表实施例的优劣。</p>
    <p>[0111]	本发明实施例中的全部或部分步骤，可以利用软件实现，相应的软件程序可以存储在可读取的存储介质中，如光盘或硬盘等。</p>
    <p>[0112]	以上所述仅为本发明的较佳实施例，并不用以限制本发明，凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1758248A?cl=zh">CN1758248A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年9月5日</td><td class="patent-data-table-td patent-date-value">2006年4月12日</td><td class="patent-data-table-td ">微软公司</td><td class="patent-data-table-td ">用于提供个性化搜索和信息访问的系统、方法和接口</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101105795A?cl=zh">CN101105795A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年10月27日</td><td class="patent-data-table-td patent-date-value">2008年1月16日</td><td class="patent-data-table-td ">北京搜神网络技术有限责任公司</td><td class="patent-data-table-td ">基于网络行为的个性化推荐方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101373486A?cl=zh">CN101373486A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年10月16日</td><td class="patent-data-table-td patent-date-value">2009年2月25日</td><td class="patent-data-table-td ">北京航空航天大学</td><td class="patent-data-table-td ">一种基于用户兴趣模型的个性化摘要系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101719145A?cl=zh">CN101719145A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年11月17日</td><td class="patent-data-table-td patent-date-value">2010年6月2日</td><td class="patent-data-table-td ">北京大学</td><td class="patent-data-table-td ">基于图书领域本体的个性化搜索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1708105A1?cl=zh">EP1708105A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年3月23日</td><td class="patent-data-table-td patent-date-value">2006年10月4日</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Data mining techniques for improving search relevance</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=2MhwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年5月16日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年6月19日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SHENZHEN SHIJI LIGHT SPEED INFORMATION TECHNOLOGY</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: TENGXUN SCI-TECH (SHENZHEN) CO., LTD.</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20131104</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">COR</td><td class="patent-data-table-td ">Bibliographic change or correction in the description</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECT: ADDRESS; FROM: 518000 SHENZHEN, GUANGDONG PROVINCE TO: 518057 SHENZHEN, GUANGDONG PROVINCE</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/c9471cee6b2556629526/CN102456019A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E6%A3%80%E7%B4%A2%E6%96%B9%E6%B3%95%E5%8F%8A%E8%A3%85%E7%BD%AE.pdf?id=2MhwBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0y_N12pKw79LijBvZsVHRZUaWxgg"},"sample_url":"https://www.google.com/patents/reader?id=2MhwBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>