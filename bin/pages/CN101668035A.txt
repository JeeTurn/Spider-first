<!DOCTYPE html><html><head><title>专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种实时识别多种p2p-tv应用视频流的方法"><meta name="DC.contributor" content="兵 李" scheme="inventor"><meta name="DC.contributor" content="超 胡" scheme="inventor"><meta name="DC.contributor" content="鸣 陈" scheme="inventor"><meta name="DC.contributor" content="中国人民解放军理工大学指挥自动化学院" scheme="assignee"><meta name="DC.date" content="2009-9-28" scheme="dateSubmitted"><meta name="DC.description" content="本发明提出了一种实时识别多种P2P-TV应用视频流的方法，从网络流量中实时准确地识别出PPLive、PPStream、SopCast和UUSee等P2P-TV应用系统视频流。该方法的基本思想是：先针对P2P-TV节点必须访问服务器地址集的行为，得到那些与服务器地址集内服务器通信的IP地址，并剔除非P2P-TV应用流分组；再对余下的流比对是否具有应用层特征字的特征，如果相匹配则将该流识别为特定的P2P-TV视频流。本发明具有识别率高、识别差错率低和实时性强的优点。"><meta name="DC.date" content="2010-3-10"><meta name="citation_patent_publication_number" content="CN:101668035:A"><meta name="citation_patent_application_number" content="CN:200910035459"><link rel="canonical" href="https://www.google.com/patents/CN101668035A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101668035A?cl=zh"/><meta name="title" content="专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法"/><meta name="description" content="本发明提出了一种实时识别多种P2P-TV应用视频流的方法，从网络流量中实时准确地识别出PPLive、PPStream、SopCast和UUSee等P2P-TV应用系统视频流。该方法的基本思想是：先针对P2P-TV节点必须访问服务器地址集的行为，得到那些与服务器地址集内服务器通信的IP地址，并剔除非P2P-TV应用流分组；再对余下的流比对是否具有应用层特征字的特征，如果相匹配则将该流识别为特定的P2P-TV视频流。本发明具有识别率高、识别差错率低和实时性强的优点。"/><meta property="og:title" content="专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101668035A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101668035A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=fdN3BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101668035A&amp;usg=AFQjCNGrHDTqS8kn7jpZ5JUY5coOo0w5mA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/834140de126b35d641ad/CN101668035A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/834140de126b35d641ad/CN101668035A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101668035A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101668035A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101668035A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101668035B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101668035A?cl=zh" style="display:none"><span itemprop="description">本发明提出了一种实时识别多种P2P-TV应用视频流的方法，从网络流量中实时准确地识别出PPLive、PPStream、SopCast和UUSee等P2P-TV应用系统视频流。该方法的基本思想是：先针对P2P-TV节点必须访问服务器地址集的行为，得到那些与服务 ...</span><span itemprop="url">https://www.google.com/patents/CN101668035A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法" title="专利 CN101668035A - 一种实时识别多种p2p-tv应用视频流的方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101668035 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200910035459</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年3月10日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2009年9月28日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2009年9月28日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101668035B?hl=zh-CN&amp;cl=zh">CN101668035B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200910035459.4, </span><span class="patent-bibdata-value">CN 101668035 A, </span><span class="patent-bibdata-value">CN 101668035A, </span><span class="patent-bibdata-value">CN 200910035459, </span><span class="patent-bibdata-value">CN-A-101668035, </span><span class="patent-bibdata-value">CN101668035 A, </span><span class="patent-bibdata-value">CN101668035A, </span><span class="patent-bibdata-value">CN200910035459, </span><span class="patent-bibdata-value">CN200910035459.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%85%B5+%E6%9D%8E%22">兵 李</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B6%85+%E8%83%A1%22">超 胡</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%B8%A3+%E9%99%88%22">鸣 陈</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E8%A7%A3%E6%94%BE%E5%86%9B%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E6%8C%87%E6%8C%A5%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2%22">中国人民解放军理工大学指挥自动化学院</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101668035A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101668035A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101668035A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=fdN3BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200910035459&amp;usg=AFQjCNF6Wd4pl5eAoIFw38ctK4kvxJjgzA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=fdN3BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101668035A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEvqt-KA9l1L3M3kENB58y4uS3zEg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT92947821" lang="ZH" load-source="patent-office">一种实时识别多种p2p-tv应用视频流的方法</invention-title>
    </span><br><span class="patent-number">CN 101668035 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA74059924" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提出了一种实时识别多种P2P-TV应用视频流的方法，从网络流量中实时准确地识别出PPLive、PPStream、SopCast和UUSee等P2P-TV应用系统视频流。该方法的基本思想是：先针对P2P-TV节点必须访问服务器地址集的行为，得到那些与服务器地址集内服务器通信的IP地址，并剔除非P2P-TV应用流分组；再对余下的流比对是否具有应用层特征字的特征，如果相匹配则将该流识别为特定的P2P-TV视频流。本发明具有识别率高、识别差错率低和实时性强的优点。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(2)</span></span></div><div class="patent-text"><div mxw-id="PCLM30351629" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种实时识别多种P2P-TV应用视频流的方法，其特征在于，包括下列步骤：    A.初始化步骤：由被识别的P2P-TV系统的服务器域名信息获取相应服务器的IP地址并存入服务器地址集ServIPAddr中；由被识别的P2P-TV系统UDP报文应用层的前n个字节作为特征字放入应用层特征字表StringBase中；构造一个节点信息表NodeSet，以存储当前已识别的正在运行P2P-TV的主机IP地址，每个地址表项都有一个时间TTL与之关联，NodeSet初始为空，继续；    B.初步识别步骤：对每个到达的网络链路的新报文，若流类型未知，由四元组{源IP地址，目的IP地址，源端口号，目的端口号}信息经散列函数判断其是否属于已有流；若该流记录类型已知则返回至步骤B；否则，当报文是TCP分组则转C，当报文是UDP分组转D；    C.识别与服务器通信的步骤：将报文目的IP地址和源IP地址与服务器地址集ServIPAddr中的服务器IP地址进行比对，若服务器地址集中有一个IP地址与一个报文的目的IP地址匹配，则将该分组的源IP地址及相关服务器所属的P2P-TV类型放入NodeSet中，并设相应TTL为10，返回至步骤B；否则直接返回至步骤B；    D.匹配应用层特征字的步骤：将报文源IP地址和目的IP地址与NodeSet中的IP地址进行比对，若报文源IP地址和目的IP地址均不在NodeSet中，返回至步骤B；否则将报文应用层第1～5个字节与StringBase中相应的P2P-TV应用层特征字比对，若不匹配继续；否则该流标识为对应类型的P2P-TV视频流，并设相应TTL为10，返回至步骤B；    E.更新NodeSet表步骤：每经过16秒就检查NodeSet所有非空表项，将其TTL值减1，若为零则删除该表项，返回至步骤B；否则直接返回至步骤B。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2、 根据权利要求1的实时识别多种P2P-TV应用视频流的方法，其特征 是在步骤A中，利用每个节点都具有不变的UDP监听端口的特点，构造一个 监听端口表ListenPort，通过统计得到各个节点的监听端口号并记录在 ListenPort中，这时可采用效率更高的端口识别方法来识别视频流。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES36811290" lang="ZH" load-source="patent-office" class="description">
    <p>一种实时识别多种P2P-TV应用视频流的方法</p>
    <p>技术领域</p>
    <p>本发明属于网络数据通信领域，特别是一种从网络流量中实时准确地识 别出PPLive、PPStream、SopCast和UUSee等P2P-TV应用系统视频流的方法， 具体地说是一种实时识别多种P2P-TV应用视频流的启发式方法。</p>
    <p>背景技术</p>
    <p>当前经过IP协议向桌面用户分发电视流式内容是因特网的一种主流应 用，并且由于P2P技术具有的资源聚合的经济性、较好的扩展性和可靠性、 自组织的动态性等优点，使这些系统大都利用P2P覆盖网络对播(peercast)流 式内容。对播是指经过P2P网络以多播、广播或单播传输数据流的方式，常 用的是P2P多播和P2P广播。目前我们见到的最为流行的对播应用包括P2P 应用无线电、P2P流式音乐和基于P2P的因特网电视(亦称P2P-TV)。而P2P-TV 又可以分为流式直播和点播两种方式。与P2P文件共享不同，上述应用中的 对等方不需要下载整个文件到本地就能够收看或收听流式(streaming)内容，这 就大大改善了用户体验。</p>
    <p>由于电视媒体对人类文化和生活方式的重要影响力，以及它在网络中产 生的巨大流量，理解、管理和引导P2P-TV应用的行为是当前各研究机构、因 特网服务提供商关注和研究的主题，而这一切的前提首先要能够识别P2P-TV 流。所谓P2P-TV流是指以P2P方式传输的电视信号报文集合，它们符合五元 组{源IP地址,源端口号,目的IP地址,目的端口号，运输层协议类型}流规范和 64秒超时定义的双向流[l]，可以采用如文献[4]类似的思路来解决流形成和按 流分析等问题。本专利给出的实时识别P2P-TV应用视频流的技术，主要是指 识别当前流行的PPLive、 PPStream、 SopCast和UUSee应用系统的视频流。</p>
    <p>由于当前大多数P2P应用都采用了随机端口技术，因而无法利用周知端口号对P2P应用进行识别。当前识别P2P-TV应用视频流的方法可分为3类: 基于应用协议特征字的识别方法、基于行为特征的识别方法和基于机器学习 的分类方法。基于应用协议特征字的识别方法通过分析P2P协议的应用层负 ~载，提取出能够唯一标识出协议类型的特征字符串，以识别出P2P应用。这 种识别方法也称为深度分组检测(Deep Packet Inspection, DPI),它具有识别准 确率高，但缺点是无法识别加密数据。基于行为特征的识别方法综合利用了 流的属性、统计特性以及流的行为特征，根据启发式规则对流进行分析，达 到识别P2P应用的目的。这种方法识别时间较长，且识别准确率不够高。基 于机器学习的分类方法通过提取各类应用的流、分组等信息对分类器进行训 练，然后利用训练好的分类器对数据进行分类。这种方法识别时间长，且准 确性有待提高。文献[2]根据不同的P2P-TV系统在起始阶段所发送的分组数 目是不同的，将系统启动后固定大小的时间段按照等比数列划分为若干个时 间片，并计算出各个时间片内所发送的分组数占总分组数的比例，构成一个 向量，并利用支持向量机识别网络中的P2P-TV流量。文献[3]通过分析PPLive 报文结构，通过构造节点列表请求报文获取网络中的PPLive节点信息，从而 提出了一种主动检测PPLive流的方法。目前的这些识别P2P-TV视频流的方 法仍存在着识别率不够高、识别滞后且节点信息残存时间较长的缺陷，需要 研制更好的识别方法。</p>
    <p>发明内容</p>
    <p>本发明的目的是针对目前识别P2P-TV视频流的方法存在的识别率不够 高、识别滞后且节点信息残存时间较长的缺陷，提出一种从网络流量中实时 准确地识别出多种P2P-TV应用系统视频流的方法。</p>
    <p>本发明的技术方案是：</p>
    <p>1. 一种实时识别多种P2P-TV应用视频流的方法（简称基于启发式的视 频流识别(Heuristic-based Identifying Video Flows, HIVF)方法），其特征在于，</p>
    <p>包括下列步骤：</p>
    <p>A.初始化步骤：由被识别的P2P-TV系统的服务器域名信息（参见表l)</p>
    <p>获取相应服务器的IP地址并存入服务器地址集ServIPAddr中；由被识别的P2P-TV系统UDP报文应用层的前n个字节（nG2&#12316;5)作为特征字（参见表2) 放入应用层特征字表StringBase中；构造一个节点信息表NodeSet，以存储当 前已识别的正在运行P2P-TV的主机IP地址，每个地址表项都有一个时间TTL 与之关联，NodeSet初始为空，继续；</p>
    <p>B.初步识别步骤：对每个到达的网络链路的新报文，若流类型未知，由 四元组(源IP地址，目的IP地址，源端口号，目的端口号}信息经散列函数 判断其是否属于已有流；若该流记录类型已知则返回至步骤B;否则，当报 文是TCP分组则转C，当报文是UDP分组转D;</p>
    <p>.C.识别与服务器通信的步骤：将报文目的IP地址和源IP地址与服务器 地址集ServIPAddr中的服务器IP地址进行比对，若服务器地址集中有一个IP 地址与一个报文的目的IP地址匹配，则将该分组的源IP地址及相关服务器所 属的P2P-TV类型放入NodeSet中，并设相应TTL为IO，返回至步骤B;否 则直接返回至步骤B;</p>
    <p>D. 匹配应用层特征字的步骤:将报文源IP地址和目的IP地址与NodeSet 中的报文源地址进行比对，若报文源IP地址和目的IP地址均不在NodeSet 中，返回至步骤B;否则将报文应用层第1~5个字节与StringBase中相应的 P2P-TV应用层特征字比对，若不匹配继续；否则该流标识为对应类型的 P2P-TV视频流，并设相应TTL为IO，返回至步骤B;</p>
    <p>E. 更新NodeSet表步骤：每经过16秒就检查NodeSet所有非空表项，将 其TTL值减1，若为零则删除该表项，返回至步骤B;否则返回至步骤B。</p>
    <p>表1各种P2P-TV系统主要的服务器域名</p>
    <p>P2P-TV系统	P2P-TV服务器域名</p>
    <p>PPLive	passport.pplive.com, vodchannel .pplive. com, iptable.pplive.com， pp.pplive.com， update.pplive.com， list.pplive.com</p>
    <p>PPStream	fds.ppstream.com, tvguide.pps.tv， vodguide.pps.tv, msg.ppstream.com, download.ppstream.com，</p>
    <p>5&lt;table&gt;table see original document page 6&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;</p>
    <p>注：表l中的信息基本稳定，但以后也可能会有变化</p>
    <p>表2几种P2P-TV系统应用层特征字及其位置信息(Ox表示16进制)</p>
    <p>&lt;table&gt;table see original document page 6&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;注：表2信息适用于近期P2P-TV应用系统的版本号：PPLive为 2.2.26.0002， PPStream为2.3.550.1950， SopCast为3.0.3， UUSee为5.9.710.2。</p>
    <p>利用每个节点都具有不变的UDP监听端口的特点，构造一个监听端口表 ListenPort,通过统计得到各个节点的监听端口号并记录在ListenPort中，这时 可采用效率更高的端口识别方法来识别视频流。</p>
    <p>本发明相对于现有技术具有以下优点：</p>
    <p>1、 识别率高。较之现有的识别方法，本发明有较高的识别率、较低的识 别差错率。这主要得益于HIVF方法采用了两阶段识别过程：与服务器通信的 过程，是根据P2P-TV节点必须访问服务器地址集的行为；应用层特征字匹配 过程，流的前几个分组包括应用层特征字。</p>
    <p>2、 效率较高，实时强。通过首先排除已经识别类型的流，使方法处理对 象大为减少；识别方法有较低的计算复杂性，能够实时在线及时处理完(不会 积压)网络链路上所有分组，要求解决方案。附图说明</p>
    <p>图1为本发明实施例运行的环境。</p>
    <p>图2为本发明实施例对应HIVF方法流程图。 具体实施方式</p>
    <p>下边结合附图和具体实施方式对本发明作进一步地说明。</p>
    <p>首先需要给出本发明提供的识别方法所需要的环境，如图1所示：在 Intel-Linux架构的PC机上安装并运行具有的本发明的HIVF识别方法的软件， 将该PC机的100/1000 Mb/s以太网卡连接到接入网络主干的局域网交换机上， 并使之能够接收到链路上的所有流量。如果要在高速网络环境下应用本发明 的识别方法，应当考虑用硬件实现相关识别方法。</p>
    <p>运行本发明提供的识别P2P-TV视频流的系统配置如下：在Intel-Linux 架构的PC机上安装并运行基于本发明HIVF的软件，PC机的100/1000 Mb/s 以太网卡与网络交换机相连。这些PC机硬件的主频3.0GHz及以上的Pentium 双核CPU的PC机，内存^2GB,硬盘80GB，运行Fedora 10操作系统。</p>
    <p>图2给出了本发明基本HIVF方法的工作流程图，该流程开始于步骤 SiOl,由被识别的P2P-TV系统的域名信息获取相应服务器的IP地址并存入 服务器地址集ServIPAddr中；由被识别的P2P-TV系统UDP报文应用层的前 几个字节作为特征字放入应用层特征字表StringBase中；构造一个节点信息表 NodeSet，以存储当前已识别的正在运行P2P-TV的主机IP地址，NodeSet初 始为空，每个地址表项都有一个时间TTL与之关联，NodeSet初始为空，继 续转S102。</p>
    <p>在步骤S102中，对每个到达的新报文，若流类型未知，由四元组(源IP 地址，目的IP地址，源端口号，目的端口号}信息经散列函数判断其是否属于 已有流；若该流记录类型已知转S102;否则，当报文是TCP分组则转S103， 当报文是UDP分组转S104。</p>
    <p>在步骤S103中，将报文目的IP地址和源IP地址与服务器地址集 ServIPAddr中的服务器IP地址进行比对，若服务器地址集中有一个IP地址与 一个报文的目的IP地址匹配，则转S105将该分组的源IP地址及相关服务器所属的P2P-TV类型放入NodeSet中，并设相应TTL为TO，转1ST02;否则转 S102。</p>
    <p>在步骤S104，若报文源和目的地址均不在NodeSet中，转S102;否则转 ~S106。</p>
    <p>在步骤S106中，将报文应用层第1~5个字节与StringBase中相应的 P2P-TV应用层特征字比对，若不匹配转S108;否则转S107，将该流标识为 对应类型的P2P-TV视频流，并设相应TTL为IO，转S102。</p>
    <p>在步骤S108中，每经过16秒就检&#26619;NodeSet所有非空表项，将其TTL 值减l，若为零则删除该表项，转S102;否则转S102。</p>
    <p>本方法可以通过中断方式M出。</p>
    <p>实施例</p>
    <p>本实施例给出了某ISP在PC上运行基于本发明识别算法的软件对某企业 网接入因特网的P2P-TV视频流进行识别，以掌握该企业网中P2P-TV视频流 的应用情况并为制定控制管理P2P-TV视频流方案提供科学依据。</p>
    <p>假定该企业网经100/1000 Mb/s速率的以太网链路与某因特网服务提供商 的网络相连。在PC上运行基于本发明识别方法的软件，将该PC的100/1000 Mb/s以太网卡连接到与因特网服务提供商网络连接的局域网交换机上，并将 该交换机配置为能够监听与主干网相连的所有网络流量。</p>
    <p>例如，当该企业网与因特网直接相连，所有机器都具有唯一的因特网IP 地址，这时网络用户使用PPLive、 PPStream、 SopCast和UUSee应用系统观 看网络电视。识别系统将调用HIVF方法，识别出基于UDP的这些应用的视 频流。</p>
    <p>通过收集上述识别出来的P2P-TV视频流信息，ISP就能统计出用户使用 P2P-TV网络电视的数量、时间长度、用户分布等情况等。据此，ISP就能够 制定相应的策略管理和控制P2P-TV网络电视了 。</p>
    <p>本发明未涉及部分均与现有技术相同或可采用现有技术加以实现。</p>
    <p>参考文献K. claffy. Internet traffic characterization. San Diego: University of California: 1994.</p>
    <p>S. Valenti， D. Rossi, M. Meo， M. Mellia， P, Bermolen. Accurate, fine-grained classification of P2P-TV applications by simply counting packets. In International In Traffic Measurement and Analysis (TMA) Workshop at IFIP Networking'09 Aachen， Germany, May 2009.</p>
    <p>胡超，陈鸣，许博，李兵.一种基于爬虫的分布式PPLive流实时检测系统. 解放军理工大学学报，2008， 9(5): 512-516</p>
    <p>N. Brownlee， C. Mills, and G. Ruth.， Traffic Flow Measurement: Architecture. RFC 2722, 1999.</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102420830A?cl=zh">CN102420830A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月15日</td><td class="patent-data-table-td patent-date-value">2012年4月18日</td><td class="patent-data-table-td ">北京大学</td><td class="patent-data-table-td ">一种p2p协议类型识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102624878A?cl=zh">CN102624878A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年2月23日</td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td ">汉柏科技有限公司</td><td class="patent-data-table-td ">基于dns协议识别p2p协议的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102624878B?cl=zh">CN102624878B</a></td><td class="patent-data-table-td patent-date-value">2012年2月23日</td><td class="patent-data-table-td patent-date-value">2014年6月18日</td><td class="patent-data-table-td ">汉柏科技有限公司</td><td class="patent-data-table-td ">基于dns协议识别p2p协议的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013123798A1?cl=zh">WO2013123798A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月12日</td><td class="patent-data-table-td patent-date-value">2013年8月29日</td><td class="patent-data-table-td ">Opzoon Technology Co. Ltd</td><td class="patent-data-table-td ">基于dns协议识别p2p协议的方法及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=fdN3BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0029080000">H04L29/08</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年3月10日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年4月28日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年8月22日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/834140de126b35d641ad/CN101668035A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%AE%9E%E6%97%B6%E8%AF%86%E5%88%AB%E5%A4%9A%E7%A7%8Dp2p_tv%E5%BA%94%E7%94%A8%E8%A7%86.pdf?id=fdN3BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3t0NdNhgaNylGzJ1WWFN8SElx88Q"},"sample_url":"https://www.google.com/patents/reader?id=fdN3BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>