<!DOCTYPE html><html><head><title>专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="具有反馈指导的英语句子识别与评价系统及其方法"><meta name="DC.contributor" content="李心广" scheme="inventor"><meta name="DC.contributor" content="李苏梅" scheme="inventor"><meta name="DC.contributor" content="陈嘉华" scheme="inventor"><meta name="DC.contributor" content="沈东雄" scheme="inventor"><meta name="DC.contributor" content="广东外语外贸大学" scheme="assignee"><meta name="DC.contributor" content="李心广" scheme="assignee"><meta name="DC.contributor" content="李苏梅" scheme="assignee"><meta name="DC.contributor" content="陈嘉华" scheme="assignee"><meta name="DC.contributor" content="沈东雄" scheme="assignee"><meta name="DC.date" content="2012-7-17" scheme="dateSubmitted"><meta name="DC.description" content="本发明为一种具有反馈指导的英语句子识别与评价系统，其特征在于：包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价模块、反馈指导模块连接的标准语句模型库，通过模型匹配得到结果；实现英语句子的语音识别、口语翻译、客观评价和反馈指导等功能。本发明具有口语翻译，语音识别效率和准确率更高，语音评价和反馈指导准确客观等优点。"><meta name="DC.date" content="2012-11-28"><meta name="DC.relation" content="CN:101105939:A" scheme="references"><meta name="DC.relation" content="CN:101739870" scheme="references"><meta name="DC.relation" content="JP:2006133521" scheme="references"><meta name="citation_reference" content="方凡泉等: &quot;语音质量客观评价方法研究及实现&quot;, 《广州大学学报（自然科学版）》, 28 February 2011 (2011-02-28), pages 1 - 4"><meta name="citation_patent_publication_number" content="CN:102800314:A"><meta name="citation_patent_application_number" content="CN:201210248276"><link rel="canonical" href="https://www.google.com/patents/CN102800314A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102800314A?cl=zh"/><meta name="title" content="专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法"/><meta name="description" content="本发明为一种具有反馈指导的英语句子识别与评价系统，其特征在于：包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价模块、反馈指导模块连接的标准语句模型库，通过模型匹配得到结果；实现英语句子的语音识别、口语翻译、客观评价和反馈指导等功能。本发明具有口语翻译，语音识别效率和准确率更高，语音评价和反馈指导准确客观等优点。"/><meta property="og:title" content="专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102800314A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102800314A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102800314A&amp;usg=AFQjCNEsZdzf1xDa6H5fkkv6bk4ToReKHQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/3a5df5e5083f99cf9fee/CN102800314A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/3a5df5e5083f99cf9fee/CN102800314A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102800314A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102800314A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102800314A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102800314B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102800314A?cl=zh" style="display:none"><span itemprop="description">本发明为一种具有反馈指导的英语句子识别与评价系统，其特征在于：包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价...</span><span itemprop="url">https://www.google.com/patents/CN102800314A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法" title="专利 CN102800314A - 具有反馈指导的英语句子识别与评价系统及其方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102800314 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210248276</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年11月28日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年7月17日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年7月17日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102800314B?hl=zh-CN&amp;cl=zh">CN102800314B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210248276.2, </span><span class="patent-bibdata-value">CN 102800314 A, </span><span class="patent-bibdata-value">CN 102800314A, </span><span class="patent-bibdata-value">CN 201210248276, </span><span class="patent-bibdata-value">CN-A-102800314, </span><span class="patent-bibdata-value">CN102800314 A, </span><span class="patent-bibdata-value">CN102800314A, </span><span class="patent-bibdata-value">CN201210248276, </span><span class="patent-bibdata-value">CN201210248276.2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E5%BF%83%E5%B9%BF%22">李心广</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E8%8B%8F%E6%A2%85%22">李苏梅</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E5%98%89%E5%8D%8E%22">陈嘉华</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B2%88%E4%B8%9C%E9%9B%84%22">沈东雄</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%B9%BF%E4%B8%9C%E5%A4%96%E8%AF%AD%E5%A4%96%E8%B4%B8%E5%A4%A7%E5%AD%A6%22">广东外语外贸大学</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%9D%8E%E5%BF%83%E5%B9%BF%22">李心广</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%9D%8E%E8%8B%8F%E6%A2%85%22">李苏梅</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E9%99%88%E5%98%89%E5%8D%8E%22">陈嘉华</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B2%88%E4%B8%9C%E9%9B%84%22">沈东雄</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102800314A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102800314A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102800314A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (8),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210248276&amp;usg=AFQjCNFsJjI3LRmltb_j_1Iqn3M2EekHQA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102800314A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFAnmokuBhXnpviD00SlK7HTeie4A"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT117620168" lang="ZH" load-source="patent-office">具有反馈指导的英语句子识别与评价系统及其方法</invention-title>
      </span><br><span class="patent-number">CN 102800314 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA102804752" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明为一种具有反馈指导的英语句子识别与评价系统，其特征在于：包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价模块、反馈指导模块连接的标准语句模型库，通过模型匹配得到结果；实现英语句子的语音识别、口语翻译、客观评价和反馈指导等功能。本发明具有口语翻译，语音识别效率和准确率更高，语音评价和反馈指导准确客观等优点。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(7)</span></span></div><div class="patent-text"><div mxw-id="PCLM46751419" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种具有反馈指导的英语句子识别与评价系统，其特征在于：包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价模块、反馈指导模块连接的标准语句模型库；  语音采集模块对语音信号进行采集；语音预处理模块对语音信号进行预加重、分帧、力口窗、端点检测预处理；语音特征提取模块对语音信号进行语音特征参数的提取；语音识别模块、客观评价模块和反馈指导模块通过与标准语句模型库的匹配对语音信号进行语音识另IJ、客观评价和反馈指导。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的具有反馈指导的英语句子识别与评价系统，其特征在于：所述客观评价模块包括依次连接的语速评价单元、准确度评价单元、重音评价单元、节奏评价单元和语调评价单元，通过比较待评价语句和标准语句的语速、准确度、重音、节奏和语调进行综合评价。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的具有反馈指导的英语句子识别与评价系统，其特征在于：  所述语速评价单元通过计算待评价语句与标准语句的时长比，与所设置的语速阈值进行比较；  所述准确度评价单元采用短时能量作为特征来提取语句的强度曲线，进而采用抽查值的方法将待评价语句规整到与标准语句相近的程度，再将之与标准语音的强度曲线图进行对比，通过比较其拟合程度进行评价；  所述重音评价单元在规整后强度曲线图的基础上，设置重音阈值和非重音阈值作为特征的双门限以及重读元音时长，进行重音单元的划分；进而采用DTW算法对待评价语句和标准语句进行模式匹配；  所述节奏评价单元采用改进的dPVI参数计算公式，根据语音单元时长差异性的特征，将标准语句与待评价语句的音节单元片段时长分别进行对比计算，并转换出相对应的参数；  所述语调评价单元通过提取语句发音的共振峰并加以分析，进而通过判断共振峰在语音信号中的趋势来判断发音在语调方面的变化，再将之与标准语音的语调变化进行对比，最后通过比较语调的拟合程度进行评价。</div>
    </div>
    </div> <div class="claim"> <div num="4" class="claim">
      <div class="claim-text">4.	一种具有反馈指导的英语句子识别与评价方法，其特征在于：包括以下步骤：  (1)语音采集模块对语音信号进行采集，并根据奈奎斯特采样定理将模拟信号数字化；  (2)语音预处理模块对所得的语音信号进行预加重、分帧、加窗、端点检测预处理；  (3)语音特征提取模块对预处理后的语音信号进行语音特征参数MFCC的提取；  (4)语音识别模块采用分段均值数据降维算法对所得的语音特征进行降维处理，然后通过与标准语句模型库的匹配，以语音和文本的形式输出识别结果；  (5)客观评价模块和反馈指导模块通过与标准语句模型库的匹配从语句的语速、准确度、重音、节奏和语调方面进行客观评价和反馈指导。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的具有反馈指导的英语句子识别与评价方法，其特征在于：所述标准语句模型库包括标准语句的语音信号库、特征参数库、聚类分组库、HMM模型库和文本库。  标准语句模型库用于对语音信号进行语音识别、客观评价和反馈指导的模式匹配。语音信号库存储标准语句的语音信号，包括语音信号的强度曲线图、时长、重音、共振峰及标准发音；特征参数库存储标准语句的特征参数；聚类分组库存储标准语句的所属分组；HMM模型库存储标准语句的HMM模型；文本库存储标准语句的中英文文本。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的具有反馈指导的英语句子识别与评价方法，其特征在于&#8226;&#8226;聚类分组库和HMM模型库采用分段均值数据降维算法、聚类模型交叉分组算法、HMM模型聚类分组技术和Viterbi算法进行语音特征降维、分组建模和模型匹配；所述分段均值数据降维算法解决语音特征参数维度较高和不同长度问题，聚类模型交叉分组算法解决分组性能较低问题，HMM模型聚类分组技术解决Viterbi算法运算量和混合高斯分布概率计算量大问题，Viterbi算法解决HMM的解码问题。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的具有反馈指导的英语句子识别与评价方法，其特征在于：步骤（4)具体还包括如下步骤：  Ca)采用分段均值数据降维算法对语音特征提取模块得到的语音特征进行降维处理；  (b)通过与标准语句模型库的匹配，利用改进的DTW算法确定语音特征聚类分组K	；  (c)对第K组内的HMM模型参数进行计算：将语音特征参数作为隐马尔可夫模型的观察序列；训练得到的语音单元为状态序列，通过Viterbi算法解出状态转移序列；  (d)采用决策判决，得到最大概率的状态转移序列；  (e)通过与标准语句模型库的匹配，根据最佳状态序列对应出英语句子。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES53078472" lang="ZH" load-source="patent-office" class="description">
    <p>具有反馈指导的英语句子识别与评价系统及其方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及语音识别与评价技术领域，特别涉及一种用于将人发出的语音信号识别后转变为相应的翻译结果，并给出客观评价和反馈指导的具有反馈指导的英语句子识别与评价系统。本发明还涉及该系统的语音识别与评价方法。</p>
    <p>背景技术</p>
    <p>[0002]	语音识别技术就是让机器通过识别和理解，把人发出的语音信号转变为相应的文本或做出设定命令的技术，它正逐步成为信息技术中人机交互的关键技术。随着语音识别技术的进步，计算机辅助语音教学技术（Computer-assisted Language Learning, CALL)成为了研究的热门，它极大地提高语言学习效率，及时、准确、客观的评价和反馈帮助学习者找出自己发音与标准发音之间的差距，并纠正发音错误。因此，具有反馈指导的英语句子 识别与评价系统有着巨大的发展潜力，可广泛适用于国内外旅游、国际展览会、国际体育赛事、宾馆服务以及语言学习等活动，使人与人之间的距离更近，交流更方便。</p>
    <p>发明内容</p>
    <p>[0003]	本发明的目的在于设计具有反馈指导的英语句子识别与评价系统，实现英语句子的语音识别、口语翻译、客观评价和反馈指导等功能。此外，本发明具有语音识别时效率更高，识别准确率更高；语音评价时，评价指标更全面，客观评价和反馈指导准确客观，真实性和可信性高的特点。</p>
    <p>[0004]	本发明的另外一个目的在于提供该系统的语音识别与评价方法。</p>
    <p>[0005]	为了实现上述发明目的，本发明包括如下技术特征：一种具有反馈指导的英语句子识别与评价系统，其包括依次连接的语音采集模块、语音预处理模块、语音特征提取模块、语音识别模块、客观评价模块及反馈指导模块，还包括分别与语音识别模块、客观评价模块、反馈指导模块连接的标准语句模型库；</p>
    <p>[0006]	语音采集模块对语音信号进行采集；语音预处理模块对语音信号进行预加重、分帧、加窗、端点检测预处理；语音特征提取模块对语音信号进行语音特征参数的提取；语音识别模块、客观评价模块和反馈指导模块通过与标准语句模型库的匹配对语音信号进行语音识别、客观评价和反馈指导。</p>
    <p>[0007]	所述客观评价模块包括依次连接的语速评价单元、准确度评价单元、重音评价单元、节奏评价单元和语调评价单元，通过比较待评价语句和标准语句的语速、准确度、重音、节奏和语调进行综合评价；</p>
    <p>[0008]	所述语速评价单元通过计算待评价语句与标准语句的时长比，与所设置的语速阈值进行比较；</p>
    <p>[0009]	所述准确度评价单元采用短时能量作为特征来提取语句的强度曲线，进而采用抽查值的方法将待评价语句规整到与标准语句相近的程度，再将之与标准语音的强度曲线图进行对比，通过比较其拟合程度进行评价；[0010]	所述重音评价单元在规整后强度曲线图的基础上，设置重音阈值和非重音阈值作为特征的双门限以及重读元音时长，进行重音单元的划分；进而采用DTW算法对待评价语句和标准语句进行模式匹配；</p>
    <p>[0011]	所述节奏评价单元采用改进的dPVI参数计算公式，根据语音单元时长差异性的特征，将标准语句与待评价语句的音节单元片段时长分别进行对比计算，并转换出相对应的参数；</p>
    <p>[0012]	所述语调评价单元通过提取语句发音的共振峰并加以分析，进而通过判断共振峰在语音信号中的趋势来判断发音在语调方面的变化，再将之与标准语音的语调变化进行对比，最后通过比较语调的拟合程度进行评价。</p>
    <p>[0013]	同时，本发明还提供一种具有反馈指导的英语句子识别与评价方法，其包括以下步骤： </p>
    <p>[0014]	(I)语音采集模块对语音信号进行采集，并根据奈奎斯特采样定理将模拟信号数字化；</p>
    <p>[0015]	(2)语音预处理模块对所得的语音信号进行预加重、分帧、加窗、端点检测预处理；</p>
    <p>[0016]	(3)语音特征提取模块对预处理后的语音信号进行语音特征参数MFCC的提取；</p>
    <p>[0017]	(4)语音识别模块采用分段均值数据降维算法对所得的语音特征进行降维处理，然后通过与标准语句模型库的匹配，以语音和文本的形式输出识别结果；</p>
    <p>[0018]	(5)客观评价模块和反馈指导模块通过与标准语句模型库的匹配从语句的语速、准确度、重音、节奏和语调方面进行客观评价和反馈指导。</p>
    <p>[0019]	所述标准语句模型库包括标准语句的语音信号库、特征参数库、聚类分组库、HMM模型库和文本库。</p>
    <p>[0020]	标准语句模型库用于对语音信号进行语音识别、客观评价和反馈指导的模式匹配。语音信号库存储标准语句的语音信号，包括语音信号的强度曲线图、时长、重音、共振峰及标准发音；特征参数库存储标准语句的特征参数；聚类分组库存储标准语句的所属分组；HMM模型库存储标准语句的HMM模型；文本库存储标准语句的中英文文本。</p>
    <p>[0021]	聚类分组库和HMM模型库采用分段均值数据降维算法、聚类模型交叉分组算法、HMM模型聚类分组技术和Viterbi算法进行语音特征降维、分组建模和模型匹配；所述分段均值数据降维算法解决语音特征参数维度较高和不同长度问题，聚类模型交叉分组算法解决分组性能较低问题，HMM模型聚类分组技术解决Viterbi算法运算量和混合高斯分布概率计算量大问题，Viterbi算法解决HMM的解码问题。</p>
    <p>[0022]	步骤（4)具体还包括如下步骤：</p>
    <p>[0023]	(a)采用分段均值数据降维算法对语音特征提取模块得到的语音特征进行降维处理；</p>
    <p>[0024]	(b)通过与标准语句模型库的匹配，利用改进的DTW算法确定语音特征聚类分组K ；</p>
    <p>[0025]	(c)对第K组内的HMM模型参数进行计算：将语音特征参数作为隐马尔可夫模型的观察序列；训练得到的语音单元为状态序列，通过Viterbi算法解出状态转移序列；</p>
    <p>[0026]	(d)采用决策判决，得到最大概率的状态转移序列；[0027]	(e)通过与标准语句模型库的匹配，根据最佳状态序列对应出英语句子。</p>
    <p>[0028]	本发明通过对采集到的语音信号进行预处理和分段均值降维处理，使系统在后期进行语音识别和评价时效率更高，准确率也更高。采用隐马尔可夫模型，并结合聚类交叉分组算法训练模型库，再用其进行模型匹配，使识别过程更加准确高效。，通过比较待评价语句和标准语句的准确度、语速、重音、节奏和语调等方面进行客观评价，并给予反馈指导，使评价结果更加准确客观。</p>
    <p>[0029]	本发明与现有技术相比，具有口语翻译，语音识别时效率更高，识别准确率更高；语音评价时评价指标更加全面，客观评价和反馈指导准确客观，真实性和可信性高等优点，在语音识别与评价系统领域具有很大的消费市场。</p>
    <p>附图说明</p>
    <p>[0030]	图I为本发明的模块原理图 </p>
    <p>[0031]	图2为语音特征参数分段均值降维示意图</p>
    <p>[0032]	图3为聚类模型交叉分组训练算法示意图</p>
    <p>[0033]	图4为HMM模型聚类分组图</p>
    <p>[0034]	图5为本发明的语音识别过程图</p>
    <p>[0035]	图6为隐马尔可夫模型识别过程图</p>
    <p>[0036]	图7为DTW算法约束后的匹配范围</p>
    <p>[0037]	图8为基于DTW算法的评价示意图</p>
    <p>[0038]	图9为共振峰提取原理图</p>
    <p>具体实施方式</p>
    <p>[0039]	本发明设计并实现了一种具有反馈指导的英语句子识别与评价系统。本发明的模块原理图如图I所示，通过语音采集模块I采集输入的语音信号；通过语音预处理模块2对所得的语音信号进行预处理；通过语音特征提取模块3对预处理后的语音信号进行语音特征参数提取；通过语音识别模块4与标准语句模型库5进行匹配，以语音和文本的形式输出识别结果；通过客观评价模块6与标准语句模型库5进行匹配，对待评价语句的重音、语速、语调、节奏等方面进行评价，实现上述处理功能的是准确度评价单元61、语速因素评价单元62、重音因素评价单元63、节奏因素评价单元64和语调因素评价单元65 ;通过反馈指导模块7与标准语句模型库5进行匹配，给予反馈指导。</p>
    <p>[0040]	下面分别对涉及到的各个模块单元进行说明：</p>
    <p>[0041]	一、标准语句模型库5</p>
    <p>[0042]	本发明的标准语句模型库包括标准语句的语音信号库、特征参数库、聚类分组库、HMM模型库和文本库。</p>
    <p>[0043]	标准语句模型库用于对语音信号进行语音识别、客观评价和反馈指导的模式匹配。语音信号库存储标准语句的语音信号，包括语音信号的强度曲线图、时长、重音、共振峰及标准发音等；特征参数库存储标准语句的特征参数；聚类分组库存储标准语句的所属分组；HMM模型库存储标准语句的HMM模型；文本库存储标准语句的中英文文本。</p>
    <p>[0044]	其中，聚类分组库和HMM模型库采用分段均值数据降维算法、聚类模型交叉分组算法、HMM模型聚类分组技术和Viterbi算法进行语音特征降维、分组建模和模型匹配；所述分段均值数据降维算法解决语音特征参数维度较高和不同长度问题，聚类模型交叉分组算法解决分组性能较低问题，HMM模型聚类分组技术解决Viterbi算法运算量和混合高斯分布概率计算量大问题，Viterbi算法解决HMM的解码问题。</p>
    <p>[0045]	I、分段均值数据降维算法</p>
    <p>[0046]	本发明采用一种分段均值的方法对语音特征参数进行降维，首先将语音信号特征参数进行平均分段，语音特征参数可表示为S (K，J)，其中K是特征参数的阶数，J为分段后特征参数的帧数，T为原语音帧数。则将特征参数平均分为N段的计算公式如下：</p>
    <p>[0047]	Md) = S(KJ)J = [^7 {/ - 1) + 1],...,[^/]</p>
    <p>     N	N</p>
    <p>[0048]	M⑴即为分段后第i段的语音特征参数。 </p>
    <p>[0049]	把特征参数平均分为N段后，再将M (i)平均分为M段，子分段计算公式可参考上式。之后对每个子分段的各帧参数进行求均值运算，得出各个子分段的均值向量M(i)k，k=l，2，...,M0在取得各个子分段的均值向量后，将各个子分段的均值合并为一个矩阵，即得到KXMXN大小的矩阵即为降维后的特征参数输出值。对语音特征参数进行分段均值降维处理如图2所示。</p>
    <p>[0050]	可知，分段均值降维算法可将T X K大小的特征参数矩阵降维为KXMX N大小的参数矩阵。由式KXMXN可知，分段均值降维算法成功去除了语音帧数T对降维后数据大小的影响，降维后参数矩阵大小只与特征参数阶数K、分段大小N以及子分段大小M有关，使得各个不同长度的语音可以规整为同一大小的矩阵，这在很大程度上方便了语音特征聚类算法的实现。</p>
    <p>[0051]	2、聚类模型交叉分组算法</p>
    <p>[0052]	成功实现对语音特征参数进行降维处理后，运用K均值算法对语音特征参数进行聚类实验。在对语句进行聚类时，本发明将训练样本中发音相同的语句采用均值的方式经行合并，使其成为一个具有代表性的标准样本，用于聚类训练。</p>
    <p>[0053]	为了进一步提高K均值聚类算法对语音的分类性能，本发明采用一种新的二次训练算法&#8212;&#8212;聚类交叉分组训练算法。图3为聚类模型交叉分组训练算法示意图。</p>
    <p>[0054]	在用K均值聚类算法对已经过分段均值降维处理的训练样本参数进行聚类后，依次对每个样本参数用DTW算法匹配其与样本中心距离，距离最小者为目标分组，然后检验目标分组是否包含输入特征参数所表示的语句，若包含则表示分类正确，若不包含则将该语句加入目标分组。</p>
    <p>[0055]	设聚类分组数为K，系统词汇量为N，第k个聚类分得词汇数量为</p>
    <p>Sk，k=(l，2，...，K)，则在进行初次聚类后有;= #，定义聚类交叉分组系数的表达</p>
    <p>            A-=I	&lt;P， &lt;P</p>
    <p>         K</p>
    <p>式为S5t ,易知在进行初次聚类后有0_&#19972;。必须提出的一个问题是，在采用聚类交叉分</p>
    <p> (D &#8212;- ?	W &#8212; ―― u</p>
    <p>r KN	K</p>
    <p>组训练算法对聚类分组进行二次训练后，是否会趋于或等于KXNjP趋近于I。若趋</p>
    <p>(p	(P</p>
    <p>近于1，则说明聚类算法退化，产生假分组现象。[0056]由于引入分段均值降维聚类算法，聚类结果有较好的稳定性，其中有部分语句完全没有出现分组错误，那么在交叉分组训练是这些语句将不会参与重新分组，这将有助于</p>
    <p>减小</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00081.png"> <img id="idf0001" file="CN102800314AD00081.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00081.png" class="patent-full-image" alt="Figure CN102800314AD00081"> </a> </div>
    <p>使交叉分组达到较好的效果。</p>
    <p>[0057]	3、HMM模型聚类分组技术</p>
    <p>[0058]	由于基于HMM的语音识别系统中每个语句都有一个与其对应的唯一 HMM模型，因此可以将语音特征参数聚类分组结果中所包含的语句映射到与这些语句相对应的HMM模型，这样就得出了如图4所示的HMM模型聚类分组。</p>
    <p>[0059]由于本发明使用的降维聚类交叉分组算法具有较好的性能，使得每个模型聚类组中包含的HMM模型数总是小于等于系统语句量。在聚类分组合适的情况下，系统将节省非常可观的计算量，系统性能得以大大提高。</p>
    <p>[0060]	4、Viterbi 算法</p>
    <p>[0061]	解码问题，本发明采用Viterbi算法解决。给定一个HMM模型入=(，A，B)，以及</p>
    <p>由模型产生的观察序列O=O1, O2, A，Ot，搜索使该模型产生此观察序列最有可能经历的状态</p>
    <p>pt s () I ?)</p>
    <p>序列S = Q1, Q2Aqt,即求解使P(S/0，A )最大的状态序列S。由于</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00082.png"> <img id="idf0002" file="CN102800314AD00082.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00082.png" class="patent-full-image" alt="Figure CN102800314AD00082"> </a> </div>
    <p>而p(o/x)对于所有的S均相同，因此解码问题等价于求解使p(s，0/x)最大的状态序列</p>
    <p>S0</p>
    <p>[0062]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00083.png"> <img id="idf0003" file="CN102800314AD00083.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00083.png" class="patent-full-image" alt="Figure CN102800314AD00083"> </a> </div>
    <p>表示找一个状态序列，这个</p>
    <p>状态序列在t时状态为i，并且状态i与前面t-1个状态构成的状态序列的概率值最大，算法的递推公式为</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00084.png"> <img id="idf0004" file="CN102800314AD00084.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00084.png" class="patent-full-image" alt="Figure CN102800314AD00084"> </a> </div>
    <p>[0063]	如图5所示，得出HMM聚类模型分组后，进行语音识别时首先对输入语音参数进行计算并确定其语音特征聚类分组K，则在进行Viterbi解码运算时只对第K组内的HMM模型参数进行计算。</p>
    <p>[0064]	如图6所示，语音识别模块采用HMM模型，调用标准语句模型库中已训练好的语音模型，同输入语音进行匹配，解出状态转移序列P (01 An) (n=l. . .M)，最终采用决策判决，得到最大概率的状态转移序列。根据最佳状态序列对应出英语句子，并以语音和文本形式输出识别结果。</p>
    <p>[0065]	二、客观评价模块6</p>
    <p>[0066]	所述客观评价模块包括依次连接的语速评价单元、准确度评价单元、重音评价单元、节奏评价单元和语调评价单元，通过比较待评价语句和标准语句的语速、准确度、重音、节奏和语调等方面进行综合评价。</p>
    <p>[0067]	重音以音节为单位，以词重音为主，其意义功能表现为起强调、对照作用。节奏分为完全重读型、不完全重读型、强调重读型三种，在朗读、说话时，以不同组合形成的节奏群为单位交替出现，其意义功能表现为增强旋律和乐感。语调以意群为单位按不同调式进行变化，其意义功能表现为表达各种不同的感情色彩。对于待评价语句的评价，除发音(Pronunciation)呈现出的表面要素外，它所要表达的意思内容、感情色彩才是本质所在。此外，语速和准确度也是衡量语句发音质量的因素。[0068]	三、语速评价单元61</p>
    <p>[0069]	由于不同人说话语速均存在一定差异，不同人对同一句子的发音均会造成句子时</p>
    <p>长的一定性差异。定义待评价语句与标准语句的时长比φ则</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00091.png"> <img id="idf0005" file="CN102800314AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00091.png" class="patent-full-image" alt="Figure CN102800314AD00091"> </a> </div>
    <p>，其中LenTest为待评</p>
    <p>价语句的时长，Lenstd为标准语句的时长。</p>
    <p>[0070]	本发明采用双门限比较法来进行语速评价，经过大量实验验证，设定两个阀值：0. 9和I. I。如果时长比炉&gt;1.域者妒&lt;0.9，将进行酌情扣分。</p>
    <p>[0071]	四、准确度评价单元62</p>
    <p>[0072]	语句的强度曲线图可以反映语音信号随着时间的变化。语句中重读音节响亮的特征将反映到时域上的能量强度，即重音音节表现为语音能量强度大。根据语音信号s(n)的短时能量的定义：</p>
    <p>[0073]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00092.png"> <img id="idf0006" file="CN102800314AD00092.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00092.png" class="patent-full-image" alt="Figure CN102800314AD00092"> </a> </div>
    <p>[0074]	对语句提取能量值，即为语句的强度曲线图。</p>
    <p>[0075]	由于不同人不同时间对同一句话的发音时长不相等、发音强度也不同，如果将待评价语句和标准语音的强度曲线直接进行模板匹配，结果将影响评价的客观性。鉴于此，本发明提出了一种基于标准语音的强度曲线提取方法：当待评价语句时长比标准语句短的时候，采用插值方法对其进行时长的补充；当待评价语句时长比标准语句长的时候，采用抽值方法对其进行时长的调整；最后，利用标准语音强度曲线的最强点，对待评价语音强度曲线进行强度规整。</p>
    <p>[0076]	该方法首先计算插值或抽值的步进K</p>
    <p>[0077]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00093.png"> <img id="idf0007" file="CN102800314AD00093.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00093.png" class="patent-full-image" alt="Figure CN102800314AD00093"> </a> </div>
    <p>[0078]	其中Magstd,MagTest分别表示标准语音和待评价语音的强度曲线，Len( &#8226;)表示该强度曲线的长度。接着，当Len (Magstd)-Len (MagTest)〈O时,表示待评价语音的时长比标准语音长，可直接对待评价语音强度曲线进行步进为K的抽值计算；当Len (Magstd) -Len (Maglest) &gt;0时，表示待评价语音的时长比标准语音短，则需计算插值位置的强度值MagATest (n)</p>
    <p>[0079]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00094.png"> <img id="idf0008" file="CN102800314AD00094.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00094.png" class="patent-full-image" alt="Figure CN102800314AD00094"> </a> </div>
    <p>[0080]其中	i = nK, n = I, 2. . . (Len(Magstd)-Len(Maglest))。最后,将由上式所得的一系列强度值以步进K插入到待评价语音强度曲线中，并对其进行语音强度的规整，如下式所示</p>
    <p>[0081]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00095.png"> <img id="idf0009" file="CN102800314AD00095.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00095.png" class="patent-full-image" alt="Figure CN102800314AD00095"> </a> </div>
    <p>[0082]其中	i = 1,2,... Len (MagATest)。</p>
    <p>[0083]	完成强度曲线的提取和规整后，本发明将之与标准语音的强度曲线图进行对比，通过比较其拟合程度进行评价。</p>
    <p>[0084]	五、重音评价单元63</p>
    <p>[0085]	重音以音节为单位，以词重音为主，其意义功能表现为起强调、对照作用。</p>
    <p>[0086]	在规整后强度曲线图的基础上，本发明采用双门限比较法来进行重音端点检测，经过大量实验验证，设定如下两个阀值：[0087]重音阀值	Tu= (max (sig_in)+min (sig_in))/2. 5</p>
    <p>[0088]非重音阀值	T1=Oiiax(Sigjnhmin(Sigjn))ZlO</p>
    <p>[0089]	双门限比较法中，根据语句的能量值逐个搜索语句中大于重音阀值Tu的最大语音信号值Smax，然后向信号值Smax左右搜索等于非重音阀值T1的语音信号值S1与&amp;，将S1与Sr设置为语句重音信号，并将S1与&amp;之间的信号量值置0，避免重复在S1与&amp;之间搜索。</p>
    <p>[0090]	由于语句中重读音节有着发音偏长的特征，而第一步搜索出来的重读音节单元可能存在能量值大，即听觉表现为发音响亮，持续时间却很短的问题，这些单元可能是短元音，也可能是信号尖峰的干扰，它们不构成重读音节，可以根据重读音节发音偏长的特征将重读音节单元进一步筛选。本发明将重读音节单元的最小单位设定为一个大致重读元音时长（Stressed vowel durations),为 100ms。 [0091]	通过以上步骤，完成对语句重音单元的划分。</p>
    <p>[0092]	接着采用改进的DTW算法进行待评价语句和标准语句的模式匹配。DTW算法的基本原理为动态时间规整，把测试模板和参考模板之间本来不匹配的时间长度进行匹配。用传统的欧氏距离计算其相似度，设参考模板和测试模板为R和T，距离D[T，R]越小则相似度越高。传统DTW算法的缺点是在进行模板匹配时，所有帧的权重一致，必须匹配所有的模板，计算量比较大，特别是当模板数增加较快时，运算量增长特别快。</p>
    <p>[0093]	如图7所示，本发明通过设置匹配边界，将需要运算的交点限定在平行四边形内。将R和T按等时分为N、M帧，可分为三段路径（l，Xa)、（Xa+l，Xb)、(Xb+1, N)计算距离，根据</p>
    <p>坐标计算可得夂=|(2财-的和Z6 =^(IN-M)，xa、Xb取最相近的整数。当不满足限制条件</p>
    <p>2M-N彡3，2N-M彡2时，不进行动态匹配，减少了系统开支。</p>
    <p>[0094]	X轴上的每一帧与Y坐标轴上[ymin，y_]间的帧匹配，yfflin, y_的计算如下</p>
    <p>      -X	xg[05X,1</p>
    <p>[0095]	Jmin= 2</p>
    <p>           2x+ (M-IN) xe(Xb,N]</p>
    <p>       2x	x ^[0,Xa]</p>
    <p>[0096]	I	I</p>
    <p>            -x + (M--N) xe (Xa7N]</p>
    <p>[0097]	若Xa&gt;Xb，匹配的路径可分为（1，Xb)、(Xb+1, Xa)、(Xa+1, N)。X坐标轴每向前一帧，虽对应Y坐标轴的帧数不同，但规整特性一致，累积距离为</p>
    <p>                               Z)(x-l,y)</p>
    <p>[0098]	v) = d(x, y) + min^ D(x -1, y -1) ^</p>
    <p>                          D(x-\,y-2)</p>
    <p>[0099]	其中D和d分别表示累积距离和帧匹配距离。</p>
    <p>[0100]	图8为基于改进的DTW算法的评价示意图，其中X轴为标准语音的强度曲线，Y轴是待评价语音的强度曲线，将两曲线等长分帧，按照顺序计算对应帧的距离，将累积距离输出，作为评分机制的参考标准。</p>
    <p>[0101]	六、节奏评价单元64</p>
    <p>[0102]	节奏分为完全重读型、不完全重读型、强调重读型三种，在朗读、说话时，以不同组合形成的节奏群为单位交替出现，其意义功能表现为增强旋律和乐感。</p>
    <p>[0103]	国外学者Pike和Abercrombie提出了所有的语言都存在着语音单元等时性(isochrony)特征，语言节奏的时同步性假设中把语言节奏定义为“某种语言单元片段的等时性重复”，这就是著名的语言节奏的时同步性假设。成对变异指数（PairwiseVariability Index, PVI),用于计算相邻单位间的时长的变异性,若变异性越小,代表该单位具有等时性。新加坡南洋理工大学的Low在对新加坡英语节奏的研究中第一次提出了PVI公式，它用于通过计算重读的和非重读的元音连续的前后音节之间的差距得出语音节奏的相关性。</p>
    <p>[0104]本发明米用改进的	dPVI (the Distinct Pairwise Variability Index)参数计算公式，根据语音单元时长差异性的特征，将标准语句与待评价语句的音节单元片段时长分别进行对比计算，并将转换出的参数用于客观评价和反馈指导依据。</p>
    <p>[0105]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00111.png"> <img id="idf0010" file="CN102800314AD00111.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102800314A/CN102800314AD00111.png" class="patent-full-image" alt="Figure CN102800314AD00111"> </a> </div>
    <p>[0106]	其中d为语句划分的语音单元片段时长(如：dk为第k个语音单元片段时长)，m=min (标准语句单元数,待评价语句单元数）,Lenstd为标准语句时长。由于进行PVI运算之前已经将待评价语句时长规整到与标准语句时长相当，计算可只用Lenstd作为计算单元。</p>
    <p>[0107]	七、语调评价单元65</p>
    <p>[0108]	语调以意群为单位按不同调式进行变化，其意义功能表现为表达各种不同的感情色彩。</p>
    <p>[0109]	在语调评价方面，本发明通过提取英语句子发音的共振峰并加以分析，通过判断共振峰在语音信号中的趋势来判断发音在语调方面的变化，再将之与标准语音的语调变化进行对比，最后通过语调的拟合程度进行打分。</p>
    <p>[0110]	共振峰是指在声音的频谱中能量相对集中的一些区域，共振峰不但是音质的决定因素，而且反映了声道(共振腔)的物理特征。共振峰是反映声道谐振特性的重要特征，它代表了发音信息的最直接来源，而且人在语音感知中利用了共振峰信息，所以共振峰是语音信号处理中非常重要的特征参数。共振峰信息包含在频率包络之中，因此共振峰参数提取的关键是估计自然语音频谱包络，一般我们认为频谱包络中的最大值就是共振峰。</p>
    <p>[0111]	声音在经过共振腔时，受到腔体的滤波作用，使得频域中不同频率的能量重新分配，一部分因为共振腔的共振作用得到强化，另一部分则受到衰减，得到强化的那些频率在时频分析的语图上表现为浓重的黑色条纹。由于能量分布不均匀，强的部分犹如山峰一般。在英语语音声学中，共振峰决定着元音的音质，每一个元音对应一个共振峰。</p>
    <p>[0112]	常见的共振峰提取方法有基于线性预测（LPC)、倒谱、LPC倒谱等方法，各种方法各有优劣，本发明主要是利用倒谱方法提取语音信号的共振峰，并将共振峰提取的结果运用于语音发音的评价中。倒谱法根据对数功率谱的逆傅里叶变换，能够分离频谱包络和细微结构，很精确地得到基音频率和共振峰信息，在噪音不大的情况下，倒谱进行基音提取的效果是很好的。倒谱的定义如下：</p>
    <p>[0113]	c(n)=IFT{ln|FT[x(n)] |}</p>
    <p>[0114]	倒谱将基音谐波和声道的频谱包络分离开来。倒谱的低时部分可以分析声道、声门和辐射信息，而高频部分可以用来分析激励源信息。对倒谱进行低时窗选，通过语音倒谱分析系统的最后一级，进行DFT后的输出即为平滑后的对数模函数，这个平滑的对数谱显示了特定输入语音段的谐振结构，即谱的峰值基本上对应于共振峰频率，对平滑过的对数谱中的峰值进行了定位，即可提取出语音信号的共振峰。图9为共振峰提取原理图。</p>
    <p>[0115]	结合上述的说明，本发明与现有技术相比，具有口语翻译，语音识别时效率更高，识别准确率更高；语音评价时，评价指标更全面，客观评价和反馈指导准确客观，真实性和 可信性高等优点，在语音识别与评价系统领域具有很大的消费市场。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101105939A?cl=zh">CN101105939A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年9月4日</td><td class="patent-data-table-td patent-date-value">2008年1月16日</td><td class="patent-data-table-td ">安徽科大讯飞信息科技股份有限公司</td><td class="patent-data-table-td ">发音指导方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101739870B?cl=zh">CN101739870B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月3日</td><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">深圳先进技术研究院</td><td class="patent-data-table-td ">交互式语言学习系统及交互式语言学习方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2006133521A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFdahL8AeK_k3JVKiMpzLmm2zUS6g">JP2006133521A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">方凡泉等: "<a href='http://scholar.google.com/scholar?q="%E8%AF%AD%E9%9F%B3%E8%B4%A8%E9%87%8F%E5%AE%A2%E8%A7%82%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6%E5%8F%8A%E5%AE%9E%E7%8E%B0"'>语音质量客观评价方法研究及实现</a>", 《广州大学学报（自然科学版）》, 28 February 2011 (2011-02-28), pages 1 - 4</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103544311A?cl=zh">CN103544311A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年11月4日</td><td class="patent-data-table-td patent-date-value">2014年1月29日</td><td class="patent-data-table-td ">北京中搜网络技术股份有限公司</td><td class="patent-data-table-td ">一种基于手机新闻客户端评价系统及其方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103617799A?cl=zh">CN103617799A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年11月28日</td><td class="patent-data-table-td patent-date-value">2014年3月5日</td><td class="patent-data-table-td ">广东外语外贸大学</td><td class="patent-data-table-td ">一种适应于移动设备的英语语句发音质量检测方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103617799B?cl=zh">CN103617799B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年11月28日</td><td class="patent-data-table-td patent-date-value">2016年4月27日</td><td class="patent-data-table-td ">广东外语外贸大学</td><td class="patent-data-table-td ">一种适应于移动设备的英语语句发音质量检测方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103646644A?cl=zh">CN103646644A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月12日</td><td class="patent-data-table-td patent-date-value">2014年3月19日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">一种获取语音识别业务信息认可度的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103971675A?cl=zh">CN103971675A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月29日</td><td class="patent-data-table-td patent-date-value">2014年8月6日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">自动语音识别方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103971675B?cl=zh">CN103971675B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月29日</td><td class="patent-data-table-td patent-date-value">2016年3月2日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">自动语音识别方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014117555A1?cl=zh">WO2014117555A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年11月7日</td><td class="patent-data-table-td patent-date-value">2014年8月7日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">Method and system for automatic speech recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015062465A1?cl=zh">WO2015062465A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年10月28日</td><td class="patent-data-table-td patent-date-value">2015年5月7日</td><td class="patent-data-table-td ">上海流利说信息技术有限公司</td><td class="patent-data-table-td ">移动设备上的实时口语评价系统及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0015140000">G10L15/14</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=gbGwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0015000000">G10L15/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年1月23日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/3a5df5e5083f99cf9fee/CN102800314A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%85%B7%E6%9C%89%E5%8F%8D%E9%A6%88%E6%8C%87%E5%AF%BC%E7%9A%84%E8%8B%B1%E8%AF%AD%E5%8F%A5%E5%AD%90%E8%AF%86%E5%88%AB.pdf?id=gbGwBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2V8FaXkJLb9Q8MQ4EzBDRQzLeAmg"},"sample_url":"https://www.google.com/patents/reader?id=gbGwBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>