<!DOCTYPE html><html><head><title>专利 CN102708365A - 信息处理装置、信息处理方法以及程序 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="信息处理装置、信息处理方法以及程序"><meta name="DC.contributor" content="伊藤修光" scheme="inventor"><meta name="DC.contributor" content="毛木达也" scheme="inventor"><meta name="DC.contributor" content="泽田敬" scheme="inventor"><meta name="DC.contributor" content="藤&#22618;诚弘" scheme="inventor"><meta name="DC.contributor" content="株式会社Pfu" scheme="assignee"><meta name="DC.date" content="2012-3-2" scheme="dateSubmitted"><meta name="DC.description" content="能高效生成用于OCR软件等的定义信息的信息处理装置、方法及程序。本发明的信息处理装置包括：区域识别部，针对在图像数据内由规定的表现方式指定的区域，来识别第一区域和第二区域，第一区域是由第一区域指定表现方式指定的区域，第二区域是由与第一区域指定表现方式不同的第二区域指定表现方式指定的区域；位置信息取得部，在图像数据内取得由区域识别部识别出的第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息；项目名取得部，取得字符信息来作为项目名，字符信息是通过对由区域识别部识别出的第二区域内存在的字符进行识别而得的信息，项目名是针对由位置信息取得部取得的位置信息所指定的成为字符识别对象的区域的项目名。"><meta name="DC.date" content="2012-10-3"><meta name="DC.relation" content="CN:101523413:A" scheme="references"><meta name="DC.relation" content="US:20070228168:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102708365:A"><meta name="citation_patent_application_number" content="CN:201210059242"><link rel="canonical" href="https://www.google.com/patents/CN102708365A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102708365A?cl=zh"/><meta name="title" content="专利 CN102708365A - 信息处理装置、信息处理方法以及程序"/><meta name="description" content="能高效生成用于OCR软件等的定义信息的信息处理装置、方法及程序。本发明的信息处理装置包括：区域识别部，针对在图像数据内由规定的表现方式指定的区域，来识别第一区域和第二区域，第一区域是由第一区域指定表现方式指定的区域，第二区域是由与第一区域指定表现方式不同的第二区域指定表现方式指定的区域；位置信息取得部，在图像数据内取得由区域识别部识别出的第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息；项目名取得部，取得字符信息来作为项目名，字符信息是通过对由区域识别部识别出的第二区域内存在的字符进行识别而得的信息，项目名是针对由位置信息取得部取得的位置信息所指定的成为字符识别对象的区域的项目名。"/><meta property="og:title" content="专利 CN102708365A - 信息处理装置、信息处理方法以及程序"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102708365A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102708365A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102708365A&amp;usg=AFQjCNE55ynRDbXBVAFAyxufnNHqwwU_UQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/9a1420a4c77b0661a575/CN102708365A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/9a1420a4c77b0661a575/CN102708365A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102708365A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102708365A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102708365A?cl=zh" style="display:none"><span itemprop="description">能高效生成用于OCR软件等的定义信息的信息处理装置、方法及程序。本发明的信息处理装置包括：区域识别部，针对在图像数据内由规定的表现方式指定的区域，来识别第一区域和第二区域，第一区域是由第一区域指定表现方式...</span><span itemprop="url">https://www.google.com/patents/CN102708365A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102708365A - 信息处理装置、信息处理方法以及程序</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102708365A - 信息处理装置、信息处理方法以及程序" title="专利 CN102708365A - 信息处理装置、信息处理方法以及程序"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102708365 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210059242</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年10月3日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年3月2日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年3月17日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US20120237131?hl=zh-CN&amp;cl=zh">US20120237131</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210059242.9, </span><span class="patent-bibdata-value">CN 102708365 A, </span><span class="patent-bibdata-value">CN 102708365A, </span><span class="patent-bibdata-value">CN 201210059242, </span><span class="patent-bibdata-value">CN-A-102708365, </span><span class="patent-bibdata-value">CN102708365 A, </span><span class="patent-bibdata-value">CN102708365A, </span><span class="patent-bibdata-value">CN201210059242, </span><span class="patent-bibdata-value">CN201210059242.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E4%BC%8A%E8%97%A4%E4%BF%AE%E5%85%89%22">伊藤修光</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%AF%9B%E6%9C%A8%E8%BE%BE%E4%B9%9F%22">毛木达也</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B3%BD%E7%94%B0%E6%95%AC%22">泽田敬</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%97%A4%E5%A1%9A%E8%AF%9A%E5%BC%98%22">藤&#22618;诚弘</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BEPfu%22">株式会社Pfu</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102708365A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102708365A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102708365A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210059242&amp;usg=AFQjCNHYGmuVPE5jjQHw95MmNOjg_CbfAA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102708365A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHDPO7C4VZBP_rG1m-igWc-gtUiGw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT115939933" lang="ZH" load-source="patent-office">信息处理装置、信息处理方法以及程序</invention-title>
      </span><br><span class="patent-number">CN 102708365 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA100821798" lang="ZH" load-source="patent-office">
    <div class="abstract">能高效生成用于OCR软件等的定义信息的信息处理装置、方法及程序。本发明的信息处理装置包括：区域识别部，针对在图像数据内由规定的表现方式指定的区域，来识别第一区域和第二区域，第一区域是由第一区域指定表现方式指定的区域，第二区域是由与第一区域指定表现方式不同的第二区域指定表现方式指定的区域；位置信息取得部，在图像数据内取得由区域识别部识别出的第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息；项目名取得部，取得字符信息来作为项目名，字符信息是通过对由区域识别部识别出的第二区域内存在的字符进行识别而得的信息，项目名是针对由位置信息取得部取得的位置信息所指定的成为字符识别对象的区域的项目名。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM45674152" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种信息处理装置，其特征在于，包括：  区域识别部，其用于针对在图像数据内利用规定的表现方式来指定的区域，识别第一区域和第二区域，所述第一区域是利用第一区域指定表现方式来指定的区域，所述第二区域是利用与所述第一区域指定表现方式不同的第二区域指定表现方式来指定的区域，   位置信息取得部，其用于在所述图像数据内取得由所述区域识别部识别出的所述第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息，  项目名取得部，其用于取得字符信息作为项目名，所述字符信息是通过对由所述区域识别部识别出的所述第二区域内存在的字符进行识别所得到的信息，所述项目名是利用由所述位置信息取得部取得的所述位置信息来指定的所述成为字符识别对象的区域的项目名。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求I所述的信息处理装置，其特征在于，  还具有用于使所述第一区域与所述第二区域相对应关联的对应关联部，  所述项目名取得部从所述第二区域取得所述字符信息作为特定区域的项目名，所述特定区域是利用特定位置信息来指定的所述成为字符识别对象的区域，所述特定位置信息是从通过所述对应关联部与该第二区域相对应关联的所述第一区域取得的位置信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的信息处理装置，其特征在于，  所述对应关联部使所述第一区域与在图像数据上离所述第一区域最近的所述第二区域相对应关联。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求2所述的信息处理装置，其特征在于，  所述对应关联部判断所述第一区域的位置与所述第二区域的位置之间的位置关系是否满足规定条件，并使判断为满足规定条件的所述第一区域与所述第二区域相对应关联。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求4所述的信息处理装置，其特征在于，  所述对应关联部，在图像数据内纵向排列的多个第一区域与纵向排列的多个第二区域中，将横向排列的一个第一区域与一个第二区域判断为满足所述规定条件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求4所述的信息处理装置，其特征在于，  所述对应关联部，在图像数据内横向排列的多个第一区域与横向排列的多个第二区域中，将纵向排列的一个第一区域与一个第二区域判断为满足所述规定条件。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求2所述的信息处理装置，其特征在于，  所述对应关联部，对存在于图像数据内的用于表示所述第一区域与所述第二区域的对应关系的规定的对应关系指示表现方式进行识别，并基于识别出的该对应关系，使所述第一区域与所述第二区域相对应关联。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求I&#12316;7中任意一项所述的信息处理装置，其特征在于，  还具有用于生成项目定义信息的项目定义信息生成部，  所述项目定义信息包括：  用于对由所述位置信息取得部取得的所述成为字符识别对象的区域进行指定的所述位置信息；  由所述项目名取得部取得的利用所述位置信息来指定的所述成为字符识别对象的区域的所述项目名。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9.	一种信息处理方法，其特征在于，使计算机执行如下步骤：区域识别步骤，针对在图像数据内利用规定的表现方式来指定的区域，识别第一区域和第二区域，所述第一区域是利用第一区域指定表现方式来指定的区域，所述第二区域是利用与所述第一区域指定表现方式不同的第二区域指定表现方式来指定的区域，  位置信息取得步骤，在所述图像数据内取得所识别出的所述第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息，  项目名取得步骤，取得字符信息作为项目名，所述字符信息是通过对识别出的所述第二区域内存在的字符进行识别所得到的信息，所述项目名是利用所取得的所述位置信息来指定的所述成为字符识别对象的区域的项目名。</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10.	一种程序，其特征在于，使计算机执行如下步骤：  区域识别步骤，针对在图像数据内利用规定的表现方式来指定的区域，识别第一区域和第二区域，所述第一区域是利用第一区域指定表现方式来指定的区域，所述第二区域是利用与所述第一区域指定表现方式不同的第二区域指定表现方式来指定的区域，  位置信息取得步骤，在所述图像数据内取得所识别出的所述第一区域的位置信息，作为用于指定成为字符识别对象的区域的位置信息，  项目名取得步骤，取得字符信息作为项目名，所述字符信息是通过对识别出的所述第二区域内存在的字符进行识别所得到的信息，所述项目名是利用所取得的所述位置信息来指定的所述成为字符识别对象的区域的项目名。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES52023753" lang="ZH" load-source="patent-office" class="description">
    <p>信息处理装置、信息处理方法以及程序</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及信息处理装置、信息处理方法以及程序的技术。</p>
    <p>背景技术</p>
    <p>[0002]	近年来，根据业务改善以及成本消减的观点，在各种业务中正在开展文牍精简化(paperless,无纸化办公）。但在一个方面看来，仍然使用纸的情况还多数存在，例如在交易文件等方面仍然使用纸。以往，为了对这样使用纸的业务的效率进行改善，而使用了OCR (Optical Character Recognition :光学字符识别)软件。</p>
    <p>[0003]	为了在这样的OCR软件中指定读取区域等，需要该读取区域等的定义信息。在以下列举的专利文献I以及专利文献2中，公开了与该定义信息相关的技术。 [0004]	在专利文献I中公开了这样的技术：按颜色来扫描图像数据，由此读取与颜色相对应的字符种类。另外，在专利文献2中公开了这样的技术：对在由规定色框围起的区域内记载的属性信息进行识别，生成读取项目的属性信息定义体。</p>
    <p>[0005]	现有技术文献：</p>
    <p>[0006]	专利文献：</p>
    <p>[0007]	专利文献I JP实开平05-008670号公报，</p>
    <p>[0008]	专利文献2 JP特开平05-081472号公报。</p>
    <p>[0009]	然而，在以往的技术中，用户在制作OCR软件的定义信息时，针对从图像数据中取得的读取区域的位置信息，需要通过手动输入来设定用于表示该读取区域的记载内容的项目名。</p>
    <p>发明内容</p>
    <p>[0010]	本发明正是考虑这样的问题点而做成的，目的在于，提供一种能够高效生成用于OCR软件等的定义信息的技术。本发明为了解决上述问题而采用以下的结构。</p>
    <p>[0011]	S卩，本发明的信息处理装置，其特征在于，包括：</p>
    <p>[0012]	区域识别部，其用于针对在图像数据内由规定的表现方式指定的区域，来识别第一区域和第二区域，所述第一区域是由第一区域指定表现方式指定的区域，所述第二区域是由与所述第一区域指定表现方式不同的第二区域指定表现方式指定的区域，</p>
    <p>[0013]	位置信息取得部，其用于在所述图像数据内取得由所述区域识别部识别出的所述第一区域的位置信息，来作为用于指定成为字符识别对象的区域的位置信息，</p>
    <p>[0014]	项目名取得部，其用于取得字符信息来作为项目名，所述字符信息是通过对由所述区域识别部识别出的所述第二区域内存在的字符进行识别而得的信息，所述项目名是针对由所述位置信息取得部取得的所述位置信息所指定的所述成为字符识别对象的区域的项目名。</p>
    <p>[0015]	在此，区域指定表现方式是指，用于指定区域的表现方式，例如框、填充图、阴影</p>
    <p>坐寸ο[0016]	通过上述结构，识别出图像数据内中的第一区域与第二区域。并且，从第一区域取得用于指定成为字符识别对象的区域的位置信息。另外，从第二区域取得针对该成为字符识别对象的区域的项目名。因此，用户无需通过手动输入来设定与所取得的位置信息相关的针对成为字符识别对象的区域的项目名。因此，通过上述结构，能够高效地生成（制作）用于OCR软件等的定义信息。</p>
    <p>[0017]	另外，作为本发明的其它方式，本发明的信息处理装置还具有用于使所述第一区域与所述第二区域相对应关联的对应关联部， [0018]	所述项目名取得部，在被所述对应关联部对应关联的所述第一区域和第二区域中，可以从被对应关联的所述第二区域取得所述字符信息来作为针对特定区域的项目名，所述特定区域是由特定位置信息指定的所述成为字符识别对象的区域，所述特定位置信息是从被对应关联的所述第一区域取得的位置信息。</p>
    <p>[0019]	通过上述结构，使得用于指定成为字符识别对象的区域的位置信息与针对该成为字符识别对象的区域的项目名相对应关联。因此，用户无需再进行使所取得的位置信息与项目名相对应关联的处理。因此，通过上述结构，能够高效地生成（制作）用于OCR软件等的定义信息。</p>
    <p>[0020]另外，作为本发明的其它实施方式，所述对应关联部可以使所述第一区域与在图像数据上距离所述第一区域最近的所述第二区域相对应关联。</p>
    <p>[0021]另外，作为本发明的其它实施方式，所述对应关联部，可以判断所述第一区域的位置与所述第二区域的位置的位置关系是否满足规定条件，使判断为满足规定条件的所述第一区域与所述第二区域相对应关联。</p>
    <p>[0022]	另外，作为本发明的其它实施方式，所述对应关联部，可以在图像数据内纵向排列的多个第一区域与纵向排列的多个第二区域中，判断为横向排列的一个第一区域与一个第二区域满足所述规定条件。</p>
    <p>[0023]另外，作为本发明的其它实施方式，所述对应关联部，可以在图像数据内横向排列的多个第一区域与横向排列的多个第二区域中，判断为纵向排列的一个第一区域与一个第二区域满足所述规定条件。</p>
    <p>[0024]	另外，作为本发明的其它实施方式，所述对应关联部，可以识别存在于图像数据内的表示所述第一区域与所述第二区域的对应关系的规定的对应关系指示表现方式，基于识别出的该对应关系，使所述第一区域与所述第二区域相对应关联。</p>
    <p>[0025]	另外，作为本发明的其它实施方式，本发明的信息处理装置还可以具有用于生成项目定义信息的项目定义信息生成部，所述项目定义信息包括：用于对由所述位置信息取得部取得的所述成为字符识别对象的区域进行指定的所述位置信息，由所述项目名取得部取得的针对由所述位置信息指定的所述成为字符识别对象的区域的所述项目名。</p>
    <p>[0026]	此外，作为本发明的其它实施方式，可以是用于实现以上各结构的信息处理方法，也可以是程序，也可以是存储了这样的程序的、计算机能够读取的存储介质。另外，作为本发明的其它实施方式，也可以是由用于实现以上各结构的多个装置构成的信息处理系统，所述多个装置能够相互通信。</p>
    <p>[0027]	通过本发明，提供了一种能够高效地生成（制作)用于OCR软件等的定义信息的技术。附图说明</p>
    <p>[0028]	图I例示出实施方式的信息处理装置的处理。</p>
    <p>[0029]	图2例示出实施方式的信息处理装置的结构。</p>
    <p>[0030]	图3是表示实施方式的信息处理装置的处理顺序一例的流程图。</p>
    <p>[0031]	图4表示通过实施方式的信息处理装置处理的图像数据的一例。</p>
    <p>[0032]	图5表示第一区域与第二区域的扫描顺序的一例。</p>
    <p>[0033]	图6表示第一区域与第二区域的对应关联的一例。 [0034]	图7表示第一区域与第二区域的对应关联的一例。</p>
    <p>[0035]	图8表示第一区域与第二区域的对应关联的一例。</p>
    <p>[0036]	图9表示第一区域与第二区域的对应关联的一例。</p>
    <p>[0037]	图10表示从图4所示的图像数据中取得的项目定义信息的一例。</p>
    <p>[0038]	附图标记的说明</p>
    <p>[0039]	I信息处理装置，</p>
    <p>[0040]	2扫描仪，</p>
    <p>[0041]	11存储部，</p>
    <p>[0042]	12控制部，</p>
    <p>[0043]	13 总线，</p>
    <p>[0044]	14输入输出部，</p>
    <p>[0045]	31区域识别部，</p>
    <p>[0046]	32位置信息取得部，</p>
    <p>[0047]	33项目名取得部，</p>
    <p>[0048]	34对应关联部，</p>
    <p>[0049]	35项目定义信息生成部</p>
    <p>[0050]	50、50a、50b、50c 第一区域，</p>
    <p>[0051]	60、60a、60b、60c 第二区域，</p>
    <p>[0052]	70对应关系指示表现方式（箭头），</p>
    <p>[0053]	71对应关系指示表现方式（线段），</p>
    <p>[0054]	72a、72b对应关系指示表现方式（标记）。</p>
    <p>具体实施方式</p>
    <p>[0055]	下面，说明本发明的一方面的信息处理装置、信息处理方法以及程序等的实施方式（下面也称为“本实施方式”）。但是，本实施方式是例示，本发明并非限于本实施方式的结构。</p>
    <p>[0056]	此外，虽然通过自然语言（中文等）来说明本实施方式中出现的数据，但在具体实施中，能够用计算机可识别的模拟语言、指令、参数、机器语言等来指定。</p>
    <p>[0057]	§ I信息处理装置</p>
    <p>[0058]	利用图I以及图2来说明本实施方式的信息处理装置。</p>
    <p>[0059]	&lt; 概要 &gt;[0060]	图I例示出本实施方式的信息处理装置所执行的处理。本实施方式的信息处理装置对第一区域50和第二区域60进行识别，该第一区域50和第二区域60是在图像数据内根据规定表现方式而指定的区域。</p>
    <p>[0061]	第一区域50由第一区域指定表现方式来指定。另一方面，第二区域60由第二区域指定表现方式来指定。即，第一区域50和第二区域60的区域指定表现方式不同。区域指定表现方式是用于指定区域的表现方式，例如，框、填充图（filling)、各种阴影等。在图I所示的例子中，第一区域指定表现方式仅为框。即，在第一区域指定表现方式中，在框内没有填充图以及各种阴影等。另一方面，在图I所示的例子中，第二区域指定表现方式是填充图。</p>
    <p>[0062]	第一区域50是在图像数据内作为字符识别对象而被指定的区域。另外，第二区域60是特定的项目名所存在的区域，所述特定的项目名是针对被指定为字符识别对象的区域的项目名。</p>
    <p>[0063]	例如，用户在表单或卡片等的纸面上通过标记、封印或印刷等，来描画框、填充图或各种阴影等，由此指定第一区域50和第二区域60。信息处理装置利用扫描仪等来读取这样指定了第一区域50和第二区域60的纸，由此取得指定了第一区域50和第二区域60的图像数据。</p>
    <p>[0064]	本实施方式的信息处理装置对由不同区域指定表现方式所指定的第一区域50和第二区域60进行识别。并且，本实施方式的信息处理装置从第一区域50中取得用于指定成为字符识别对象的区域的位置信息。另外，本实施方式的信息处理装置从第二区域60中取得针对成为该字符识别对象的区域的项目名（与成为该字符识别对象的区域相关的项目名）。</p>
    <p>[0065]	这样一来，本实施方式的信息处理装置，从在图像数据上被指定的第一区域以及第二区域中，针对成为字符识别对象的区域，分别取得位置信息和项目名，由此，用户能够高效制作定义信息。</p>
    <p>[0066]	此外，用户也可以利用描画软件等来编辑图像数据，由此在该图像数据上指定第一区域50和第二区域60。</p>
    <p>[0067]	&lt;结构例&gt;</p>
    <p>[0068]	图2表示本实施方式的信息处理装置I的结构例。信息处理装置I如图2所示，作为其硬件结构，具有与总线13连接的存储部11、控制部12、输入输出部14等。</p>
    <p>[0069]	存储部11用于存储由控制部12执行的处理中所用的各种数据和程序（未图示）。存储部11例如由硬盘实现。存储部11也可以由USB (UniversalSerial Bus:通用串行总线）存储器等的存储介质实现。</p>
    <p>[0070]	此外,存储部11所存储的上述各种数据和程序也可以从⑶(CompactDisc :光盘)或DVD(Digital Versatile Disc :数字化通用磁盘）等的存储介质中取得。另外,存储部11也可以称为辅助存储装置。 </p>
    <p>[0071]	控制部12具有：微处理器或CPU (Central Processing Unit :中央处理器）等的一个或多个处理器；该处理器的处理所使用的周边电路（ROM(Readonly Memory :只读存储器）、RAM (Random Access Memory :随机存取存储器）、接口电路等）。控制部12通过执行存储在存储部11中的各种数据和程序，来实现本实施方式中的信息处理装置I的处理。从配置在由控制部12内的处理器访问的地址空间内的意义上来说，ROM、RAM等也可以称为主</p>
    <p>存储装置。</p>
    <p>[0072]	输入输出部14是一个或多个接口，用于与信息处理装置I外部的装置之间收发数据。输入输出部14例如是：用于连接LAN(Local Area Network :局域网）电缆的接口，用于与输入装置以及输出装置等用户接口相连接的接口，或USB(Universal Serial Bus :通用串行总线）等的接口。</p>
    <p>[0073]	如图2所示，输入输出部14例如可以与扫描仪2相连接。另外，输入输出部14也可以与未图示的用户接口（触摸面板、辅助键盘、键盘、鼠标、显示器等的输入输出装置）相连接。进而，输入输出部14也可以与⑶驱动器、DVD驱动器等可装拆的存储介质的输入输出装置相连接，或者与存储卡等的非易失性的便携式存储介质等的输入输出装置相连接。输入输出部14也可以具有进行网络连接的接口（通信部）功能。 [0074]	本实施方式的信息处理装置，分别取得针对成为字符识别对象的区域的位置信息和项目名，由此使用户高效地制作定义信息。该处理实现为控制部12的处理。</p>
    <p>[0075]	如图2所示，控制部12为了实现上述处理而包括：区域识别部31、位置信息取得部32、项目名取得部33、对应关联部34以及项目定义信息生成部35。例如，通过在作为控制部12的周边电路的RAM等中将存储在存储部11中的程序等展开，由控制部12的处理器来执行这些程序等，由此实现区域识别部31、位置信息取得部32、项目名取得部33、对应关联部34以及项目定义信息生成部35。</p>
    <p>[0076]	区域识别部31，针对在图像数据内由规定表现方式指定的区域，来识别第一区域和第二区域，所述第一区域是由第一区域指定表现方式所指定的区域，所述第二区域是由与所述第一区域指定表现方式不同的第二区域指定表现方式所指定的区域。区域识别部31例如区分识别出图I所示的第一区域50和第二区域60。</p>
    <p>[0077]	位置信息取得部32在图像数据内取得由区域识别部识别出的第一区域的位置信息，将其作为用于指定成为字符识别对象的区域的位置信息。如图I所示，位置信息取得部32例如取得图像数据内的第一区域50的位置信息，将其作为用于指定成为字符识别对象的区域的位置信息。</p>
    <p>[0078]	此外，位置信息取得部32也可以为了后述的对应关联部34的处理而可以取得第二区域的位置信息。位置信息取得部32例如取得图I所示的图像数据内的第二区域60的</p>
    <p>位置信息。</p>
    <p>[0079]	项目名取得部33取得字符信息来作为项目名，所述字符信息是通过对由区域识别部31识别出的第二区域内存在的字符进行识别而得到的信息，所述项目名是针对成为字符识别对象的区域的项目名，所述字符识别对象是根据由位置信息取得部32取得的位置信息而指定的。如图I所示，例如，项目名取得部33取得通过对第二区域内存在的字符进行字符识别而得的字符信息，来作为针对第一区域50的项目名。</p>
    <p>[0080]	此外，如后述，对应关联部34对第一区域和第二区域进行对应关联。在本实施方式中，对应关联部34对第一区域和第二区域进行对应关联，从被关联的第一区域取得位置信息，根据取得的位置信息指定作为字符识别对象的区域，项目名取得部33从关联的该第二区域取得字符信息来作为针对该区域的项目名。</p>
    <p>[0081]	对应关联部34使第一区域和第二区域对应关联。[0082]	例如，对应关联部34使第一区域与在图像数据上距离该第一区域最近的第二区域相对应关联。</p>
    <p>[0083]	另外，例如，对应关联部34判断第一区域的位置与第二区域的位置之间的位置关系是否满足规定条件，将判断为满足规定条件的第一区域与第二区域相对应关联。规定条件是针对对应关系中第一区域与第二区域的位置关系赋予的条件。详细后述。</p>
    <p>[0084]	另外，例如，对应关联部34识别出存在于图像数据内的规定的对应关系指示表现方式，该规定的对应关系指示表现方式表示第一区域与第二区域的对应关联。并且，对应关联部34基于该识别出的对应关系，来使第一区域与第二区域对应关联。</p>
    <p>[0085]	对应关系指示表现方式表示第一区域与第二区域的对应关联。例如，对应关系指示表现方式是指：设在第一区域与第二区域之间的箭头，连接第一区域与第二区域的线段，在第一区域与第二区域标注的相同标记或印记。对应关系指示表现方式只要能够表示第一 区域与第二区域的对应关系即可，可以使用任何方式实现。</p>
    <p>[0086]	项目定义信息生成部35生成包括位置信息和项目名的项目定义信息，该位置信息是位置信息取得部32取得的用于指定成为字符识别对象的区域的信息，该项目名是，由项目名取得部33取得的、针对由该位置信息指定的成为字符识别对象的区域的项目名。所生成的项目定义信息，是用于指定成为字符识别对象的区域的位置以及项目名的信息。该项目定义信息例如通过OCR软件等使用。</p>
    <p>[0087]	§ 2动作例</p>
    <p>[0088]	接着，利用图3来说明本实施方式的信息处理装置I的动作例。图3表示本实施方式的信息处理装置I的处理顺序的一例。此外，在图3中，将步骤简称为“S”。  [0089]	&lt; 开始 &gt;</p>
    <p>[0090]	首先，例如响应于用户的操作，存储在存储部11中的程序被展开在控制部12的RAM等中。然后，由控制部12的处理器执行展开在控制部12的RAM等中的该程序。这样一来，信息处理装置I开始处理。</p>
    <p>[0091]〈步骤	101〉</p>
    <p>[0092]	接着，控制部12取得用于该处理的图像数据（步骤101)。所取得的图像数据例如可以是通过图2所示的扫描仪2获取的数据。另外，所取得的图像数据也可以是存储在存储部11中的数据。这样的图像数据也可以是通过网络取得的。另外，图像数据也可以是从存储卡等的非易失性的便携式的存储介质等中取得的。</p>
    <p>[0093]	图4表示此时取得的图像数据的一例。图像数据例如是通过对表单以及卡片等纸介质进行电子化而得到的数据。如图4所示，第一区域（50a、50b)以及第二区域（60a、60b)，被指定在记载于表单以及卡片等中的栏以及字符等之上。将第一区域（50a、50b)以及第二区域（60a、60b)表现为能够与记载于表单以及卡片等中的栏以及字符等相区别。</p>
    <p>[0094]	例如，为了使第一区域（50a、50b)以及第二区域（60a、60b)能够明确地与记载于表单以及卡片等中的栏以及字符等相区别，可以用与记载于表单以及卡片等中的栏以及字符等的颜色不同的颜色来表现第一区域（50a、50b)以及第二区域^0a、60b)。如果这样表现，通过对该不同颜色进行检测读取的OCR引擎，能够从图像数据内描画图像数据中，只提取第一区域（50a、50b)以及第二区域^0a、60b)的区域指定表现方式。例如，如果记载在表单以及卡片等中栏以及字符等为黑色，则该OCR引擎检测读取该黑色以外的颜色，由此提取第一区域（50a、50b)以及第二区域（60a、60b)。</p>
    <p>[0095]	但是，并非一定要用与记载于表单以及卡片等中的栏以及字符等的颜色不同的颜色来表现第一区域（50a、50b)以及第二区域（60a、60b)。例如，只要通过能够与记载于表单以及卡片等中的栏等的区域指定表现方式相区别的区域指定表现方式来表现出将第一区域（50a、50b)以及第二区域（60a、60b)即可，也可以使用与记载于表单以及卡片等中的栏以及字符等的颜色相同的颜色来表现。</p>
    <p>[0096]	&lt; 步骤 102〉</p>
    <p>[0097]	接着，如图3所示，控制部12对在步骤101中取得的图像数据内的第一区域进行识别(步骤102)。</p>
    <p>[0098]	在图4所示的图像数据中、使用框来作为第一区域指定表现方式。换言之，在图4所示的图像数据中，第一区域（50a、50b)是由框表现出来的。控制部12对由该框表现的第一区域（50a、50b)进行识别。&#183;</p>
    <p>[0099]	例如，控制部12从在图像数据内描画的图像数据中提取第一区域以及第二区域的区域指定表现方式。由于第一区域（50a、50b)以及第二区域（60a、60b)表现为能够与记载于表单以及卡片等中的栏以及字符等相区别，因此该提取能够执行。接着，控制部12从所提取的第一区域以及第二区域的区域指定表现方式中确定第一区域指定表现方式的区域。例如通过图案匹配等来实现用于该确定的处理。并且，控制部12将所确定的区域识别为第一区域。这样一来，控制部12在图4所示的图像数据内识别出由框表现的第一区域(50a、50b)ο</p>
    <p>[0100]〈步骤	103〉</p>
    <p>[0101]	接着，控制部12取得在步骤102中识别出的第一区域的图像数据内的位置信息(步骤103)。</p>
    <p>[0102]	位置信息只要是表示图像数据内的位置的信息即可，可以是任意信息。在本实施方式中，用xy坐标系来表现位置信息，该xy坐标系以图像数据的左上端为原点，以横轴为X轴，以纵轴为y轴。但是，位置信息的表现方式并不限于xy坐标系。例如，位置信息的表现方式也可以是极坐标系，该极坐标系以图像数据的某一点（例如，图像数据的中心）为原点。</p>
    <p>[0103]	另外，本实施方式的第一区域的位置信息包括第一区域的左上端的位置（坐标）、横向长度以及纵向长度。该位置信息如后述的图9中例示。控制部12确定在步骤102中识别出的第一区域的左上端的位置坐标。另外，控制部12确定所识别出的第一区域的横向长度与纵向长度。由此，控制部12取得所识别出的第一区域的图像数据内的位置信息。</p>
    <p>[0104]〈步骤	104〉</p>
    <p>[0105]	接着，控制部12对在步骤101中取得的图像数据内的第二区域进行识别（步骤104)。</p>
    <p>[0106]	在图4所示的图像数据中，用填充图作为第二区域指定表现方式。换言之，在图4所示的图像数据中、第二区域^0a、60b)由填充图表现出来。控制部12对由该填充图表现的第二区域（60a、60b)进行识别。此外，利用与在步骤102中的第一区域的识别方法相同的方法来识别该第二区域。</p>
    <p>[0107]〈步骤	105〉[0108]	接着，控制部12取得在步骤104中识别出的第二区域的图像数据内的位置信息(步骤105)。此外，该步骤105也可以省略。本实施方式中，由于在后述的步骤107中使用对应关联的第二区域的位置信息，因此取得该第二区域的位置信息。此外，第二区域的位置信息的取得方法与步骤103中的第一区域的位置信息的取得方法相同。</p>
    <p>[0109]〈步骤	106〉</p>
    <p>[0110]	接着，控制部12通过对在步骤104中识别出的第二区域内存在的字符进行字符识另|J，由此取得该第二区域内存在的字符的字符信息（步骤106)。</p>
    <p>[0111]	字符识别可以通过任意方法执行。在本步骤106中，控制部12通过对记载在第二区域内的字符进行字符识别，由此取得记载在该第二区域内的字符的字符信息。</p>
    <p>[0112]	此外，所取得的字符信息，作为针对成为字符识别对象的第一区域的项目名。第一 区域与第二区域分别只存在一个时，只考虑一种第一区域与第二区域的组合，因此无需确定第一区域与第二区域的对应关系。即，在本步骤106中从第二区域取得的字符信息，无需确定是针对哪个第一区域的项目名。在本步骤106中取得了字符信息的时刻，将该字符信息确定为针对步骤102以及103所涉及的第一区域的项目名。</p>
    <p>[0113]	另一方面，在第一区域与第二区域分别存在多个时，需要确定从第二区域取得的字符信息是针对哪个第一区域的项目名。在本实施方式中，在后述的步骤107中，通过使第一区域与第二区域相对应关联，由此确定从第二区域取得的字符信息是针对哪个第一区域的项目名。</p>
    <p>[0114]	然而，这样的对应关联并非都是必要的。例如，如图5所示，控制部12从图像数据的上部开始按顺序进行扫描，从而进行步骤102涉及的第一区域的识别以及步骤104涉及的第二区域的识别。并且，控制部12每发现一个第一区域和一个第二区域，就会重复步骤102&#12316;106的处理。此时，所处理的第一区域与第二区域一直分别为一个，因此不需要上述对应关联的处理。</p>
    <p>[0115]	此外，例如，如果这样执行处理，则在图5所示的例子中，从第二区域60a取得的字符信息被确定为针对第一区域50a的项目名。另外，从第二区域60b取得的字符信息被确定为针对第一区域50b的项目名。从第二区域60c取得的字符信息被确定为针对第一区域50c的项目名。此外，在该处理中，根据发现第一区域与第二区域的顺序，交替执行步骤102&#12316;103和步骤104&#12316;106。</p>
    <p>[0116]〈步骤	107〉</p>
    <p>[0117]	接着，控制部12确定在步骤102中识别出的第一区域与在步骤104中识别出的第二区域之间的对应关系，因此将该第一区域与该第二区域相对应关联。例如在对应关联的第一区域与第二区域分别为一个时，也可以省略本步骤107。在本步骤107中，如上述，确定从第二区域取得的字符信息是针对哪个第一区域的项目名。</p>
    <p>[0118]	利用图6&#12316;9来说明控制部12进行的对应关联的处理的例子。</p>
    <p>[0119]	例如，控制部12将第一区域与图像数据上距离该第一区域最近的第二区域相对应关联。图6表示该处理的例子。在本实施方式中，在步骤103以及105中，取得第一区域与第二区域的位置信息。在该位置信息中，包括各区域的左上端的位置坐标。控制部12利用该位置坐标，分别计算第一区域与第二区域的距离。即，控制部12分别计算第一区域的左上端的位置坐标与第二区域的左上端的位置坐标之间的距离。并且，控制部12将该距离最短的第一区域与第二区域相对应关联。</p>
    <p>[0120]	在图6所示的例子中，控制部12将第一区域50a与图像数据上距离该第一区域50a最近的第二区域60a相对应关联。另外，将第一区域50b与图像数据上距离该第一区域50b最近的第二区域60b相对应关联。</p>
    <p>[0121]	此外，也可以交换该处理中的第一区域与第二区域。即，控制部12也可以将第二区域与图像数据上距离该第二区域最近的第一区域相对应关联。</p>
    <p>[0122]	另外，例如，控制部12也可以判断第一区域的位置与第二区域的位置之间的位置关系是否满足规定条件，从而将判断为满足规定条件的第一区域与第二区域相对应关联。</p>
    <p>[0123]	规定条件是在对应关系中对第一区域与第二区域的位置关系附加的条件。</p>
    <p>[0124]	例如，规定条件涉及对应关系中第一区域与第二区域的距离。控制部12，在图像数据内的第一区域与第二区域中，判断为处于阈值以内距离的第一区域与第二区域满足规定条件，所述阈值可以由用户设定以及变更。</p>
    <p>[0125]	另外，例如，规定条件涉及对应关系中第一区域与第二区域的相对位置关系。控制部12，在图像数据内的第一区域与第二区域中，判断为处于某特定相对位置关系的第一区域与第二区域满足规定条件。在此，在本实施方式中，相对位置关系表现为，以图像数据的左上端为原点，指向第一区域左上端的矢量与指向第二区域左上端的矢量之间的差分矢量。另外，某特定相对位置关系表现为，应该满足该差分矢量的条件矢量。并且，例如，在该差分矢量与条件矢量的内积处于特定范围内的情况下，判断为该差分矢量的第一区域与第二区域满足某特定相对位置关系，该特定范围是能够由用户设定以及变更值的范围。</p>
    <p>[0126]另外，例如，规定条件涉及对应关系中的第一区域与第二区域的横向排列方式。控制部12，在图像数据内纵向排列的第一区域与纵向排列的第二区域中，判断为横向排列的第一区域与第二区域满足规定条件。图7例示出满足该条件的第一区域与第二区域。此外，图7中的坐标（X、y)中的X表示横轴（X轴）的坐标。另外，y表示纵轴（y轴）的坐标。</p>
    <p>[0127]	在此，在本实施方式中，纵向排列的第一区域是指，与第一区域的左上端的横轴（X轴）相关的位置坐标（X坐标）存在于阈值以内误差范围内的第一区域，所述阈值能够由用户设定以及变更。例如，图7所示的第一区域50a的X坐标为70。第一区域50b的x坐标 为68。第一区域50c的X坐标为70。此时，例如如果阈值为5，则第一区域50a、第一区域50b以及第一区域50c分别是纵向排列的第一区域。</p>
    <p>[0128]	针对第二区域也是同样的。在本实施方式中，纵向排列的第二区域是指，与第二区域的左上端的横轴（X轴）相关的位置坐标（X坐标）存在于阈值以内误差范围内的第二区域，所述阈值能够由用户设定以及变更。例如，图7所示的第二区域60a的X坐标为20。第二区域60b的X坐标为21。第二区域60c的X坐标为19。此时,例如如果阈值为5,则第二区域60a、第二区域60b以及第二区域60c分别为纵向排列的第二区域。</p>
    <p>[0129]	控制部12取得这样纵向排列的第一区域与纵向排列的第二区域。并且，控制部12，在纵向排列的第一区域以及第二区域中，判断为横向排列的第一区域与第二区域满足上述规定条件。</p>
    <p>[0130]	在此，在本实施方式中，第一区域与第二区域横向排列是指如下状态：第一区域左上端的纵轴（y轴）所相关的位置坐标（y坐标）与第二区域左上端的纵轴所相关的位置坐标之间的差，处于能够由用户设定以及变更的阈值以内。[0131]	例如，图7所示的第一区域50a的y坐标为59。第一区域50b的y坐标为98。第一区域50c的y坐标为140。与此相对，图7所示的第二区域60a的y坐标为60。第二区域60b的Y坐标为100。第二区域60c的Y坐标为141。</p>
    <p>[0132]	此时，例如如果阈值为5，则控制部12判断为第一区域50a与第二区域60a为横向排列，满足规定条件。另外，控制部12判断为第一区域50b与第二区域60b为横向排列,满足规定条件。进而，控制部12判断为第一区域50c与第二区域60c为横向排列,满足规定条件。即，控制部12使第一区域50a与第二区域60a相对应关联。另外，控制部12使第一区域50b与第二区域60b相对应关联。进而，控制部12使第一区域50c与第二区域60c相对应关联。</p>
    <p>[0133]	另外，例如，规定条件涉及对应关系中的第一区域与第二区域的纵向排列方式。控制部12，在图像数据内横向排列的第一区域与横向排列的第二区域中，判断为纵向排列的第一区域与第二区域满足规定条件。图8例示出满足该条件的第一区域与第二区域。图8中的坐标（x、y)与图7中的坐标相同。  </p>
    <p>[0134]	在此，判断第一区域是否为横向排列的方法，以及判断第二区域是否为横向排列的方法，与判断上述第一区域与第二区域是否为横向排列的方法相同。另外，判断第一区域与第二区域是否为纵向排列的方法，与判断上述第一区域是否为纵向排列的方法以及判断上述第二区域是否为纵向排列的方法相同。</p>
    <p>[0135]	例如，如果阈值为5，则控制部12判断图8中的第一区域50a与第二区域60a为纵向排列，满足规定条件。另外，控制部12判断为第一区域50b与第二区域60b为纵向排列，满足规定条件。进而，控制部12判断为第一区域50c与第二区域60c为纵向排列，满足规定条件。即，控制部12使第一区域50a与第二区域60a相对应关联。另外，控制部12使第一区域50b与第二区域60b相对应关联。进而，控制部12使第一区域50c与第二区域60c相对应关联。</p>
    <p>[0136]	另外，例如，控制部12识别出存在于图像数据内的规定的对应关系指示表现方式，该规定的对应关系指示表现方式表示第一区域与第二区域的对应关系。并且，控制部12基于该识别出的对应关系指示表现方式所示的对应关系，使第一区域与第二区域相对应关联。</p>
    <p>[0137]	对应关系指示表现方式，表示第一区域与第二区域的对应关联。图9例示出该对应关系指示表现方式。</p>
    <p>[0138]	例如，对应关系指示表现方式是图9所示的箭头70。例如，控制部12识别出存在于图像数据内的箭头70。然后，控制部12根据识别出的箭头70，来取得与该箭头70所指示的方向相关的矢量信息。进而，控制部12利用该取得的矢量信息，来确定该箭头70所指示的第一区域50a和第二区域60a。其结果，控制部12使所确定的第一区域50a和第二区域60a相对应关联。</p>
    <p>[0139]	另外，例如，对应关系指示表现方式是图9所示的线段71。例如，控制部12识别出存在于图像数据内的线段71。然后，控制部12确定线段71所连接的第一区域50b和第二区域60b。其结果，控制部12使所确定的第一区域50b和第二区域60b相对应关联。</p>
    <p>[0140]	另外,例如,对应关系指示表现方式是图9所示的标记72a和标记72b。例如,控制部12识别出存在于图像数据内的作为同一标记的标记72a和标记72b。然后，控制部12确定标注了作为同一标记的标记72a和标记72b的第一区域50c和第二区域60c。其结果，控制部12使所确定的第一区域50c和第二区域60c相对应关联。</p>
    <p>[0141]	控制部12，通过至此为止例示的对应关联的方法，使在步骤102中识别出的第一区域与在步骤104中识别出的第二区域相对应关联。此外，控制部12也可以使用至此为止例示的对应关联的方法的多种组合 ，来使第一区域与第二区域相对应关联。</p>
    <p>[0142]〈步骤	108〉</p>
    <p>[0143]	接着，控制部12生成项目定义信息，该项目定义信息包括在步骤103中取得的位置信息和在步骤106中取得的项目名。图10例示出针对图4所示的图像数据执行上述步骤102&#12316;107的处理的结果，即，在该步骤108中生成的项目定义信息。</p>
    <p>[0144]	如图10所示,第一区域50a与第二区域60a相对应关联。另外,第一区域50b与第二区域60b相对应关联。</p>
    <p>[0145]	并且，第一区域50a的x坐标（左侧）、y坐标（顶端）、横轴的长度（宽度）以及纵轴的长度（高度）分别为120、80、320以及30。第一区域50b的x坐标、y坐标、横轴的长度以及纵轴的长度分别为120、120、320以及30。另外，第二区域60a的x坐标、y坐标、横轴的长度以及纵轴的长度分别为20、80、90以及30。第二区域60b的x坐标、y坐标、横轴的长度以及纵轴的长度分别为20、120、90以及30。</p>
    <p>[0146]	图10例示出从这样的第一区域50a与第二区域60a以及第一区域50b与第二区域60b取得的项目定义信息。此外，图10例示的项目定义信息中的“项目名”字段（field)存储有从第二区域取得的字符信息。“左侧”字段存储有第一区域的左上端的X坐标。“顶端”字段存储有第一区域的左上端的y坐标。“宽度”字段存储有第一区域的横轴的长度。“高度”字段存储有第一区域的纵轴的长度。</p>
    <p>[0147]	在此，项目定义信息的行数据（记录record)表示对应关系中的第一区域与第二区域的信息。即，项目定义信息的记录包括成为字符识别对象的区域的位置信息与针对该区域的项目名。</p>
    <p>[0148]	此外，OCR软件等可以从项目定义信息的记录中取得成为字符识别对象的区域的位置信息以及针对该区域的项目名。即，可以在OCR软件等中，为了确定成为字符识别对象的区域的信息而使用项目定义信息。</p>
    <p>[0149]	另外，控制部12，可以将从项目定义信息的记录中得到的成为字符识别对象的区域的位置信息与项目名以及取得了这些信息的图像数据，一起显示在与信息处理装置I连接的显示装置上。</p>
    <p>[0150]〈结束〉</p>
    <p>[0151]	最后，控制部12例如将在步骤108中生成的项目定义信息存储在存储部11中。然后，信息处理装置I结束本动作例的处理。</p>
    <p>[0152]〈其它〉</p>
    <p>[0153]	此外，控制部12进行的上述步骤102和104中的第一区域和第二区域的识别处理，相当于区域识别部31的处理。</p>
    <p>[0154]	控制部12进行的上述步骤103中的位置信息取得的处理，相当于位置信息取得部32的处理。</p>
    <p>[0155]	控制部12进行的上述步骤106中的项目名取得的处理，相当于项目名取得部33的处理。</p>
    <p>[0156]	控制部12进行的上述步骤107中的对应关联的处理，相当于对应关联部34的处理。</p>
    <p>[0157]	控制部12进行的上述步骤108中的项目定义信息的生成处理，相当于项目定义信息生成部35的处理。</p>
    <p>[0158]	§ 3实施方式的作用以及效果</p>
    <p>[0159]	根据上述，在本实施方式的信息处理装置I中，识别出图像数据内中的第一区域与第二区域（步骤102以及104)。并且，从第一区域取得用于指定成为字符识别对象的区域的位置信息（步骤103)。另外，从第二区域取得针对该成为字符识别对象的区域的项目 名(步骤106)。</p>
    <p>[0160]	因此，通过本实施方式的信息处理装置1，用户无需通过手动输入来设定与所取得的位置信息相关的、针对成为字符识别对象的区域的项目名。因此，通过本实施方式的信息处理装置1，能够高效地生成（制作）用于OCR软件等的定义信息。</p>
    <p>[0161]	另外，在本实施方式的信息处理装置I中，使得用于指定成为字符识别对象的区域的位置信息与针对该成为字符识别对象的区域的项目名相对应关联（步骤107)。因此，用户无需再进行使所取得的位置信息与项目名相对应关联的处理。因此，通过本实施方式的信息处理装置1，能够高效地生成（制作）用于OCR软件等的定义信息。</p>
    <p>[0162]	§4 补充</p>
    <p>[0163]	以上，详细说明了本发明的实施方式，但上述说明的全部观点仅为本发明的例示，并非用于限定其范围。在不脱离本发明的精神的范围内，能够进行各种改良和变形。</p>
    <p>[0164]	本领域技术人员能够根据上述本实施方式的记载，基于权利要求书的记载以及技术常识，来实施等价的范围。另外，本说明书中使用的用语并不特别限定，能够用作该领域常用用语。因此，只要没有其它定义，本说明书中使用的全部专用用语和技术用语，具有本发明所属领域技术人员能够一般理解的意义。在两者矛盾时，在本说明书（包括定义）中记载的意义中来理解本说明书中使用的用语。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101523413A?cl=zh">CN101523413A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年11月7日</td><td class="patent-data-table-td patent-date-value">2009年9月2日</td><td class="patent-data-table-td ">国际商业机器公司</td><td class="patent-data-table-td ">根据硬拷贝表单自动生成表单定义</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070228168">US20070228168</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年3月29日</td><td class="patent-data-table-td patent-date-value">2007年10月4日</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">OCR sheet-inputting device, OCR sheet, program for inputting an OCR sheet and program for drawing an OCR sheet form</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009200000">G06K9/20</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K2209/01">G06K2209/01</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=lsqmBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/2063">G06K9/2063</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年10月3日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年2月11日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/9a1420a4c77b0661a575/CN102708365A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E8%A3%85%E7%BD%AE_%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E4%BB%A5.pdf?id=lsqmBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0dkQ0mmJlqI6DKs5IadAuBPncTVA"},"sample_url":"https://www.google.com/patents/reader?id=lsqmBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>