<!DOCTYPE html><html><head><title>专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="使用者情绪检测方法与应用其的手写输入电子装置"><meta name="DC.contributor" content="陈剑航" scheme="inventor"><meta name="DC.contributor" content="纬创资通股份有限公司" scheme="assignee"><meta name="DC.date" content="2012-3-8" scheme="dateSubmitted"><meta name="DC.description" content="使用者情绪检测方法，应用于一手写输入电子装置。根据一使用者手写输入，取得至少一手写输入特征参数。根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数。显示该使用者情绪参数于该手写输入电子装置的一触控显示面板上。接收一使用者反馈参数。根据该使用者反馈参数来决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值，以建造及调整该类神经网络。"><meta name="DC.date" content="2013-8-21"><meta name="DC.relation" content="CN:101370195:A" scheme="references"><meta name="DC.relation" content="CN:101930735:A" scheme="references"><meta name="DC.relation" content="CN:102193620:A" scheme="references"><meta name="DC.relation" content="TW:200836112" scheme="references"><meta name="DC.relation" content="TW:M383932" scheme="references"><meta name="DC.relation" content="US:20110217679:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103257736:A"><meta name="citation_patent_application_number" content="CN:201210059530"><link rel="canonical" href="https://www.google.com/patents/CN103257736A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103257736A?cl=zh"/><meta name="title" content="专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置"/><meta name="description" content="使用者情绪检测方法，应用于一手写输入电子装置。根据一使用者手写输入，取得至少一手写输入特征参数。根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数。显示该使用者情绪参数于该手写输入电子装置的一触控显示面板上。接收一使用者反馈参数。根据该使用者反馈参数来决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值，以建造及调整该类神经网络。"/><meta property="og:title" content="专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103257736A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103257736A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103257736A&amp;usg=AFQjCNEbDciWOVMfIh0URFxzN-1eJ2mAbQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/d5efedb81bcfd4f80473/CN103257736A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/d5efedb81bcfd4f80473/CN103257736A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103257736A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103257736A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN103257736A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN103257736B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103257736A?cl=zh" style="display:none"><span itemprop="description">使用者情绪检测方法，应用于一手写输入电子装置。根据一使用者手写输入，取得至少一手写输入特征参数。根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数。显示该使...</span><span itemprop="url">https://www.google.com/patents/CN103257736A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置" title="专利 CN103257736A - 使用者情绪检测方法与应用其的手写输入电子装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103257736 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210059530</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年8月21日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年3月8日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年2月21日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103257736B?hl=zh-CN&amp;cl=zh">CN103257736B</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8885927?hl=zh-CN&amp;cl=zh">US8885927</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130216126?hl=zh-CN&amp;cl=zh">US20130216126</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210059530.4, </span><span class="patent-bibdata-value">CN 103257736 A, </span><span class="patent-bibdata-value">CN 103257736A, </span><span class="patent-bibdata-value">CN 201210059530, </span><span class="patent-bibdata-value">CN-A-103257736, </span><span class="patent-bibdata-value">CN103257736 A, </span><span class="patent-bibdata-value">CN103257736A, </span><span class="patent-bibdata-value">CN201210059530, </span><span class="patent-bibdata-value">CN201210059530.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E5%89%91%E8%88%AA%22">陈剑航</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E7%BA%AC%E5%88%9B%E8%B5%84%E9%80%9A%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">纬创资通股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103257736A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103257736A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103257736A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (8),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210059530&amp;usg=AFQjCNFjCyIWEd-ZL3JA2ntLeNOWWBEHEw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103257736A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNF0wzDP57lQgPU5laIKXlD0bTKcCQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT127501695" lang="ZH" load-source="patent-office">使用者情绪检测方法与应用其的手写输入电子装置</invention-title>
      </span><br><span class="patent-number">CN 103257736 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA119764189" lang="ZH" load-source="patent-office">
    <div class="abstract">使用者情绪检测方法，应用于一手写输入电子装置。根据一使用者手写输入，取得至少一手写输入特征参数。根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数。显示该使用者情绪参数于该手写输入电子装置的一触控显示面板上。接收一使用者反馈参数。根据该使用者反馈参数来决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值，以建造及调整该类神经网络。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(19)</span></span></div><div class="patent-text"><div mxw-id="PCLM54282210" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种使用者情绪检测方法，用于一手写输入电子装置，该方法包括：  根据一使用者手写输入，取得至少一手写输入特征参数；  根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数；  显示该使用者情绪参数于该手写输入电子装置的一触控显示面板上；  接收一使用者反馈参数；以及  根据该使用者反馈参数来决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值，以建造及调整该类神经网络。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的使用者情绪检测方法，其中该手写输入特征参数包括下列的至少一者或其任意组合：一手写速度参数、一手写压力参数与一手写修改次数参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的使用者情绪检测方法，其中该手写速度参数包括下列的至少一者或其任意组合：一手写笔划速度参数、一手写初笔划速度参数、一手写终笔划速度参数与一手写平均速度参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求2所述的使用者情绪检测方法，其中该手写压力参数包括下列的至少一者或其任意组合：一手写初点压力参数、一手写终点压力参数与一手写平均压力参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求I所述的使用者情绪检测方法，其中该使用者情绪参数包括下列的至少一者或其任意组合：一使用者情绪分数参数与一使用者情绪分类参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的使用者情绪检测方法，其中根据该使用者情绪分数参数，以得到该使用者情绪分类参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求I所述的使用者情绪检测方法，其中接收该使用者反馈参数的该步骤包括：  接收并正规化该使用者反馈参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求I所述的使用者情绪检测方法，其中根据该使用者反馈参数来决定是否要调整该至少一相关链接值的该步骤包括：  如果该使用者反馈参数与该使用者情绪参数间的一差值大于一误差门坎值且该类神经网络的一训练次数大于一训练次数门坎值，则不调整该至少一相关链接值，反之则调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求I所述的使用者情绪检测方法，其中调整该至少一相关链接值的该步骤包括：  根据该使用者反馈参数与该使用者情绪参数的一差值来调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的使用者情绪检测方法，其中调整该至少一相关链接值的该步骤包括：  根据该差值、该手写输入特征参数与该至少一相关链接值来得到该至少一相关链接值的一修正值；以及  根据该修正值来调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11.	一种手写输入电子装置，包括：  一触控显示面板，用以接收一使用者手写输入；  一触控电路，耦接至该触控显示面板，根据该使用者手写输入，取得一手写速度参数及/或一手写压力参数；一存储器，内储有一手写输入辨认软件，根据该使用者手写输入，该手写输入辨认软件取得一手写修改次数参数；以及  一处理单元，耦接至该触控显示面板、该触控电路与该存储器；  其中，该处理单元根据至少一相关链接值、该手写速度参数及/或该手写压力参数及/或该手写修改次数参数来判断一使用者情绪参数并控制该触控显示面板显示该使用者情绪参数；  该触控显示面板接收一使用者反馈参数；以及  根据该使用者反馈参数，该处理单元决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求11所述的手写输入电子装置，其中该手写速度参数包括下列的至少一者或其任意组合：一手写笔划速度参数、一手写初笔划速度参数、一手写终笔划速度参数与一手写平均速度参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求11所述的手写输入电子装置，其中该手写压力参数包括下列的至少一者或其任意组合：一手写初点压力参数、一手写终点压力参数与一手写平均压力参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求11所述的手写输入电子装置，其中该使用者情绪参数包括下列的至少一者或其任意组合：一使用者情绪分数参数与一使用者情绪分类参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求14所述的手写输入电子装置，其中根据该使用者情绪分数参数，该处理单元得到该使用者情绪分类参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求11所述的手写输入电子装置，其中该处理单元正规化所接收的该使用者反馈参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求11所述的手写输入电子装置，其中：  如果该处理单元判断该使用者反馈参数与该使用者情绪参数间的一差值大于一误差门坎值且一训练次数大于一训练门坎值，则该处理单元不调整该至少一相关链接值，反之该处理单元调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求11所述的手写输入电子装置，其中：  根据该使用者反馈参数与该使用者情绪参数的一差值，该处理单元调整该至少一相关链接值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.根据权利要求18所述的手写输入电子装置，其中：  根据该差值、该手写输入特征参数与该至少一相关链接值，该处理单元得到该至少一相关链接值的一修正值；以及  根据该修正值，该处理单元调整该至少一相关链接值。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES61301039" lang="ZH" load-source="patent-office" class="description">
    <p>使用者情绪检测方法与应用其的手写输入电子装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明是有关于一种使用者情绪检测方法与应用其的手写输入电子装置。</p>
    <p>背景技术</p>
    <p>[0002]自从平板计算机(比如由苹果公司所开发的1-Pad等)问世后，在全球掀起了一股风潮。越来越多的厂商纷纷投入平板计算机的开发，可以预期在未来的日子，平板计算机即将在人们日常生活扮演越来越重要的角色。</p>
    <p>[0003]	平板计算机特色之一在于输入装置由键盘/鼠标改为触控式输入装置，这和目前桌上型计算机以及笔记本型计算机有很大的差距。故而，平板计算机的使用相较于传统计算机方便许多。许多新型的应用程序也开始在平板计算机上使用，如:电子书包应用程序、病历应用程序等等。触控装置的进步，比如灵敏度的提升，乃是平板计算机能够快速普及的原因之一。</p>
    <p>[0004]	一般触控装置上的输入方式包括虚拟键盘(Software keyboard)与手写输入。在识别使用者手写时，电子装置的触控装置可以接受到手指压力参数、手指速度参数、识别是否正确、使用者是否重新输入等因素，这些因素是使用者送给电子装置。这些使用者消息可能代表使用者的情绪。譬如:当人类情绪烦躁时，其手写速度可能较快。</p>
    <p>[0005]	故而，本发明提供一种基于手写输入/识别的使用者情绪检测学习系统与应用其的手写输入电子装置，其能根据使用者反馈来更新其情绪检测。</p>
    <p>发明内容</p>
    <p>[0006]	本发明实施例是有关于一种使用者情绪检测方法与应用其的手写输入电子装置，其初始根据手写特征参数来检测`使用者情绪，且会依据使用者的反馈，来逐渐自我学习。</p>
    <p>[0007]	根据本发明的一示范性实施例，提出一种使用者情绪检测方法，应用于一手写输入电子装置。此使用者情绪检测方法包括:根据一使用者手写输入，取得至少一手写输入特征参数；根据该手写输入特征参数与至少一相关链接值，该手写输入电子装置的一类神经网络判断一使用者情绪参数；显示该使用者情绪参数于该手写输入电子装置的一触控显示面板上；接收一使用者反馈参数；以及根据该使用者反馈参数来决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值，以建造及调整该类神经网络。</p>
    <p>[0008]	根据本发明的一示范性实施例，提出一种手写输入电子装置，包括:一触控显示面板，用以接收一使用者手写输入；一触控电路，耦接至该触控显示面板，根据该使用者手写输入，取得一手写速度参数及/或一手写压力参数；一存储器，内储有一手写输入辨认软件，根据该使用者手写输入，该手写输入辨认软件取得一手写修改次数参数；以及一处理单元，耦接至该触控显示面板、该触控电路与该存储器。该处理单元根据至少一相关链接值、该手写速度参数及/或该手写压力参数及/或该手写修改次数参数来判断一使用者情绪参数并控制该触控显示面板显示该使用者情绪参数。该触控显示面板接收一使用者反馈参数。根据该使用者反馈参数，该处理单元决定是否要调整该至少一相关链接值及如何调整该至少一相关链接值。</p>
    <p>[0009]	为了对本发明的上述及其它方面有更佳的了解，下文特举实施例，并配合所附图式，作详细说明如下。</p>
    <p>附图说明</p>
    <p>[0010]	图1显示根据本发明实施例的手写输入电子装置的功能方块图。</p>
    <p>[0011]	图2显示根据本发明实施例的手写输入电子装置的使用者情绪检测流程图。</p>
    <p>[0012]	图3显示监督式学习应用的类神经网络的一例。</p>
    <p>[0013]	图4显示根据本发明另一实施例的使用者情绪检测流程图。</p>
    <p>[0014][主要元件标号说明]</p>
    <p>[0015]	100:手写输入电子装置	110:触控显示面板</p>
    <p>[0016]	112:触控电路	120:存储器</p>
    <p>[0017]	122:手写输入辨认软件	130:处理单元</p>
    <p>[0018]	210 &#12316;280: 步骤	410 &#12316;490:步骤</p>
    <p>具体实施方式</p>
    <p>[0019]	本发明实施例提出基于手写输入特征来检测使用者情绪的学习系统。当使用者在使用电子装置时，电子装置检测使用者情绪并显示让使用者了解，甚至提醒使用者。电子装置根据使用者的反馈，自动学习来逐渐提高情绪识别准确率。</p>
    <p>[0020]	现请参考图1与图2，其分别显示根据本发明实施例的手写输入电子装置的功能方块图与使用者情绪检测流程图。</p>
    <p>[0021]	如图1所示，本发明实施例的手写输入电子装置100包括:触控显示面板110，接收使用者手写输入，且可显示画面；触控电路112，耦接至触控显示面板110，根据使用者手写输入，取得使用者手写输入特征(比如但不受限于使用者手写速度参数及/或使用者手写压力参数)；存储器120，内储有手写输入辨认软件122，根据使用者手写输入，该手写输入辨认软件122取得使用者手写修改次数参数；以及处理单元130，耦接至触控显示面板110、触控电路112与存储器120。</p>
    <p>[0022]	处理单元130根据至少一相关链接值、手写速度参数及/或手写压力参数及/或手写修改次数参数来判断使用者的情绪参数(比如是情绪分数)并控制触控显示面板110显示所判断出的使用者情绪参数/分数。</p>
    <p>[0023]	在使用者看到显示于触控显示面板110上的情绪参数/分数，使用者可以根据提示(此提示为选择做法)给予反馈，比如，使用者可以在触控显示面板110上输入其目前的情绪参数/情绪分数。根据使用者上所反馈的参数，处理单元130决定是否要调整相关链接值及如何调整相关链接值，其细节将于底下描述之。</p>
    <p>[0024]	虽然于图1中，触控电路112乃是形成于触控显示面板110之内，但本发明并不受限于此。</p>
    <p>[0025]	现请参考图2。于步骤210中，使用者通过触控装置(比如图1中的触控显示面板110)来手写输入。</p>
    <p>[0026]	于步骤220中，取得手写压力及/或手写速度及/或修改次数等数值，这些数值即是手写输入特征参数。步骤220中的手写压力及/或手写速度参数比如是由图1中的触控电路112所取得，而修改次数参数则比如是由图1中的手写输入识别软件122所取得。图1中的触控电路112输出手写速度参数V与手写压力参数P给处理单元130。图1中的手写输入识别软件122输出修改次数参数N给处理单元130。</p>
    <p>[0027]	手写压力包括下列的至少一者或其任意组合:手写初点压力参数(这代表使用者在写第一笔划时，施加至触控装置的压力)、手写终点压力参数(这代表使用者在手写输入的最后一笔时，施加至触控装置的压力)与手写平均压力参数(这代表使用者在手写输入过程中的平均压力)。</p>
    <p>[0028]	手写速度参数包括下列的至少一者或其任意组合:手写笔划速度参数(可能是使用者的任一笔笔划的速度)、手写初笔划速度参数(这代表使用者在写第一笔划的手写速度)、手写终笔划速度参数(这代表使用者在写最一笔划的手写速度)与手写平均速度参数(这代表使用者在此次手写过程中的平均手写速度)。</p>
    <p>[0029]	通常来讲，如果使用者处于情绪较为激动或生气或高昂的话，则其手写压力及/或速度参数(比如是手写初点压力参数及/或手写初笔划速度参数)可能比较高；反之，如果使用者处于情绪较为低落、难过的话，则其手写压力及/或速度参数(比如是手写初点压力参数及/或手写初笔划速度参数)可能比较低。</p>
    <p>[0030]	此外，修改次数参数代表使用者在进行此次手写输入过程中的修改次数。相似地，如果使用者处于情绪较为激动或生气或高昂的话，则修改次数可能比较高(因为使用者可能因为情绪不平静，比较容易写错字)。反之，如果使用者处于情绪较为平静的话，则其修改次数参数可能比较少(因为使用者可能因为情绪平静，比较不会写错字)。</p>
    <p>[0031]	本发明实施例可以通过这些手写压力及/或速度参数及/或修改次数参数来渐进式调整学习系统，以更正确地反映使用者情绪。</p>
    <p> [0032]	于步骤230中，步骤220所取得手写输入特征参数会被丢入至神经网络，以判断情绪分数。步骤230比如可由图1中的处理单元130所执行。至于如何判断情绪分数则如下所述。</p>
    <p>[0033]	于步骤240中，将情绪分数给予分类。比如，如果情绪分数大于0.7的话，则分类为「坏情绪」。情绪分数介于0.3&#12316;0.7之间，则分类为「普通情绪」。情绪分数介于O&#12316;0.3的话，则分类为「好情绪」。当然，本发明并不受限于此。</p>
    <p>[0034]	于步骤250中，将情绪分数及/或情绪分类显示于屏幕上。</p>
    <p>[0035]	于步骤260后，使用者看到情绪分数及/或情绪分类后，使用者可以反馈其情绪分数，以让系统进行学习。</p>
    <p>[0036]	于步骤270中，系统取得使用者所反馈的情绪分数。甚至，系统对使用者所反馈的情绪分数进行正规化。</p>
    <p>[0037]	于步骤280中，根据使用者反馈的(正规化后)情绪分数，类神经网络调整其各别链接值，来更新其网络。</p>
    <p>[0038]	现将说明如何计算情绪分数及如何训练类神经网络。</p>
    <p>[0039]	本发明实施例的学习系统利用类神经网络。类神经网络通过CPU的快速计算能力，可具有推论结果的能力。类神经网络经过学习可拥有推论能力。也就是说，对类神经网络事先设定，何种状况会得到何种结果。对类神经网络输入越多正确的范例(状况+结果)，类神经网络就能够愈正确的回答，甚至于没有学过的范例，类神经网络也能告诉你可能的结果。本发明实施例以类神经网络中的监督式学习应用为例。</p>
    <p>[0040]	图3显示监督式学习应用的类神经网络的一例。如图3所示，类神经网络包括输入层、隐藏层与输出层。虽然图3只显示出一个隐藏层，实际上网神经网络可能包括多个隐藏层(当然，将会影响运算速度、资源消耗等)。</p>
    <p>[0041]	如图3所示，类神经网络的输入层接收使用者手写速度参数、使用者手写压力参数、与使用者修改次数参数，其细节如上述所示。</p>
    <p>[0042]	隐藏层包括运算处理单元(比如是图1中的处理单元130)。隐藏层包括一些函式。</p>
    <p>[0043]	为方便解释，在本发明实施例中，假设速度初始键结值:0.4、压力初始键结值:0.5、修改次数初始键结值:0.1。当知本发明并不受限于此。在图3中，键结值以Wij来表</p>
    <p>/Jn ο</p>
    <p>[0044]	得到三个输入参数后，对此三个输入参数与其各别链接值Wij计算得出数值，由隐藏层加总后至输出层，以做为输出结果(这可视为对使用者的目前情绪分数)。如果使用者有反馈其情绪分数的话(比如使用者通过触控装置来输入其自己所认为的情绪分数)，对所判断出的使用者目前情绪分数与使用者反馈的情绪分数取差值(亦即以使用者所反馈的情绪分数当成参考值)，根据此差值来调整/训练各别键结Wij值。经过多次训练后，类神经网络的判断会越来越准确，甚至进而达到稳定值。</p>
    <p>[0045]	比如，类神经网络的隐藏层的学习算法的式子如下:</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103257736A/CN103257736AD00071.png"> <img id="idf0001" file="CN103257736AD00071.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103257736A/CN103257736AD00071.png" class="patent-full-image" alt="Figure CN103257736AD00071"> </a> </div>
    <p>[0048]	在上式(I)与⑵中:</p>
    <p>[0049]	Tj为第j个单元的目标输出值，j为正整数，以图3为例，图3有3个单元(j =3)；</p>
    <p>[0050]	为第η层的第j个单元输出值，η为正整数，以图3为例，图3有3层(η = 3);</p>
    <p>[0051]	为第η层第j个单元的目标输出和实际输出值之间的误差值；</p>
    <p>[0052]	Π为学习率；</p>
    <p>[0053]	AWij为需要修正的键结值量；</p>
    <p>[0054]	为集成函数，其将从其它处理单元转来的信息加以综合；</p>
    <p>[0055]	f' (.)为转换函数,其将作用函数的输出值转换成处理单元的输出值。</p>
    <p>[0056]	在本发明实施例中，集成函数比如但不受限于为加权乘积合，而转换函数则比如但不受限于为无门限性函数。</p>
    <p>[0057]	底下说明本发明实施例的训练类神经网络的一个流程范例，当知本发明并不受限于此。使用者在触控装置手写输入，系统(比如是触控电路112与手写输入识别软件122)取得速度参数、压力参数与修改次数参数等手写输入特征。此外，于不同系统中，可对这些参数定义分别定义其最大值与最小值，且对之正规化(使正规化后参数介于O&#12316;I之间)。为方便说明，假设使用者的某一次手写输入的速度参数、压力参数与修改次数参数分别为0.7,0.7 与 0.5。[0058]	根据三个初始化键结值与(正规化后)的这三个参数，计算出情绪分数(比如，将此三个参数分别与其初始化键结值相乘，取其总和)。以上例而言，情绪分数为:</p>
    <p>0.7*0.4+0.7*0.5+0.5*0.1 = 0.64。</p>
    <p>[0059]	对情绪分数进行分类，并将分类结果/以及情绪分数显示于屏幕上给使用者认知。</p>
    <p>[0060]	于使用者看到情绪分类结果/以及情绪分数后，系统亦要求使用者回复其情绪分类及/或情绪分数。对于使用者的回复，将其正规化到O&#12316;I (假设为0.9)。</p>
    <p>[0061]目标输出值和实际输出值差距为0.9-0.64 = 0.26。根据此差值，计算出每个键结值的修正值分别为(比如，修正值=手写特征参数值*链接值*差值):</p>
    <p>[0062]	速度键结值的修正值:0.4*0.26*0.7 = 0.0728。</p>
    <p>[0063]	压力键结值的修正值:0.5*0.26*0.7 = 0.091。</p>
    <p>[0064]	修改次数键结值的修正值:0.1*0.26*0.5 = 0.013。</p>
    <p>[0065]	修正后的键结值分别为(比如为初始键结值加上键结值的修正值):</p>
    <p>[0066]	修正后的速度键结值:0.4+0.0728 = 0.4728。</p>
    <p>[0067]	修正后的压力键结值:0.5+0.091 = 0.591。</p>
    <p>[0068]	修正后的修改次数键结值:0.1+0.013 = 0.113。</p>
    <p>[0069]	再将修正后的 链接值正规化至O&#12316;I之间，分别变成:</p>
    <p>[0070](正规化后)速度链接值:0.401。</p>
    <p>[0071](正规化后)压力链接值:0.502。</p>
    <p>[0072](正规化后)修改次数链接值:0.097。</p>
    <p>[0073]	经过多次训练(也就是经过多次使用者回复，系统修正其链接值)，键结值会慢慢收敛到稳定状态。</p>
    <p>[0074]	所以，在本发明实施例中，可以将使用者的反馈当作该次的目标(参数)输出值，进行情绪检测以及学习，不必重新训练类神经网络后，才进行学习。</p>
    <p>[0075]	现请参考图4，其显示根据本发明另一实施例的使用者情绪检测流程图。步骤410&#12316;470与步骤480原则上可相同或相似于图2的步骤210&#12316;270与步骤280，故其细节在此省略。</p>
    <p>[0076]	于步骤475中，判断差值(使用者反馈分数与所判断出的情绪分数间的差值)是否大于一误差门坎值，且此类神经网络的训练次数是否大于一训练次数门坎值。如果步骤475为是的话，则放弃此次的训练(步骤490)，也就是说，因为差值(亦即误差值)大于误差门坎值的话，可以将这次的判断结果当作不正确的数据而忽略。如果步骤475的判断结果为否的话，则进行步骤480。</p>
    <p>[0077]	本发明上述实施例能够使用在任何运用到手写输入的电子装置上，并且让使用者能够了解其情绪，适时做出提醒。故而，本实施例可以应用在许多个人化的装置上，如手机，平板计算机...等。甚至，本实施例也可用在提供情绪记录方面，例如，将本实施例应用于电子书包的话，家长/老师可以了解子女/学生的情绪变化。甚至，随着学习算法的效率改良，本实施例的应用可以更加人性化，以及增加学习效率。</p>
    <p>[0078]	综上所述，虽然本发明已以实施例揭露如上，然其并非用以限定本发明。本发明所属技术领域中具有通常知识者，在不脱离本发明的精神和范围内，当可作各种的更动与润饰。因此，本 发明的保护范围当视所附的权利要求范围所界定者为准。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101370195A?cl=zh">CN101370195A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年8月16日</td><td class="patent-data-table-td patent-date-value">2009年2月18日</td><td class="patent-data-table-td ">英华达(上海)电子有限公司</td><td class="patent-data-table-td ">移动终端中实现情绪调节的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101930735A?cl=zh">CN101930735A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年6月23日</td><td class="patent-data-table-td patent-date-value">2010年12月29日</td><td class="patent-data-table-td ">富士通株式会社</td><td class="patent-data-table-td ">语音情感识别设备和进行语音情感识别的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102193620A?cl=zh">CN102193620A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年3月2日</td><td class="patent-data-table-td patent-date-value">2011年9月21日</td><td class="patent-data-table-td ">三星电子（中国）研发中心</td><td class="patent-data-table-td ">一种基于表情识别的输入方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DTW%26NR%3D200836112A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHzc0PQ1Tyho0zNRQnHyD1Y_ZPB9w">TW200836112A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DTW%26NR%3DM383932U%26KC%3DU%26FT%3DD&amp;usg=AFQjCNE4vgB0v4gPeikNfE_xXpuorp-PBQ">TWM383932U</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110217679">US20110217679</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年11月5日</td><td class="patent-data-table-td patent-date-value">2011年9月8日</td><td class="patent-data-table-td ">Carmel-Haifa University Economic Corporation Ltd.</td><td class="patent-data-table-td ">Diagnosis method and system based on handwriting analysis</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003041000">G06F3/041</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F2203/011">G06F2203/011</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00436">G06K9/00436</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/04883">G06F3/04883</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/011">G06F3/011</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/6263">G06K9/6263</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/017">G06F3/017</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=kh_OCAABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/62">G06K9/62</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年8月21日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年9月18日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年2月24日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/d5efedb81bcfd4f80473/CN103257736A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BD%BF%E7%94%A8%E8%80%85%E6%83%85%E7%BB%AA%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8%E5%85%B6.pdf?id=kh_OCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0jVQxz7eePO9nWJZp5hXDVQWHlIg"},"sample_url":"https://www.google.com/patents/reader?id=kh_OCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>