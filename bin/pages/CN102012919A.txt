<!DOCTYPE html><html><head><title>专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="电视截屏图像关联搜索方法、装置及数字电视终端"><meta name="DC.contributor" content="罗金华" scheme="inventor"><meta name="DC.contributor" content="谢俊" scheme="inventor"><meta name="DC.contributor" content="深圳市同洲电子股份有限公司" scheme="assignee"><meta name="DC.date" content="2010-11-26" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种电视截屏图像关联搜索方法，包括如下步骤：取得电视截屏图像中的人脸图像部分；对所述人脸图像进行识别并将其转换为关键词；用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。本发明还涉及一种电视截屏图像关联搜索装置及数字电视终端。实施本发明的电视截屏图像关联搜索方法、装置及数字电视终端，具有以下有益效果：其操作步骤较为简单，且均在数字电视终端上完成，不需要附加的设备。"><meta name="DC.date" content="2011-4-13"><meta name="DC.relation" content="CN:101387824:A" scheme="references"><meta name="DC.relation" content="CN:101883230:A" scheme="references"><meta name="citation_reference" content="《计算机工程》 20041031 宋红等 视频图像中的实时人脸检测方法 第23至24页以及第158页 1-8 第30卷, 第19期"><meta name="citation_reference" content="《计算机工程与应用》 20031231 徐杰等 基于Gabor小波特征的多姿态人脸图像识别 3-5,8-10 , 第21期"><meta name="citation_reference" content="《计算机工程与应用》 20031231 徐杰等 基于Gabor小波特征的多姿态人脸图像识别 3-5,8-10 , 第21期 2"><meta name="citation_patent_publication_number" content="CN:102012919:A"><meta name="citation_patent_application_number" content="CN:201010561654"><link rel="canonical" href="https://www.google.com/patents/CN102012919A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102012919A?cl=zh"/><meta name="title" content="专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端"/><meta name="description" content="本发明涉及一种电视截屏图像关联搜索方法，包括如下步骤：取得电视截屏图像中的人脸图像部分；对所述人脸图像进行识别并将其转换为关键词；用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。本发明还涉及一种电视截屏图像关联搜索装置及数字电视终端。实施本发明的电视截屏图像关联搜索方法、装置及数字电视终端，具有以下有益效果：其操作步骤较为简单，且均在数字电视终端上完成，不需要附加的设备。"/><meta property="og:title" content="专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102012919A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102012919A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=dkNyBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102012919A&amp;usg=AFQjCNGM40Gh2nUuQpJFjDsCv1a5V_iSOw" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/f9e6fcf4af2a439f7609/CN102012919A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/f9e6fcf4af2a439f7609/CN102012919A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102012919A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102012919A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102012919A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102012919B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102012919A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种电视截屏图像关联搜索方法，包括如下步骤：取得电视截屏图像中的人脸图像部分；对所述人脸图像进行识别并将其转换为关键词；用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。本发明还涉及...</span><span itemprop="url">https://www.google.com/patents/CN102012919A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端" title="专利 CN102012919A - 电视截屏图像关联搜索方法、装置及数字电视终端"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102012919 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010561654</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年4月13日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年11月26日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年11月26日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102012919B?hl=zh-CN&amp;cl=zh">CN102012919B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010561654.3, </span><span class="patent-bibdata-value">CN 102012919 A, </span><span class="patent-bibdata-value">CN 102012919A, </span><span class="patent-bibdata-value">CN 201010561654, </span><span class="patent-bibdata-value">CN-A-102012919, </span><span class="patent-bibdata-value">CN102012919 A, </span><span class="patent-bibdata-value">CN102012919A, </span><span class="patent-bibdata-value">CN201010561654, </span><span class="patent-bibdata-value">CN201010561654.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%BD%97%E9%87%91%E5%8D%8E%22">罗金华</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B0%A2%E4%BF%8A%22">谢俊</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B7%B1%E5%9C%B3%E5%B8%82%E5%90%8C%E6%B4%B2%E7%94%B5%E5%AD%90%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">深圳市同洲电子股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102012919A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102012919A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102012919A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (10),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (4)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=dkNyBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010561654&amp;usg=AFQjCNEOSIeMGDLVLpfNno6FC-qkUQ-fbA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=dkNyBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102012919A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEc9e8yMT3usisrRNTXq1QxDyyYqQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT102457040" lang="ZH" load-source="patent-office">电视截屏图像关联搜索方法、装置及数字电视终端</invention-title>
      </span><br><span class="patent-number">CN 102012919 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA84406434" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种电视截屏图像关联搜索方法，包括如下步骤：取得电视截屏图像中的人脸图像部分；对所述人脸图像进行识别并将其转换为关键词；用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。本发明还涉及一种电视截屏图像关联搜索装置及数字电视终端。实施本发明的电视截屏图像关联搜索方法、装置及数字电视终端，具有以下有益效果：其操作步骤较为简单，且均在数字电视终端上完成，不需要附加的设备。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM35571810" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种电视截屏图像关联搜索方法，其特征在于，包括如下步骤：A)取得电视截屏图像中的人脸图像部分；B)对所述人脸图像进行识别并将其转换为关键词；C)用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的电视截屏图像关联搜索方法，其特征在于，所述步骤A)进 一步包括：Al)控制正在播放电视节目并取得其中的图像；A2)选择所述取得图像中的完整的人脸部分并将其转换为位图。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的电视截屏图像关联搜索方法，其特征在于，所述步骤B)进 一步包括：Bi)利用人脸识别技术，对所述取得的人脸图像进行处理，将其转换为多个参数；B2)在数据库中查找其参数与所述取得参数一致的关键词。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3所述的电视截屏图像关联搜索方法，其特征在于，所述数据库中存 储有多个多个关键词以及由人脸识别技术分别通过对与所述关键词相关的人脸图像处理 后得到的多个参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的电视截屏图像关联搜索方法，其特征在于，所述步骤C)进 一步包括：Cl)将所述取得的关键词提交给互联网搜索引擎； C2)所述搜索引擎在互联网上搜索与所述关键词相关的链接； C3)显示取得的搜索结果及链接。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6.&#8212;种电视截屏图像关联搜索装置，其特征在于，包括如下装置： 图像取得装置，用于取得电视截屏图像中的人脸图像部分；图像识别模块，用于对所述人脸图像进行识别并将其转换为关键词；搜索模块，用于使用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的电视截屏图像关联搜索装置，其特征在于，所述图像取得装 置进一步包括：用于取得正在播放电视节目中的图像的播放控制模块以及用于选择所述 取得图像中的完整的人脸部分并将其转换为位图的图像处理模块；所述图像处理模块包 括用于在取得的电视节目图像中选择其人脸部分的图像选择单元和将所述选择部分转换 为位图的位图转换单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的电视截屏图像关联搜索装置，其特征在于，所述图像识别模 块进一步包括：用于对所述取得的人脸图像进行处理，将其转换为多个参数的人脸识别 单元、用于在数据库中查找其参数与所述取得参数一致的关键词的数据库查找单元以及 用于取得所述关键词的关键词取得单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的电视截屏图像关联搜索装置，其特征在于，还包括用于输入 关键词并将所述关键词分别和与其相关的图像识别参数关联后存入数据库的关键词输入 单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.&#8212;种数字电视终端，其特征在于，所述数字电视终端包括如权利要求6-9任意一 项所述的电视截屏图像关联搜索装置。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES41364584" lang="ZH" load-source="patent-office" class="description">
    <p>电视截屏图像关联搜索方法、装置及数字电视终端</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及数字电视领域，更具体地说，涉及一种电视截屏图像关联搜索方 法、装置及数字电视终端。</p>
    <p>背景技术</p>
    <p>[0002]	技术的发展使得人们可以实现之前不能或不易实现的要求或愿望。例如， 在以前人们观看电视时即使对其中的某个演员有兴趣、希望进一步了解时，并不能立即 得知，需要查找许多资料后才能得到一个结果；但是在今天，人们则可以通过互联网上 的海量信息，迅速地、较为准确地得到关于这个演员的资料；当然，前提是人们要知道 该演员的姓名，在电脑上输入其姓名查找就可以。但是，这样的操作随着技术的进步而 使人们感到较为繁琐，这种方法中首先需要得知演员姓名，其次需要在与电视系统不同 的、与互联网连接的电脑上进行查找。虽然可以实现目的，但是，在提倡三网合一的今 天，这种方法较为繁琐，其需要的设备或装置较多。因此，一种较为简单的、不需要附 加设备的搜索方法就变得很有必要。</p>
    <p>发明内容</p>
    <p>[0003]	本发明要解决的技术问题在于，针对现有技术的上述操作较为繁琐、需要的设 备或装置较多的缺陷，提供一种操作较为简单、不需要附加设备的电视截屏图像关联搜 索方法、装置及数字电视终端。</p>
    <p>[0004]	本发明解决其技术问题所采用的技术方案是：构造一种电视截屏图像关联搜索 方法，包括如下步骤：</p>
    <p>A)取得电视截屏图像中的人脸图像部分；</p>
    <p>B)对所述人脸图像进行识别，将其转换为关键词；</p>
    <p>C)用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。</p>
    <p>[0005]	在本发明所述的电视截屏图像关联搜索方法中，所述步骤A)进一步包括： Al)取得正在播放电视节目中的图像，将其转换为位图；</p>
    <p>A2)选择所述位图中的完整的人脸部分。</p>
    <p>[0006]	在本发明所述的电视截屏图像关联搜索方法中，所述步骤B)进一步包括： Bi)利用人脸识别技术，对所述取得的人脸图像进行处理，将其转换为多个参</p>
    <p>数；</p>
    <p>B2)在数据库中查找其参数与所述取得参数一致的关键词。</p>
    <p>[0007]	在本发明所述的电视截屏图像关联搜索方法中，所述数据库中存储有多个多个 关键词以及由人脸识别技术分别通过对与所述关键词相关的人脸图像处理后得到的多个 参数。</p>
    <p>[0008]	在本发明所述的电视截屏图像关联搜索方法中，所述步骤C)进一步包括： Cl)将所述取得的关键词提交给互联网搜索引擎；C2)所述搜索引擎在互联网上搜索与所述关键词相关的链接； C3)显示所述链接。</p>
    <p>[0009]	本发明还涉及一种电视截屏图像关联搜索装置，包括如下装置： 图像取得装置，用于取得电视截屏图像中的人脸图像部分；</p>
    <p>图像识别模块，用于对所述人脸图像进行识别并将其转换为关键词；</p>
    <p>搜索模块，用于使用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接。</p>
    <p>[0010]	在本发明所述的电视截屏图像关联搜索装置中，所述图像取得装置进一步包 括：用于取得正在播放电视节目中的图像的播放控制模块以及用于选择所述取得图像中 的完整的人脸部分并将其转换为位图的图像处理模块；所述图像处理模块包括用于在取 得的电视节目图像中选择其人脸部分的图像选择单元和将所述选择部分转换为位图的位 图转换单元。</p>
    <p>[0011]	在本发明所述的电视截屏图像关联搜索装置中，所述图像识别模块进一步包 括：用于对所述取得的人脸图像进行处理，将其转换为多个参数的人脸识别单元、用于 在数据库中查找其参数与所述取得参数一致的关键词的数据库查找单元以及用于取得所 述关键词的关键词取得单元。</p>
    <p>[0012]	在本发明所述的电视截屏图像关联搜索装置中，还包括用于输入关键词并将所 述关键词分别和与其相关的图像识别参数关联后存入数据库的关键词输入单元。</p>
    <p>[0013]	本发明还涉及一种数字电视终端，所述数字电视终端包括电视截屏图像关联搜 索装置；所述数字电视截屏图像关联搜索装置进一步包括用于取得电视截屏图像中的人 脸图像部分的图像取得装置、用于对所述人脸图像进行识别并将其转换为关键词的图像 识别模块以及用于使用所述关键词在互联网上进行搜索并显示取得的搜索结果及链接的 搜索模块，。</p>
    <p>[0014]	实施本发明的电视截屏图像关联搜索方法、装置及数字电视终端，具有以下有 益效果：由于直接由正在播放的电视节目中截屏而得到图像，并直接利用事先通过同一 人脸识别技术处理而得到的参数比对进而得到关键词，在互联网上搜索并显示结果，所 以其操作步骤较为简单，且均在数字电视系统上完成，不需要附加的设备。</p>
    <p>附图说明</p>
    <p>[0015]	图1是本发明电视截屏图像关联搜索方法、装置及数字电视终端实施例中搜索 方法流程图；</p>
    <p>图2是所述实施例中搜索装置结构示意图。</p>
    <p>具体实施方式</p>
    <p>[0016]	下面将结合附图对本发明实施例作进一步说明。</p>
    <p>[0017]	如图1所示，在本发明电视截屏图像关联搜索方法、装置及数字电视终端实施 例中，其电视截屏图像关联搜索方法包括如下步骤：</p>
    <p>步骤SlOl暂停播放并取得当前显示的图像：在本实施例中，该电视截屏图像关联 搜索方法是在电视播放的过程中实施的。当电视在播放时，其接收到的图像在不断地变</p>
    <p>5化，在本步骤中，先将正在播放的电视停下来，使其图像“定格”，实际上就是选择恰 当的时间，使得电视机不再播放，将其由播放模式转换到另一种状态，也就是关联搜索 模式；即将当时的一个帧的图像保存下来，并将其显示出来。</p>
    <p>[0018]	步骤S102选择上述图像中人脸部分，将图像转换为位图：在本步骤中，在上述 截屏取得的图像中进行选择，这种选择通常都是选择一个区域；由于该选择区域的图像 在之后的程序中要对其进行识别，而识别一个人（演员）的较好的方法是对其脸部进行 识别，所以在本实施例中，在上述截屏而得的图像中选择其人脸部分，并且，将选中部 分的图像转换为位图，便于之后的处理。一般来讲，对人脸进行识别时最好是其正面的 图像，这种图像最大限度地表现了不同人之间的特点，这使得后续步骤中对人脸的识别 变得较为容易，也较为准确。</p>
    <p>[0019]	步骤S103对位图进行识别，将该选择部分图像转换为多个参数：在本步骤中， 对上述得到的位图进行识别，我们知道，通常的人脸识别是将具有人脸特点的图像分为 多个部分，并在各个部分将其图像特定转换为一定的参数。不同的人，其脸的图像不 同，最后得到的参数也不同，这样就将不同人区分开了；当然，进行这种转换需要专 门的算法，不同的算法得到的结果可能不同，并且不同的算法之间得到的参数也可能不 同，不具有可比性。所以，在本实施例中，需要使用同一种算法，也就是同一种识别技 术。并且不仅仅是在识别过程中，当事先将演员的数据存在数据库时，其使用的识别技 术也应该与之后识别过程中使用相同的识别技术。</p>
    <p>[0020]	步骤S104在数据库中查找与上述参数匹配的关键词：在上述步骤中将取得的 图像中的选择部分转换为一些该识别技术特有的参数时，在数据库中查找与这些参数相 同或相近的参数。在本实施例中，数据库中有事先存储的数据，这些数据包括多个关键 词以及分别与该关键词对应的多个参数，一个关键词可以对应多个参数；这些关键词是 事先输入的，而这些与该关键词对应的参数是通过同样的识别技术对该关键词所对应的 图像或照片进行识别后得到的，这些参数被设置到该关键词下，并与之对应；在本步骤 中，就是依据上述步骤中取得的、对电视截屏图像中选择部分进行识别后得到的参数， 在数据库中查找与其相同或相近似的参数。</p>
    <p>[0021]	步骤S105找到？在本步骤中，判断是否在数据库中找到相同或相对应的参数， 如果找到，执行步骤S107，如果未找到，执行步骤S106。</p>
    <p>[0022]	步骤S106返回未找到信息：在本步骤中，由于在数据库中没有找到与取得参 数相同或相近似的参数，表明不能识别该选择图像，于是，返回错误信息并退出搜索模 式。</p>
    <p>[0023]	步骤S107取得该关键词：在本步骤中，在数据库中找到了与取得参数相同或 相近似的参数，表明对该选择图像识别成功，于是，取得数据库中这些参数对应的关键 词，作为识别结果。</p>
    <p>[0024]	步骤S108在互联网上对取得的关键词进行搜索：在本步骤中，对上述关键词进 行搜索。首先，将上述取得的关键词输送到搜索引擎，之后，启动搜索引擎对该关键词 在互联网上进行搜索。在本实施例中，上述搜索引擎是现有的，其与互联网通过有线电 视的HFC网络连接，当搜索引擎被启动时，其直接连接互联网并开始搜索，因此，不需 要其他的附加上网设备就可以完成上述搜索。[0025]	步骤S109将搜索结果显示出来：在本步骤中，将上述搜索引擎对关键词的搜索 结果显示出来，在本实施例中，主要是显示该演员的介绍、作品及作品连接。这使得人 们在了解该演员的同时，可以直接通过数字电视终端观看互联网上的该演员的作品，操 作较为简单、不需要附加的设备。</p>
    <p>[0026]	本实施例中还揭示了一种电视截屏图像关联搜索装置，图2示出了该装置的结 构示意图。如图2所示，在该装置中，包括播放控制模块1、图像处理模块2、图像识 别模块3以及搜索模块4，其中，播放控制模块1和图像处理模块2构成图像取得装置， 该图像取得装置用于取得电视截屏图像中的人脸图像部分；而图像识别模块3用于对上 述图像取得装置所取得的图像（具体而言，该图像是演员的人脸图像）进行识别并将其 转换为关键词；搜索模块4用于使用上述得到的关键词在互联网上进行搜索并显示取得 的搜索结果及链接。在本实施例中，上述搜索结果包括演员关联信息包含国籍、出生日 期、出演过的电视剧名以及点播链接、出演过的电影以及点播链接、发行过的唱片专辑 以及试听链接等。</p>
    <p>[0027]	在本实施例中，如上所述，图像取得装置由播放控制模块1和图像处理模块2 构成。其中播放控制模块1用于取得正在播放电视节目中的图像，这是通过将数字电视 终端由播放模式转换为搜索模式，并取得当前电视图像中的一帧或两帧图像数据而实现 的；图像处理模块2用于选择所述取得图像中的完整的人脸部分并将其转换为位图；图 像处理模块2又包括用于在取得的电视节目图像中选择其人脸部分的图像选择单元21和 将上述选择部分转换为位图的位图转换单元22。在本实施例中，图像识别模块3包括用 于对上述取得的人脸图像进行处理（也就是识别）并将其转换为多个参数的人脸识别单 元41、用于在数据库中查找其参数与上述取得参数一致的关键词的数据库查找单元42以 及用于取得上述关键词的关键词取得单元43。此外，上述搜索模块4包括了搜索引擎41 和显示单元42，其中搜索引擎41用于在取得关键词后在互联网上进行相关搜索，而显示 单元42则是将上述搜索引擎41取得的结果显示出来，这些结果包括演员的国籍、出生日 期、出演过的电视剧名以及点播链接、出演过的电影以及点播链接、发行过的唱片专辑 以及试听链接等。</p>
    <p>[0028]	此外，在本实施例中，该搜索装置还包括用于输入关键词并将该关键词分别和 与其相关的图像识别参数关联后存入数据库的关键词输入单元（图中未示出）。</p>
    <p>[0029]	本实施例中还揭示了一种数字电视终端，其用于接收数字电视信号并显示，该 数字电视终端可以是机顶盒加上电视机，也可以是数字电视一体机或数字电视网络接收 设备，在本实施例中，是机顶盒加上电视机，该机顶盒中除设置有常见的功能模块外。 还设置有上述电视截屏图像关联搜索装置。这种设置使得该机顶盒具有由电视图像中取 得截屏图像，并以此为依据在互联网上搜索并显示搜索结果的功能。在其他实施例中， 上述电视截屏图像关联搜索装置也可以设置在数字电视一体机或数字电视网络接收设备 内。</p>
    <p>[0030]	以上所述实施例仅表达了本发明的几种实施方式，其描述较为具体和详细，但 并不能因此而理解为对本发明专利范围的限制。应当指出的是，对于本领域的普通技术 人员来说，在不脱离本发明构思的前提下，还可以做出若干变形和改进，这些都属于本 发明的保护范围。因此，本发明专利的保护范围应以所附权利要求为准。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101387824A?cl=zh">CN101387824A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年9月13日</td><td class="patent-data-table-td patent-date-value">2009年3月18日</td><td class="patent-data-table-td ">鸿富锦精密工业（深圳）有限公司;鸿海精密工业股份有限公司</td><td class="patent-data-table-td ">照片内容自动注解系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101883230A?cl=zh">CN101883230A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月31日</td><td class="patent-data-table-td patent-date-value">2010年11月10日</td><td class="patent-data-table-td ">中山大学</td><td class="patent-data-table-td ">一种数字电视演员检索方法及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《计算机工程》 20041031 宋红等 视频图像中的实时人脸检测方法 第23至24页以及第158页 1-8 第30卷, 第19期</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《计算机工程与应用》 20031231 徐杰等 基于Gabor小波特征的多姿态人脸图像识别 3-5,8-10 , 第21期</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《计算机工程与应用》 20031231 徐杰等 基于Gabor小波特征的多姿态人脸图像识别 3-5,8-10 , 第21期 2</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102158732A?cl=zh">CN102158732A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年4月22日</td><td class="patent-data-table-td patent-date-value">2011年8月17日</td><td class="patent-data-table-td ">深圳创维－Rgb电子有限公司</td><td class="patent-data-table-td ">基于电视画面的信息搜索方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102868934A?cl=zh">CN102868934A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td patent-date-value">2013年1月9日</td><td class="patent-data-table-td ">青岛海信传媒网络技术有限公司</td><td class="patent-data-table-td ">基于智能电视的视频对象信息检索方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103051934A?cl=zh">CN103051934A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年10月14日</td><td class="patent-data-table-td patent-date-value">2013年4月17日</td><td class="patent-data-table-td ">中国科学院计算技术研究所</td><td class="patent-data-table-td ">智能电视人机交互方法、装置和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103064972A?cl=zh">CN103064972A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月8日</td><td class="patent-data-table-td patent-date-value">2013年4月24日</td><td class="patent-data-table-td ">深圳市中兴移动通信有限公司</td><td class="patent-data-table-td ">移动终端图像检索的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103096182A?cl=zh">CN103096182A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年11月4日</td><td class="patent-data-table-td patent-date-value">2013年5月8日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">一种网络电视节目信息的分享方法和系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103246682A?cl=zh">CN103246682A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年2月13日</td><td class="patent-data-table-td patent-date-value">2013年8月14日</td><td class="patent-data-table-td ">联想(北京)有限公司</td><td class="patent-data-table-td ">数据搜索方法和数据搜索装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103338405A?cl=zh">CN103338405A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年6月3日</td><td class="patent-data-table-td patent-date-value">2013年10月2日</td><td class="patent-data-table-td ">四川长虹电器股份有限公司</td><td class="patent-data-table-td ">一种截屏应用的方法、设备及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103428537A?cl=zh">CN103428537A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月30日</td><td class="patent-data-table-td patent-date-value">2013年12月4日</td><td class="patent-data-table-td ">北京小米科技有限责任公司</td><td class="patent-data-table-td ">一种视频处理方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104536995A?cl=zh">CN104536995A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年12月12日</td><td class="patent-data-table-td patent-date-value">2015年4月22日</td><td class="patent-data-table-td ">北京奇虎科技有限公司</td><td class="patent-data-table-td ">基于终端界面触控操作进行搜索的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013037082A1?cl=zh">WO2013037082A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月12日</td><td class="patent-data-table-td patent-date-value">2013年3月21日</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Using gestures to capture multimedia clips</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=dkNyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=dkNyBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年4月13日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年6月1日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年8月7日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年12月16日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of patent application or patent right or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/f9e6fcf4af2a439f7609/CN102012919A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%94%B5%E8%A7%86%E6%88%AA%E5%B1%8F%E5%9B%BE%E5%83%8F%E5%85%B3%E8%81%94%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95_%E8%A3%85.pdf?id=dkNyBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2-KfDtlTMPTJRWW9nTh0KhCPRxig"},"sample_url":"https://www.google.com/patents/reader?id=dkNyBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>