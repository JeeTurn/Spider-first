<!DOCTYPE html><html><head><title>专利 CN101819631A - 一种身份识别方法和身份识别系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种身份识别方法和身份识别系统"><meta name="DC.contributor" content="沈琳琳" scheme="inventor"><meta name="DC.contributor" content="深圳大学" scheme="assignee"><meta name="DC.date" content="2010-4-16" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及身份识别技术，针对现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的缺陷，提供一种身份识别方法和身份识别系统。方法包括：采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；对人脸特征图像和掌纹特征图像进行Gabor滤波；融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特征；通过将待识别用户的身份特征与身份特征库中的身份特征进行匹配，来对该待识别用户进行身份识别。本发明可有效的解决现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的问题。"><meta name="DC.date" content="2010-9-1"><meta name="DC.relation" content="CN:101281598:A" scheme="references"><meta name="DC.relation" content="CN:1341401:A" scheme="references"><meta name="DC.relation" content="US:20040234131:A1" scheme="references"><meta name="citation_reference" content="《中国图象图形学报》 20071231 黄申 等 采样式多通道Gabor滤波对掌纹的特征提取和分类 第12卷, 第12期 2"><meta name="citation_reference" content="《深圳大学学报理工版》 20080131 SHEN Lin-lin et al Automatic face recognition based on skin masking and improved HMM 第25卷, 第1期 2"><meta name="citation_patent_publication_number" content="CN:101819631:A"><meta name="citation_patent_application_number" content="CN:201010148570"><link rel="canonical" href="https://www.google.com/patents/CN101819631A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101819631A?cl=zh"/><meta name="title" content="专利 CN101819631A - 一种身份识别方法和身份识别系统"/><meta name="description" content="本发明涉及身份识别技术，针对现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的缺陷，提供一种身份识别方法和身份识别系统。方法包括：采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；对人脸特征图像和掌纹特征图像进行Gabor滤波；融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特征；通过将待识别用户的身份特征与身份特征库中的身份特征进行匹配，来对该待识别用户进行身份识别。本发明可有效的解决现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的问题。"/><meta property="og:title" content="专利 CN101819631A - 一种身份识别方法和身份识别系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101819631A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101819631A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=yxV6BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101819631A&amp;usg=AFQjCNFTj1seXY8fQuSrou9bq9yIQtcVEg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/eefae7c5047178d2132d/CN101819631A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/eefae7c5047178d2132d/CN101819631A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101819631A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101819631A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101819631A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101819631B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101819631A?cl=zh" style="display:none"><span itemprop="description">本发明涉及身份识别技术，针对现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的缺陷，提供一种身份识别方法和身份识别系统。方法包括：采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和...</span><span itemprop="url">https://www.google.com/patents/CN101819631A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101819631A - 一种身份识别方法和身份识别系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101819631A - 一种身份识别方法和身份识别系统" title="专利 CN101819631A - 一种身份识别方法和身份识别系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101819631 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010148570</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年9月1日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年4月16日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年4月16日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101819631B?hl=zh-CN&amp;cl=zh">CN101819631B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010148570.7, </span><span class="patent-bibdata-value">CN 101819631 A, </span><span class="patent-bibdata-value">CN 101819631A, </span><span class="patent-bibdata-value">CN 201010148570, </span><span class="patent-bibdata-value">CN-A-101819631, </span><span class="patent-bibdata-value">CN101819631 A, </span><span class="patent-bibdata-value">CN101819631A, </span><span class="patent-bibdata-value">CN201010148570, </span><span class="patent-bibdata-value">CN201010148570.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B2%88%E7%90%B3%E7%90%B3%22">沈琳琳</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B7%B1%E5%9C%B3%E5%A4%A7%E5%AD%A6%22">深圳大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101819631A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101819631A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101819631A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=yxV6BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010148570&amp;usg=AFQjCNFKoYy-b8xnW2EATJwOWtodOAMaoQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=yxV6BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101819631A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHOZum-mFNKmmNbiVOjCcIycBQ0wQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT97539873" lang="ZH" load-source="patent-office">一种身份识别方法和身份识别系统</invention-title>
      </span><br><span class="patent-number">CN 101819631 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA80049008" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及身份识别技术，针对现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的缺陷，提供一种身份识别方法和身份识别系统。方法包括：采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；对人脸特征图像和掌纹特征图像进行Gabor滤波；融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特征；通过将待识别用户的身份特征与身份特征库中的身份特征进行匹配，来对该待识别用户进行身份识别。本发明可有效的解决现有基于单一一种生物特征的身份识别技术的准确度和鲁棒性相对较差的问题。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><ol mxw-id="PCLM33036542" lang="ZH" load-source="patent-office" class="claims">
    <li class="claim"> <div num="1" class="claim">
      <div class="claim-text">一种身份识别方法，其特征在于，包括：提取步骤，包括：采集步骤，包括分别采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；滤波步骤，包括分别对人脸特征图像和掌纹特征图像进行Gabor滤波；编码步骤，包括分别对Gabor滤波后的人脸特征图像和Gabor滤波后的掌纹特征图像进行编码，得到对应的人脸特征编码和掌纹特征编码；融合步骤，包括融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特征；匹配步骤，包括通过将待识别用户的身份特征与身份特征库中的身份特征进行匹配，来对该待识别用户进行身份识别。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的身份识别方法，其特征在于，所述采集步骤进一步包括： 人脸特征图像采集步骤，包括：采集所述人脸图像，定位其中的双眼位置；旋转该人脸图像，使得旋转后的双眼位置连线处于水平位置；在旋转后的人脸图像中截取大小为128X128像素的部分作为人脸特征图像F(x，y)， 其中该人脸特征图像的中心为旋转后的人脸图像的中心。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的身份识别方法，其特征在于，所述采集步骤进一步包括： 掌纹特征图像采集步骤，包括：采集所述掌纹图像，定位其中食指和中指之间的角点，以及无名指和小拇指之间的角点旋转该掌纹图像，使得旋转后的双眼位置连线处于垂直位置； 在旋转后的掌纹图像中截取大小为128X128像素的部分作为掌纹特征图像P(x，y)， 其中该掌纹特征图像的中心为旋转后的掌纹图像的中心。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3所述的身份识别方法，其特征在于，在所述滤波步骤中， 所述对人脸特征图像进行Gabor滤波包括：分别基于多个Gabor小波{^ΛΑ，σ:ι|对所述人脸特征图像进行卷积操作，得到对应的多 个卷积图像拟(X，y)，i = 0，1，. . .，uv}，其中每一 Gabor小波表示为： &lt;formula&gt;formula see original document page 2&lt;/formula&gt;ι f /	ν其中，u为频率，ν为方向，人=h ,θν=、π尸=7，所述多个卷积图像表示为：&lt;formula&gt;formula see original document page 2&lt;/formula&gt;生成滤波后的人脸特征图像W(x，y)，其中W(x，y)表示为： &lt;formula&gt;formula see original document page 2&lt;/formula&gt;</div>
    </div>
    </li> <li class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的身份识别方法，其特征在于，在所述滤波步骤中， 所述对掌纹特征图像进行Gabor滤波包括：分别基于两个Gabor小波^⑹= O,lj对所述掌纹特征图像P (x，y)进行卷积操作， 得到对应的多个卷积图像{Gi(X，y)，i = 0，1}，其中每一 Gabor小波表示为：1	( (χ2 + v2)^φ(θ) O, y) = -~&#906; exP--2~ exp(y2^f (χ cos θ, + y sin6&gt;,.))λπσ y σ )其中，其中f = 0.0916，σ =5.6179，θ i = i ji/2，所述多个卷积图像表示为：bi (x，&gt;0|Gi (x，&gt;0 = F * (Piei)(x^y)J = ο,ι}生成滤波后的掌纹特征图像W(x，y)，其中W(x，y)表示为： W(x,y) =Gm(x'y) (x,y)其中 m(x, y) = arg max \\G' (χ, , / = 0,1。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的身份识别方法，其特征在于，所述编码步骤进一步包括： 计算滤波后的人脸特征图像W(x，y)每个像素的相位P(x，y)，依照如下公式生成人脸&lt;formula&gt;formula see original document page 3&lt;/formula&gt;</div>
    </div>
    </li> <li class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的身份识别方法，其特征在于，所述编码步骤进一步包括： 计算滤波后的掌纹特征图像W(x，y)每个像素的相位P(x，y)，依照如下公式生成人脸&lt;formula&gt;formula see original document page 3&lt;/formula&gt;</div>
    </div>
    </li> <li class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的身份识别方法，其特征在于，所述待识别用户的身份特征为 Xface-Paim= (bi(x, y), b2(x, y), b3(x, y), b4(x，y))，其中 bi(x, y) = b^^^x, y), b2(x, y)= b2face(x, y), b3(x, y) = Valm (x, y), b4(x, y) = b2palm(x, y)。</div>
    </div>
    </li> <li class="claim"> <div num="9" class="claim">
      <div class="claim-text">9. 一种身份识别系统，其特征在于，包括： 提取模块，包括：采集模块，用于分别采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图像和 掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像； 滤波模块，用于分别对人脸特征图像和掌纹特征图像进行Gabor滤波； 编码模块，用于分别对Gabor滤波后的人脸特征图像和Gabor滤波后的掌纹特征图像 进行编码，得到对应的人脸特征编码和掌纹特征编码；融合模块，用于融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特征； 匹配模块，用于通过将待识别用户的身份特征与身份特征库中的身份特征进行匹配， 来对该待识别用户进行身份识别。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的身份识别系统，其特征在于，所述采集模块进一步包括： 人脸特征图像采集模块，用于：采集所述人脸图像，定位其中的双眼位置；旋转该人脸图像，使得旋转后的双眼位置连线处于水平位置；在旋转后的人脸图像中截取大小为128X128像素的部分作为人脸特征图像F(x，y)，其中该人脸特征图像的中心为旋转后的人脸图像的中心。</div>
    </div>
  </li> </ol>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES38338011" lang="ZH" load-source="patent-office" class="description">
    <p>一种身份识别方法和身份识别系统</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及身份识别技术，更具体地说，涉及一种身份识别方法和身份识别系统。 背景技术</p>
    <p>[0002]	身份识别方法广泛应用于人们日常生活的方方面面。传统的身份识别方法主要包括两种，第一种是基于知识的身份识别方法，第二种是基于物品的身份识别方法。基于知识 的身份识别方法包括基于例如但不限于密码、口令等认证手段的身份识别方法，这种方法 存在的主要缺陷在于密码、口令等认证手段容易被忘记。基于物品的身份识别方法包括基 于例如但不限于钥匙、身份证、智能卡等认证手段的身份识别方法，这种方法存在的主要缺 陷在于钥匙、身份证、智能卡等认证手段容易丢失。因此，一旦认证手段被忘记、丢失或者被 其他人获取，个人身份就很容易被冒名者顶替。</p>
    <p>[0003]	相对传统身份识别方法，生物特征识别方法采用诸如人脸、指纹、掌纹等人体固有 特征进行身份识别，具有不会遗忘、丢失和很难被仿冒等优点，因此可以达到更安全的身份 认证目的。</p>
    <p>[0004]	各种不同的生物特征有不同的优缺点，因而可以应用于不同的应用场合。人脸是 人类最普遍采用的身份认证手段，具有采集简易、方便且隐蔽的优点，但是受光线等环境影 响较大；虹膜精确度高，但是采集困难，而且采集过程会给用户带来不舒适感；掌纹的精确 度介于人脸和虹膜之间，采集相对方便，受环境影响较小。</p>
    <p>[0005]	由上文所述不难理解，不同的生物特征各具优缺点。基于单一一种生物特征的身 份识别技术的准确度和鲁棒性相对较差。</p>
    <p>[0006]	因此，需要一种身份识别解决方案，可融合各种生物特征的优点，以提高基于生物 特征的身份识别技术的准确度和鲁棒性。</p>
    <p>发明内容</p>
    <p>[0007]	本发明要解决的技术问题在于，针对现有基于单一一种生物特征的身份识别技术 的准确度和鲁棒性相对较差的缺陷，提供一种身份识别方法和身份识别系统。</p>
    <p>[0008]	本发明解决其技术问题所采用的技术方案是：</p>
    <p>[0009]	一种身份识别方法，包括：</p>
    <p>[0010]	提取步骤，包括：</p>
    <p>[0011]	采集步骤，包括分别采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图 像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；</p>
    <p>[0012]	滤波步骤，包括分别对人脸特征图像和掌纹特征图像进行Gabor滤波；</p>
    <p>[0013]	编码步骤，包括分别对Gabor滤波后的人脸特征图像和Gabor滤波后的掌纹特征 图像进行编码，得到对应的人脸特征编码和掌纹特征编码；</p>
    <p>[0014]	融合步骤，包括融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特 征；[0015]	匹配步骤，包括通过将待识别用户的身份特征与身份特征库中的身份特征进行匹 配，来对该待识别用户进行身份识别。</p>
    <p>[0016]	优选的，所述采集步骤进一步包括：</p>
    <p>[0017]	人脸特征图像采集步骤，包括：</p>
    <p>[0018]	采集所述人脸图像，定位其中的双眼位置；</p>
    <p>[0019]	旋转该人脸图像，使得旋转后的双眼位置连线处于水平位置；</p>
    <p>[0020]	在旋转后的人脸图像中截取大小为128X128像素的部分作为人脸特征图像F(x， y)，其中该人脸特征图像的中心为旋转后的人脸图像的中心。</p>
    <p>[0021]	优选的，所述采集步骤进一步包括：</p>
    <p>[0022]	掌纹特征图像采集步骤，包括：</p>
    <p>[0023]	采集所述掌纹图像，定位其中食指和中指之间的角点，以及无名指和小拇指之间 的角点；</p>
    <p>[0024]	旋转该掌纹图像，使得旋转后的双眼位置连线处于垂直位置；</p>
    <p>[0025]	在旋转后的掌纹图像中截取大小为128X128像素的部分作为掌纹特征图像P(x， y)，其中该掌纹特征图像的中心为旋转后的掌纹图像的中心。</p>
    <p>[0026]	优选的，在所述滤波步骤中，</p>
    <p>[0027]	所述对人脸特征图像进行Gabor滤波包括：</p>
    <p>[0028]	分别基于多个Gabor小波{^ΛΑ，σ:ι j对所述人脸特征图像进行卷积操作，得到对应</p>
    <p>的多个卷积图像{&amp;(Χ，y)，i = 0，1，. . .，uv}，其中每一 Gabor小波表示为：</p>
    <p>[0029]</p>
    <p>1	( (χ2 +v2)^</p>
    <p>φσ θ a) (x^y) = -~^exp--2~ exp(y2&lt;(xcos6&gt;v + 少 sin6&gt;v》</p>
    <p>λπσ y σ )</p>
    <p>ι f / η ν	2π</p>
    <p>[0030]	其中，U为频率，ν为方向，/&#8222; = h A=孓兀^ = γ，所述多个卷积图像表示</p>
    <p>为：</p>
    <p>[0031]</p>
    <p>^yple, ^y)=F *	= 0，Λ 4^ = 0，Λ，7}</p>
    <p>[0032]	生成滤波后的人脸特征图像W(x，y)，其中W(x，y)表示为：</p>
    <p>[0033]	W(x, y) = Gm(x'y)(x, y)</p>
    <p>[0034]	其中 m(x, y) = arg max\p' (u)|, / = 0,1,..., wv。</p>
    <p>[0035]	优选的，在所述滤波步骤中，</p>
    <p>[0036]	所述对掌纹特征图像进行Gabor滤波包括：</p>
    <p>[0037]	分别基于两个Gabor小波⑹= 0,lj对所述掌纹特征图像P (x, y)进行卷积</p>
    <p>操作，得到对应的多个卷积图像{&amp;(Χ，Υ)，i = 0，1}，其中每一 Gabor小波表示为：</p>
    <p>[0038]</p>
    <p>1	( (χ2 + v2)^</p>
    <p>φ(θ) O, y) = -~&#906; exP--2~ exp(y2^f (χ cos θ, + y sin6&gt;,.))</p>
    <p>λπσ y σ )</p>
    <p>[0039]	其中，其中f = 0.0916，σ =5.6179，θ i = i ji/2，所述多个卷积图像表示为：[0040]</p>
    <p>&lt;formula&gt;formula see original document page 7&lt;/formula&gt;</p>
    <p>[0041]	生成滤波后的掌纹特征图像W(x，y)，其中W(x，y)表示为：</p>
    <p>[0042]	W(x, y) = Gm(x'y)(x, y)</p>
    <p>[0043]	其中	= arg max ||(7 (U)I,/ = 0,1。</p>
    <p>[0044]	优选的，所述编码步骤进一步包括：</p>
    <p>[0045]	计算滤波后的人脸特征图像W(x，y)每个像素的相位P(x，y)，依照如下公式生成 人脸特征编码(Vace (X，y)，b2face(x, y))：</p>
    <p>&lt;formula&gt;formula see original document page 7&lt;/formula&gt;</p>
    <p>[0047]	优选的，所述编码步骤进一步包括：</p>
    <p>[0048]	计算滤波后的掌纹特征图像W(x，y)每个像素的相位P(x，y)，依照如下公式生成 人脸特征编码(Valm (X，y)，b2palm(x, y))：</p>
    <p>&lt;formula&gt;formula see original document page 7&lt;/formula&gt;</p>
    <p>[0049]	(brlm(x,y),brlm(x,y)) = \ ，々	\y) 。 \ ‘ (0,0), π&lt;Ρ(χ,γ)&lt;3π/2</p>
    <p>(1,0), 3π/2&lt;Ρ(χ,γ)&lt;2π</p>
    <p>[0050]	优选的，所述待识别用户的身份特征为Xface_palm = Od1 (χ, y)，b2(χ, y)，b3(χ, y)， 匕4(1，7))，其中131(1，7) =νυ，Μχ，γ) =b2face(x,y),b3(x,y) = Valm (x，y)，b4 (x， y) =b2palm(x，y)。</p>
    <p>[0051]	一种身份识别系统，包括：</p>
    <p>[0052]	提取模块，包括：</p>
    <p>[0053]	采集模块，用于分别采集待识别用户的人脸图像和掌纹图像，再从采集的人脸图 像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；</p>
    <p>[0054]	滤波模块，用于分别对人脸特征图像和掌纹特征图像进行Gabor滤波；</p>
    <p>[0055]	编码模块，用于分别对Gabor滤波后的人脸特征图像和Gabor滤波后的掌纹特征 图像进行编码，得到对应的人脸特征编码和掌纹特征编码；</p>
    <p>[0056]	融合模块，用于融合人脸特征编码和掌纹特征编码，得到待识别用户的身份特 征；</p>
    <p>[0057]	匹配模块，用于通过将待识别用户的身份特征与身份特征库中的身份特征进行匹 配，来对该待识别用户进行身份识别。</p>
    <p>[0058]	优选的，所述采集模块进一步包括：</p>
    <p>[0059]	人脸特征图像采集模块，用于：</p>
    <p>[0060]	采集所述人脸图像，定位其中的双眼位置；</p>
    <p>[0061]	旋转该人脸图像，使得旋转后的双眼位置连线处于水平位置；</p>
    <p>[0062]	在旋转后的人脸图像中截取大小为128X128像素的部分作为人脸特征图像F(x，y)，其中该人脸特征图像的中心为旋转后的人脸图像的中心。</p>
    <p>[0063]	实施本发明的技术方案，具有以下有益效果：本发明提供的技术方案基于人脸和 掌纹两种生物特征来进行身份识别，可有效的解决现有基于单一一种生物特征的身份识别 技术的准确度和鲁棒性相对较差的问题。同时，本发明提供的技术方案无需使用训练数据 进行学习，使用简单，在不同的应用场合配置方便，可以克服子空间投影方法需要对维数参 数反复测试进行确定的缺点。此外，本发明提供的技术方案对生物特征采用0/1编码，在计 算机上通过异或操作进行匹配，所需存储空间小，可以在提高匹配效率的同时降低所占用 的存储空间，非常适合嵌入式应用。而且本发明技术方案的特征抽取时间约为传统核空间 方法的一般，存储119个人的生物特征所占用的存储空间约为核方法的1/300。 最后，仿真 实验证明本发明提供的技术方案可以获得比传统方法更高的识别准确度。</p>
    <p>附图说明</p>
    <p>[0064]	下面将结合附图及实施例对本发明作进一步说明，附图中：</p>
    <p>[0065]	图1是依据本发明一较佳实施例的身份识别方法的流程图；</p>
    <p>[0066]	图2A&#12316;2D是依据本发明一较佳实施例的人脸特征图像的详细采集过程的示意 图；</p>
    <p>[0067]	图3A&#12316;3E是依据本发明一较佳实施例的掌纹图像的详细采集过程的示意图；</p>
    <p>[0068]	图4A是人脸图像的示意图；</p>
    <p>[0069]	图4B是Gabor小波的示意图；</p>
    <p>[0070]	图4C是滤波后的卷积图像的示意图；</p>
    <p>[0071]	图5是掌纹图像的示意图；</p>
    <p>[0072]	图6A、6B是编码后的人脸特征图像的示意图；</p>
    <p>[0073]	图6C、6D是编码后的掌纹特征图像的示意图；</p>
    <p>[0074]	图7是本发明身份识别系统的逻辑结构示意图。</p>
    <p>具体实施方式</p>
    <p>[0075]	为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对 本发明进行进一步详细说明。应当理解，此处所描述的具体实施例仅仅用以解释本发明，并 不用于限定本发明。</p>
    <p>[0076]	本发明提供了一种身份识别方法和身份识别系统，基于人脸和掌纹两种生物特征 来进行身份识别，可有效的解决现有基于单一一种生物特征的身份识别技术的准确度和鲁 棒性相对较差的问题。同时，本发明提供的技术方案无需使用训练数据进行学习，使用简 单，在不同的应用场合配置方便，可以克服子空间投影方法需要对维数参数反复测试进行 确定的缺点。此外，本发明提供的技术方案对生物特征采用0/1编码，在计算机上通过异或 操作进行匹配，所需存储空间小，可以在提高匹配效率的同时降低所占用的存储空间，非常 适合嵌入式应用。而且本发明技术方案的特征抽取时间约为传统核空间方法的一般，存储 119个人的生物特征所占用的存储空间约为核方法的1/300。最后，仿真实验证明本发明提 供的技术方案可以获得比传统方法更高的识别准确度。下面就结合附图和具体实施例来对 本发明提供的技术方案进行详细描述。[0077]	图1是依据本发明一较佳实施例的身份识别方法100的流程图。如图1所示，方法100开始于步骤102。</p>
    <p>[0078]	随后，在下一步骤104，执行采集步骤，包括分别采集待识别用户的人脸图像和掌 纹图像，再从采集的人脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和 掌纹特征图像；</p>
    <p>[0079]	在具体实现过程中，采集步骤进一步包括人脸特征图像采集步骤，该步骤包括：</p>
    <p>[0080]	采集所述人脸图像，定位其中的双眼位置；</p>
    <p>[0081]	旋转该人脸图像，使得旋转后的双眼位置连线处于水平位置；</p>
    <p>[0082]	在旋转后的人脸图像中截取大小为128X128像素的部分作为人脸特征图像F(x， y)，其中该人脸特征图像的中心为旋转后的人脸图像的中心。</p>
    <p>[0083]	人脸特征图像的详细采集过程请参见图2A&#12316;2D所示。</p>
    <p>[0084]	在具体实现过程中，采集步骤进一步包括掌纹特征图像采集步骤，该步骤包括：</p>
    <p>[0085]	采集所述掌纹图像，定位其中食指和中指之间的角点，以及无名指和小拇指之间 的角点；</p>
    <p>[0086]	旋转该掌纹图像，使得旋转后的双眼位置连线处于垂直位置；</p>
    <p>[0087]	在旋转后的掌纹图像中截取大小为128X128像素的部分作为掌纹特征图像P(x， y)，其中该掌纹特征图像的中心为旋转后的掌纹图像的中心。</p>
    <p>[0088]	在具体实现过程中，可采用边缘提取、跟踪等算法得到掌纹图像中食指和中指、无 名指和小拇指之间的角点。</p>
    <p>[0089]	掌纹特征图像的详细采集过程请参见图3A&#12316;3E所示。</p>
    <p>[0090]	随后，在下一步骤106，执行滤波步骤，包括分别对人脸特征图像和掌纹特征图像 进行Gabor滤波；</p>
    <p>[0091]	在具体实现过程中，对人脸特征图像进行Gabor滤波可进一步包括：</p>
    <p>[0092]	分别基于多个Gabor小波{^ΛΑ，σ:ι j对所述人脸特征图像进行卷积操作，得到对应</p>
    <p>的多个卷积图像{&amp;(Χ，y)，i = 0，1，. . .，uv}，其中每一 Gabor小波表示为：</p>
    <p>[0093]&lt;formula&gt;formula see original document page 9&lt;/formula&gt;</p>
    <p>[0094]	其中，U为频率，ν为方向&lt;formula&gt;formula see original document page 9&lt;/formula&gt;，所述多个卷积图像表示</p>
    <p>为：</p>
    <p>[0095]</p>
    <p>&lt;formula&gt;formula see original document page 9&lt;/formula&gt;</p>
    <p>[0096]	生成滤波后的人脸特征图像W(x，y)，其中W(x，y)表示为：</p>
    <p>[0097]	ff(x,y) =Gm(x'y)(x,y)</p>
    <p>[0098]	其中 &lt;formula&gt;formula see original document page 9&lt;/formula&gt;</p>
    <p>[0099]	在具体实现过程中，可设计5个频率，8个方向的40个Gabor小波fe/义内j，u = 0，Λ4，ν = 0，Λ，7来执行卷积操作。当人脸图像如图4Α所示时，这40个Gabor小波如图4B所示，而滤波后得到的40个卷积图像如图4C所示。</p>
    <p>[0100]	在具体实现过程中，上述卷积操作也可以通过将图像和小波分别进行快速傅立叶 变换，变换到频域进行乘积操作，再将乘积进行快速反傅立叶变换得到。</p>
    <p>[0101]	在具体实现过程中，对掌纹特征图像进行Gabor滤波可进一步包括：</p>
    <p>[0102]	分别基于两个Gabor小波⑹= 0,lj对所述掌纹特征图像P (x, y)进行卷积</p>
    <p>操作，得到对应的多个卷积图像{Gi(X，y)，i = 0，1}，其中每一 Gabor小波表示为：</p>
    <p>[0103]</p>
    <p>&lt;formula&gt;formula see original document page 10&lt;/formula&gt;</p>
    <p>[0104]	其中，其中f = 0.0916，σ =5.6179，θ i = i ji/2，所述多个卷积图像表示为：</p>
    <p>[0105]</p>
    <p>&lt;formula&gt;formula see original document page 10&lt;/formula&gt;</p>
    <p>[0106]	生成滤波后的掌纹特征图像W(x，y)，其中W(x，y)表示为：</p>
    <p>[0107]	ff(x,y) =Gm(x'y)(x,y)</p>
    <p>[0108]其中册0,力=&amp;&#38917;111严||(70,少)||,/	= 0,1。</p>
    <p>[0109]	在具体实现过程中，上述卷积操作也可以通过将图像和小波分别进行快速傅立叶 变换，变换到频域进行乘积操作，再将乘积进行快速反傅立叶变换得到。</p>
    <p>[0110]	掌纹图像如图5所示。</p>
    <p>[0111]	随后，在下一步骤108，执行编码步骤，包括分别对Gabor滤波后的人脸特征图像 和Gabor滤波后的掌纹特征图像进行编码，得到对应的人脸特征编码和掌纹特征编码以作 为待识别用户的身份特征；</p>
    <p>[0112]	在具体实现过程中，编码步骤可进一步包括，计算滤波后的人脸特征图像W(x，y) 每个像素的相位P (X，y)，依照如下公式生成人脸特征两位编码…广力，y)，b2face(x, y))：</p>
    <p>[0113]	&lt;formula&gt;formula see original document page 10&lt;/formula&gt;</p>
    <p>[0114]	上述人脸特征编码（ν(χ，Υ)，ν(χ，Υ))所对应的图像如图6Α和图6Β所示。</p>
    <p>[0115]	在具体实现过程中，编码步骤可进一步包括，计算滤波后的掌纹特征图像W(x，y) 每个像素的相位P (x，y)，依照如下公式生成人脸特征编码（V5alm(Lyhb2palmO^y))：</p>
    <p>[0116]	&lt;formula&gt;formula see original document page 10&lt;/formula&gt;</p>
    <p>[0117]	上述掌纹特征编码（ν(χ，Υ)，ν(χ，Υ))所对应的图像如图6C和图6D所示。</p>
    <p>[0118]	随后，在下一步骤110，执行融合步骤，包括融合人脸特征编码和掌纹特征编码，得 到待识别用户的身份特征。</p>
    <p>[0119]	在具体实现过程中，待识别用户的身份特征为Xflm= (^(χ,γ)^2(χ,γ)^3(χ,y)，b4(x，y))，其中：</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt;</p>
    <p>[0121]	此外，在具体实现过程中，还可将待识别用户的身份特征保存为单独的人脸特征 编码和单独的掌纹特征编码的形式。</p>
    <p>[0122]	随后，在下一步骤112，执行匹配步骤，包括通过将待识别用户的身 份特征与身份 特征库中的身份特征进行匹配，来对该待识别用户进行身份识别。</p>
    <p>[0123]	在具体实现过程中，可按照如下方式计算待识别用户的身份特征与身份特征库中 的身份特征之间的距离：</p>
    <p>[0124]身份特征为	X1faceL = (V (X，y))，i = ι，Λ B 以及 X2face_palm = (bi2 (X，y))， X2face-Paim = {b'{x,y)\ i = 1，AB的两个用户P，Q的之间的距离可以采用以下公式计算：</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt;</p>
    <p>[0126]	在具体实现过程中，若待识别用户的身份特征采用单独的人脸特征编码和单独的 掌纹特征编码的形式，则可按照如下方式计算待识别用户的身份特征与身份特征库中的身 份特征之间的距离：</p>
    <p>[0127]	假设用户P的人脸编码为X1fac^掌纹编码为X1palm,用户Q的人脸编码为X2f_，掌纹 编码为x2Palm。首先分别计算P、Q人脸的距离dfa。e = CKX1face, X2face)和掌纹的距离dpalm =</p>
    <p>(KX1palffl'X2palJ，用户P、Q的整体距离则可以通过下式计算&#183;&lt;formula&gt;formula see original document page 11&lt;/formula&gt;[0129]	在具体实现过程中，可设置对应的距离阈值，若算得的距离小于该阈值，则表明待 识别用户的身份特征与身份特征库中的身份特征匹配，否则不匹配。</p>
    <p>[0130]	最后，方法100结束于步骤114。</p>
    <p>[0131 ] 在具体实现过程中，步骤104-110可称为提取步骤，步骤112可称为匹配步骤。</p>
    <p>[0132]	本发明还提供了一种身份识别系统，下面就结合图7对其进行详细描述。</p>
    <p>[0133]	图7是依据本发明一较佳实施例的身份识别系统700的逻辑结构示意图。如图7 所示，身份识别系统700包括提取模块702和匹配模块704。</p>
    <p>[0134]	提取模块702包括：</p>
    <p>[0135]	采集模块7022，用于分别采集待识别用户的人脸图像和掌纹图像，再从采集的人 脸图像和掌纹图像中截取各自的特征部分分别作为人脸特征图像和掌纹特征图像；</p>
    <p>[0136]	滤波模块7024，用于分别对人脸特征图像和掌纹特征图像进行Gabor滤波；</p>
    <p>[0137]	编码模块7026，用于分别对Gabor滤波后的人脸特征图像和Gabor滤波后的掌纹 特征图像进行编码，得到对应的人脸特征编码和掌纹特征编码；</p>
    <p>[0138]	融合模块7028，用于融合人脸特征编码和掌纹特征编码，得到待识别用户的身份 特征；</p>
    <p>[0139]	匹配模块704用于通过将待识别用户的身份特征与身份特征库中的身份特征进 行匹配，来对该待识别用户进行身份识别。[0140]	在具体实现过程中，身份识别系统700中的各个模块的功能与图1中各方法步骤 中的操作相对应。有关这些操作步骤的具体内容已经在前文做了详细的描述，因此此处不 再赘述。</p>
    <p>[0141]	以上所述仅为本发明的较佳实施例而已，并不用以限制本发明，凡在本发明的精神和原则之内所作的任何修改、等同替换和改进等，均应包含在本发明的保护范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1341401A?cl=zh">CN1341401A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2001年10月19日</td><td class="patent-data-table-td patent-date-value">2002年3月27日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">基于部件主分量分析的多模式人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101281598A?cl=zh">CN101281598A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年5月23日</td><td class="patent-data-table-td patent-date-value">2008年10月8日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">基于多部件多特征融合的人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040234131">US20040234131</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2002年10月25日</td><td class="patent-data-table-td patent-date-value">2004年11月25日</td><td class="patent-data-table-td ">Hiroshi Kondo</td><td class="patent-data-table-td ">Image characteristic identification signal regeneration apparatus and image characteristic identification signal generation method</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《中国图象图形学报》 20071231 黄申 等 采样式多通道Gabor滤波对掌纹的特征提取和分类 第12卷, 第12期 2</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《深圳大学学报理工版》 20080131 SHEN Lin-lin et al Automatic face recognition based on skin masking and improved HMM 第25卷, 第1期 2</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102385766A?cl=zh">CN102385766A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月23日</td><td class="patent-data-table-td patent-date-value">2012年3月21日</td><td class="patent-data-table-td ">哈尔滨工业大学深圳研究生院</td><td class="patent-data-table-td ">基于掌纹的认证开锁方法、终端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102968738A?cl=zh">CN102968738A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月6日</td><td class="patent-data-table-td patent-date-value">2013年3月13日</td><td class="patent-data-table-td ">中国科学院半导体研究所</td><td class="patent-data-table-td ">广告投放系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=yxV6BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009540000">G06K9/54</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=yxV6BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年9月1日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年10月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年12月26日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/eefae7c5047178d2132d/CN101819631A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E8%BA%AB%E4%BB%BD%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E8%BA%AB%E4%BB%BD%E8%AF%86%E5%88%AB.pdf?id=yxV6BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1wsIvDbY78AcEmsrsIQK0-8-0XJw"},"sample_url":"https://www.google.com/patents/reader?id=yxV6BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>