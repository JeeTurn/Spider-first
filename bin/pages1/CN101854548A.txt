<!DOCTYPE html><html><head><title>专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4874c258b856314cce6b80d777b4ee7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4874c258b856314cce6b80d777b4ee7a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种面向无线多媒体传感器网络的视频压缩方法"><meta name="DC.contributor" content="叶晓国" scheme="inventor"><meta name="DC.contributor" content="孙力娟" scheme="inventor"><meta name="DC.contributor" content="王汝传" scheme="inventor"><meta name="DC.contributor" content="肖甫" scheme="inventor"><meta name="DC.contributor" content="郭剑" scheme="inventor"><meta name="DC.contributor" content="马子平" scheme="inventor"><meta name="DC.contributor" content="南京邮电大学" scheme="assignee"><meta name="DC.date" content="2010-5-25" scheme="dateSubmitted"><meta name="DC.description" content="本发明是一种面向无线多媒体传感器网络的视频压缩方法，提出一种面向无线多媒体传感器网络的视频压缩方法，来解决视频应用中数据量大的问题。通过使用本发明提出的方法在降低码率的同时提高了解码图像的质量，最终降低传感器节点能耗，从而延长了网络生存周期。该方法采用ROI区分算法，加强对运动剧烈区域和运动边缘区域的编码，并且对解码后的图像采用去块效应滤波后处理，进一步提高解码图像的主观质量，本方法在Wyner-Ziv分布式视频编码方案的基础上，基于图像梯度场域，通过ROI判定准则提取运动剧烈区域并基于Huffman编解码压缩，其余区域则基于LDPC分布式编解码，在降低码率的同时提高解码图像质量，降低节点的处理和传输能耗，实现视频的优化传输，延长整个网络的生存周期。"><meta name="DC.date" content="2010-10-6"><meta name="DC.relation" content="CN:101005621:A" scheme="references"><meta name="DC.relation" content="CN:101360236:A" scheme="references"><meta name="DC.relation" content="CN:101621690:A" scheme="references"><meta name="DC.relation" content="US:20070013561:A1" scheme="references"><meta name="DC.relation" content="US:20080031344:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:101854548:A"><meta name="citation_patent_application_number" content="CN:201010182470"><link rel="canonical" href="https://www.google.com/patents/CN101854548A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101854548A?cl=zh"/><meta name="title" content="专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法"/><meta name="description" content="本发明是一种面向无线多媒体传感器网络的视频压缩方法，提出一种面向无线多媒体传感器网络的视频压缩方法，来解决视频应用中数据量大的问题。通过使用本发明提出的方法在降低码率的同时提高了解码图像的质量，最终降低传感器节点能耗，从而延长了网络生存周期。该方法采用ROI区分算法，加强对运动剧烈区域和运动边缘区域的编码，并且对解码后的图像采用去块效应滤波后处理，进一步提高解码图像的主观质量，本方法在Wyner-Ziv分布式视频编码方案的基础上，基于图像梯度场域，通过ROI判定准则提取运动剧烈区域并基于Huffman编解码压缩，其余区域则基于LDPC分布式编解码，在降低码率的同时提高解码图像质量，降低节点的处理和传输能耗，实现视频的优化传输，延长整个网络的生存周期。"/><meta property="og:title" content="专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?hl=zh-CN&tbm=isch&source=og&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?hl=zh-CN&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?hl=zh-CN&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101854548A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101854548A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101854548A&amp;usg=AFQjCNGST-OMvLti2YqOukO025fNVabfhA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/78eb83267682c519b726/CN101854548A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/78eb83267682c519b726/CN101854548A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101854548A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101854548A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101854548A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101854548B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101854548A?cl=zh" style="display:none"><span itemprop="description">本发明是一种面向无线多媒体传感器网络的视频压缩方法，提出一种面向无线多媒体传感器网络的视频压缩方法，来解决视频应用中数据量大的问题。通过使用本发明提出的方法在降低码率的同时提高了解码图像的质量，最终降...</span><span itemprop="url">https://www.google.com/patents/CN101854548A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法" title="专利 CN101854548A - 一种面向无线多媒体传感器网络的视频压缩方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101854548 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010182470</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年10月6日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年5月25日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年5月25日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101854548B?hl=zh-CN&amp;cl=zh">CN101854548B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010182470.6, </span><span class="patent-bibdata-value">CN 101854548 A, </span><span class="patent-bibdata-value">CN 101854548A, </span><span class="patent-bibdata-value">CN 201010182470, </span><span class="patent-bibdata-value">CN-A-101854548, </span><span class="patent-bibdata-value">CN101854548 A, </span><span class="patent-bibdata-value">CN101854548A, </span><span class="patent-bibdata-value">CN201010182470, </span><span class="patent-bibdata-value">CN201010182470.6</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%8F%B6%E6%99%93%E5%9B%BD%22">叶晓国</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%99%E5%8A%9B%E5%A8%9F%22">孙力娟</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E6%B1%9D%E4%BC%A0%22">王汝传</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%82%96%E7%94%AB%22">肖甫</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%83%AD%E5%89%91%22">郭剑</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%A9%AC%E5%AD%90%E5%B9%B3%22">马子平</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8D%97%E4%BA%AC%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%22">南京邮电大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101854548A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101854548A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101854548A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (13),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (5),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010182470&amp;usg=AFQjCNGyjmEfDsU11P9RfkcWmxDFPxfWuA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101854548A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGlp--mS8q1b2AbtWAiQ9_VdLAUTA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT98269923" lang="ZH" load-source="patent-office">一种面向无线多媒体传感器网络的视频压缩方法</invention-title>
      </span><br><span class="patent-number">CN 101854548 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA80749805" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明是一种面向无线多媒体传感器网络的视频压缩方法，提出一种面向无线多媒体传感器网络的视频压缩方法，来解决视频应用中数据量大的问题。通过使用本发明提出的方法在降低码率的同时提高了解码图像的质量，最终降低传感器节点能耗，从而延长了网络生存周期。该方法采用ROI区分算法，加强对运动剧烈区域和运动边缘区域的编码，并且对解码后的图像采用去块效应滤波后处理，进一步提高解码图像的主观质量，本方法在Wyner-Ziv分布式视频编码方案的基础上，基于图像梯度场域，通过ROI判定准则提取运动剧烈区域并基于Huffman编解码压缩，其余区域则基于LDPC分布式编解码，在降低码率的同时提高解码图像质量，降低节点的处理和传输能耗，实现视频的优化传输，延长整个网络的生存周期。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(3)</span></span></div><div class="patent-text"><ol mxw-id="PCLM33439118" lang="ZH" load-source="patent-office" class="claims">
    <li class="claim"> <div num="1" class="claim">
      <div class="claim-text">一种面向无线多媒体传感器网络的视频压缩方法，其特征是：采用ROI区分算法，加强对运动剧烈区域和运动边缘区域的编码，并且对解码后的图像采用去块效应滤波后处理，进一步提高解码图像的主观质量，该方法具体如下：1)在编码端a)帧分离器：视频序列被分为关键帧和非关键帧，其中关键帧周期性的插入，取决于图像组的大小，帧分离器将视频序列分为不同的帧，每两个关键帧之间所分配的非关键帧的数目不同，关键帧采用帧内编码，非关键帧采用低密度奇偶校验码编码；b)空间变换：基于块的变换，特别地把离散余弦变换应用到每个非关键帧上，非关键帧被划分为互不重叠的块，依据每个块的离散余弦变换系数所处的位置，形成不同的离散余弦变换系数集；c)量化：每个离散余弦变换集被统一的量化，这些量化级依赖于所要得到图像的质量，对于一个给定的集合，量化信号的位流被一起分组，形成位平面，然后独立地进行编码；d)编码：对于关键帧，使用传统的联合图像专家组进行编码，利用感兴趣区域区分算法将非关键帧分为感兴趣区域和非感兴趣区域：对于感兴趣区域采用霍夫曼编码，对于非感兴趣区域采用低密度奇偶校验码编码；2)在解码端a)生成边信息：解码端使用最近的已解码帧，通过采用运动补偿帧内插或外推的方式生成每个非关键帧的边信息，每个非关键帧的边信息被当作原始非关键帧的估计值，估计值的质量越好，低密度奇偶校验码解码端需要改正的“错误”越少，并且向缓冲器所请求的奇偶校验位或位流越少；b)相关噪声模型：非关键帧和边信息中对应的离散余弦变换系数的残差统计被假定为一个服从拉普拉斯分布的模型，其参数使用离线的训练模式进行初始化估计；c)低密度奇偶校验码解码：关键帧使用传统的联合图像专家组技术进行解码；非关键帧的感兴趣区域使用霍夫曼进行解码复原；对于非关键帧的非感兴趣区域，一旦知道了边信息离散余弦变换系数和一个给定离散余弦变换系数的残差统计，每个位平面可以进行低密度奇偶校验码解码，从最重要的位平面开始解码；在低密度奇偶校验码解码器的请求下，编码器通过反馈信道发送一些奇偶校验消息，为了判定解码某个特定的位平面是否需要更多的校验位，解码器采用一个请求停止标准，当低密度奇偶校验码正确地解码一个离散余弦变换集的最重要位平面之后，低密度奇偶校验码解码器将以统一的方式处理其余相关的集合，当所有的离散余弦变换集合的位平面都被低密度奇偶校验码正确地解码时，解码器则开始解码下一个集合；d)重构：在低密度奇偶校验码解码后，所有的位平面及每个离散余弦变换集合被一起分组，以形成解码的量化信号流和集合，一旦可以获得所有的解码量化信号，在相应的边信息系数的辅助下，便可重构所有的离散余弦变换系数，对于所传输的不含非关键帧位流的离散余弦变换系数集合，由边信息对应的离散余弦变换集合来代替；e)反变换：当所有的离散余弦变换集被重建以后，执行反离散余弦变换，由此便可得到解码的非关键帧；3)解码图像后处理对解码后的图像使用滤波器，从而削弱由量化带来的方块效应，去块效应滤波器是一维滤波器，为了得到二维效果，对一个块要进行两次滤波，第一次是在水平方向，第二次在垂直方向，由于块效应产生的原因是量化误差将原来相邻像素值的连续变化变成了“台阶”变化，看起来就有“伪边缘”的方块现象，去块效应就是在尽量使图像总的能量保持不变的条件下，把那些“台阶”很高的阶跃型的灰度变化重新变成“台阶”很小或接近连续的灰度变化；4)帧混合对于已经正确解码的各帧，即利用传统的联合图像专家组编解码的关键帧和利用低密度奇偶校验码及霍夫曼混合编解码的非关键帧，根据在编码端所采用的编码图像组的大小，将关键帧和非关键帧按图像组的相应次序混合成视频流，进而恢复成解码后的视频序列，至此，视频编解码压缩处理结束。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的面向无线多媒体传感器网络的视频压缩方法，其特征是所述 感兴趣区域采用霍夫曼编码的过程如下：将待编码的灰度级按出现的次数排序，出现次数 多的在前面，次数少的在后面；取出现次数最少的两个数的次数相加，之和作为一个新的出 现次数的集合元素并重新排序，新出现的次数在新集合中仍遵循降序规则以确定所处的位 置，相加的两个次数最少所对应的灰度级成为霍夫曼树的一个叶结点，这两个结点构造一 个双亲结点，重复该步骤，直到所有的灰度级都被用来构造霍夫曼树为止；设所有结点的左 孩子为“0”，右孩子为“1”，则从根开始，经各中间结点到叶结点的路径代码即是该叶结点 的霍夫曼码；对于非感兴趣区域的每个离散余弦变换集合，从最重要的位平面进行低密码 奇偶校验码编码；对于每个位平面，所生成的奇偶检验信息被存储在缓冲器中，在解码端的 请求下，通过反馈机制，不断地发送校验信息。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的面向无线多媒体传感器网络的视频压缩方法，其特征是对于 关键帧，使用传统的联合图像专家组进行编码，利用感兴趣区域区分算法将非关键帧分为 感兴趣区域和非感兴趣区域：对于感兴趣区域采用霍夫曼编解码，对于非感兴趣区域采用 低密度奇偶校验码进行编解码，具体步骤如下：步骤1)：将每帧分成大小相等且互不重叠的8X8宏块；步骤2)：将关键帧和非关键帧进行梯度变化；步骤3)：计算关键帧和非关键帧相同位置宏块的绝对差值之和；步骤4)：根据感兴趣区域宏块的判定准则，对非关键帧每个宏块进行感兴趣区域区分；步骤5)：对非关键帧的感兴趣区域宏块采用霍夫曼编解码压缩； 步骤6)：对非关键帧的其它宏块则采用低密度奇偶校验码编解码压缩。</div>
    </div>
  </li> </ol>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES38705214" lang="ZH" load-source="patent-office" class="description">
    <p>一种面向无线多媒体传感器网络的视频压缩方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明是一种针对无线多媒体传感器网络（Wireless Multimedia SensorNetworks, WMSN)中多媒体数据压缩的技术方案。主要用于解决视频压缩编码的问 题，并尽可能提高解码图像的质量，属于计算机无线通信技术领域。</p>
    <p>背景技术</p>
    <p>[0002]	近年来，随着无线多媒体通信技术的发展，出现了越来越多的视频应用需求，如： 无线多媒体传感器网络、移动可视电话、无线视频监控、无线PC摄像机等。在无线多媒体 传感器网络中，视频应用需要处理大量的数据，由于节点计算能力或节点能量受限，传统视 频编码标准不再适用于无线视频场合。一种全新的视频编解码框架一分布式视频编码 (Distributed Video Coding, DVC)被应用到无线多媒体传感器网络中。</p>
    <p>[0003]	传统的视频编码标准（如MPEG、H. 26x)采用了混合编码框架，编码采用运动补偿 技术，充分利用视频序列的时间和空间相关性进行预测编码，一般情况下，编码复杂度是解 码复杂度的5&#12316;10倍。而分布式视频编码具有编码简单、解码复杂的特点。此外，分布式 视频编码具有较好的鲁棒性、较高的压缩效率，且易形成分级编码的码流，适用于编码复杂 度较低的无线视频场合。</p>
    <p>[0004]	目前比较经典的分布式编解码方案主要包括斯坦福大学Girod和Aaron等提出 的Wyner-Ziv视频编码，加州大学伯克利分校的Ramchandran等提出的PRISM视频编码， Zixiang Xiong提出的分层Wyner-Ziv视频编码，Sehgal等提出的state-free分布式视频 编码，基于小波编码的分布式视频编码以及多视角分布式视频编码等。Wyner-Ziv分布式视 频编码由关键帧（Key帧)和Wyner-Ziv帧（WZ帧)两种帧组成。其中Key帧采用传统的 帧内编解码的方式，而WZ帧采用帧内编码和帧间解码相结合的方式。WZ帧编码时，先进行 基于块的DCT变换和量化，然后采用S1印ian-Wolf编码器进行编码。编码器将编码生成的 校验位存储在编码端的缓冲器中，根据解码端的解码反馈请求，将校验位发送给解码器进 行纠错解码。解码时，Slepian-Wolf解码器根据解码边信息和接收到的校验位进行解码，根 据解码端的解码的正确性，不断反馈请求bit数，编码端缓存器不断发送校验位，直到能够 正确解码为止。接着对解码后的系数进行IDCT和反量化以及解码重建。这些方案都是基于 turbo或LDPC对Wyner-Ziv帧的所有区域不加区别的编码，这种编码处理方式，适应于运 动平缓的情况，但对于运动比较剧烈的区域和运动对象的边缘区域，运动估计和运动补偿 技术就不能够准确预测，解码时需要向编码端请求较多的反馈信息，这样不仅增加了码率， 而且解码的部分图像仍不够精确。针对该问题，本发明提出了像素域感兴趣区（Region of Intrest, R0I)区分算法。在Wyne-Ziv分布式视频编码理论的基础上，提出了一种改进的 Wyner-Ziv分布式视频编码算法，该算法基于图像梯度场，通过感兴趣区域判定准则提取运 动剧烈区域并基于熵编码压缩，其余区域则基于LDPC分布式编解码，最终实现视频的优化 传输。此外，对解码后的图像进行后处理，采用块效应滤波，进一步提高了图像的质量，满足 了人们对图像的主观要求。发明内容</p>
    <p>[0005]	技术问题：本发明的目的是提出一种面向无线多媒体传感器网络的视频压缩方 法，来解决视频应用中数据量大的问题。通过使用本发明提出的方法在降低码率的同时提 高了解码图像的质量，最终降低传感器节点能耗，从而延长了网络生存周期。</p>
    <p>[0006]	技术方案：本发明的一种面向无线多媒体传感器网络的视频压缩方法是一种改进 性的方法，分布式视频压缩算法主要的任务是将视频应用中较大的数据量进行压缩，从而 降低节点的能耗，延长网络生存周期，此外，为了进一步提高解码图像的主观质量，对解码 后的图像采用后处理滤波以减少方块效应。</p>
    <p>[0007]	一、体系结构</p>
    <p>[0008]	本方法在Wyner-Ziv分布式视频编码方案的基础上，基于图像梯度场，通过R0I判 定准则提取运动剧烈区域并基于Huffman编解码压缩，其余区域则基于LDPC分布式编解 码，在降低码率的同时提高解码图像质量，降低节点的处理和传输能耗，实现视频的优化传 输，延长整个网络的生存周期。对解码后的图像采用去块效应滤波，提高了图像的主观质 量，满足了人们对图像的视觉要求。</p>
    <p>[0009]	本方法基于Wyner-Ziv分布式视频编码方案，将视频序列分为两种不同的帧：关 键字（Key Frame, K)和非关键帧（Wyner-Ziv frame, WZ)0对关键帧采用传统的JPEG编码 方式，利用R0I区分算法将Wyner-Ziv帧分为R0I区域和非R0I区域，对Wyner-Ziv帧的 R0I区域采用Huffman编解码的方式，其余的非R0I区域采用LPDC的编解码方式。对解码 后的图像采用去块效应滤波处理，进一步提高了解码图像的质量。</p>
    <p>[0010]	具体步骤如下：（1)在编码端：a)帧分离器：将编码端输入的视频序列分为关键 帧（Key帧)和Wyner-Ziv帧（WZ帧)；b)空间变换：对W帧进行基于块的离散余弦变换 (Discrete Cosine Transform,DCT) ；c)量化：对每个DCT变换后的系数进行量化；d)编码： 使用传统的JPEG技术编码Key帧，利用R0I提取算法将Wyner-Ziv帧区分为R0I区域和非 R0I区域：对R0I区域采用Huffman编码，对非R0I区域采用LDPC编码；(2)在解码端：a) 生成边信息：使用解码出的帧，进行运动补偿帧内插（或外推）生成边信息；b)相关噪声模 型：WZ帧和边信息之间对应的DCT系数的残差统计当作一个拉普拉斯分布进行建模；c)解 码：对Key帧，使用传统的JPEG技术解码，对Wyner-Ziv帧的R0I区域采用Huffman解码，其 余的非R0I区域采用LDPC解码；d)重构：在边信息的辅助下，重建所有的DCT系数；e)反变 换：对重建后的系数执行反离散余弦变换（Inverse Discrete Cosine Transform, IDCT)； (3)解码图像后处理：对解码后的图像采用去块效应滤波；(4)帧混合：将解码后的Key帧 和WZ帧整合为视频流。</p>
    <p>[0011]	二、方法流程</p>
    <p>[0012]	本方法包括以上所述4个步骤，详细论述如下：</p>
    <p>[0013](一）：在编码端：</p>
    <p>[0014]	a)帧分离器：视频序列被分为Wyner-Ziv帧（WZ帧)和关键帧（Key帧)，其中关 键帧周期性的插入，取决于GOP (Group of Pictures)大小。利用帧分离器将视频序列分为 不同的帧，对于每个不同的视频序列，由于编码结构的不同，每帧的被赋予的属性不同，因 而，采用的编码处理方式也不同。[0015]	b)空间变换：基于块的变换，特别地把DCT变换应用到每个WZ帧。依据每个块的 DCT系数所处的位置，将整个WZ帧的DCT系数被分为不同的组，从而形成不同的DCT系数集。</p>
    <p>[0016]	c)量化：每个DCT集被统一的量化，这些量化级依赖于所要得到图像的质量。对 于一个给定的集合，量化信号的位流被一起分组，形成位平面，然后独立地进行编码。</p>
    <p>[0017]	d)编码：对于Key帧，使用传统的JPEG技术编码，利用R0I区分算法将Wyner-Ziv 帧分为R0I区域和非R0I区域：对于R0I区域采用Huffman编码，对于非R0I区域采用LDPC 编码。R0I区域采用Huffman编码的过程如下：将待编码的灰度级按出现的次数排序，出 现次数多的在前面，次数少的在后面；取出现次数最少的两个数的次数相加，之和作为一 个新的出现次数的集合元素并重新排序，新出现的次数在新集合中仍遵循降序规则以确定 所处的位置，相加的两个次数最少所对应的灰度级成为Huffman树的一个叶结点，这两个 结点构造一个双亲结点，重复该步骤，直到所有的灰度级都被用来构造Huffman树为止; 设所有结点的左孩子为“0”，右孩子为“1”，则从根开始，经各中间结点到叶结点的路径代 码即是该叶结点的Huffman码。对于非R0I区域的每个DCT集，从最重要的位平面（Most Significant Bit-plane,MSB)进行LDPC编码。对于每个位平面（bit-plane)，所生成的奇 偶检验信息被存储在缓冲器中，在解码端的请求下，通过反馈机制，不断地发送校验信息。</p>
    <p>[0018]	(二）：在解码端：</p>
    <p>[0019]	a)生成边信息：解码端使用最近的已解码帧，通过执行运动补偿帧内插（或外推） 的方式生成每个WZ帧的边信息（Side Information，SI)。每个WZ帧的边信息被当作原始 WZ帧的一种估计值。估计值的质量越好，LDPC解码端需要改正的“错误”越少，并且向缓冲 器所请求的奇偶校验位（或位流）越少。</p>
    <p>[0020]	b)相关噪声模型：在WZ帧和边信息中对应的DCT系数的残差统计被假定当作一 个服从拉普拉斯分布的模型，其参数使用离线（off-line)的训练阶段进行初始化估计。 [0021 ] c) LDPC解码：关键帧使用传统的JPEG技术进行解码；WZ帧的R0I区域使用 Huffman进行解码复原；对于WZ帧的非R0I区域，一旦知道了边信息DCT系数和一个给定 DCT系数的残差统计，每个位平面可以进行LDPC解码（从MSB解码)。在LDPC解码器的请 求下，编码器通过反馈信道发送一些奇偶校验消息。为了判定正确的解码某个特定的位平 面是否需要更多的校验位，解码器采用一个请求停止标准。当成功地LDPC解码一个DCT集 的MSB位平面之后，LDPC解码器以一个统一的的方式处理其余相关的集。一旦所有的DCT 集的位平面被成功地LDPC解码，LDPC解码器开始解码下一个集。</p>
    <p>[0022]	d)重构：在LDPC解码后，所有的位平面及每个DCT集被一起分组，以形成解码的 量化信号流和每个集。一旦可以获得所有的解码量化信号，在相应的边信息系数的辅助下， 便可重构所有的DCT系数。对于所传输的不含WZ位流的DCT系数集由边信息对应的DCT 集来代替。</p>
    <p>[0023]	e)反变换：当所有的DCT集被重建以后，执行IDCT，由此便可得到解码的WZ帧。</p>
    <p>[0024](三）：解码图像后处理：对解码后的图像使用滤波器，从而削弱由量化带来的方 块效应。去块效应滤波器是一维滤波器，为了得到二维效果，对一个块要进行两次滤波，第 一次是在水平方向，第二次在垂直方向。由于块效应产生的原因是量化误差将原来相邻像 素值的连续变化变成了 “台阶”变化，看起来就有“伪边缘”的方块现象。去块效应就是在尽量使图像总的能量保持不变的条件下，把那些“台阶”很高的阶跃型的灰度变化重新变成 “台阶”很小或接近连续的灰度变化。</p>
    <p>[0025](四）：帧混合：最后，对于已经正确解码的各帧，即利用传统JPEG编解码Key帧 和利用LDPC及Huffman混合编解码的WZ帧，根据在编码端所采用的编码结构G0P的大小， 将Key帧和WZ帧按G0P次序混合成视频流，恢复成解码后的视频序列。至此，视频编解码 压缩处理结束。</p>
    <p>[0026]	该方法采用R0I区分算法，加强对运动剧烈区域和运动边缘区域的编码，并且对 解码后的图像采用去块效应滤波后处理，进一步提高解码图像的主观质量，该方法具体如 下：</p>
    <p>[0027]	1)在编码端</p>
    <p>[0028]	a)帧分离器：视频序列被分为关键帧和非关键帧，其中关键帧周期性的插入，取 决于图像组的大小，帧分离器将视频序列分为不同的帧，每两个关键帧之间所分配的非关 键帧的数目不同，关键帧采用帧内编码，非关键帧采用低密度奇偶校验码编码；</p>
    <p>[0029]	b)空间变换：基于块的变换，特别地把离散余弦变换应用到每个非关键帧上，非 关键帧被划分为互不重叠的块，依据每个块的离散余弦变换系数所处的位置，形成不同的 离散余弦变换系数集；</p>
    <p>[0030]	c)量化：每个离散余弦变换集被统一的量化，这些量化级依赖于所要得到图像的 质量，对于一个给定的集合，量化信号的位流被一起分组，形成位平面，然后独立地进行编 码；</p>
    <p>[0031]	d)编码：对于关键帧，使用传统的联合图像专家组进行编码，利用感兴趣区域区 分算法将非关键帧分为感兴趣区域和非感兴趣区域：对于感兴趣区域采用霍夫曼编码，对 于非感兴趣区域采用低密度奇偶校验码编码；</p>
    <p>[0032]	2)在解码端</p>
    <p>[0033]	a)生成边信息：解码端使用最近的已解码帧，通过采用运动补偿帧内插或外推的 方式生成每个非关键帧的边信息，每个非关键帧的边信息被当作原始非关键帧的估计值， 估计值的质量越好，低密度奇偶校验码解码端需要改正的“错误”越少，并且向缓冲器所请 求的奇偶校验位或位流越少；</p>
    <p>[0034]	b)相关噪声模型：非关键帧和边信息中对应的离散余弦变换系数的残差统计被 假定为一个服从拉普拉斯分布的模型，其参数使用离线的训练模式进行初始化估计；</p>
    <p>[0035]	c)低密度奇偶校验码解码：关键帧使用传统的联合图像专家组技术进行解码；非 关键帧的感兴趣区域使用霍夫曼进行解码复原；对于非关键帧的非感兴趣区域，一旦知道 了边信息离散余弦变换系数和一个给定离散余弦变换系数的残差统计，每个位平面可以进 行低密度奇偶校验码解码，从最重要的位平面开始解码；在低密度奇偶校验码解码器的请 求下，编码器通过反馈信道发送一些奇偶校验消息，为了判定解码某个特定的位平面是否 需要更多的校验位，解码器采用一个请求停止标准，当低密度奇偶校验码正确地解码一个 离散余弦变换集的最重要位平面之后，低密度奇偶校验码解码器将以统一的方式处理其余 相关的集合，当所有的离散余弦变换集合的位平面都被低密度奇偶校验码正确地解码时， 解码器则开始解码下一个集合；</p>
    <p>[0036]	d)重构：在低密度奇偶校验码解码后，所有的位平面及每个离散余弦变换集合被一起分组，以形成解码的量化信号流和集合，一旦可以获得所有的解码量化信号，在相应的边信息系数的辅助下，便可重构所有的离散余弦变换系数，对于所传输的不含非关键帧位流的离散余弦变换系数集合，由边信息对应的离散余弦变换集合宋代替；[0037]  e)反变换：当所有的离散余弦变换集被重建以后，执行反离散余弦变换，由此便可得到解码的非关键帧；[0038]  3)解码图像后处理[0039]  对解码后的图像使用滤波器，从而削弱由量化带来的方块效应，去块效应滤波器是一维滤波器，为了得到二维效果，对一个块要进行两次滤波，第一次是在水平方向，第二次在垂直方向，由于块效应产生的原因是量化误差将原来相邻像素值的连续变化变成了“台阶”变化，看起来就有“伪边缘”的方块现象，去块效应就是在尽量使图像总的能量保持不变的条件下，把那些“台阶”很高的阶跃型的灰度变化重新变成“台阶”很小或接近连续的灰度变化；[0040]  4)帧混合[0041]  对于已经正确解码的各帧，即利用传统的联合图像专家组编解码的关键帧和利用低密度奇偶校验码及霍夫曼混合编解码的非关键帧，根据在编码端所采用的编码图像组的大小，将关键帧和非关键帧按图像组的相应次序混合成视频流，进而恢复成解码后的视频序列，至此，视频编解码压缩处理结束。[0042]  所述感兴趣区域采用霍夫曼编码的过程如下：将待编码的灰度级按出现的次数排序，出现次数多的在前面，次数少的在后面；取出现次数最少的两个数的次数相加，之和作为一个新的出现次数的集合元素并重新排序，新出现的次数在新集合中仍遵循降序规则以确定所处的位置，相加的两个次数最少所对应的灰度级成为霍夫曼树的一个叶结点，这两个结点构造一个双亲结点，重复该步骤，直到所有的灰度级都被用来构造霍夫曼树为止；设所有结点的左孩子为“o”，右孩子为“l”，则从根开始，经各中间结点到叶结点的路径代码即是该叶结点的霍夫曼码；对于非感兴趣区域的每个离散余弦变换集合，从最重要的位平面进行低密码奇偶校验码编码；对于每个位平面，所生成的奇偶检验信息被存储在缓&#27798;器中，在解码端的请求下，通过反馈机制，不断地发送校验信息。[0043]  对于关键帧，使用传统的联合图像专家组进行编码，利用感兴趣区域区分算法将非关键帧分为感兴趣区域和非感兴趣区域：对于感兴趣区域采用霍夫曼编解码，对于非感兴趣区域采用低密度奇偶校验码进行编解码，具体步骤如下：[0044]  步骤1)：将每帧分成大小相等且互不重叠的8×8宏块；[0045]  步骤2)：将关键帧和非关键帧进行梯度变化；[0046]  步骤3)：计算关键帧和非关键帧相同位置宏块的绝对差值之和；[0047]  步骤4)：根据感兴趣区域宏块的判定准则，对非关键帧每个宏块进行感兴趣区域区分；[0048]  步骤5)：对非关键帧的感兴趣区域宏块采用霍夫曼编解码压缩；[0049]  步骤6)：对非关键帧的其它宏块则采用低密度奇偶校验码编解码压缩。[0050]  有益效果：本发明方法提出了一种改进的wyner&#8212;ZiV分布式视频压缩方法，主要是用来解决无线多媒体传感器网络中视频数据量大所带来的网络节点能耗大，网络生存周期短的问题，并满足人们对解码图像质量以及视频实时性的需求。无线多媒体传感器网络通过使用本发明提出的方法，可以解决因大数据量传输带来的网络节点能耗大、网络生存 周期短，由运动剧烈带来的运动估计失效及由量化步长带来的方块效应的问题，以及对视 频的实时性和主观质量的要求高的问题。达到减少网络传输的数据量，降低节点传输能耗， 延长网络生存周期，确保多媒体视频数据传输的实时性和图像的高质量。下面给出具体的 说明：</p>
    <p>[0051]	1.编码简单：相对于传统的视频编码标准（如MPEG系列，H. 26x)，本发明由于采 用Wyner-Ziv分布式视频编码方案，编码端简单，解码端复杂。分布式视频编码将运动估计 和及运动补偿所带来的编码端的高复杂性、大计算量转移到解码端，而解码端一般位于汇 聚节点或网络中心，充分利用汇聚节点和网络中心计算能力强、存储能力大、持续供电的优 点，完成对视频的压缩编码。</p>
    <p>[0052]	2.低码率：本发明可以设置图像的G0P的大小，并对WZ帧采用了 LDPC和Huffman 相结合的编解码方式，向缓冲器所请求的奇偶校验位较少，从而大大降低了编码的码率。</p>
    <p>[0053]	3.能耗低：本发明由于可以改变Key帧之间WZ帧的数量，减少了待处理的视频流 的数据量，从而降低了每个传感器节点的编码处理能耗，进而延长了整个网络的生命周期。</p>
    <p>[0054]	4.实时性：本发明由于对视频数据的压缩率高，压缩编码后的数据量小，因此减 少了传输的数据量，优化了实时传输，进而保证了视频流传输的实时性。</p>
    <p>[0055]	5.可靠性：本发明由于采用了 R0I提取算法，将WZ帧分为R0I区域和非R0I区域， 对R0I区域采用Huffman编解码方式，实现了无失真压缩，提高了解码的准确性，此外，对解 码后的图像采取去块效应滤波，进一步提高了解码图像的主观质量，进而实现了对视频编 码压缩可靠性的要求。</p>
    <p>附图说明</p>
    <p>[0056]	图1是分布式视频编码示意图。如图，分布式视频编码框架包括低复杂度编码器 和高复杂度解码器。</p>
    <p>[0057]	图2是点对点无线移动视频通信的示意图。如图，发送方采用Wyner-Ziv分布式 视频编码并将编码的视频流发送至基站或网络中心节点，在基站或网络中心结点设置码流 转换器，将分布式码率转换为H. 26x/MPEG码流，然后由基站或网络中心结点将转换后的视 频流传送给接收方。对于发送方和接收方终端而言，仅需要进行较低复杂度的编码和解码。</p>
    <p>[0058]	图3是分布式编解码示意图。如图，采用帧内编码和帧间解码相结合的方式，在编 码端，采用帧内编码技术相互独立地编码两个或者多个相关的信源，将编码位流发送到接 收端；在解码端，利用各个信源间的相关性，进行联合预测解码。</p>
    <p>[0059]	图4是本发明基于梯度域的R0I区分的Wyner-Ziv分布式视频编码示意图。利用 R0I区分算法将WZ帧区分为R0I区域和非R0I区域，然后分别采用Huffman和LDPC进行编解码。</p>
    <p>[0060]	图5是解码图像后处理流程图。去块效应滤波仅在图像被解码之后进行滤波。</p>
    <p>[0061]	图6是本发明方法的整个流程图。如图所示，描述了基于梯度域R0I区分的 ffyner-Ziv分布式视频编解码的全过程。具体实施方式</p>
    <p>[0062]	本方法在Wyner-Ziv分布式视频编码方案的基础上，基于图像梯度场域，通过R0 判定准则提取运动剧烈区域并基于Huffman编解码压缩，其余区域则基于LDPC分布式编解 码，在降低码率的同时提高解码图像质量，降低节点的处理和传输能耗，实现视频的优化传 输，延长整个网络的生存周期。对解码后的图像采用去块效应滤波处理，进一步提高了解码 图像的质量。</p>
    <p>[0063]	本方法基于Wyner-Ziv分布式视频编码方案，将视频序列分为两种不同的帧：关 键帧（Key Frame，K帧）和Wyner-Ziv帧（WZ帧）。对关键帧采用传统的JPEG编码方式，利 用R0I区分算法将Wyner-Ziv帧分为R0I区域和非R0I区域，对Wyner_Ziv帧的R0I区域 采用Huffman编解码的方式，其余的非R0I区域LPDC的编解码方式。对解码后的图像进行 后处理，采用去块效应滤波，进一步提高了解码图像的质量。本方法的实施分为4个阶段： i)在编码端；ii)在解码端；iii)解码图像后处理；iv)帧混合，具体描述如下：</p>
    <p>[0064]	第一阶段：在编码端</p>
    <p>[0065]	该阶段分为以下几个处理过程：</p>
    <p>[0066]	a)帧分离器：视频序列被分为Wyner-Ziv帧（WZ帧)和关键帧（Key帧），其中关 键帧周期性的插入，取决于GOP (Group of Pictures)大小。利用帧分离器将视频序列分为 不同的帧，对于每个不同的视频序列，由于编码结构的不同，每帧的被赋予的属性不同，因 而，采用的编码处理方式也不同。</p>
    <p>[0067]	b)空间变换：基于块的变换，特别地把DCT变换应用到每个WZ帧。依据每个块的 DCT系数所处的位置，将整个WZ帧的DCT系数被分为不同的组，从而形成不同的DCT系数集。</p>
    <p>[0068]	c)量化：每个DCT集被统一的量化，这些量化级依赖于所要得到图像的质量。对 于一个给定的集合，量化信号的位流被一起分组，形成位平面，然后独立地进行编码。</p>
    <p>[0069]	d)编码：对于Key帧，使用传统的JPEG技术编码，利用R0I区分算法将Wyner-Ziv 帧分为R0I区域和非R0I区域：对于R0I区域采用Huffman编码，对于非R0I区域采用LDPC 编码。R0I区域采用Huffman编码的过程如下：将待编码的灰度级按出现的次数排序，出 现次数多的在前面，次数少的在后面；取出现次数最少的两个数的次数相加，之和作为一 个新的出现次数的集合元素并重新排序，新出现的次数在新集合中仍遵循降序规则以确定 所处的位置，相加的两个次数最少所对应的灰度级成为Huffman树的一个叶结点，这两个 结点构造一个双亲结点，重复该步骤，直到所有的灰度级都被用来构造Huffman树为止； 设所有结点的左孩子为“0”，右孩子为“1”，则从根开始，经各中间结点到叶结点的路径代 码即是该叶结点的Huffman码。对于非R0I区域的每个DCT集，从最重要的位平面（Most Significant Bit-plane,MSB)开始进行LDPC编码。对于每个位平面（bit-plane)，所生成 的奇偶检验信息被存储在缓冲器中，在解码端的请求下，通过反馈机制，不断地发送校验信 肩、o</p>
    <p>[0070]	通过这个阶段对视频序列进行了编码的相关处理，为下一阶段的解码作好了准 备。第二阶段：在解码端</p>
    <p>[0071]	该阶段分为以下几个处理过程：</p>
    <p>[0072]	a)生成边信息：解码端使用最近的已解码帧，通过执行运动补偿帧内插（或外推） 的方式生成每个WZ帧的边信息（Side Information，SI)。每个WZ帧的边信息被当作原始WZ帧的一种估计值。估计值的质量越好，LDPC解码端需要改正的“错误”越少，并且向缓冲 器所请求的奇偶校验位（或位流）越少。</p>
    <p>[0073]	b)相关噪声模型：在WZ帧和边信息中对应的DCT系数的残差统计被假定当作一 个服从拉普拉斯分布的模型，其参数使用离线（off-line)的训练阶段进行初始化估计。</p>
    <p>[0074]	c) LDPC解码：关键帧使用传统的JPEG技术进行解码；WZ帧的R0I区域使用 Huffman进行解码复原；对于WZ帧的非R0I区域，一旦知道了边信息DCT系数和一个给定 DCT系数的残差统计，每个位平面可以进行LDPC解码（从MSB解码)。在LDPC解码器的请 求下，编码器通过反馈信道发送一些奇偶校验消息。为了判定正确的解码某个特定的位平 面是否需要更多的校验位，解码器采用一个请求停止标准。当成功地LDPC解码一个DCT集 的MSB位平面之后，LDPC解码器以一个统一的的方式处理其余相关的集。一旦所有的DCT 集的位平面被成功地LDPC解码，LDPC解码器开始解码下一个集。</p>
    <p>[0075]	d)重构：在LDPC解码后，所有的位平面及每个DCT集被一起分组，以形成解码的 量化信号流和每个集。一旦可以获得所有的解码量化信号，在相应的边信息系数的辅助下， 便可重构所有的DCT系数。对于所传输的不含WZ位流的DCT系数集由边信息对应的DCT 集来代替。</p>
    <p>[0076]	e)反变换：当所有的DCT集被重建以后，执行IDCT，由此便可得到解码的WZ帧。</p>
    <p>[0077]	通过以上几个处理过程，完成了对Key帧和WZ帧的正确解码。</p>
    <p>[0078]	第三阶段：解码图像后处理</p>
    <p>[0079]	对解码后的图像使用滤波器，从而削弱由量化带来的方块效应。去块效应滤波器 是一维滤波器，为了得到二维效果，对一个块要进行两次滤波，第一次是在水平方向，第二 次在垂直方向。由于块效应产生的原因是量化误差将原来相邻像素值的连续变化变成了 “台阶”变化，看起来就有“伪边缘”的方块现象。去块效应就是在尽量使图像总的能量保持 不变的条件下，把那些“台阶”很高的阶跃型的灰度变化重新变成“台阶”很小或接近连续 的灰度变化。</p>
    <p>[0080]	第四阶段：帧混合</p>
    <p>[0081]	最后，对于已经正确解码的各帧，即利用传统JPEG编解码Key帧和利用LDPC及 Huffman混合编解码的WZ帧，根据在编码端所采用的编码结构G0P的大小，将Key帧和WZ 帧按G0P次序混合成视频流，恢复成解码后的视频序列。至此，视频编解码压缩处理结束。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101005621A?cl=zh">CN101005621A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年1月11日</td><td class="patent-data-table-td patent-date-value">2007年7月25日</td><td class="patent-data-table-td ">北京交通大学</td><td class="patent-data-table-td ">基于自适应哈什和格型矢量量化的分布式视频编码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101360236A?cl=zh">CN101360236A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年8月8日</td><td class="patent-data-table-td patent-date-value">2009年2月4日</td><td class="patent-data-table-td ">宁波大学</td><td class="patent-data-table-td ">一种Wyner-ziv视频编解码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101621690A?cl=zh">CN101621690A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年7月24日</td><td class="patent-data-table-td patent-date-value">2010年1月6日</td><td class="patent-data-table-td ">北京交通大学</td><td class="patent-data-table-td ">基于Wyner-Ziv理论的两描述视频编码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070013561">US20070013561</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年1月20日</td><td class="patent-data-table-td patent-date-value">2007年1月18日</td><td class="patent-data-table-td ">Qian Xu</td><td class="patent-data-table-td ">Signal coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080031344">US20080031344</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年8月4日</td><td class="patent-data-table-td patent-date-value">2008年2月7日</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Wyner-Ziv and Wavelet Video Coding</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102137262A?cl=zh">CN102137262A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年5月3日</td><td class="patent-data-table-td patent-date-value">2011年7月27日</td><td class="patent-data-table-td ">深圳市融创天下科技发展有限公司</td><td class="patent-data-table-td ">一种不规则划分视频编码模式选择方法、装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102158703A?cl=zh">CN102158703A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年5月4日</td><td class="patent-data-table-td patent-date-value">2011年8月17日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于分布式视频编码自适应相关噪声模型构造系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102510427A?cl=zh">CN102510427A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月1日</td><td class="patent-data-table-td patent-date-value">2012年6月20日</td><td class="patent-data-table-td ">大连三通软件有限公司</td><td class="patent-data-table-td ">一种低网络带宽手机实时在线传输的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102510427B?cl=zh">CN102510427B</a></td><td class="patent-data-table-td patent-date-value">2011年12月1日</td><td class="patent-data-table-td patent-date-value">2013年12月18日</td><td class="patent-data-table-td ">大连三通科技发展有限公司</td><td class="patent-data-table-td ">一种低网络带宽手机实时在线传输的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102572428A?cl=zh">CN102572428A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月28日</td><td class="patent-data-table-td patent-date-value">2012年7月11日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">面向多媒体传感网分布式编解码的边信息估计方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102572428B?cl=zh">CN102572428B</a></td><td class="patent-data-table-td patent-date-value">2011年12月28日</td><td class="patent-data-table-td patent-date-value">2014年5月7日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">面向多媒体传感网分布式编解码的边信息估计方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102595132A?cl=zh">CN102595132A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年2月17日</td><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">一种应用于无线传感器网络的分布式视频编解码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102630008A?cl=zh">CN102630008A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月29日</td><td class="patent-data-table-td patent-date-value">2012年8月8日</td><td class="patent-data-table-td ">北京京东方光电科技有限公司</td><td class="patent-data-table-td ">无线视频传输方法及终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102630008B?cl=zh">CN102630008B</a></td><td class="patent-data-table-td patent-date-value">2011年9月29日</td><td class="patent-data-table-td patent-date-value">2014年7月30日</td><td class="patent-data-table-td ">北京京东方光电科技有限公司</td><td class="patent-data-table-td ">无线视频传输方法及终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102833536A?cl=zh">CN102833536A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月24日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">一种面向无线传感器网络的分布式视频编解码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103002283A?cl=zh">CN103002283A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月20日</td><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">多视角分布式视频压缩的边信息生成方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103517072A?cl=zh">CN103517072A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月18日</td><td class="patent-data-table-td patent-date-value">2014年1月15日</td><td class="patent-data-table-td ">联想(北京)有限公司</td><td class="patent-data-table-td ">视频通信方法和设备</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103582901A?cl=zh">CN103582901A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月29日</td><td class="patent-data-table-td patent-date-value">2014年2月12日</td><td class="patent-data-table-td ">汤姆逊许可公司</td><td class="patent-data-table-td ">生成运动合成数据的方法和生成运动合成数据的设备</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019860000">H04N19/86</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019800000">H04N19/80</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019177000">H04N19/177</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0005210000">H04N5/21</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=2VV7BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04W0084180000">H04W84/18</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年10月6日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年11月24日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年9月7日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/78eb83267682c519b726/CN101854548A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4874c258b856314cce6b80d777b4ee7a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E9%9D%A2%E5%90%91%E6%97%A0%E7%BA%BF%E5%A4%9A%E5%AA%92%E4%BD%93%E4%BC%A0%E6%84%9F%E5%99%A8%E7%BD%91.pdf?id=2VV7BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2Y2WMgf6s6SGAmmY-2nKJgCACvfg"},"sample_url":"https://www.google.com/patents/reader?id=2VV7BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>