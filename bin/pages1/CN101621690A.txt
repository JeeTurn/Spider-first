<!DOCTYPE html><html><head><title>专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4874c258b856314cce6b80d777b4ee7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4874c258b856314cce6b80d777b4ee7a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于Wyner-Ziv理论的两描述视频编码方法"><meta name="DC.contributor" content="王安红" scheme="inventor"><meta name="DC.contributor" content="耀 赵" scheme="inventor"><meta name="DC.contributor" content="北京交通大学" scheme="assignee"><meta name="DC.date" content="2009-7-24" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种基于Wyner-Ziv的两描述视频编码方法。包括下列步骤：1)低复杂度编码，具体包括：奇偶帧分离；零运动H.264编码产生描述的第一部分；残差SW-SPIHT编码产生第二部分；冗余优化；2)高复杂度解码，具体包括：当两个描述都收到时，使用中心解码器解码；假设只有一个描述收到，例如，收到描述1，其第一部分进行零运动H.264解码得到W′&lt;sub&gt;1&lt;/sub&gt;，然后利用插值公式产生参考帧W&lt;sub&gt;re2&lt;/sub&gt;和边信息Y&lt;sub&gt;2&lt;/sub&gt;，并产生差值D&lt;sub&gt;1y&lt;/sub&gt;＝Y&lt;sub&gt;2&lt;/sub&gt;-W&lt;sub&gt;re2&lt;/sub&gt;。之后，进行SW-SPIHT解码器以重构差值D′&lt;sub&gt;1&lt;/sub&gt;，得到W″&lt;sub&gt;2&lt;/sub&gt;＝D′&lt;sub&gt;1&lt;/sub&gt;+W&lt;sub&gt;re2&lt;/sub&gt;，最后合并W′&lt;sub&gt;1&lt;/sub&gt;和W″&lt;sub&gt;2&lt;/sub&gt;，得到恢复的整个视频序列V′&lt;sub&gt;1&lt;/sub&gt;。本发明是一种兼具编码复杂度低和鲁棒性能好的视频编码框架，在有描述丢失时，该方法有更好的压缩性能，同时保持了低复杂度编码，可以满足低能耗设备的网络视频传输需求。"><meta name="DC.date" content="2010-1-6"><meta name="citation_patent_publication_number" content="CN:101621690:A"><meta name="citation_patent_application_number" content="CN:200910089805"><link rel="canonical" href="https://www.google.com/patents/CN101621690A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101621690A?cl=zh"/><meta name="title" content="专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法"/><meta name="description" content="本发明涉及一种基于Wyner-Ziv的两描述视频编码方法。包括下列步骤：1)低复杂度编码，具体包括：奇偶帧分离；零运动H.264编码产生描述的第一部分；残差SW-SPIHT编码产生第二部分；冗余优化；2)高复杂度解码，具体包括：当两个描述都收到时，使用中心解码器解码；假设只有一个描述收到，例如，收到描述1，其第一部分进行零运动H.264解码得到W′&lt;sub&gt;1&lt;/sub&gt;，然后利用插值公式产生参考帧W&lt;sub&gt;re2&lt;/sub&gt;和边信息Y&lt;sub&gt;2&lt;/sub&gt;，并产生差值D&lt;sub&gt;1y&lt;/sub&gt;＝Y&lt;sub&gt;2&lt;/sub&gt;-W&lt;sub&gt;re2&lt;/sub&gt;。之后，进行SW-SPIHT解码器以重构差值D′&lt;sub&gt;1&lt;/sub&gt;，得到W″&lt;sub&gt;2&lt;/sub&gt;＝D′&lt;sub&gt;1&lt;/sub&gt;+W&lt;sub&gt;re2&lt;/sub&gt;，最后合并W′&lt;sub&gt;1&lt;/sub&gt;和W″&lt;sub&gt;2&lt;/sub&gt;，得到恢复的整个视频序列V′&lt;sub&gt;1&lt;/sub&gt;。本发明是一种兼具编码复杂度低和鲁棒性能好的视频编码框架，在有描述丢失时，该方法有更好的压缩性能，同时保持了低复杂度编码，可以满足低能耗设备的网络视频传输需求。"/><meta property="og:title" content="专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?hl=zh-CN&tbm=isch&source=og&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?hl=zh-CN&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?hl=zh-CN&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101621690A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101621690A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=aTl2BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101621690A&amp;usg=AFQjCNG_uGSQvfNNQWJn7T4AmwOsKl5Rww" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/e6d37ff5658dd25ca063/CN101621690A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/e6d37ff5658dd25ca063/CN101621690A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101621690A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101621690A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101621690A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101621690B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101621690A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种基于Wyner-Ziv的两描述视频编码方法。包括下列步骤：1)低复杂度编码，具体包括：奇偶帧分离；零运动H.264编码产生描述的第一部分；残差SW-SPIHT编码产生第二部分；冗余优化；2)高复杂度解码，具体包括：当两个 ...</span><span itemprop="url">https://www.google.com/patents/CN101621690A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法" title="专利 CN101621690A - 基于Wyner-Ziv理论的两描述视频编码方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101621690 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200910089805</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年1月6日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2009年7月24日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2009年7月24日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101621690B?hl=zh-CN&amp;cl=zh">CN101621690B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200910089805.7, </span><span class="patent-bibdata-value">CN 101621690 A, </span><span class="patent-bibdata-value">CN 101621690A, </span><span class="patent-bibdata-value">CN 200910089805, </span><span class="patent-bibdata-value">CN-A-101621690, </span><span class="patent-bibdata-value">CN101621690 A, </span><span class="patent-bibdata-value">CN101621690A, </span><span class="patent-bibdata-value">CN200910089805, </span><span class="patent-bibdata-value">CN200910089805.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E5%AE%89%E7%BA%A2%22">王安红</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%80%80+%E8%B5%B5%22">耀 赵</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%22">北京交通大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101621690A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101621690A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101621690A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (12),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (4)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=aTl2BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200910089805&amp;usg=AFQjCNGgOQ-0UFtfG8vvzmQ_yDb029x7fg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=aTl2BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101621690A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHF-0LRBBzvdF9WkTrjLMbFnbHWNw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT91631569" lang="ZH" load-source="patent-office">基于Wyner-Ziv理论的两描述视频编码方法</invention-title>
      </span><br><span class="patent-number">CN 101621690 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA72429304" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种基于Wyner-Ziv的两描述视频编码方法。包括下列步骤：1)低复杂度编码，具体包括：奇偶帧分离；零运动H.264编码产生描述的第一部分；残差SW-SPIHT编码产生第二部分；冗余优化；2)高复杂度解码，具体包括：当两个描述都收到时，使用中心解码器解码；假设只有一个描述收到，例如，收到描述1，其第一部分进行零运动H.264解码得到W′&lt;sub&gt;1&lt;/sub&gt;，然后利用插值公式产生参考帧W&lt;sub&gt;re2&lt;/sub&gt;和边信息Y&lt;sub&gt;2&lt;/sub&gt;，并产生差值D&lt;sub&gt;1y&lt;/sub&gt;＝Y&lt;sub&gt;2&lt;/sub&gt;-W&lt;sub&gt;re2&lt;/sub&gt;。之后，进行SW-SPIHT解码器以重构差值D′&lt;sub&gt;1&lt;/sub&gt;，得到W″&lt;sub&gt;2&lt;/sub&gt;＝D′&lt;sub&gt;1&lt;/sub&gt;+W&lt;sub&gt;re2&lt;/sub&gt;，最后合并W′&lt;sub&gt;1&lt;/sub&gt;和W″&lt;sub&gt;2&lt;/sub&gt;，得到恢复的整个视频序列V′&lt;sub&gt;1&lt;/sub&gt;。本发明是一种兼具编码复杂度低和鲁棒性能好的视频编码框架，在有描述丢失时，该方法有更好的压缩性能，同时保持了低复杂度编码，可以满足低能耗设备的网络视频传输需求。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(1)</span></span></div><div class="patent-text"><div mxw-id="PCLM28775000" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1、一种基于Wyner-Ziv理论的两描述视频编码方法，其特征在于：包括低复杂度编码和高复杂度解码，    所述的低复杂度编码步骤如下：    步骤1：帧分离，奇偶帧分离产生两个子序列W1和W2；    步骤2：对W1和W2分别用零运动H.264编码以产生两个描述的part 1；    步骤3：解码两个子序列的part 1码流得到W′1和W′2，并根据公式    &lt;maths id="math0001" num="0001" &gt;&lt;math&gt;&lt;![CDATA[  &lt;mrow&gt;    &lt;msub&gt;      &lt;mi&gt;W&lt;/mi&gt;      &lt;mrow&gt;        &lt;mi&gt;re&lt;/mi&gt;        &lt;mn&gt;1&lt;/mn&gt;        &lt;mo&gt;,&lt;/mo&gt;        &lt;mi&gt;i&lt;/mi&gt;      &lt;/mrow&gt;    &lt;/msub&gt;    &lt;mo&gt;=&lt;/mo&gt;    &lt;mfrac&gt;      &lt;mrow&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;2&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;          &lt;/mrow&gt;        &lt;/msub&gt;        &lt;mo&gt;+&lt;/mo&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;2&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;            &lt;mo&gt;+&lt;/mo&gt;            &lt;mn&gt;1&lt;/mn&gt;          &lt;/mrow&gt;        &lt;/msub&gt;      &lt;/mrow&gt;      &lt;mn&gt;2&lt;/mn&gt;    &lt;/mfrac&gt;  &lt;/mrow&gt;]]&gt;&lt;/math&gt; id="icf0001" file="A2009100898050002C1.tif" wi="39" he="10" top= "90" left = "29" img-content="drawing" img-format="tif" orientation="portrait" inline="yes"/&gt;&lt;/maths&gt;和&lt;maths id="math0002" num="0002" &gt;&lt;math&gt;&lt;![CDATA[  &lt;mrow&gt;    &lt;msub&gt;      &lt;mi&gt;W&lt;/mi&gt;      &lt;mrow&gt;        &lt;mi&gt;re&lt;/mi&gt;        &lt;mn&gt;2&lt;/mn&gt;        &lt;mo&gt;,&lt;/mo&gt;        &lt;mi&gt;i&lt;/mi&gt;      &lt;/mrow&gt;    &lt;/msub&gt;    &lt;mo&gt;=&lt;/mo&gt;    &lt;mfrac&gt;      &lt;mrow&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;1&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;            &lt;mo&gt;-&lt;/mo&gt;            &lt;mn&gt;1&lt;/mn&gt;          &lt;/mrow&gt;        &lt;/msub&gt;        &lt;mo&gt;+&lt;/mo&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;1&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;          &lt;/mrow&gt;        &lt;/msub&gt;      &lt;/mrow&gt;      &lt;mn&gt;2&lt;/mn&gt;    &lt;/mfrac&gt;  &lt;/mrow&gt;]]&gt;&lt;/math&gt; id="icf0002" file="A2009100898050002C2.tif" wi="39" he="10" top= "90" left = "75" img-content="drawing" img-format="tif" orientation="portrait" inline="yes"/&gt;&lt;/maths&gt;    产生两个子序列每帧的参考帧Wre1和Wre2，其中，W′1，i-1和W′1，i是描述1中当前帧的前、后解码帧；    步骤4：做减法产生残差，对描述1，D1＝W′2-Wre2，对描述2，D2＝W′1-Wre1；    步骤5：根据优化的组合量化，对残差D1和D2分别进行SW-SPIHT编码产生两个Wyner-Ziv码流，形成对应描述的part 2；    步骤6：将相同描述的part 1和part 2码流送入相同的信道进行传输；    所述的高复杂度解码步骤如下：    步骤1：判断有无描述丢失；    步骤2：假设描述2丢失，只收到描述1，进行下列的解码；    1)：先进行零运动H.264解码得到part 1，W′1；    2)：分别根据公式&lt;maths id="math0003" num="0003" &gt;&lt;math&gt;&lt;![CDATA[  &lt;mrow&gt;    &lt;msub&gt;      &lt;mi&gt;W&lt;/mi&gt;      &lt;mrow&gt;        &lt;mi&gt;re&lt;/mi&gt;        &lt;mn&gt;2&lt;/mn&gt;        &lt;mo&gt;,&lt;/mo&gt;        &lt;mi&gt;i&lt;/mi&gt;      &lt;/mrow&gt;    &lt;/msub&gt;    &lt;mo&gt;=&lt;/mo&gt;    &lt;mfrac&gt;      &lt;mrow&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;1&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;            &lt;mo&gt;-&lt;/mo&gt;            &lt;mn&gt;1&lt;/mn&gt;          &lt;/mrow&gt;        &lt;/msub&gt;        &lt;mo&gt;+&lt;/mo&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;1&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;          &lt;/mrow&gt;        &lt;/msub&gt;      &lt;/mrow&gt;      &lt;mn&gt;2&lt;/mn&gt;    &lt;/mfrac&gt;  &lt;/mrow&gt;]]&gt;&lt;/math&gt; id="icf0003" file="A2009100898050002C3.tif" wi="39" he="10" top= "203" left = "80" img-content="drawing" img-format="tif" orientation="portrait" inline="yes"/&gt;&lt;/maths&gt;和    Y2，i(x，y)＝0.25×W′1，i-1(x+0.5×dxf，y+0.5×dyf)    +0.25×W′1，i(x-0.5×dxf，y-0.5×dyf)    +0.25×W′1，i-1(x-0.5×dxb，y-0.5×dyb)    +0.25×W′1，i(x+0.5×dxb，y+0.5×dyb)    产生参考帧Wre2和边信息Y2，其中，W′1，i-1和W′1，i是描述1中当前帧的前、后解码帧，(x，y)是内插帧的坐标，[dxf，dyf]和[dxb，dyb]分别是前、后向运动矢量，可通过W′1，i-1和W′1，i用半像素运动估计等到；    3)：计算差值Dy1＝Y2-Wre2，并用差值Dy1作为边信息进行SW-SPIHT解码，得到恢复的差值D′1；    4)：作加法得到恢复的part 2，即W″2＝D′1+Wre2；    5)：合并W′1和W″2，得到恢复的原始视频序列V′1；    步骤3：假设描述1丢失，只收到描述2，进行下列的解码；    1)：先进行零运动H.264解码得到part 1，W′2；    2)：分别根据公式&lt;maths id="math0004" num="0004" &gt;&lt;math&gt;&lt;![CDATA[  &lt;mrow&gt;    &lt;msub&gt;      &lt;mi&gt;W&lt;/mi&gt;      &lt;mrow&gt;        &lt;mi&gt;re&lt;/mi&gt;        &lt;mn&gt;1&lt;/mn&gt;        &lt;mo&gt;,&lt;/mo&gt;        &lt;mi&gt;i&lt;/mi&gt;      &lt;/mrow&gt;    &lt;/msub&gt;    &lt;mo&gt;=&lt;/mo&gt;    &lt;mfrac&gt;      &lt;mrow&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;2&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;          &lt;/mrow&gt;        &lt;/msub&gt;        &lt;mo&gt;+&lt;/mo&gt;        &lt;msub&gt;          &lt;msup&gt;            &lt;mi&gt;W&lt;/mi&gt;            &lt;mo&gt;&amp;prime;&lt;/mo&gt;          &lt;/msup&gt;          &lt;mrow&gt;            &lt;mn&gt;2&lt;/mn&gt;            &lt;mo&gt;,&lt;/mo&gt;            &lt;mi&gt;i&lt;/mi&gt;            &lt;mo&gt;+&lt;/mo&gt;            &lt;mn&gt;1&lt;/mn&gt;          &lt;/mrow&gt;        &lt;/msub&gt;      &lt;/mrow&gt;      &lt;mn&gt;2&lt;/mn&gt;    &lt;/mfrac&gt;  &lt;/mrow&gt;]]&gt;&lt;/math&gt; id="icf0004" file="A2009100898050003C1.tif" wi="37" he="9" top= "106" left = "74" img-content="drawing" img-format="tif" orientation="portrait" inline="yes"/&gt;&lt;/maths&gt;和    Y1，i(x，y)＝0.25×W′2，i(x+0.5×dxf，y+0.5×dyf)    +0.25×W′2，i+1(x-0.5×dxf，y-0.5×dyf)    +0.25×W′2，i(x-0.5×dxb，y-0.5×dyb)    +0.25×W′2，i+1(x+0.5×dxb，y+0.5×dyb)    产生参考帧Wre1和边信息Y1，并得到差值Dy2＝Y1-Wre1；    3)：用差值Dy2作为边信息进行SW-SPIHT解码，得到恢复的差值D′2；    4)：作加法得到恢复的part 2，即W″1＝D′2+Wre1；    5)：合并W″1和W′2，得到恢复的原始视频序列V′2；    步骤4：当没有描述丢失时，进行下列的解码；    1)：用零运动H.264解码得到两个描述的part 1，W′1和W′2，    2)：合并W′1和W′2以恢复视频V′0。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES35266981" lang="ZH" load-source="patent-office" class="description">
    <p>基于Wyner-Ziv理论的两描述视频编码方法</p>
    <p>技术领域</p>
    <p>本发明涉及一种视频编码方法，尤其是涉及一种基于Wyner-Ziv理论的 两描述视频编码方法。 背景技术</p>
    <p>多描述视频编码（Multiple Description Video Coding)是应码流鲁 棒传输而产生的一种新的编码思想，它将一个视频信源分为多个码流（即多 个描述），不同的描述被发送到不同的信道，当有信道丢失时，丢失的描述 可用接收到的描述来估计得到，从而取得可以接受的恢复质量。当没有信道 丢失时，用所有接收到的描述来恢复得到较高质量的视频。</p>
    <p>两描述编码是一种最基本的多描述编码方式，仅考虑将信源分为两个描 述发送到两个信道的情况，基本原理如图l (a) ,l(b)所示。两边信道的解 码器1和解码器2被称为边解码器（side decoder)，中间信道的解码器O 被称为中心解码器（central decoder)。若只有一个信道工作，利用边解 码器进行解码，重建信号的失真值大于最小限度失真值；若两个信道的信号 都收到，则用中心解码器来恢复以获得更高质量的重建值。</p>
    <p>一般而言，多描述或两描述视频编码的实现有两种方式：基于运动补偿循 环和基于前后处理的方法。基于运动补偿循环的方法，首先在编码端进行运动 估计和运动补偿，然后将运动矢量和预测误差通过多个信道发送到解码端。由 于该方法不易与现有视频标准兼容，从而限制了其实际应用。而基于前后处理 的多描述视频编码方法，首先将原始视频序列进行预处理，引入冗余，然后将预 处理后的序列分割成多个视频子序列，对各个子序列独立进行编解码。解码端 用收到的子序列来估计丢失的子序列，后处理阶段将所有子序列进行融合以生 成最后的重建视频。该方法易于兼容现有视频编码标准，实现容易。时域插帧和空域填补零是基于前后处理多描述视频编码的两种常用方法。前者根据视频 的运动情况，自适应地加入冗余帧，然后将视频抽取为多个描述，每个描述分 别用标准编码器进行压缩后传送到解码端；解码端在后处理阶段又去掉冗余帧。 而后者对输入视频序列的每一帧分别进行DCT (Discrete Consine Transform)变 换，并向DCT系数中添加零系数引入冗余，然后进行逆DCT变换产生过采样 帧，接着将过采样帧按空域亚采样分解为多个描述，例如奇行奇列和偶行偶列 像素组成一个描述，其余像素组成另一个描述。两个描述分别由带运动估计的 标准编码器编码。若两个描述同时收到，可按上述过程的逆过程恢复视频信号， 如果只收到一个描述，则丢失像素由其相邻像素进行内插重构得到。</p>
    <p>上述传统的多描述视频编码方法中，都在不同阶段利用了复杂度较高的运 动估计，因此方案的一个最大缺陷是编码的复杂度高，而它们的解码端，由于 没有运动估计，相对来说比较简单，因此这种多描述编码方法适合于一次编码 多次解码的广播式视频传输。</p>
    <p>随着网络通信的发展和3G通信的兴起， 一些新兴的低能耗视频设备大量涌 现，如3G手机、无线传感器网络、网络视频监控等等，这些设备都有视频的摄 取能力，但是由于其自身的能量和内存有限，它们要求低复杂度的编码方法， 而他们的解码端， 一般连接到网络的基站，基站具有较高的运算能力，可以适 应一些高复杂度的解码算法。这和上述传统方法的适应场合恰恰相反。因此， 采用现有的方法来生成多描述视频码流是不能满足低能耗设备的视频传输要求 的。</p>
    <p>上世纪70年代信息论中出现的Wyner-Ziv理论是针对多个相关信源编码的 理论，近几年，Wyenr-Ziv理论随着通信中低复杂度编码要求而得到很高的关 注。对两个相关信源Z和JS如果在编码端不利用信源的相关性而仅仅在解码 端利用信源的相关性进行解码，则Wyner-Ziv编码的码率范围可以表示为：(1)</p>
    <p>Wyner-Ziv理论表明，对相关信源义和r，如果在编码端不利用信源的相关 性而仅仅在解码端利用信源的相关性进行解码，则总码率也可以得到和编、解 码端都利用相关性基本类似的性能。Wyner-Ziv理论提出了一种简化编码端的 新思路，可以将一些计算量巨大的去相关方法从编码端移动到解码端进行，从 而可以实现低复杂度编码。</p>
    <p>一个典型的Wyner-Ziv编码器如图2所示，对相关信源x和。假设信源r 已用传统方法进行压&#32302;并在解码端恢复了，仅考虑义的压&#32302;问题。编码端对义进 行独立编码而不考虑r的相关性，解码端利用y的相关性进行解码以恢复义，即 H又仅作为义解码的边信息。具体实现中，编码器由量化器和信道编码组成，量 化器首先将信源X量化为二进制序列g，然后二进制序列进行系统信道编码生成 伴随式位和信息位，抛弃信息位，只传输部分的伴随式到解码端。解码端利用 接收到得伴随位和边信息Y进行信道纠错解码以恢复量化序列《'，最后再利用边 信息r，将《'恢复为原始值r。由于x和y之间较强的相关性，编码端仅传输较</p>
    <p>少的的伴随式，解码端也可以利用伴随式和边信息来恢复信源&#20034;，正是因为传 送的伴随式少于g的比特数，Wyner-Ziv编码可取得压&#32302;。</p>
    <p>将Wyner-Ziv理论应用于视频编码，将相邻帧看做相关信源，设当前要进 行编码的帧是Wyner-Ziv帧，对Wyner-Ziv帧首先进行变换编码以进一步去除 帧内空间相关性，边信息y通过已解码的帧用运动估计和运动补偿产生。如图3 所示，Wyner-Ziv视频编码器由于将复杂度高的运动估计移到解码端，因而实 现了低复杂度编码。与成熟的视频压缩技术相比（如MPEG系列，H. 26*系列等）， Wyner-Ziv编码的复杂度仅仅与其帧内编码相当，远远小于其帧间编码复杂度。 正因为低复杂度编码特性，Wyner-Ziv视频编码特别适合于现在新兴的低能耗 网络终端的视频传输要求。虽然Wyner-Ziv的解码端由于采用迭代的信道纠错 解码算法，造成较高的复杂度，但是对低能耗设备的网络视频通信来说，我们 可以将复杂的解码算法转移到基站中进行。发明内容</p>
    <p>本发明的目的在于改进现有技术中的不足而提供一种基于Wyner-Ziv 理论的两描述视频编码方法。充分利用Wyner-Ziv编码在解码端利用信源相 关性的特性，将运动估计从编码端转移到解码端进行，从而实现低复杂度编 码，并用Wyner-Ziv码流来恢复丢失的子序列，取得较好的传输鲁棒性。</p>
    <p>本发明的目的通过以下技术方案来达到：</p>
    <p>一种基于Wyner-Ziv理论的两描述视频编码方法，包括低复杂度编码和 高复杂度解码，</p>
    <p>所述的低复杂度编码步骤如下：</p>
    <p>步骤l:帧分离，奇偶帧分离产生两个子序列W和K;</p>
    <p>步骤2:对R和K分别用零运动H. 264编码以产生两个描述的part 1;</p>
    <p>步骤3:解码两个子序列的part 1码流得到^和PF'2，并根据公式&lt;formula&gt;formula see original document page 7&lt;/formula&gt;</p>
    <p>产生两个子序列每帧的参考帧L,和^2，其中，i和『i，,是描述1中当</p>
    <p>前帧的前、后解码帧；</p>
    <p>步骤4:做减法产生残差，对描述l， A=『2jre2，对描述2， D2=『,&#8212;</p>
    <p>步骤5:根据优化的组合量化，对残差A和A分别进行SW-SPIHT编码产 生两个Wyner-Ziv码流，形成对应描述的part 2;</p>
    <p>步骤6:将相同描述的part 1和part 2码流送入相同的信道进行传输；</p>
    <p>所述的高复杂度解码步骤如下：</p>
    <p>步骤1:判断有无描述丢失；</p>
    <p>步骤2:假设描述2丢失，只收到描述l，进行下列的解码；</p>
    <p>1) :先进行零运动H. 264解码得到part 1，『、；</p>
    <p>2) :分别根据公式 ^A&lt;formula&gt;formula see original document page 7&lt;/formula&gt;^2,; (A力=0.25 x『w一 (x + 0.5 x&#12316;，&gt;&gt; + 0.5 x办,) + 0.25 x（x &#8212; 0.5 x&#12316;，y - 0.5 x办f ) + 0.25 x『L卜t (x &#8212; 0.5 x血6, _y - 0.5 x命6 ) + 0.25 x(x + 0.5 x血6, _y + 0.5 x办6 )</p>
    <p>产生参考帧^2和边信息72，其中，『'1,,_1和^,,是描述1中当前帧的前、后解</p>
    <p>码帧， o，力 是内插帧的坐标， J和[a,^]分别是前、后向运动矢量，可</p>
    <p>通过和『,,用半像素运动估计等到；</p>
    <p>3) :计算差值&#12316;=6-^2，并用差值&#12316;作为边信息进行SW-SPIHT解码，</p>
    <p>得到恢复的差值o'"</p>
    <p>4) :作加法得到恢复的part 2，即『'2^'1+^2;</p>
    <p>5) :合并^和『'、，得到恢复的原始视频序列rv, 步骤3:假设描述l丢失，只收到描述2，进行下列的解码；</p>
    <p>1) :先进行零运动H. 264解码得到part 1，  tr2;</p>
    <p>『，</p>
    <p>2) :分别根据公式『一="2 ""禾口</p>
    <p>(;c,力=0.25x『2&gt; O + 0.5x&#12316;，j + 0.5x勿）</p>
    <p>十0.25x PT2,,.+1 (x &#8212; 0.5x血,，y-0.5x办,) + 0.25 x『2,,. (x - 0.5 x血&amp;, j; 一 0.5 x ) + 0.25 x『2,,.+1 (x + 0.5 x&#12316;，少+ 0.5 x ^)</p>
    <p>产生参考帧l和边信息y,，并得到差值~2 = y, ;</p>
    <p>3) :用差值Z^作为边信息进行SW-SPIHT解码，得到恢复的差值D'2;</p>
    <p>4) :作加法得到恢复的part 2，即『1=/72《|;</p>
    <p>5) :合并『、和『、，得到恢复的原始视频序列「2; 步骤4:当没有描述丢失时，进行下列的解码；</p>
    <p>1) :用零运动H. 264解码得到两个描述的part 1，『',和『2 ，</p>
    <p>2) :合并^和『、以恢复视频r。。本发明的优点在于：</p>
    <p>具有编码复杂度低和鲁棒性能好的视频编码框架，实验表明，在有描述 丢失时，该方法有更好的压缩性能，同时保持了低复杂度编码，因而可以满 足低能耗视频设备的网络传输需求。 附图说明</p>
    <p>图1 (a)，图1  (b)为两描述编码原理图； 图2为一个典型的Wyner-Ziv编码原理框图； 图3为Wyner-Ziv视频编码原理框图； 图4为基于Wyner-Ziv理论的两描述视频编码原理框架； 图5为残差Wyner-Ziv编码原理框图； 图6. SW-SPIHT编码原理图； 图7(a),图7(b)为率失真性能比较图; 图8(a)，图8(b)为Ql点的帧PSNR比较图。 具体实施方式</p>
    <p>如图4所示，本发明基于Wyner-Ziv的两描述视频编码方法包含了低复 杂度编码和高复杂度解码两部分。在低复杂度编码端，视频序列首先被分成 两个子序列，每个子序列首先用零运动H. 264 (图中标示为H. 264 0-mv)编 码形成描述的第一部分part 1，然后用优化的残差Wyner-Ziv编码来产生 描述的第二部分part 2。</p>
    <p>l.低复杂度编码</p>
    <p>(1) 帧分离</p>
    <p>一个视频序列首先被分成两个子序列，为了实现低复杂度编码，方案采 用简单的奇偶帧分离法，奇数帧组成描述l，偶数帧形成描述2。</p>
    <p>(2) H. 264 O-mv编码</p>
    <p>使用H. 264 O-mv编码是为了满足part 1的低复杂度编码要求，H. 264 O-mv意味着用前一时刻帧作参考帧进行零运动矢量搜索编码，因此它类似于一个差分脉冲编码调制（DPCM)。由于DPCM利用了相邻帧的时域相关性， 因此H.264 0-mv编码的率失真性能高于帧内编码的性能，另外，由于编码 端没有使用运动估计，其编码计算量也是较低的。在实验中，我们使用了 H. 264的测试版本JM9. 0进行仿真，结果发现H. 264 0-mv的编码复杂度与 帧内编码类似。</p>
    <p>(3) 残差Wyner-Ziv编码</p>
    <p>残差Wyner-Ziv的原理如图5所示，对当前Wyner-Ziv帧『和参考帧W^ 的残差Z)进行Wyner-Ziv编码。由于残差Wyner-Ziv编码相当于在经典方案 的编、解码端同时增加了一个条件P^，  ^与r间有一定的相关性，因而从</p>
    <p>信息论的角度来说，增加的条件将使得系统的码率降低，从而使得残差 Wyner-Ziv编码取得比非残差Wyner-Ziv编码更好的率失真性能。</p>
    <p>(4) 两描述残差Wyner-Ziv编码</p>
    <p>本发明将残差Wyner-Ziv编码的思想扩展到两描述Wyner-Ziv中来减少 描述间的冗余，形成两描述残差Wyner-Ziv编码。图4的方案中，视频序列 首先被分成两个子序列，两个子序列编码分别形成对应描述的Part 1， part 2由另一子序列用残差Wyner-Ziv编码产生。在有描述丢失时，Wyner -Ziv 码流可以帮助恢复丢失的描述，但当没有丢失时，Wyner-Ziv码流是冗余的。 由于两个子序列间有较强的相关性，因此可以借助另一子序列产生参考帧来 进行残差Wyner-Ziv编码以减少冗余。</p>
    <p>对每个描述的差值&#163;&gt; =『-K《进行Wyner-Ziv编码以形成对应的part 2，</p>
    <p>D4-i用作解码的边信息，其中f^是参考帧。对描述l来说，A=『2-^2， D,1 = r2&#8212;『re2，对描述2，  D"『广^p  z^-r广『rel。参考帧Re和边信息r通过</p>
    <p>内插生成，方案中使用两种内插方案， 一种是简单的平均内插，这种内插在 编码端和解码端都被使用以产生参考帧4,和12， 一种是复杂的运动估计 内插，运动估计内插仅仅在解码端被用来产生边信息帧^和72 。比如，描 述1中，对第,帧来说，其参考帧^2,,和边信息帧分别利用下列公式来产生，『"-</p>
    <p>『W =      ，  2      ' (2)</p>
    <p>y2,, (x,力=0.25 x『'1M (x + 0.5 x血y j + 0.5 x勿） + 0.25 xO &#8212; 0.5 x&#12316;，；;一 0.5 x t/j^ )</p>
    <p>+ 0.25 x（x &#8212; 0.5 x血6 ， _V _ 0.5 x     ) ( 3 )</p>
    <p>+ 0.25 x(x + 0.5 x ~ ， _V + 0.5 x )</p>
    <p>参考帧和内插帧，其中，『1，,-,和^,是描述1中当前帧的前后解码帧，（x,力是</p>
    <p>内插帧的坐标 ]禾口 [AA ，办A ]分别是前、后向运动矢量，可通il WV,&#8212;,和</p>
    <p>用半像素运动估计等到。</p>
    <p>类似地，描述2的参考帧和边信息帧用下列公式产生：</p>
    <p>『4, =    2，' 2 2'' 1 (4)</p>
    <p>~(x，力=0.25x『'2i. O + 0.5x血,，少+ 0.5x勿）</p>
    <p>+ 0.25 x『2'i+1 (jc - 0.5 x&#12316;，；;一 0.5 x勿）</p>
    <p>+ 0.25 x『'2,,0 - 0.5 x血6,y-0.5 x办O (5) + 0.25 x PP2';+1 O + 0.5 x ~少+ 0.5 x办6)</p>
    <p>(5) sw-spiht编码</p>
    <p>SW-SPIHT是小波域Wyner-Ziv编码的一种实现，对相关信源义和r， x经 过小波变换禾口 SPIHT (Set partitioning in hierarchical tree)量化后的 信息与信源y的对应信息也相关，因此可以用信道码来编码，仅仅传送部分 的伴随式，解码端用边信息和伴随式通过信道解码来恢复J的SPIHT信息。</p>
    <p>SW-SPIHT编码原理如图6所示，对于小波系数c^首先执行传统SPIHT 编码得到每个位平面的零树分布信息叫，有效位信息m，符号信息戮和细 化信息竭，，表示G的第,个位平面。假设要恢复的位平面数是"，，=i，然 后使用信道码LDPCA (Low Density Parity Check Codes Accumulate)执</p>
    <p>行下面的交错编解码步骤。</p>
    <p>步骤一：用熵编码压缩零树分布信息SD,，然后发送到解码端。</p>
    <p>步骤二：在解码端，用解码的S",来抽取边信息的有效位信息S;，即假设边信息的零树信息是SD,.，则可以根据SA来判断当前位平面所有非零树的有效 信息S&amp;,，然后将S^作为^的边信息。</p>
    <p>步骤三：对化进行LDPCA编码，将其所有伴随式比特存放缓存，然后根</p>
    <p>据反馈信息逐步发送其伴随式比特到解码端。解码端利用收到的伴随式比特 和边信息S;来进行LDPCA解码以恢复M。其中的反馈信道是为了适应S尸,和</p>
    <p>S:的相关性变化。</p>
    <p>步骤四：解码端用恢复的有效信息W和零树分布信息SA来抽取S,的符</p>
    <p>号信息和细化信息，这将作为^和M,解码的边信息。</p>
    <p>步骤五：用LDPCA编码S5,和细化信息朋,，存储所有伴随式比特，然后根</p>
    <p>据反馈信道的信息逐步地发送其伴随式到解码端。解码端利用收到的伴随式 和边信息S&amp;, 、        解码恢复主信息5S,和朋,。</p>
    <p>步骤六：令/ = "1，然后返回到步骤一，重复执行，直到n个位平面都恢复。</p>
    <p>步骤七：用边信息对小波系数进行精细重构以恢复^，见下面介绍。 步骤八：IDWT恢复原始图像。</p>
    <p>(6) SW-SPIHT中基于边信息的小波系数重构</p>
    <p>SW-SPIHT解码可以得到恢复的SPIHT流，假设此恢复是无差错的。由 于恢复的SPIHT码流含有G的信息，而G与边信息CJ之间有很强的相关性， 此相关性在高位平面时尤为突出，因此恢复的SPIHT码流与CJ也同样有较 强的相关性。基于此种情况，我们提出了一种更好的重构^的方法，也就是 用公式（6)通过恢复的SPIHT码流来精细CJ。</p>
    <p>"max ， Cj 一 Vmax</p>
    <p>C '/ C^(V,nin,v&#8222; vmin,    '/ 《v&#33139;</p>
    <p>(6)其中C、为最终恢复的小波系数；；和^分别为^可能的最大值和最 小值，可根据恢复的SPIHT信息推断；m为^的位平面总数，要恢复的位 平面数用"来表示，其中w^w。此方法提高了小波系数的重构，原因有二， 其一，用恢复的w个位平面信息限制了单纯由CJ位平面重构C,而产生的失 真；其二， C纟其余的m-n个低位平面信息补充了恢复的n个高位平面的信息， 从而对重构起到了补偿作用。</p>
    <p>(7)冗余优化</p>
    <p>方案中，当没有描述丢失时，Wyner-Ziv比特将是冗余的。冗余的 Wyner-Ziv比特数将会影响系统的性能， 一方面，Wyner-Ziv比特数越多， 两个描述的相关性越大，当有信道丢失时，由收到的描述来估计丢失描述所 产生的失真小，这使得边解码质量变好；但另一方面，当没有信道丢失时， Wyner-Ziv比特数越多，增加的冗余越多，从而中心解码的率失真性能会降 低。因此要对冗余进行优化，优化基于下列思想。</p>
    <p>设视频输入是r， J。(r,w)和(或者"&#8222;))分别表示中心和边解码 的均方误差，设Wyner-Ziv的比特是w， w化,ao是两个描述的总码率，^(k，w) 和A(k,ao分别是两个描述的码率，设两描述平衡，我们的优化目的是寻找 优化的参数w以解决下列的优化问题：</p>
    <p>受约束于 条件1:</p>
    <p>尺(7， w) =     (f, w) = 2/?2(f, w) s wwge (7)</p>
    <p>条件2:</p>
    <p>其中，^柳是编码两个描述的总码率，4命是中心解码的最大失真。优</p>
    <p>化过程可以解释为：固定中心解码质量和总码率，调整w使得边失真最小。优化方案的执行过程首先初始化，然后在条件1和2约束下，逐渐搜索W使 得",最小。</p>
    <p>具体地，在我们的方案中，SW-SPIHT编码将产生冗余，它的码率将影响 系统的率失真性能，为了实现简单，我们对SW-SPIHT比特的优化是基于位 平面（bit plane, BP)的个数，也就是，给定part 1的H. 264 0-mv量化 参数QP，基于上述的优化函数来调整BP的个数，最后，得到了一个优化的 BP和QP组合，见表1所示。</p>
    <p>表1.优化的组合量化参数</p>
    <p>&lt;table&gt;table see original document page 14&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;</p>
    <p>2.高复杂度解码</p>
    <p>由于解码端要进行运动估计来产生边信息r、并且要进行信道码 的迭代解码，这些造成了解码端的高复杂度。</p>
    <p>(1) 边解码器算法</p>
    <p>当只有一个描述收到时，使用边解码器解码。</p>
    <p>假设只接收到描述1，使用边解码器1进行解码。其part 1，即『,通 过H.264 0-mv解码得到；在恢复part 2的f 2时，首先根据公式（2) 、 （3) 产生参考帧^2和边信息&amp;，并得到差值&#12316;=&amp;-^2，然后用差值&#12316;作为边信</p>
    <p>息进行SW-SPIHT解码，得到恢复的差值"，再作加法得到恢复的part 2，</p>
    <p>即『2=/)',+^2 。</p>
    <p>合并『',和『2 ，最终得到恢复的原始视频序列^ 。</p>
    <p>当只接收到描述2时，利用边解码器2进行解码，步骤与上述边解码器 1的类似。</p>
    <p>(2) 中心解码器算法当没有描述丢失时，使用中心解码器恢复视频序列。</p>
    <p>首先用零运动H. 264解码得到两个描述的part 1，  ^和『2，然后合并 w、和^以恢复视频r。 本发明的效果</p>
    <p>我们测试了 2个QCIF015Hz序列的性能，Cp/?o77e和Jfo^?er-A收/?ter， 比较了三种两描述方案的性能：</p>
    <p>(1) 零运动H. 264两描述方法，此方法仅仅用奇偶帧分离将序列分为 两个描述，然后对每个序列用零运动H.264进行压&#32302;。方法具有低复杂度编 码特性。</p>
    <p>(2) 本发明提出的基于Wyner-Ziv的残差两描述视频编码方法，原理 如图4所示。</p>
    <p>(3) 基于Wyner-Ziv的非残差两描述视频编码方法，与图4不同的是， 没有采用残差编码，即只是对图中的^和^进行Wyner-Ziv编码，产生两 个描述的part 2。</p>
    <p>实验测试了上述三种方案中两个描述的总比特，实验结果如图7a, 7b和 图8a， 8b所示。图中将上述三种方案分别标识为MDC H. 264 0-mv、残差2D-DVC 和2D-DVC。</p>
    <p>l.率失真性能比较</p>
    <p>图7a， 7b表示了率失真性能曲线，从比较结果看出基于Wyner-Ziv的残 差两描述视频编码方案明显地好于非残差方案，其原因是残差Wyner-Ziv编 码利用了一个编解码端都可得到的参考帧，从而减少了码率。具体而言，对 运动量小的Mother-daughter序列，残差方案比非残差方案得到0. 5-1. 8dB 的边解码质量提高，0.2-1.7dB的中心解码质量提高。对运动量较大的 Carphone序列而言，在中心解码质量几乎相当的条件下，边质量的提高是 0.2-1.7dB 。我们又比较了基于H.264 0-mv的两描述编码，很明显，所提 方案与参考方案有几乎相当的效率，然而，我们的方案比H.264 0-mv两描述方案的优势在于质量的连续性，这个特性我们将用下面的试验来验证。</p>
    <p>图8a， 8b表明了三种方案在Ql点的帧边质量对比。很明显，我们的残差 两描述和非残差两描述都比零运动H. 264两描述有更连续的帧质量，原因是 我们的方案加入了 Wyner-Ziv码流，它很好地纠正了丢失的描述，尤其是， 有效的残差方案取得了最好的质量。</p>
    <p>为了进一步比较，我们计算了各点的帧边质量的方差，方差计算根据下 列公式：</p>
    <p>r『t(尸鹏(/),鹏))2 (9)</p>
    <p>其中/^(0是第/帧的PSNR值，"是总帧数，E(f，）是所有帧的平均值， 表2表示了所有点的PS服方差，很明显，在各个失真点，我们的残差两描 述方案均取得了最小的方差，这意味着他们在有描述丢失时有更好的边质量 连续性。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101835042A?cl=zh">CN101835042A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年3月19日</td><td class="patent-data-table-td patent-date-value">2010年9月15日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于无反馈速率控制的Wyner-Ziv视频编码系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101835042B?cl=zh">CN101835042B</a></td><td class="patent-data-table-td patent-date-value">2010年3月19日</td><td class="patent-data-table-td patent-date-value">2013年1月23日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于无反馈速率控制的Wyner-Ziv视频编码系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101854548A?cl=zh">CN101854548A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月25日</td><td class="patent-data-table-td patent-date-value">2010年10月6日</td><td class="patent-data-table-td ">南京邮电大学</td><td class="patent-data-table-td ">一种面向无线多媒体传感器网络的视频压缩方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102186077A?cl=zh">CN102186077A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年5月4日</td><td class="patent-data-table-td patent-date-value">2011年9月14日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于Wyner-Ziv视频编码的Wyner-Ziv帧码率控制系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102186077B?cl=zh">CN102186077B</a></td><td class="patent-data-table-td patent-date-value">2011年5月4日</td><td class="patent-data-table-td patent-date-value">2012年12月26日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于Wyner-Ziv视频编码的Wyner-Ziv帧码率控制系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102625124A?cl=zh">CN102625124A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月5日</td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td ">北京交通大学</td><td class="patent-data-table-td ">一种立体编码、解码装置及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102790881A?cl=zh">CN102790881A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td ">西安电子科技大学</td><td class="patent-data-table-td ">基于帧级编码端速率控制的变换域分布式视频编解码器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102970616A?cl=zh">CN102970616A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月4日</td><td class="patent-data-table-td patent-date-value">2013年3月13日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">一种传输视频的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102970616B?cl=zh">CN102970616B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月4日</td><td class="patent-data-table-td patent-date-value">2015年4月29日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">一种传输视频的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103002286A?cl=zh">CN103002286A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月6日</td><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">深圳广晟信源技术有限公司</td><td class="patent-data-table-td ">视频单元的复杂度生成方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103002286B?cl=zh">CN103002286B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月6日</td><td class="patent-data-table-td patent-date-value">2015年10月28日</td><td class="patent-data-table-td ">深圳广晟信源技术有限公司</td><td class="patent-data-table-td ">视频单元的复杂度生成方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013143286A1?cl=zh">WO2013143286A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月7日</td><td class="patent-data-table-td patent-date-value">2013年10月3日</td><td class="patent-data-table-td ">Beijing Jiaotong University</td><td class="patent-data-table-td ">基于多描述视频编码、解码方法、装置及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=aTl2BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019174000">H04N19/174</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=aTl2BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019390000">H04N19/39</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年1月6日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年3月3日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年9月10日</td><td class="patent-data-table-td ">C17</td><td class="patent-data-table-td ">Cessation of patent right</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/e6d37ff5658dd25ca063/CN101621690A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4874c258b856314cce6b80d777b4ee7a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8EWyner_Ziv%E7%90%86%E8%AE%BA%E7%9A%84%E4%B8%A4%E6%8F%8F%E8%BF%B0%E8%A7%86%E9%A2%91.pdf?id=aTl2BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0_06M_K1sWJa7sFtl1PgkzXFRWCQ"},"sample_url":"https://www.google.com/patents/reader?id=aTl2BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>