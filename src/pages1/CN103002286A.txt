<!DOCTYPE html><html><head><title>专利 CN103002286A - 视频单元的复杂度生成方法及装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4874c258b856314cce6b80d777b4ee7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4874c258b856314cce6b80d777b4ee7a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="视频单元的复杂度生成方法及装置"><meta name="DC.contributor" content="刘伟杰" scheme="inventor"><meta name="DC.contributor" content="林斯铭" scheme="inventor"><meta name="DC.contributor" content="何辉" scheme="inventor"><meta name="DC.contributor" content="深圳广晟信源技术有限公司" scheme="assignee"><meta name="DC.date" content="2012-12-6" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种视频单元的复杂度生成方法及装置，该方法包括步骤：获取当前视频单元和参考视频单元；分别生成当前视频单元的子单元和参考视频单元的子单元、以及当前视频单元的初始复杂度；基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相对差值；基于相对差值生成初始复杂度的修正量；采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。基于当前视频单元、当前视频单元的子单元，参考视频单元，参考视频单元的子单元来补偿对复杂度的预测结果，可以及时对当前视频单元的内容复杂度进行准确预估，从而提高码率控制的准确性和整体编码效率。"><meta name="DC.date" content="2013-3-27"><meta name="DC.relation" content="CN:101252689:A" scheme="references"><meta name="DC.relation" content="CN:101621690:A" scheme="references"><meta name="DC.relation" content="CN:101656887:A" scheme="references"><meta name="DC.relation" content="CN:101877784:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:103002286:A"><meta name="citation_patent_application_number" content="CN:201210518064"><link rel="canonical" href="https://www.google.com/patents/CN103002286A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103002286A?cl=zh"/><meta name="title" content="专利 CN103002286A - 视频单元的复杂度生成方法及装置"/><meta name="description" content="本发明公开了一种视频单元的复杂度生成方法及装置，该方法包括步骤：获取当前视频单元和参考视频单元；分别生成当前视频单元的子单元和参考视频单元的子单元、以及当前视频单元的初始复杂度；基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相对差值；基于相对差值生成初始复杂度的修正量；采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。基于当前视频单元、当前视频单元的子单元，参考视频单元，参考视频单元的子单元来补偿对复杂度的预测结果，可以及时对当前视频单元的内容复杂度进行准确预估，从而提高码率控制的准确性和整体编码效率。"/><meta property="og:title" content="专利 CN103002286A - 视频单元的复杂度生成方法及装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?hl=zh-CN&tbm=isch&source=og&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?hl=zh-CN&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?hl=zh-CN&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103002286A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103002286A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=1BbsBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103002286A&amp;usg=AFQjCNGdd8i4snksiyLLRRcPehM1829pJA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/09f886a329a1583c5277/CN103002286A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/09f886a329a1583c5277/CN103002286A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103002286A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103002286A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN103002286A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN103002286B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103002286A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种视频单元的复杂度生成方法及装置，该方法包括步骤：获取当前视频单元和参考视频单元；分别生成当前视频单元的子单元和参考视频单元的子单元、以及当前视频单元的初始复杂度；基于当前视频单元、参考...</span><span itemprop="url">https://www.google.com/patents/CN103002286A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103002286A - 视频单元的复杂度生成方法及装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103002286A - 视频单元的复杂度生成方法及装置" title="专利 CN103002286A - 视频单元的复杂度生成方法及装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103002286 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210518064</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年3月27日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年12月6日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年12月6日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103002286B?hl=zh-CN&amp;cl=zh">CN103002286B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210518064.1, </span><span class="patent-bibdata-value">CN 103002286 A, </span><span class="patent-bibdata-value">CN 103002286A, </span><span class="patent-bibdata-value">CN 201210518064, </span><span class="patent-bibdata-value">CN-A-103002286, </span><span class="patent-bibdata-value">CN103002286 A, </span><span class="patent-bibdata-value">CN103002286A, </span><span class="patent-bibdata-value">CN201210518064, </span><span class="patent-bibdata-value">CN201210518064.1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%88%98%E4%BC%9F%E6%9D%B0%22">刘伟杰</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9E%97%E6%96%AF%E9%93%AD%22">林斯铭</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E4%BD%95%E8%BE%89%22">何辉</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B7%B1%E5%9C%B3%E5%B9%BF%E6%99%9F%E4%BF%A1%E6%BA%90%E6%8A%80%E6%9C%AF%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">深圳广晟信源技术有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103002286A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103002286A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103002286A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=1BbsBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210518064&amp;usg=AFQjCNHTZhFQw1wX3jtQB3RSlmH7Vrw3Lw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=1BbsBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103002286A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNE8-JuQkBOTVrMR0KgQcWNc6ajGVA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT122901857" lang="ZH" load-source="patent-office">视频单元的复杂度生成方法及装置</invention-title>
      </span><br><span class="patent-number">CN 103002286 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA109781995" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种视频单元的复杂度生成方法及装置，该方法包括步骤：获取当前视频单元和参考视频单元；分别生成当前视频单元的子单元和参考视频单元的子单元、以及当前视频单元的初始复杂度；基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相对差值；基于相对差值生成初始复杂度的修正量；采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。基于当前视频单元、当前视频单元的子单元，参考视频单元，参考视频单元的子单元来补偿对复杂度的预测结果，可以及时对当前视频单元的内容复杂度进行准确预估，从而提高码率控制的准确性和整体编码效率。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM52326206" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种视频单元的复杂度生成方法，其特征在于，包括步骤：获取当前视频单元和参考视频单元；分别生成所述当前视频单元的子单元和所述参考视频单元的子单元、以及当前视频单兀的初始复杂度；基于所述当前视频单元、所述参考视频单元、所述当前视频单元的子单元以及所述参考视频单元的子单元生成至少两个相对差值；基于所述相对差值生成所述初始复杂度的修正量；采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，所述参考视频单元为所述当前视频单元之前的一个或多个视频单元。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，所述第一相对差值为所述当前视频单元与所述当前视频单元的子单元的相对差值；所述第二相对差值为所述参考视频单元与所述参考视频单元的子单元的相对差值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，所述第一相对差值为所述当前视频单元与所述参考视频单元的相对差值；所述第二相对差值为所述当前视频单元的子单元与所述参考视频单元的子单元的相对差值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，当所述至少两个相对差值包括第一相对差值和第二相对差值时，所述修正量为所述第一相对差值与所述第二相对差值的比值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，在步骤采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度中，通过下述公式对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度：C1= α &#183; r &#183; C0 ；其中C1为所述当前视频单元最终的复杂度，Ctl为所述初始复杂度，r为所述修正量，α 为调整常数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1所述的视频单元的复杂度生成方法，其特征在于，所述视频单元包括视频巾贞、视频宏块和视频条带。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.	一种视频单元的复杂度生成装置，其特征在于，包括：输入模块，用于分别获取当前视频单元和参考视频单元；子单元生成模块，用于分别生成所述当前视频单元的子单元和所述参考视频单元的子单元；初始复杂度生成模块，用于生成当前视频单元的初始复杂度；相对差值生成模块，用于基于所述当前视频单元、所述参考视频单元、所述当前视频单元的子单元以及所述参考视频单元的子单元生成至少两个相对差值；修正量生成模块，用于基于所述相对差值生成所述初始复杂度的修正量；补偿模块，用于采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的视频单元的复杂度生成装置，其特征在于，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，所述第一相对差值为所述当前视频单元与所述当前视频单元的子单元的相对差值；所述第二相对差值为所述参考视频单元与所述参考视频单元的子单元的相对差值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求8所述的视频单元的复杂度生成装置，其特征在于，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，所述第一相对差值为所述当前视频单元与所述参考视频单元的相对差值；所述第二相对差值为所述当前视频单元的子单元与所述参考视频单元的子单元的相对差值。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES59393277" lang="ZH" load-source="patent-office" class="description">
    <p>视频单元的复杂度生成方法及装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及视频处理，尤其涉及一种视频单元的复杂度生成方法及装置。</p>
    <p>背景技术</p>
    <p>[0002]	现有的各种视频编码标准在实现视频编码时可以设置三个层次的码率控制机制，即画面组（GOP :Group of Picture)层、帧层和宏块层码率控制。GOP层的码率控制通常包括以下一些功能，根据对视频编码的整体要求指标（比特率，帧率等)确定可用于该GOP的总比特数以及初始量化参数，依据初始量化参数实现对GOP初始帧(通常为I帧)的编码，依据对初始帧的编码结果设定或更新编码用缓存器的状态。从第2个GOP开始，在选择初始量化参数和更新编码用缓存器时，需要适当考虑与前一 GOP间的连续性。</p>
    <p>[0003]	对GOP内非I帧进行编码时，需要用到帧层码率控制。帧层码率控制的目的是为GOP内未编码各帧设定适量的目标比特数(通常主要针对P帧)。设定目标比特数时主要依据以下一些参数，即所在GOP的剩余比特数，编码用缓存器的状态，以及各帧的内容复杂度。</p>
    <p>[0004]	在帧层码率控制的基础上可以进一步选择宏块层码率控制。宏块层码率控制的动作机制与帧层码率控制的类似，即基于一帧的可用剩余比特数，进一步为帧内每一宏块设定适量的目标比特数或直接选择合适的量化参数。实现宏块层码率控制时也可以适当考虑宏块的内容复杂度或宏块的视觉重要度。</p>
    <p>[0005]	以帧层码率控制为例，现行国际标准H. 264的参考模型中，在实现帧层码率控制时，对I帧，P帧，B帧采用不同的处理方式。在处理P帧时用到帧的内容复杂度。对I帧的处理则依据初始量化参数直接得到I帧用量化参数，而对B帧的处理则是在相关P帧处理后，依据B帧前后两侧的相关P帧的量化参数得到B帧的量化参数。在设定P帧的目标比特数时，上述参考模型利用了以下内容复杂度计算公式，</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103002286A/CN103002286AD00041.png"> <img id="idf0001" file="CN103002286AD00041.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103002286A/CN103002286AD00041.png" class="patent-full-image" alt="Figure CN103002286AD00041"> </a> </div>
    <p>[0010]	其中，j表示帧序号，当第j帧为P帧时用上述公式（I)和（3)，当第j帧为B帧时用上述公式（2)和（4)式。WP(j)和巧(/)分别表示P帧的复杂度和平均复杂度，Wb (j)和巧(/)分别表示B帧的复杂度和平均复杂度。b(j)，Qp(J)，Qb(J)分别为第j帧的实际使用比特数，P帧时的量化参数，和B帧时的量化参数。上述4个复杂度值Wp(j)，％(_/)，Wb (j)，1&#190;/)将在估计第j+Ι帧的目标比特数时被用到。</p>
    <p>[0011]	但是，明显地，上述复杂度的计算方式只是用前一帧或前几帧的实际编码量来做为对当前帧的内容复杂度的预测估计，并没有真正考虑当前帧的内容，以及当前帧与前一帧或前几帧内容有什么不同。所以，如果当前帧的内容与前一帧相比发生较大变化时，现有处理方式有可能出现对当前帧的内容复杂度估计不准确，从而造成码率控制的不准确以及整体编码效率的下降。</p>
    <p>发明内容</p>
    <p>[0012]	本发明要解决的技术问题在于针对现有技术中在获取复杂度时只采用前一个视频单元或前几个视频单元的实际编码量来做为对当前视频单元的内容复杂度的预测估计，并没有真正考虑当前视频单元的内容，以及当前视频单元与之前的视频单元在内容上的不同，从而造成码率控制不准确以及整体编码效率下降的缺陷，提供一种视频单元的复杂度生成方法及装置。</p>
    <p>[0013]	本发明解决其技术问题所采用的技术方案是：提供了一种视频单元的复杂度生成方法，包括步骤：</p>
    <p>[0014]	获取当前视频单元和参考视频单元；</p>
    <p>[0015]	分别生成所述当前视频单元的子单元和所述参考视频单元的子单元、以及当前视频单元的初始复杂度；</p>
    <p>[0016]	基于所述当前视频单元、所述参考视频单元所述当前视频单元的子单元以及所述参考视频单元的子单元生成至少两个相对差值；</p>
    <p>[0017]	基于所述相对差值生成所述初始复杂度的修正量；</p>
    <p>[0018]	采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度。</p>
    <p>[0019]	在依据本发明实施例的视频单元的复杂度生成方法中，所述参考视频单元为所述当前视频单元之前的一个或多个视频单元。</p>
    <p>[0020]	在依据本发明实施例的视频单元的复杂度生成方法中，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，</p>
    <p>[0021]	所述第一相对差值为所述当前视频单元与所述当前视频单元的子单元的相对差值；所述第二相对差值为所述参考视频单元与所述参考视频单元的子单元的相对差值。</p>
    <p>[0022]	在依据本发明实施例的视频单元的复杂度生成方法中，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，</p>
    <p>[0023]	所述第一相对差值为所述当前视频单元与所述参考视频单元的相对差值；所述第二相对差值为所述当前视频单元的子单元与所述参考视频单元的子单元的相对差值。</p>
    <p>[0024]	在依据本发明实施例的视频单元的复杂度生成方法中，当所述至少两个相对差值包括第一相对差值和第二相对差值时，所述修正量为所述第一相对差值与所述第二相对差值的比值。</p>
    <p>[0025]	在依据本发明实施例的视频单元的复杂度生成方法中，在步骤采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度中，通过下述公式对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度：</p>
    <p>[0026]	C1= α &#183; r &#183; C0 ；</p>
    <p>[0027]	其中C1为所述当前视频单元最终的复杂度，C0为所述初始复杂度， r为所述修正量，α为调整常数。</p>
    <p>[0028]	在依据本发明实施例的视频单元的复杂度生成方法中，所述视频单元包括视频中贞、视频宏块和视频条带。</p>
    <p>[0029]	本发明还提供了一种视频单元的复杂度生成装置，包括：</p>
    <p>[0030]	输入模块，用于分别获取当前视频单元和参考视频单元；</p>
    <p>[0031]	子单元生成模块，用于分别生成所述当前视频单元的子单元和所述参考视频单元的子单元；</p>
    <p>[0032]	初始复杂度生成模块，用于生成当前视频单元的初始复杂度；</p>
    <p>[0033]	相对差值生成模块，用于基于所述当前视频单元、所述参考视频单元、所述当前视 频单元的子单元以及所述参考视频单元的子单元生成至少两个相对差值；</p>
    <p>[0034]	修正量生成模块，用于基于所述相对差值生成所述初始复杂度的修正量；</p>
    <p>[0035]	补偿模块，用于采用所述修正量对所述初始复杂度进行补偿以获得所述当前视频单元最终的复杂度。</p>
    <p>[0036]	在依据本发明实施例的视频单元的复杂度生成装置中，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，</p>
    <p>[0037]	所述第一相对差值为所述当前视频单元与所述当前视频单元的子单元的相对差值；所述第二相对差值为所述参考视频单元与所述参考视频单元的子单元的相对差值。</p>
    <p>[0038]	在依据本发明实施例的视频单元的复杂度生成装置中，所述至少两个相对差值包括第一相对差值和第二相对差值；其中，</p>
    <p>[0039]	所述第一相对差值为所述当前视频单元与所述参考视频单元的相对差值；所述第二相对差值为所述当前视频单元的子单元与所述参考视频单元的子单元的相对差值。</p>
    <p>[0040]	本发明产生的有益效果是：在依据本发明实施例的视频单元的复杂度生成方法及装置中，不再直接比较当前视频单元和它的以前的视频单元（以下称为参考视频单元)，而是首先得到当前视频单元和参考视频单元各自对应的子单元，然后依据当前视频单元、当前视频单元的子单元，参考视频单元，参考视频单元的子单元来获取至少两个相对差值，再通过比较不同的相对差值来确定复杂度的修正量，从而用复杂度加权值补偿对复杂度的预测结果。从而，在当前视频单元的内容与前一个视频单元的内容发生较大变化时，可以及时对当前视频单元的内容复杂度进行准确预估，从而提高码率控制的准确性和整体编码效率。</p>
    <p>附图说明</p>
    <p>[0041]	下面将结合附图及实施例对本发明作进一步说明，附图中：</p>
    <p>[0042]	图1示出了依据本发明实施例的视频单元的复杂度生成装置的逻辑框图；</p>
    <p>[0043]	图2示出了依据本发明实施例的视频单元的复杂度生成方法的流程图。</p>
    <p>具体实施方式</p>
    <p>[0044]	为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本发明进行进一步详细说明。应当理解，此处所描述的具体实施例仅用以解释本发明，并不用于限定本发明。[0045]	图1示出了依据本发明实施例的视频单元的复杂度生成装置的逻辑框图，如图1所示，该视频单元的复杂度生成装置（以下简称装置）包括输入模块100、子单元生成模块200、初始复杂度生成模块300、存储模块400、相对差值生成模块500、修正量生成模块600以及补偿模块700。此处的视频单元包括但不限于视频帧、视频宏块和视频条带，在本说明书中，当以视频单元为视频帧为例进行阐述时，本领域的技术人员应当知晓，其仅用作举例，并不是对本发明的限制，本发明中的方法及装置可应用于各种合适的视频单元。</p>
    <p>[0046]	其中，输入模块100可分别获取当前视频单元和参考视频单元；子单元生成模块200可分别生成当前视频单元的子单元和参考视频单元的子单元；初始复杂度生成模块300可生成当前视频单元的初始复杂度；相对差值生成模块500可基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相对差值；修正量生成模块600可基于相对差值生成初始复杂度的修正量；补偿模块700可采用修正量 对初始复杂度进行补偿以获得当前视频单元最终的复杂度。应当注意的是，在本说明书中定义的子单元是原视频单元在空间分辨率上的近似单元。</p>
    <p>[0047]	具体而言，一方面，输入模块100获取当前的视频的一个单元，以作为当前视频单元，例如获取当前视频帧；与此同时，将获取的当前视频单元存储到存储模块400中，这样，此时的当前视频单元也可以作为后续的视频单元的参考视频单元。另一方面，输入模块100从存储模块400或其它地方获取该当前视频单元的参考视频单元，该参考视频单元为其当前视频单元之前的一个或多个视频单元。</p>
    <p>[0048]	以视频单元为视频帧为例，参考帧为当前帧的前一帧或前若干帧。可以根据需要抽取特定类型的前一帧作为参考帧，比如前一 P帧或前一 B帧。也可以根据需要抽取前若干帧。如果用多个参考帧，则可以采用非平等加权。即距离近的帧用较大的加权实现利用多帧时的复杂度计算。另外，当前帧与之前的参考帧的顺序依据的是编码顺序，与播放顺序可能有所不同。另外，本发明不限制初始帧的编码方式，可以用现有编码方式编码各类型的初始帧，然后以初始帧做为参考，来启动本发明的编码方式。</p>
    <p>[0049]	子单元生成模块200与输入模块100连接，以从输入模块100接收当前视频单元和参考视频单元，从而分别生成当前视频单元的子单元和参考视频单元的子单元。子单元生成模块200可采用现有的任意适合的方法来生成各视频单元的子单元。同样地，可将生成的视频单元的子单元存储到存储模块400中，以作为后续的视频单元的参考视频单元的子单元，从而减少数据处理量和处理时间。</p>
    <p>[0050]	在本发明的一个实施例中，可通过对视频单元进行分块来获取该视频单元的子单元。以视频单元为视频帧为例，此时，子帧是对原视频帧的一个粗略采样，可以通过对原帧像素分块化实现。本发明不限制分块的方法，但这里以2X2分块为例说明。通过对像素做2X2分块，每次从一个分块按序取出一个像素，则可以得到4个不同的子帧。当然，该方法也适用于视频宏块和视频条带等其它视频单元。</p>
    <p>[0051]	初始复杂度生成模块300与输入模块100连接，以从输入模块100接收当前视频单元，从而可采用现有的任意适合方式来生成当前视频单元的初始复杂度。例如，可采用上述的国际标准H. 264的参考模型来生成当前视频帧的初始复杂度。在获取初始复杂度过程中，可利用全部分量来获取复杂度，也可以只采用一个分量获取复杂度，例如，只采用亮度分量来获取当前视频单元的初始复杂度。[0052]	相对差值生成模块500分别与输入模块100和子单元生成模块200连接，用以从输入模块100接收当前视频单元和参考视频单元，以及从子单元生成模块200获取当前视频单元的子单元和参考视频单元的子单元。从而，相对差值生成模块500可基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相</p>
    <p>对差值。</p>
    <p>[0053]	在本发明的第一实施例中，上述的至少两个相对差值包括第一相对差值和第二相对差值；其中，第一相对差值为当前视频单元与当前视频单元的子单元的相对差值;第二相对差值为参考视频单元与参考视频单元的子单元的相对差值。</p>
    <p>[0054]	因为子单元和原单元有不同的像素数，所以在计算差值时，首先要在分块内将子单元的像素加以拷贝，扩大到原单元大小，然后以原单元大小为基准计算相应的差值。</p>
    <p>[0055]	具体操作中，以视频单元为视频帧为例，假设视频为LUV CL是亮度，U和V是色度 坐标）格式，则可以先分别计算L、U、V各分量的相对差。计算差的方法可以有多种，这里以绝对值差为例进行阐述。以CL (i，j)和CML (i，j)分别表示当前帧和当前帧的子帧在像素（i，j)位置的L分量值,CL_ave和CML_ave分别表不当前巾贞和当前巾贞的子巾贞在L分量所有像素的平均值，I和J分别表示像素数，则可以用下述的公式（5)计算当前帧与当前帧的子中贞在L分量的相对差值dL ：</p>
    <p>[0056]</p>
    <p>dL = ±±\CUL /')-CL _ ave&#8212;(CML(i, j) &#8212; CML _ ave)\</p>
    <p>仁":1	―	_	(5〕</p>
    <p>[0057]	采用相同的方法，可以分别得到当前帧和当前帧的子帧在U分量和V分量的相对差值dU和dV。最后采用公式（6)对dL，dU，dV求加权平均得到当前帧和当前帧的子帧的相对差值dl ：</p>
    <p>[0058]	dl = wL &#183; dL+Wu &#183; dU+wv &#183; dV	(6)</p>
    <p>[0059]	其中I，Wu，wv为加权系数，可以简单地选为1/3或依实验结果选择其它适合的值。</p>
    <p>[0060]	相应地，采用相同的方法，可以得到参考帧与参考帧的子帧的相对差值d2，具体操作过程不再赘述。</p>
    <p>[0061]	在本发明的第二实施例中，上述的至少两个相对差值包括第一相对差值和第二相对差值；其中，第一相对差值为当前视频单元与参考视频单元的相对差值；第二相对差值为当前视频单元的子单元与参考视频单元的子单元的相对差值。</p>
    <p>[0062]	在本实施例中，仍以视频单元为视频帧为例，假设视频为LUV，则可以先分别计算L、U、V各分量的相对差。计算差的方法可以有多种，这里以绝对值差为例进行阐述。以CL(i，j )和RL (i，j )分别表示当前帧和参考帧在像素（i，j )位置的L分量值，CL_ave和RL_ave分别表示当前帧和参考帧在L分量所有像素的平均值，I和J分别表示像素数，则当前帧与参考帧在L分量的相对差值dL可以用下述的公式（7)计算获得：</p>
    <p>[0063]</p>
    <p>    I J</p>
    <p>dL 二 1[|("-(人 /) - ( V. _ ave- (Rl.(/. j) - R1. _a\ c)\</p>
    <p>&#171;片	_	&#8212;	(7)</p>
    <p>[0064]	采用同样的方法可以获得当前帧和参考帧在U分量和V分量的相对差值dU和dV。最后采用公式（8)对dL、dU、dV求加权平均得到当前帧和参考帧的相对差dl ：[0065]	dl = wL &#183; dL+Wu &#183; dU+wv &#183; dV	(8)</p>
    <p>[0066]	其中&amp;，wu，wv为加权系数，可以简单地选为1/3或依实验结果选择其它适合的值。</p>
    <p>[0067]	相应地，采用相同的方法，可以得到当前帧的子帧与参考帧的子帧的相对差值d2，具体操作过程不再赘述。需要指出的是，子帧的像素数与原帧的不同。</p>
    <p>[0068]	本领域的技术人员应当知晓，以上仅采用视频帧为例进行阐述，对于其它的视频单元，例如视频宏块或视频条带，上述方法同样适用。类似地，根据本发明的教导，也可以在视频的色彩分量(例如R、G、B)上分别计算相对差值，来获得最终的相对差值。或者，也可以采用一个分量或任意数量分量的相对差值来获得最终的相对差值，例如只采用亮度分量的相对差值作为最终的相对差值。而且，上述方法仅用作举例，并不是对本发明的限制，本领域的技术人员在本发明的教导下，可以采用任意适合的方法来获得相对差值。</p>
    <p>[0069]	修正量生成模块600与相对差值生成模块500连接，以从相对差值生成模块500获取上述的至少两个相对差值，从而可基于该相对差值生成初始复杂度的修正量。例如，当上述的至少两个相对差值包括上述的第一实施例或第二实施例中的第一相对差值dl和第二相对差值d2时，修正量r为第一相对差值dl与第二相对差值d2的比值，即：</p>
    <p>[0070]	r = dl/d2	(9)</p>
    <p>[0071]	其中，r的数值越大,表明当前帧的相对复杂度越大。</p>
    <p>[0072]	补偿模块700分别与修正量生成模块600和初始复杂度生成模块300连接，用以获取当前视频单元的初始复杂度以及初始复杂度的修正量，从而可采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。例如，可通过下述的公式（10)对初始复杂度进行补偿以获得当前视频单元最终的复杂度：</p>
    <p>[0073]	C1=Ct &#183; r &#183; C0 ；	(10)</p>
    <p>[0074]	其中C1为当前视频单元最终的复杂度,Ctl为初始复杂度为修正量，α为调整常数，可以通过实验结果获得。</p>
    <p>[0075]	上述获取的复杂度适用于任何与复杂度有关的应用，包括但不限于码率控制、图像处理工具的效果评价等等。例如，文献（H Yu, et al, Applications andImprovement of H. 264in Medical Video Compression, IEEE Trans, on Circuits andSystems, vol. 52，no. 12，Dec2005)记载的码率分配方式中，米用下述的公式（11)进行巾贞层码率控制：</p>
    <p>[0076]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103002286A/CN103002286AD00091.png"> <img id="idf0002" file="CN103002286AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103002286A/CN103002286AD00091.png" class="patent-full-image" alt="Figure CN103002286AD00091"> </a> </div>
    <p>[0077]	其中，i表示GOP内的当前帧序号，N表示GOP的帧总数。BT;i为第i帧的目标比特数，Ci称为活动复杂度（motion complexity),即依据巾贞内容的复杂度指标，Biu为该GOP的剩余可用比特数，β i是一个O到I间的常数，Fs为编码用缓存器的容量，Fi为编码第i帧时编码缓存器的充满度，Rb为指定的编码比特率，Rf为指定的帧率。</p>
    <p>[0078]	此时，本发明的复杂度计算结果可以用来取代公式（11)中的Ci,即可用下述的公式（12)获得的来代替Ci以作为新的活动复杂度：</p>
    <p>[0079]</p>
    <p>&lt;=&#12316;..(： (12)[0080]	其中r为上述的修正量，α为上述调整常数。</p>
    <p>[0081]	然而，现实中实现视频编码时，通常依指定的帧类型（S卩，I帧，P帧，B帧）而用不同的编码方式。所以用实际编码量估计帧的复杂度时，同类型帧之间可以直接比较，而不同类型帧间需要一定的折衷变换。具体而言，本发明中的参考帧如果与当前帧属于同一类型，则参考帧复杂度可以直接利用。属于不同类型时，则可以对参考帧复杂度做适当变换。例如，可采用上述的公式（4)中记载的系数1. 3636进行折衷变换。</p>
    <p>[0082]	图2示出了依据本发明实施例的视频单元的复杂度生成方法的流程图，可采用上述的视频单元的复杂度生成装置来实施该方法，因此，此处全部或任意引用上述与视频单元的复杂度生成装置有关的阐述。下面将按步骤描述该视频单元的 复杂度生成方法。此处的视频单元包括但不限于视频帧、视频宏块和视频条带。</p>
    <p>[0083]	S100、获取当前视频单元和参考视频单元。此处，可采用输入模块100从外界或存储模块400获取当前视频单元和参考视频单元。</p>
    <p>[0084]	S200、分别生成当前视频单元的子单元和参考视频单元的子单元、以及当前视频单元的初始复杂度。子单元生成模块200可采用现有的任意适合的方法来生成各视频单元的子单元。同样地，可将生成的视频单元的子单元存储到存储模块400中，以作为后续的视频单元的参考视频单元的子单元，从而减少数据处理量和处理时间。</p>
    <p>[0085]	S300、基于当前视频单元、参考视频单元、当前视频单元的子单元以及参考视频单元的子单元生成至少两个相对差值。此处，可采用相对差值生成模块500生成上述的至少两个差值。在本发明的第一实施例中，上述的至少两个相对差值包括第一相对差值和第二相对差值；其中，第一相对差值为当前视频单元与当前视频单元的子单元的相对差值;第二相对差值为参考视频单元与参考视频单元的子单元的相对差值。在本发明的第二实施例中，上述的至少两个相对差值包括第一相对差值和第二相对差值；其中，第一相对差值为当前视频单元与参考视频单元的相对差值；第二相对差值为当前视频单元的子单元与参考视频单元的子单元的相对差值。</p>
    <p>[0086]	S400、基于相对差值生成初始复杂度的修正量。此处，修正量生成模块600可基于该相对差值生成初始复杂度的修正量。</p>
    <p>[0087]	S500、采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。补偿模块700可采用修正量对初始复杂度进行补偿以获得当前视频单元最终的复杂度。</p>
    <p>[0088]	从以上可以看出，在依据本发明实施例的视频单元的复杂度生成方法及装置中，不再直接比较当前视频单元和它的以前的视频单元（以下称为参考视频单元)，而是首先得到当前视频单元和参考视频单元各自对应的子单元，然后依据当前视频单元、当前视频单元的子单元，参考视频单元，参考视频单元的子单元来获取至少两个相对差值，再通过比较不同的相对差值来确定复杂度的修正量，从而用复杂度加权值补偿对复杂度的预测结果。从而，在当前视频单元的内容与前一个视频单元的内容发生较大变化时，可以及时对当前视频单元的内容复杂度进行准确预估，从而提高码率控制的准确性和整体编码效率。</p>
    <p>[0089]	特别地，一个视频单元的子单元可以通过将原视频单元的像素分块化得到。例如取2 X 2像素块时，一单元可以分为4个子单元，每个子单元取一块中的一个特定像素。子单元和原单元有不同的像素数，但如果简单地把子单元的像素加以拷贝，扩大到原单元大小，则可以把子单元看做是对原视频单元的一个近似。在此状况下，两个子单元的相对差通常小于相应的两个原视频单元的相对差。于是原视频单元的相对差与子单元的相对差在一定程度上反映了一单元从简向繁的变化程度，即复杂度的变化。所以可以通过对相对差的比较得到复杂度的变化，进而实现对复杂度的补偿。</p>
    <p>[0090]	应当理解的是，对本领域普通技术人员来说，可以根据上述说明加以改进或变换，而所有这些改进和变换都应属于本发明所附权利要求的保护范围。&#183;</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101252689A?cl=zh">CN101252689A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年2月29日</td><td class="patent-data-table-td patent-date-value">2008年8月27日</td><td class="patent-data-table-td ">杭州爱威芯科技有限公司</td><td class="patent-data-table-td ">一种自适应的码率控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101621690A?cl=zh">CN101621690A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年7月24日</td><td class="patent-data-table-td patent-date-value">2010年1月6日</td><td class="patent-data-table-td ">北京交通大学</td><td class="patent-data-table-td ">基于Wyner-Ziv理论的两描述视频编码方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101656887A?cl=zh">CN101656887A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年9月23日</td><td class="patent-data-table-td patent-date-value">2010年2月24日</td><td class="patent-data-table-td ">杭州华三通信技术有限公司</td><td class="patent-data-table-td ">码率控制算法的选择方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101877784A?cl=zh">CN101877784A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年4月30日</td><td class="patent-data-table-td patent-date-value">2010年11月3日</td><td class="patent-data-table-td ">上海华平软件技术有限公司</td><td class="patent-data-table-td ">一种适用于实时应用的h.264码率控制方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=1BbsBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0019140000">H04N19/14</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年4月24日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年10月28日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/09f886a329a1583c5277/CN103002286A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4874c258b856314cce6b80d777b4ee7a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E8%A7%86%E9%A2%91%E5%8D%95%E5%85%83%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E5%8F%8A.pdf?id=1BbsBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2BA2vARKj9Z35qMoGCCAlfxLbLOg"},"sample_url":"https://www.google.com/patents/reader?id=1BbsBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>