<!DOCTYPE html><html><head><title>专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5bd24152bf5a1e342ae546da267fae0b/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5bd24152bf5a1e342ae546da267fae0b__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于多特征融合的车流监控图像检测和跟踪系统及方法"><meta name="DC.contributor" content="范文兵" scheme="inventor"><meta name="DC.contributor" content="李浩亮" scheme="inventor"><meta name="DC.contributor" content="赵龙贺" scheme="inventor"><meta name="DC.contributor" content="范程龙" scheme="inventor"><meta name="DC.contributor" content="冯文" scheme="inventor"><meta name="DC.contributor" content="郑州大学" scheme="assignee"><meta name="DC.date" content="2014-7-9" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于多特征融合的车流监控图像检测和跟踪系统及方法，采用VIBE算法第一帧图像的背景模型，比较当前帧分割出帧内图像目标并更新背景模型。对分割出的图像目标采用颜色特征和SILTP纹理特征去除噪声干扰，提取LBP分块目标图像纹理特征，计算LBP的直方图，生成整幅图像的特征向量，应用FAST算法计算目标图像的主方向和角点描述子。计算目标图像的直方图和特征算子，自动调整搜索窗口，应用MeanShift算法或Kalman滤波算法计算图像特征相似度匹配，计算新窗口中心位置，比较并确定搜索目标，对其标记或车流检测记录上传。本发明检测准确率较高，跟踪速度较快，具有较好的应用前景。"><meta name="DC.date" content="2014-11-5"><meta name="citation_patent_publication_number" content="CN:104134222:A"><meta name="citation_patent_application_number" content="CN:201410324245"><link rel="canonical" href="https://www.google.com/patents/CN104134222A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN104134222A?cl=zh"/><meta name="title" content="专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法"/><meta name="description" content="本发明公开了一种基于多特征融合的车流监控图像检测和跟踪系统及方法，采用VIBE算法第一帧图像的背景模型，比较当前帧分割出帧内图像目标并更新背景模型。对分割出的图像目标采用颜色特征和SILTP纹理特征去除噪声干扰，提取LBP分块目标图像纹理特征，计算LBP的直方图，生成整幅图像的特征向量，应用FAST算法计算目标图像的主方向和角点描述子。计算目标图像的直方图和特征算子，自动调整搜索窗口，应用MeanShift算法或Kalman滤波算法计算图像特征相似度匹配，计算新窗口中心位置，比较并确定搜索目标，对其标记或车流检测记录上传。本发明检测准确率较高，跟踪速度较快，具有较好的应用前景。"/><meta property="og:title" content="专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?hl=zh-CN&tbm=isch&source=og&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?hl=zh-CN&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?hl=zh-CN&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN104134222A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN104134222A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=RLMoCQABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN104134222A&amp;usg=AFQjCNG9Qt31BxNRxGW-CUpQbwt3RL0STQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/6677b0ed08508c541143/CN104134222A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/6677b0ed08508c541143/CN104134222A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN104134222A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN104134222A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN104134222A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于多特征融合的车流监控图像检测和跟踪系统及方法，采用VIBE算法第一帧图像的背景模型，比较当前帧分割出帧内图像目标并更新背景模型。对分割出的图像目标采用颜色特征和SILTP纹理特征去除噪声干扰，...</span><span itemprop="url">https://www.google.com/patents/CN104134222A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法" title="专利 CN104134222A - 基于多特征融合的车流监控图像检测和跟踪系统及方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN104134222 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201410324245</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2014年11月5日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2014年7月9日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2014年7月9日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201410324245.X, </span><span class="patent-bibdata-value">CN 104134222 A, </span><span class="patent-bibdata-value">CN 104134222A, </span><span class="patent-bibdata-value">CN 201410324245, </span><span class="patent-bibdata-value">CN-A-104134222, </span><span class="patent-bibdata-value">CN104134222 A, </span><span class="patent-bibdata-value">CN104134222A, </span><span class="patent-bibdata-value">CN201410324245, </span><span class="patent-bibdata-value">CN201410324245.X</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%8C%83%E6%96%87%E5%85%B5%22">范文兵</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E6%B5%A9%E4%BA%AE%22">李浩亮</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B5%B5%E9%BE%99%E8%B4%BA%22">赵龙贺</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%8C%83%E7%A8%8B%E9%BE%99%22">范程龙</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%86%AF%E6%96%87%22">冯文</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E9%83%91%E5%B7%9E%E5%A4%A7%E5%AD%A6%22">郑州大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN104134222A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN104134222A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN104134222A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=RLMoCQABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201410324245&amp;usg=AFQjCNFjA2RtI6dhx0cXUzNsiYlkGrbNPg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=RLMoCQABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D104134222A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHDNk2PPvYObGoiGLe1Sk-zuMCwKw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT151267010" lang="ZH" load-source="patent-office">基于多特征融合的车流监控图像检测和跟踪系统及方法</invention-title>
      </span><br><span class="patent-number">CN 104134222 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA147810749" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于多特征融合的车流监控图像检测和跟踪系统及方法，采用VIBE算法第一帧图像的背景模型，比较当前帧分割出帧内图像目标并更新背景模型。对分割出的图像目标采用颜色特征和SILTP纹理特征去除噪声干扰，提取LBP分块目标图像纹理特征，计算LBP的直方图，生成整幅图像的特征向量，应用FAST算法计算目标图像的主方向和角点描述子。计算目标图像的直方图和特征算子，自动调整搜索窗口，应用MeanShift算法或Kalman滤波算法计算图像特征相似度匹配，计算新窗口中心位置，比较并确定搜索目标，对其标记或车流检测记录上传。本发明检测准确率较高，跟踪速度较快，具有较好的应用前景。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(2)</span></span></div><div class="patent-text"><div mxw-id="PCLM78238600" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于多特征融合的车流监控图像检测和跟踪系统，其特征在于，包括视频输入设备、网络接口、视频采集模块、车辆检测和跟踪模块、车流量统计模块，视频输入设备拍摄到的车辆运动图像通过网络接口传送到视频采集模块，完成视频流数据的读取、解码、存储、播放功能，车辆检测和跟踪模块从视频流数据中检测运动车辆，提取特征数据和跟踪目标车辆，车流量统计模块从检测到车辆信息来计算不同方向车流量。</div>
    </div>
    </div> <div class="claim"> <div num="2" class="claim">
      <div class="claim-text">2.一种基于多特征融合的车流监控图像检测和跟踪方法，其特征在于，包括以下步骤:  步骤1:获取并解码摄像头视频流并转换为HSV格式的序列帧图像；  步骤2:运动目标检测  对第一帧图像根据像素点空间上的相关性和时间上的相关性，应用VIBE算法建立图像背景模型，并比较背景帧和当前帧进行背景/前景分类，同时采用背景更新策略更新背景模型；  步骤3:目标图像特征提取  (3.1)采用颜色特征和SILTP纹理特征结合方法，消除分割出来的前景运动目标阴影粘连干扰和其它噪声干扰；  (3.2)对于(3.1)获取的目标图像进行分块，采用局部二值化模式LBP提取若干个分块目标图像的纹理特征，并统计LBP的直方图，生成整幅图像的特征向量；  (3.3)结合(3.2)得到的均匀旋转不变LBP纹理描述特征向量，采用加速分割检测特征FAST算法计算目标图像的主方向和角点描述子，从而得到前景目标的特征描述；  步骤4:运动目标跟踪  (4.1)将RGB颜色转化HSV空间，计算检测目标直方图，记录中心坐标以及搜索窗口 ；(4.2)计算直方图到二维图像上的反向投影，即用当前颜色值的统计值代替当前像素点的值；  (4.3)根据MeanShift算法计算目标图像模型和当前帧候选目标图像特征的相似度，判断是否搜索到目标，若搜索到转(4.6)，若未搜索到转到(4.4)；  (4.4)当前巾贞未搜索到时,加入基于ROI的运动目标检测和Kalman预测功能,当目标图像再次出现在场景中时，继续对目标跟踪；  (4.5)调整搜索窗口大小，重复(4.2)和(4.3)步骤直到搜索到目标；  (4.6)求取窗口目标大小,对运动目标进行标记或车流检测记录上传,转到(4.2)进行下一帧图像的跟踪。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES86559292" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">基于多特征融合的车流监控图像检测和跟踪系统及方法</invention-title>
    <technical-field>
      <p>技术领域</p>
      <p>[0001]	本发明属于视频图像处理及模式识别技术领域，涉及一种基于多特征融合的车流监控图像检测和跟踪系统及方法。</p>
    </technical-field>
    <background-art>
      <p>背景技术</p>
      <p>[0002]	车流监测和车辆自动跟踪技术在公路车辆行驶安全和智能交通等领域都有广泛的应用价值。由于当前交通视频监控系统只能简单的处理和记录影像，或者通过操作员观看录像回放来判断监控场景内的各路段路况信息，一方面人工监控较易出错，也带来了较高的人力成本，并且对于及时快速处理大量视频信息，实现最佳交通调度，实时监控路况信息，记录违规车辆是不可能的。因此智能交通领域迫切需要一种能够具有理解所监控场景能力的视频监控技术。</p>
      <p>[0003]	智能视频监控技术主要包括运动目标检测、运动目标跟踪以及对监控场景中目标行为的理解与描述。目标检测与跟踪的目的是提取视频中运动的视觉信息，根据运动信息对视频分析是智能视频监控的重要组成部分，其结果直接影响对行为的理解与描述。智能监控与分析有两大发展方向:以车牌、人脸识别为代表的智能识别技术，主要应用于城市交通、机场、海关；另一个是以人数统计、自动追踪、周边危险检测为代表的行为分析技术，主要有商场，周边警戒区，交通违规违法行为等。</p>
      <p>[0004]	传统的图像检测和跟踪方法，如基于统计的方法、背景差分法、光流场法及时间差分法等图像处理方法，较难达到较高的准确率。目标特征提取和跟踪技术，目标检测将场景分割成前景/背景后，需要用一些特殊的符号来描述场景中的目标特征，以便于后续的视频序列的目标跟踪，特征提取分为全局特征提取和局部特征提取，全局特征是一帧图像所有像素计算的特征，目前常用的有纹理特征、颜色特征和形状特征；与全局特征相比，局部特征提取图像的区域信息，具有更好的不变形、唯一性和鲁棒性，能更好的地适应光照变化、局部遮挡等复杂场景。</p>
    </background-art>
    <disclosure>
      <p>发明内容</p>
      <p>[0005]	本发明的目的在于克服上述技术存在的缺陷，提供一种基于多特征融合的车流监控图像检测和跟踪系统及方法，采用VIBE算法第一帧图像的背景模型，比较当前帧分割出帧内图像目标并更新背景模型。对分割出的图像目标采用颜色特征和SILTP纹理特征去除噪声干扰，提取LBP分块目标图像纹理特征，计算LBP的直方图，生成整幅图像的特征向量，应用FAST算法计算目标图像的主方向和角点描述子。计算目标图像的直方图和特征算子，自动调整搜索窗口，应用MeanShift算法或Kalman滤波算法计算图像特征相似度匹配,计算新窗口中心位置，比较并确定搜索目标，对其标记或车流检测记录上传。该方法应用于监控场景中的目标进行检测与分析，当发生异常情况时可以实现自动报警并记录信息，从而节省大量人力、物力，加快了城市交通安全系统建设。其具体技术方案为:</p>
      <p>[0006]	一种基于多特征融合的车流监控图像检测和跟踪系统，包括视频输入设备、网络接口、视频采集模块、车辆检测和跟踪模块、车流量统计模块，视频输入设备拍摄到的车辆运动图像通过网络接口传送到视频采集模块，完成视频流数据的读取、解码、存储、播放功能，车辆检测和跟踪模块从视频流数据中检测运动车辆，提取特征数据和跟踪目标车辆，车流量统计模块从检测到车辆信息来计算不同方向车流量。</p>
      <p>[0007]	一种基于多特征融合的车流监控图像检测和跟踪方法，包括以下步骤:</p>
      <p>[0008]	步骤1:获取并解码摄像头视频流并转换为HSV格式的序列帧图像；</p>
      <p>[0009]	步骤2:运动目标检测</p>
      <p>[0010]	对第一帧图像根据像素点空间上的相关性和时间上的相关性，应用VIBE算法建立图像背景模型，并比较背景帧和当前帧进行背景/前景分类，同时采用背景更新策略更新背景模型。</p>
      <p>[0011]	步骤3:目标图像特征提取</p>
      <p>[0012]	(3.1)采用颜色特征和SILTP纹理特征结合方法，消除分割出来的前景运动目标阴影粘连干扰和其它噪声干扰；</p>
      <p>[0013]	(3.2)对于(3.1)获取的目标图像进行分块，采用局部二值化模式LBP提取若干个分块目标图像的纹理特征，并统计LBP的直方图，生成整幅图像的特征向量；</p>
      <p>[0014]	(3.3)结合(3.2)得到的均匀旋转不变LBP纹理描述特征向量，采用加速分割检测特征(FAST)算法计算目标图像的主方向和角点描述子，从而得到前景目标的特征描述。</p>
      <p>[0015]	步骤4:运动目标跟踪</p>
      <p>[0016]	(4.1)将RGB颜色转化HSV空间，计算检测目标直方图，记录中心坐标以及搜索窗Π ；</p>
      <p>[0017]	(4.2)计算直方图到二维图像上的反向投影，即用当前颜色值的统计值代替当前像素点的值；</p>
      <p>[0018]	(4.3)根据MeanShift算法计算目标图像模型和当前帧候选目标图像特征的相似度，判断是否搜索到目标，若搜索到转(4.6)，若未搜索到转到(4.4)；</p>
      <p>[0019]	(4.4)当前帧未搜索到时，加入基于ROI的运动目标检测和Kalman预测功能，当目标图像再次出现在场景中时，继续对目标跟踪；</p>
      <p>[0020]	(4.5)调整搜索窗口大小，重复(4.2)和(4.3)步骤直到搜索到目标；</p>
      <p>[0021]	(4.6)求取窗口目标大小，对运动目标进行标记或车流检测记录上传，转到(4.2)进行下一帧图像的跟踪。</p>
      <p>[0022]	与现有技术相比，本发明的有益效果为:本发明基于计算机视觉中车流监控检测和跟踪领域的最新进展，检测准确率较高，跟踪速度较快，具有较好的应用前景。另外，通过结合运动目标的特征提取方法，采用LBP纹理与改进FAST角点混合特征，提高了特征提取的速度，采用均值漂移跟踪算法和运动目标位置预测算法，解决了运动目标因大面积遮挡或背景干扰而跟踪丢失的问题，达到实用水平。</p>
    </disclosure>
    <description-of-drawings>
      <p>附图说明</p>
      <p>[0023]图1是本发明的基于多特征融合的车流监控图像检测和跟踪系统的系统框图；</p>
      <p>[0024]	图2是本发明的基于多特征融合的车流监控图像检测和跟踪方法的实现流程图；</p>
      <p>[0025]	图3是本发明的运动目标图像跟踪程序框图；</p>
      <p>[0026]	图4是本发明的均值漂移目标跟踪程序流程图；</p>
      <p>[0027]	图5是本发明的阴影及光照去除程序流程；</p>
      <p>[0028]	图6是本发明的前景与背景分割流程。</p>
    </description-of-drawings>
    <mode-for-invention>
      <p>具体实施方式</p>
      <p>[0029]	为了使本发明实现的技术手段、创作特征、达成目的与功效易于明白了解，下面结合附图和具体实例，进一步阐述本发明。</p>
      <p>[0030]	本发明基于多特征融合的车流监控图像检测和跟踪系统的系统框图在图1所示的系统上实现，系统包括视频输入设备、网络端口、控制中心、视频采集模块、车辆检测与跟踪模块、车流量统计模块等。</p>
      <p>[0031]	视频输入设备:本系统所需视频输入设备可以为一个或者多个，视频输入设备可以采用监控摄像头或传统的摄像头，要求摄像头拍摄分辨率高于320*240，帧率高于20FPS，像素深度不低于RGB1200，摄像头离地10&#12316;15米，拍摄角度为斜向下三十到六十度，要求摄像头的放置位置和拍摄角度使得行驶车辆都出现在拍摄区域。</p>
      <p>[0032]	控制中心:本系统控制中心可以由普通或专用的PC机或服务器来实现，通过局域网或互联网与摄像机相连，网络传输速率10MBPS，控制中心通过视频管理软件实现视频流图像采集、存储、播放等功能。</p>
      <p>[0033]	如图2所示的基于多特征融合的车流监控图像检测和跟踪系统的系统框图，该方法包括如下步骤:</p>
      <p>[0034]	步骤1:获取并解码摄像头视频流RGB格式图像，经过转换为HSV格式的序列帧图像。</p>
      <p>[0035]	步骤2:运动目标和背景分割流程如图6所示，首先对图像进行高斯平滑预处理，然后提取三帧图像序列的SILTP值并且分别求取相邻两帧之间的距离。对第一帧图像应用VIBE背景建模，针对当前帧，对每一个像素点建立一个像素点集合空间，计算当前帧像素点与背景模型的欧几里德距离，用下面式子计算比较判断背景帧和当前帧。</p>
      <p>[0036]	SE(pt(x, y)) = {p | EuclidDis (p, pt (x, y)) &lt; R}</p>
      <p>[0037]	count = # {SE (pt (x, y)) Π Bto (x, y)}</p>
      <p>[0038]</p>
      <p>                   t 、[前景点，count i#min                   L &#20867;京点,，count &gt; #min</p>
      <p>[0039]	对于背景模型更新采用一定概率的方式更新背景点，增强算法的实时性。</p>
      <p>[0040]	步骤3:对于运动目标阴影粘连和其它噪声干扰问题，采用颜色特征和SILTP纹理特征相结合的方法，完成运动目标和阴影的分割，其流程图如图5所示。</p>
      <p>[0041]</p>
      <p>         k	[O	其他</p>
      <p>[0042]	利用背景帧差法提取运动区域的二值化区域，Dn(x, y) = I表示前景目标，否则为进旦&#20867;月^ ；</p>
      <p>[0043]	在011(&#20034;，7) = I处,判断当前巾贞灰度值与背景Bn (x, y)灰度值比r</p>
      <p>[0044]	r= d</p>
      <p>[0045]</p>
      <p>r	[I ifr &gt; th\ 8cr &lt; th2</p>
      <p>                           Mr{x,v) = \                              tV " [0 其他</p>
      <p>[0046]	利用U、V分两段对检测的目标区域修正；</p>
      <p>[0047]</p>
      <p>           Μυν-(χ i1 ifpc1-^y)-Ub(x^y)\+\uc(^y)-Ub(^y)I &gt; Tur             4	[ο	其它</p>
      <p>[0048]	HiftCfr=MirUMf为检测出的运动车辆区域，否则为阴影区域。</p>
      <p>[0049]	图像的纹理与灰度值无关，而是与邻域灰度差值有关，对均匀亮度变化具有不变性，对灰度范围内平移不变性，对于分割后的目标图像进行分块，采用局部二值化模式(LBP)提取若干个分块目标图像的纹理特征，LBP模式特征如下:</p>
      <p>[0050]	灰度线性变化平移不变性LBP模式</p>
      <p>      p-1	&#943; I X &gt; O</p>
      <p>[0051]	LBPrji	其中 = χ&lt;()</p>
      <p>[0052]	旋转不变的LBP模式</p>
      <p>[0053]	LB P;': R: mm{ROR(LBP/&gt;h,J) | / = 0,1,...,&#8212; l}</p>
      <p>[0054]	对每个子块提取LBP特征并统计LBP直方图，选择合适的P，R值，P值越大生成的维数越高，在匹配跟踪的时候耗费的时间就越多，并且跟踪的准确性与目标分块大小也有一定的关系。在基于LBP描述子对目标进行跟踪时，采用直方图的相似性来区分不同目标，下面是几种相似性度量方法:</p>
      <p>[0055]卡尔统计	/:(尸.(?) = Σ(&#971;.</p>
      <p>[0056]直方图相交	= Σηιιη(6,β)</p>
      <p>                                                      i</p>
      <p>[0057]	G 统计	= ~Σι S.1.丨0g Mi</p>
      <p>                                                 I</p>
      <p>[0058]	结合得到LBP纹理描述的特征描述，采用FAST算法提取角点特征:</p>
      <p>[0059]	角点的主方向:</p>
      <p>[0060]	半径为R的数字图像f (X，y)的二维(p+q)阶矩定义为:</p>
      <p>[0061]</p>
      <p>                           χ,ν</p>
      <p>[0062]	主方向为:    f \</p>
      <p>[0063]	C=</p>
      <p>             V mOQ mQQ J</p>
      <p>[0064]	建立Hessian矩阵对伪角点特征进行去除，使用质心算法提取角点主方向，然后融合LBP文理对目标特征进行提取。</p>
      <p>[0065]	特征向量生成向量后，距离采用式</p>
      <p>[0066]	IK-^I=ZK I</p>
      <p>                                  /=1</p>
      <p>[0067]	并使用距离描述关键点之间的相似性判定度量。</p>
      <p>[0068]	步骤4:运动目标检测和跟踪流程，如图3所示。</p>
      <p>[0069]	基于颜色统计特征的均值漂移算法流程如图4所示，其步骤如下</p>
      <p>[0070]	(I)当前位置坐标％点，求取概率密度!Pu(Y0)Ku = I^…,m),并计算/?(/?(凡),的；</p>
      <p>[0071]	(2)求取权重值 Wi (i = 1，2，...η);</p>
      <p>[0072]	(3)计算候选目标位置Λ ,并计算B氏系数；</p>
      <p>[0073]	(4)如果8氏系数广[政1;|),&lt;7]&lt;/()[/;(&gt;，|,),7]，贝|]7110.5(.1,，|1+&gt;;1),重新计算，y!处 B</p>
      <p>氏系数，否则进行下一步；如果I Iy1IcJ I &lt; ε，则迭代结束，否则返回步骤2继续执行。</p>
      <p>[0074]	均值漂移算法简单可以达到实时性的要求，在场景简单的情况下，能够准确的跟踪出目标，但遇到环境复杂的情况，比如目标和周围背景的颜色相似时，引起错误收敛，从而导致目标跟踪丢失。因此本发明加入基于ROI的运动目标检测，去除静止不动的背景而避免了来自背景对目标的干扰；另外当目标处于大范围遮挡的情况，由于均值漂移算法没有预测功能，则出现目标丢失，因此加入基于预测功能的Kalman预测来对目标预测，当目标再次出现在场景中时，能继续对目标加以跟踪，算法流程如图3所示。</p>
      <p>[0075]	上述计算目标图像模型和当前帧候选目标图像特征的相似度，当搜索到目标时对跟踪到的目标求取窗口目标大小，对运动目标进行标记或车流检测记录上传，然后转到下一帧图像的跟踪。</p>
      <p>[0076]	当前帧未搜索到目标图像时，加入基于ROI的运动目标检测和Kalman预测功能，解决目标被大面积遮挡问题，当目标图像再次出现在场景中时，继续对目标跟踪.</p>
      <p>[0077]	调整搜索窗口大小和中心坐标位置，重复上述计算和搜索直到检测到目标。</p>
      <p>[0078]	在监控视频场中设置检测线，根据运动目标标记和或跟踪轨迹判断不同方向的车流，并统计车流量信息，在监控计算机上显示。</p>
      <p>[0079]	首先获取并解码摄像头视频流并转换为HSV格式的序列帧图像，其次对第一帧图像使用VIBE进行背景建模，后续帧与背景模型比较检测出前景车辆目标并更新背景模型，再次通过计算前景车辆目标颜色和SILTP纹理特征实现监控目标区域的阴影去除，进一步地提取出车辆目标的LBP纹理特征与改进FAST角点特征，最后在目标跟踪算法中采用均值漂移算法，实现视频场中车辆目标的精确定位和跟踪。另外针对均值漂移算法无法适应移动目标尺寸变化，采用了感兴趣区域运动检测和Kalman滤波器目标位置预测算法实现运动车辆目标的准确跟踪。在监控视频场中设置检测线，通过运动车辆目标的跟踪轨迹判断不同方向的车流量，并统计车流量信息。本发明基于计算机视觉中车流监控检测和跟踪领域的最新进展，检测准确率较高，跟踪速度较快，具有较好的应用前景。特别是运动目标的特征提取采用LBP纹理与改进FAST角点混合特征，提高了特征提取的速度，采用运动检测和目标位置预测方法，解决了运动目标因大面积遮挡或背景干扰而跟踪丢失的问题。</p>
      <p>[0080]	以上所述，仅为本发明最佳实施方式，任何熟悉本技术领域的技术人员在本发明披露的技术范围内，可显而易见地得到的技术方案的简单变化或等效替换均落入本发明的保护范围内。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=RLMoCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0007200000">G06T7/20</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=RLMoCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009620000">G06K9/62</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2014年11月5日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年12月24日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/6677b0ed08508c541143/CN104134222A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5bd24152bf5a1e342ae546da267fae0b.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E8%BD%A6%E6%B5%81%E7%9B%91%E6%8E%A7%E5%9B%BE.pdf?id=RLMoCQABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2cwPTqR5NhklVVyCJBuHK2qYGrVg"},"sample_url":"https://www.google.com/patents/reader?id=RLMoCQABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>