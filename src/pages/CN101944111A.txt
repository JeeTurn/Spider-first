<!DOCTYPE html><html><head><title>专利 CN101944111A - 新闻视频的搜索方法和装置 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="新闻视频的搜索方法和装置"><meta name="DC.contributor" content="尹文科" scheme="inventor"><meta name="DC.contributor" content="崔昊&#26107;" scheme="inventor"><meta name="DC.contributor" content="朱明 " scheme="inventor"><meta name="DC.contributor" content="李自勉" scheme="inventor"><meta name="DC.contributor" content="中国科学技术大学" scheme="assignee"><meta name="DC.date" content="2010-9-9" scheme="dateSubmitted"><meta name="DC.description" content="本发明实施例提供了一种新闻视频的搜索方法及装置。该方法主要包括：基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联网中搜索出新闻视频网站；对所述新闻视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔；利用所述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内容中的新闻视频。利用本发明，有效地解决了互联网新闻视频自动、准确、及时的搜索与集成的问题，可以快速、准确地识别出新闻视频网站，可以自动、及时地发现和集成新闻视频。"><meta name="DC.date" content="2011-1-12"><meta name="DC.relation" content="CN:101065749:A" scheme="references"><meta name="DC.relation" content="CN:101599089:A" scheme="references"><meta name="citation_reference" content="《Signal Processing,ICSP 2008》 20081208 Ming Zhu,etc Effective Video Content Abstraction by Similar Shots Clustering 第1445-1448页 1-10 , 2"><meta name="citation_reference" content="《计算机仿真》 20080831 朱明等 基于多超级节点的PMDN资源搜索策略 第131-135页 1-10 第25卷, 第8期 2"><meta name="citation_patent_publication_number" content="CN:101944111:A"><meta name="citation_patent_application_number" content="CN:201010280175"><link rel="canonical" href="https://www.google.com/patents/CN101944111A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101944111A?cl=zh"/><meta name="title" content="专利 CN101944111A - 新闻视频的搜索方法和装置"/><meta name="description" content="本发明实施例提供了一种新闻视频的搜索方法及装置。该方法主要包括：基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联网中搜索出新闻视频网站；对所述新闻视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔；利用所述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内容中的新闻视频。利用本发明，有效地解决了互联网新闻视频自动、准确、及时的搜索与集成的问题，可以快速、准确地识别出新闻视频网站，可以自动、及时地发现和集成新闻视频。"/><meta property="og:title" content="专利 CN101944111A - 新闻视频的搜索方法和装置"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101944111A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101944111A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=60iNBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101944111A&amp;usg=AFQjCNFHb_TT65hxw4xBosQ6xw5OO3al4g" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/3889d9683dcbeaca96c6/CN101944111A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/3889d9683dcbeaca96c6/CN101944111A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101944111A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101944111A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101944111A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101944111B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101944111A?cl=zh" style="display:none"><span itemprop="description">本发明实施例提供了一种新闻视频的搜索方法及装置。该方法主要包括：基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联网中搜索出新闻视频网站；对所述新闻视频网站进行及时性的评价，利用所...</span><span itemprop="url">https://www.google.com/patents/CN101944111A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101944111A - 新闻视频的搜索方法和装置</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101944111A - 新闻视频的搜索方法和装置" title="专利 CN101944111A - 新闻视频的搜索方法和装置"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101944111 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010280175</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年1月12日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年9月9日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年9月9日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101944111B?hl=zh-CN&amp;cl=zh">CN101944111B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010280175.4, </span><span class="patent-bibdata-value">CN 101944111 A, </span><span class="patent-bibdata-value">CN 101944111A, </span><span class="patent-bibdata-value">CN 201010280175, </span><span class="patent-bibdata-value">CN-A-101944111, </span><span class="patent-bibdata-value">CN101944111 A, </span><span class="patent-bibdata-value">CN101944111A, </span><span class="patent-bibdata-value">CN201010280175, </span><span class="patent-bibdata-value">CN201010280175.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%B0%B9%E6%96%87%E7%A7%91%22">尹文科</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%B4%94%E6%98%8A%E6%97%BB%22">崔昊&#26107;</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9C%B1%E6%98%8E%EF%BF%BD%22">朱明 </a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E8%87%AA%E5%8B%89%22">李自勉</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%22">中国科学技术大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101944111A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101944111A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101944111A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=60iNBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010280175&amp;usg=AFQjCNFaHmYIPhCEqRVzbkIRP8v6OU9n4Q"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=60iNBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101944111A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFasZZ4ODhSkf_1G7nWY7XbI4_iHw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT100029712" lang="ZH" load-source="patent-office">新闻视频的搜索方法和装置</invention-title>
      </span><br><span class="patent-number">CN 101944111 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA82294563" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明实施例提供了一种新闻视频的搜索方法及装置。该方法主要包括：基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联网中搜索出新闻视频网站；对所述新闻视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔；利用所述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内容中的新闻视频。利用本发明，有效地解决了互联网新闻视频自动、准确、及时的搜索与集成的问题，可以快速、准确地识别出新闻视频网站，可以自动、及时地发现和集成新闻视频。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><ol mxw-id="PCLM34275093" lang="ZH" load-source="patent-office" class="claims">
    <li class="claim"> <div num="1" class="claim">
      <div class="claim-text">一种新闻视频的搜索方法，其特征在于，包括：基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联网中搜索出新闻视频网站；对所述新闻视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔；利用所述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内容中的新闻视频。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的新闻视频的搜索方法，其特征在于，所述的语义关联信息包 括：搜索引擎本身提供的搜索关键词、已搜索发现的新闻视频网站的内容关键词、已搜索发 现的新闻视频网站的内容组织结构关键词和已搜索发现的新闻视频网站的内容描述关键 词。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的新闻视频的搜索方法，其特征在于，所述的利用所述本体知 识从互联网中搜索出新闻视频网站，包括：针对所述本体知识中的每一个关键词，利用元搜索技术构造对互联网中的搜索引擎的 搜索请求，抽取设定数量的所述搜索引擎返回的搜索结果，提取出所述搜索结果中包括的 统一资源定位符URL ；通过网站主题识别方法识别出所述URL中包括的新闻视频网站的URL，将识别出的新 闻视频网站存储在预先建立的新闻视频网站数据库。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3所述的新闻视频的搜索方法，其特征在于，所述的通过网站主题识 别方法识别出所述URL中包括的新闻视频网站的URL，包括：利用所述搜索结果中包括的URL的模式信息识别出所述URL是网站URL还是网页URL ；对于识别出的每个网站URL，抓取网站第一层内的所有网页，利用播放页识别技术计 算所述所有网页中的视频播放页的比例，如果该比例小于预先设定的视频播放页阈值，则 认为所述网站URL是与新闻视频网站主题无关，将所述网站URL排除；否则，认为所述网站 URL是与新闻视频网站主题相关的；利用所述与新闻视频网站主题相关的网站中的视频播放页对应的链接文字对预先建 立的新闻视频数据库执行模糊查询，统计出总的相似结果数。计算平均每条链接文字对应 的相似结果数，如果该相似结果数小于预先设定的相似结果数阈值，则认为所述网站与新 闻视频网站主题无关；否则，识别出所述网站是新闻视频网站。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的新闻视频的搜索方法，其特征在于，所述的对所述新闻视频 网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间 隔，包括：从所述种子网站里获得一定数量的当天的新闻视频，根据所述当天的新闻视频对新闻 视频数据库执行模糊查询，统计新闻视频数据库中的每个新闻视频网站中包含的和所述当 天的新闻视频相似的新闻视频数量，将该新闻视频数量作为新闻视频网站的及时性的评价 结果存入新闻视频网站数据库中；根据所述包含的和所述当天的新闻视频相似的新闻视频数量设置每个新闻视频网站 的抓起时间间隔，包含的和所述当天的新闻视频相似的新闻视频数量多的网站对应的抓起 时间间隔短。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1至5任一项所述的新闻视频的搜索方法，其特征在于，所述的利用所 述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的新 闻视频，包括：当新闻视频网站数据库中的新闻视频网站距上次抓起结束时的时间已经超过所述新 闻视频网站的抓起时间间隔后，通过设定的搜索方法对所述新闻视频网站中的内容进行抓 起；对从所述新闻视频网站中抓起到的每个网页利用播放页识别技术判断其是否为视 频播放页，对于判断出的视频播放页除去其包含的噪声信息后，将余下的信息作为新闻视 频；对所述新闻视频利用基于内容的重复检测技术进行重复检测，利用基于视频压缩域的 反向迭代投影法提高重复检测通过的新闻视频的质量，然后，将所述新闻视频和对应的描 述信息存入新闻视频数据库中。</div>
    </div>
    </li> <li class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.	一种新闻视频的搜索装置，其特征在于，包括：新闻视频网站搜索模块，用于基于语义关联信息构建搜索新闻视频网站的本体知识， 利用所述本体知识从互联网中搜索出新闻视频网站；抓起时间间隔设定模块，用于对所述新闻视频网站搜索模块所搜索出来的新闻视频 网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间 隔；新闻视频获取模块，用于利用所述抓起时间间隔设定模块所设定的新闻视频网站的抓 起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内容中 的新闻视频。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的新闻视频的搜索装置，其特征在于，所述的新闻视频网站搜 索模块包括：搜索模块，用于针对所述本体知识中的每一个关键词，利用元搜索技术构造对互联网 中的搜索引擎的搜索请求，抽取设定数量的所述搜索引擎返回的搜索结果，提取出返回结 果中包括的统一资源定位符URL ；识别模块，用于通过网站主题识别方法识别出所述搜索模块提取出的URL中包括的新 闻视频网站的URL，将识别出的新闻视频网站存储在预先建立的新闻视频网站数据库。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求7所述的新闻视频的搜索装置，其特征在于，所述的抓起时间间隔设 定模块包括：统计模块，用于从种子网站里获得一定数量的当天的新闻视频，根据所述当天的新闻 视频对新闻视频数据库执行模糊查询，统计新闻视频数据库中的每个新闻视频网站中包含 的和所述当天的新闻视频相似的新闻视频数量，将该新闻视频数量作为新闻视频网站的及 时性的评价结果存入新闻视频网站数据库中；设定模块，用于根据所述包含的和所述当天的新闻视频相似的新闻视频数量设定每个 新闻视频网站的抓起时间间隔，新闻视频数量多的新闻视频网站对应的抓起时间间隔短。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求7或8或9所述的新闻视频的搜索装置，其特征在于，所述的新闻视 频获取模块包括：抓起模块，用于当新闻视频网站数据库中的新闻视频网站距上次抓起结束时的时间已经超过所述新闻视频网站的抓起时间间隔后，通过设定的搜索方法对所述新闻视频网站中 的内容进行抓起；识别模块，用于对从所述新闻视频网站中抓起到的每个网页利用播放页识别技术判断 其是否为视频播放页，对于判断出的视频播放页除去其包含的噪声信息后，将余下的信息 作为新闻视频；检测和增强模块，用于对所述新闻视频利用基于内容的重复检测技术进行重复检测， 利用基于视频压缩域的反向迭代投影法增强重复检测通过的新闻视频的质量，然后，将所 述新闻视频和对应的描述信息存入新闻视频数据库中。</div>
    </div>
  </li> </ol>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES40150823" lang="ZH" load-source="patent-office" class="description">
    <p>新闻视频的搜索方法和装置</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及计算机应用技术领域，尤其涉及一种新闻视频的搜索方法和装置。 背景技术</p>
    <p>[0002]	为了支持三网融合业务演进，需要研究如何基于资源有限的终端设备，支持开展 更多的电视业务，尤其是目前电视业务中比较吸引观众的新闻业务。如何使电视观众可以 随时收看电视新闻，享受电视新闻的个性化与专题化的服务，成为了三网融合背景下值得 关注的问题。</p>
    <p>[0003]	现有技术中的一种网页主题识别和网页信息抽取的方法主要包括：在网页主题分 析的基础上，把网站的所有网页合并为一个虚拟网页，采用词频特征向量进行网站分类。采 用向量空间模型，利用向量间的距离进行网站主题分析，采用主题频次向量来描述网站的 主题特征，根据网站中所包含每个主题的网页数来相应确定向量元素的权值。此外，网站的 内部链接结构常常被视为一种层次性的树或图结构。例如：根据站点的物理与逻辑链接结 构来合并网页主题，从而确定网站主题。</p>
    <p>[0004]	然后，利用人工构建的信息抽取系统、有监督的信息抽取系统、半监督的信息抽取 系统和无监督的信息抽取系统进行网页信息抽取。</p>
    <p>[0005]	在实现本发明过程中，发明人发现上述现有技术中的网页主题识别和网页信息抽 取的方法至少存在如下问题：需要对网站的整体链接结构进行复杂的统计和分析，面对快 速增长的网络规模，适用性有待提高。无法快速、准确地识别出新闻视频网站，也无法自动、 及时地发现和集成新闻视频。</p>
    <p>发明内容</p>
    <p>[0006]	本发明的实施例提供了一种新闻视频的搜索方法和装置，以实现自动、准确和及 时地发现和集成新闻视频。</p>
    <p>[0007]	一种新闻视频的搜索方法，包括：</p>
    <p>[0008]	基于语义关联信息构建搜索新闻视频网站的本体知识，利用所述本体知识从互联 网中搜索出新闻视频网站；</p>
    <p>[0009]	对所述新闻视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新 闻视频网站的抓起时间间隔；</p>
    <p>[0010]	利用所述新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻 视频网站中的内容，获取所述内容中的新闻视频。</p>
    <p>[0011]	一种新闻视频的搜索装置，包括：</p>
    <p>[0012]	新闻视频网站搜索模块，用于基于语义关联信息构建搜索新闻视频网站的本体知 识，利用所述本体知识从互联网中搜索出新闻视频网站；</p>
    <p>[0013]	抓起时间间隔设定模块，用于对所述新闻视频网站搜索模块所搜索出来的新闻视 频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔；</p>
    <p>[0014]	新闻视频获取模块，用于利用所述抓起时间间隔设定模块所设定的新闻视频网站 的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述内 容中的新闻视频。</p>
    <p>[0015]	由上述本发明的实施例提供的技术方案可以看出，本发明实施例有效地解决了互 联网新闻视频自动、准确、及时的搜索与集成的问题，可以快速、准确地识别出新闻视频网 站，可以自动、及时地发现和集成新闻视频。</p>
    <p>附图说明</p>
    <p>[0016]	为了更清楚地说明本发明实施例的技术方案，下面将对实施例描述中所需要使用 的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本 领域普通技术人员来讲，在不付出创造性劳动性的前提下，还可以根据这些附图获得其他 的附图。</p>
    <p>[0017]	图1为本发明实施例一提供的一种新闻视频的搜索方法的原理示意图；</p>
    <p>[0018]	图2为本发明实施例一提供的一种新闻视频的搜索方法的处理流程图；</p>
    <p>[0019]	图3为本发明实施例一提供的一种本体知识的构建原理示意图；</p>
    <p>[0020]	图4为本发明实施例一提供的一种网站主题识别方法的处理流程图；</p>
    <p>[0021]	图5为本发明实施例一提供的一种对本体知识进行新链接产生力、主题相关度评 价的具体处理流程图；</p>
    <p>[0022]	图6为本发明实施例一提供的一种对新闻视频数据库中存储的新闻视频网站进 行及时性评价的处理流程图；</p>
    <p>[0023]	图7为本发明实施例一提供的一种对新闻视频数据库中存储的新闻视频网站进 行新颖性评价的处理流程图；</p>
    <p>[0024]	图8为本发明实施例一提供的一种对新闻视频数据库中存储的新闻视频网站进 行原创性评价的处理流程图；</p>
    <p>[0025]	图9为本发明实施例一提供的一种基于内容的重复检测技术的处理流程图；</p>
    <p>[0026]	图10为本发明实施例一提供的一种实时抓起新闻视频数据库中存储的新闻视频 网站的内容的处理流程图；</p>
    <p>[0027]	图11为本发明实施例二提供的一种新闻视频的搜索装置的结构示意图。 具体实施方式</p>
    <p>[0028]	在本发明实施例中，基于语义关联信息构建搜索新闻视频网站的本体知识，利用 所述本体知识从互联网中搜索出新闻视频网站。对所述新闻视频网站进行及时性的评价， 利用所述及时性的评估结果设定所述新闻视频网站的抓起时间间隔。然后，利用所述新闻 视频网站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获 取所述内容中的新闻视频。</p>
    <p>[0029]	为便于对本发明实施例的理解，下面将结合附图以几个具体实施例为例做进一步 的解释说明，且各个实施例并不构成对本发明实施例的限定。</p>
    <p>[0030]	实施例一[0031]	该实施例提供的一种新闻视频的搜索方法的原理示意图如图1所示，该新闻视频 的搜索方法的具体处理流程如图2所示，包括如下的处理步骤：</p>
    <p>[0032]	步骤21、基于语义关联信息构建搜索新闻视频网站的本体知识，利用上述本体知 识、元搜索技术和网站主题识别方法从互联网中搜索出新闻视频网站，并将新闻视频网站 存储在新闻视频网站数据库中。</p>
    <p>[0033]	首先，利用少量种子网站的新闻视频数据预先建立新闻视频数据库，该新闻视频 数据库中存储各个新闻视频和各个新闻视频的描述信息。上述种子网站包括“新华网新 闻”、“腾迅网新闻”等网站。</p>
    <p>[0034]	在本发明实施例中，还要预先建立新闻视频网站数据库，该新闻视频网站数据库 中存储各个新闻视频网站，以及各个新闻视频网站的评价信息、抓起时间间隔等信息。</p>
    <p>[0035]	基于语义关联信息构建搜索新闻视频网站的本体知识。该本体知识的构建原理示 意图如图3所示。上述语义关联信息主要包括：搜索引擎本身提供的搜索关键词、已搜索发 现的新闻视频网站的内容关键词、已搜索发现的新闻视频网站的内容组织结构关键词，以 及已搜索发现的新闻视频网站的内容描述关键词。上述新闻视频网站的内容关键词包括： 新闻视频网站的内容的标题中的关键词，上述新闻视频网站的内容描述关键词包括：热点 视频标题。因此，上述本体知识中主要包括四种关键词，即搜索关键词、内容关键词、内容组 织结构关键词和内容描述关键词。</p>
    <p>[0036]	针对上述本体知识中每一个关键词，利用元搜索技术构造对互联网中的搜索引 擎的搜索请求，抽取设定数量的上述搜索引擎返回的搜索结果，提取出返回结果中包括的 URL (Universal Resource Locator，统一资源定位符）。通过网站主题识别方法识别出上述 URL中包括的新闻视频网站的URL。</p>
    <p>[0037]	该实施例提供的一种上述网站主题识别方法的处理流程如图4所述，具体处理过 程主要包括：</p>
    <p>[0038]	首先利用上述返回结果中包括的URL的模式信息，如URL的长度、深度和格式等信 息，使用决策树或者规则集等技术识别出上述URL是网站URL还是网页URL。</p>
    <p>[0039]	对于识别出的每个网站URL，抓取网站第一层内的所有网页，利用播放页识别技术 计算上述所有网页中的视频播放页的比例，如果该比例小于预先设定的视频播放页阈值， 则认为该网站URL是与新闻视频网站主题无关，将该网站URL排除；否则，认为上述网站 URL是与新闻视频网站主题相关的。</p>
    <p>[0040]	利用上述与新闻视频网站主题相关的网站中的视频播放页对应的链接文字（锚 文字）对预先建立的新闻视频数据库执行模糊查询，统计出总的相似结果数。计算平均每 条链接文字对应的相似结果数，如果该相似结果数小于预先设定的相似结果数阈值，则认 为该网站与新闻视频网站主题无关；否则，认为上述网站URL与新闻视频网站主题相关，即 识别出上述网站是新闻视频网站。</p>
    <p>[0041]	然后，将识别出的新闻视频网站存储在预先建立的新闻视频网站数据库中。</p>
    <p>[0042]	在本发明实施例中，还可以利用上述网站主题识别方法所识别出的新闻视频网 站，对上述构建的本体知识进行新链接产生力、主题相关度两方面的评价，该评价过程的具 体处理流程图如图5所示，主要包括如下过程：</p>
    <p>[0043]	针对上述本体知识中每一个关键词，利用元搜索技术构造对互联网中的搜索引擎的搜索请求，抽取设定数量的上述搜索引擎返回的搜索结果，提取出返回结果中包括的 URL。</p>
    <p>[0044]	通过网站主题识别方法获取上述URL中包括的新闻视频网站的URL，计算该新闻 视频网站的URL的数量占上述返回结果中包括的URL的总数量的比例，如果该比例小于预 先设定的主题相关度阈值，则认为该关键词与新闻视频网站的主题无关，将该关键词从上 述本体知识中剔除掉；否则，认为该关键词与新闻视频网站的主题相关。继续对该关键词进 行新链接产生力相关的评价。</p>
    <p>[0045]	在新闻视频网站数据库中查找上述识别出的所有的新闻视频网站的URL，根据查 找结果计算出不包括在新闻视频网站数据库中的新闻视频网站的URL的数量占上述新闻 视频网站的URL的总数量之间的比例，如果该比例小于预先设定的新链接产生能力阈值， 则认为该关键词不具有新链接产生能力，将该关键词从上述本体知识中剔除掉；否则，认为 该关键词具有主题相关性和新链接产生能力。</p>
    <p>[0046]	&#8212;般来说，上述网站主题相关度阈值和新链接产生能力阈值均设为0. 1效果较 好。</p>
    <p>[0047]	步骤22、对新闻视频数据库中存储的新闻视频网站进行及时性、新颖性和原创性 的评价，利用新闻视频网站的及时性评估结果设定新闻视频网站的抓起时间间隔。</p>
    <p>[0048]	对新闻视频数据库中存储的新闻视频网站进行及时性、新颖性和原创性三个方面 的评价。</p>
    <p>[0049]	该实施例提供的一种对新闻视频数据库中存储的新闻视频网站进行及时性评价 的处理流程如图6所示，具体处理过程包括：</p>
    <p>[0050]	从上述种子网站里获得一定数量的当天的新闻视频，根据上述当天的新闻视频对 新闻视频数据库执行模糊查询。统计新闻视频数据库中的每个新闻视频网站中包含的和上 述当天的新闻视频相似的新闻视频数量，同一个新闻视频搜索出的属于同一个新闻视频网 站的多个相似新闻视频只记录一次。</p>
    <p>[0051]	对所有新闻视频网站按包含的和上述当天的新闻视频相似的新闻视频数量进行 降序排列，排名前10%的设为5分、排名10%&#12316;30%的设为4分、排名30&#12316;70%的设为3 分、排名70%&#12316;90%的设为2分，排名最后10%的设为1分，此外对于包含的和上述当天的 新闻视频相似的新闻视频数量为0的新闻视频网站直接设为0分。</p>
    <p>[0052]	最后，将上述各个新闻视频网站的及时性评价结果存入新闻网站数据库中，作为 各个新闻视频网站的内容及时性的度量依据。</p>
    <p>[0053]	利用新闻视频网站的及时性评估结果设定新闻视频网站的抓起时间间隔。根据 上述包含的和所述当天的新闻视频相似的新闻视频数量设置每个新闻视频网站的抓起时 间间隔，包含的和所述当天的新闻视频相似的新闻视频数量多的网站对应的抓起时间间隔短。</p>
    <p>[0054]	一种可行的抓起时间间隔的设定方法为：对及时性得分5分的新闻视频网站设定 其抓起时间间隔为5分钟，得分4分的设为10分钟，得分3分为设20分钟，得分2分的设 为40分钟，得分1分的设为80分钟，得分0分的设为1天。</p>
    <p>[0055]	该实施例提供的一种对新闻视频数据库中存储的新闻视频网站进行新颖性评价 的处理流程如图7所示，具体处理过程包括：[0056]	利用基于内容的重复检测技术对从每个新闻视频网站中新获取的新闻视频进行 聚类，从每个聚类中选择一定数量的发现时间比较早的新闻视频予以保留。然后，统计出保 留下来的每个新闻视频网站中的所有新闻视频的总点击次数，进而计算出平均每个新闻视 频的点击次数。</p>
    <p>[0057]	按上述平均每个新闻视频的点击次数对各个新闻视频网站进行降序排列，排名前 10%的设为5分、排名10%&#12316;30%的设为4分、排名30&#12316;70%的设为3分、排名70%&#12316; 90%的设为2分，排名最后10%的设为1分，此外对于平均每个视频点击次数为0的新闻视 频网站直接设为0分。</p>
    <p>[0058]	最后，将上述各个新闻视频网站的新颖性评价结果存入新闻网站数据库中，作为 各个新闻视频网站的新颖性的度量依据。</p>
    <p>[0059]	该实施例提供的一种对新闻视频数据库中存储的新闻视频网站进行原创性评价 的处理流程如图8所示，具体处理过程包括：</p>
    <p>[0060]	利用基于内容的重复检测技术对从每个新闻视频网站中新获取的新闻视频进行 聚类，从每个聚类中选择一定数量的发现时间比较早的新闻视频予以保留，其余的新闻视 频作为重复的新闻视频。统计出每个新闻视频网站包含的总视频数量和重复视频数量，进 而计算出每个新闻视频网站的重复视频比例。对所有新闻视频网站按重复视频比例的升序 排列，排名前10%的设为5分、排名10%&#12316;30%的设为4分、排名30&#12316;70%的设为3分、 排名70%&#12316;90%的设为2分，排名最后10%的设为1分，此外对于重复视频比例为100% 的新闻视频网站直接设为0分。</p>
    <p>[0061]	最后，将上述各个新闻视频网站的原创性评价结果存入新闻网站数据库中，作为 各个新闻视频网站的原创性的度量依据。</p>
    <p>[0062]	该实施例提供的一种上述基于内容的重复检测技术的处理流程如图9所示，具体 处理过程包括如下：</p>
    <p>[0063]	首先提取每个新闻视频的一定数量的视频关键帧，对每个视频关键帧使用 Harris(哈里斯）算子检测出角点，利用SIFT(尺度不变特征转换）特征构造上述视频关 键帧的角点子区域的特征向量，并利用PCA(主成分分析）降低上述特征向量的维数。在两 个新闻视频的两两视频关键帧的之间，使用KNN(K最近邻）算法，计算距离最近的前K个特 征向量对，将BIC(贝叶斯信息测度）算法用于上述K个特征向量对组成的特征值序列X = 1x1，χ2, ..., χΝ} (N = 2K)的比较，如果上述特征值序列X序列中存在跳变点，则判定两个 视频关键帧不重复；否则，判定两个视频关键帧重复。</p>
    <p>[0064]	统计出两个新闻视频之间的重复的视频关键帧的数量，计算出重复的视频关键帧 占总的视频关键帧的比例，如果大于设定的视频关键帧阈值，则判定两个新闻视频是重复 的；否则，判定两个新闻视频不重复。</p>
    <p>[0065]	步骤23、利用新闻视频网站的抓起时间间隔，通过设定的搜索方法实时抓起新闻 视频网站中的新闻视频，将抓起的新闻视频存入新闻视频数据库中。</p>
    <p>[0066]	该实施例提供的一种实时抓起新闻视频数据库中存储的新闻视频网站的内容的 处理流程如图10所示，具体处理过程如下：</p>
    <p>[0067]	首先从新闻视频网站数据库中获得各个新闻视频网站的URL和及时性评估结果， 利用新闻视频网站的及时性评估结果设定新闻视频网站的抓起时间间隔，一种可行的抓起</p>
    <p>9时间间隔设定方法为：对及时性得分5分的新闻视频网站设定其抓起时间间隔为5分钟，得 分4分的设为10分钟，得分3分为设20分钟，得分2分的设为40分钟，得分1分的设为80 分钟，得分0分的设为1天。</p>
    <p>[0068]	按照一定的排列顺序依次判断新闻视频网站数据库中的各个新闻视频网站距上 次抓起结束时的时间间隔是否已超过对应的抓起时间间隔，如果已经超过，则对相应的新 闻视频网站启动新一轮的内容抓起进程；否则，判断下一个网站距上次抓起结束时的时间 间隔是否已超过对应的抓起时间间隔。</p>
    <p>[0069]	对于每个待抓起的新闻视频网站，通过设定的搜索方法对上述新闻视频网站中的 内容进行抓起，上述设定的搜索方法包括：深度受限的广度优先搜索方法等方法。</p>
    <p>[0070]	利用深度受限的广度优先搜索方法对上述新闻视频网站进行遍历，具体的深度限 制可以是一个全局的常量，也可以随新闻视频网站的不同而变化。对于上述遍历过程中遇 到的每个网页，首先利用播放页识别技术判断其是否为视频播放页，对于视频播放页利用 网页噪声去除技术除去其包含的噪声信息，这里的噪声包括：背景噪声、随机噪声，和残留 噪声。将视频播放页中余下的信息作为新闻视频。</p>
    <p>[0071]	对该新闻视频利用上述基于内容的重复检测技术进行重复检测，对于重复检测通 过的新闻视频，利用基于视频压缩域的反向迭代投影法提高新闻视频的画面质量。利用已 有工具对新闻视频进行转码处理后，得到MP4或FLV(FLV流媒体格式）封装格式的新闻视 频。然后，将新闻视频和对应的描述信息存入新闻视频数据库中。当新闻视频网站抓起结 束时，将结束时间存入新闻视频网站数据库中。</p>
    <p>[0072]	上述新闻视频网站数据库中的新闻视频可以供面向电视新闻门户的视频点播系 统使用。可以将新闻视频的描述及关联信息推送至PortalOIP)网站。用户的STB(Set Top Box，机顶盒）访问Portal网站后，可以看到最新的新闻视频列表，用户可以对新闻视 频列表中的新闻视频进行浏览、订购和点播。</p>
    <p>[0073]	实施例二</p>
    <p>[0074]	该实施例提供的一种新闻视频的搜索装置的结构示意图如图11所示，包括如下 的模块：</p>
    <p>[0075]	新闻视频网站搜索模块11，用于基于语义关联信息构建搜索新闻视频网站的本体 知识，利用所述本体知识从互联网中搜索出新闻视频网站；</p>
    <p>[0076]	新闻视频网站评价模块12，用于对所述新闻视频网站搜索模块所搜索出来的新闻 视频网站进行及时性的评价，利用所述及时性的评估结果设定所述新闻视频网站的抓起时 间间隔；</p>
    <p>[0077]	新闻视频获取模块13，用于利用所述新闻视频网站评价模块所设定的新闻视频网 站的抓起时间间隔，通过设定的搜索方法实时抓起所述新闻视频网站中的内容，获取所述 内容中的新闻视频。</p>
    <p>[0078]	所述的新闻视频的搜索装置还可以包括：</p>
    <p>[0079]	本体知识评价模块14，用于针对上述本体知识中每一个关键词，利用元搜索技术 构造对互联网中的搜索引擎的搜索请求，抽取设定数量的上述搜索引擎返回的搜索结果， 提取出返回结果中包括的URL。</p>
    <p>[0080]	通过网站主题识别方法获取上述URL中包括的新闻视频网站的URL，计算该新闻视频网站的URL的数量占上述返回结果中包括的URL的总数量的比例，如果该比例小于预 先设定的主题相关度阈值，则认为该关键词与新闻视频网站的主题无关，将该关键词从上 述本体知识中剔除掉；否则，认为该关键词与新闻视频网站的主题相关。继续对该关键词进 行新链接产生力相关的评价。</p>
    <p>[0081]	在新闻视频网站数据库中查找上述识别出的所有的新闻视频网站的URL，根据查 找结果计算出不包括在新闻视频网站数据库中的新闻视频网站的URL的数量占上述新闻 视频网站的URL的总数量之间的比例，如果该比例小于预先设定的新链接产生能力阈值， 则认为该关键词不具有新链接产生能力，将该关键词从上述本体知识中剔除掉；否则，认为 该关键词具有主题相关性和新链接产生能力。</p>
    <p>[0082]	所述的新闻视频网站搜索模块11具体可以包括：</p>
    <p>[0083]	搜索模块111，用于针对所述本体知识中的每一个关键词，利用元搜索技术构造对 互联网中的搜索引擎的搜索请求，抽取设定数量的所述搜索引擎返回的搜索结果，提取出 返回结果中包括的统一资源定位符URL ；</p>
    <p>[0084]	识别模块112，用于通过网站主题识别方法识别出所述搜索模块提取出的URL中 包括的新闻视频网站的URL，将识别出的新闻视频网站存储在预先建立的新闻视频网站数 据库。</p>
    <p>[0085]	所述的新闻视频网站评价模块12具体可以包括：</p>
    <p>[0086]	统计模块121，用于从种子网站里获得一定数量的当天的新闻视频，根据所述当天 的新闻视频对新闻视频数据库执行模糊查询，统计新闻视频数据库中的每个新闻视频网站 中包含的和所述当天的新闻视频相似的新闻视频数量，将该新闻视频数量作为新闻视频网 站的及时性的评价结果存入新闻视频网站数据库中；</p>
    <p>[0087]	设定模块122，用于根据所述包含的和所述当天的新闻视频相似的新闻视频数量 设定每个新闻视频网站的抓起时间间隔，新闻视频数量多的新闻视频网站对应的抓起时间 间隔短。</p>
    <p>[0088]	所述的新闻视频获取模块13具体可以包括：</p>
    <p>[0089]	抓起模块131，用于当新闻视频网站数据库中的新闻视频网站距上次抓起结束时 的时间已经超过所述新闻视频网站的抓起时间间隔后，通过设定的搜索方法对所述新闻视 频网站中的内容进行抓起；</p>
    <p>[0090]	识别模块132，用于对从所述新闻视频网站中抓起到的每个网页利用播放页识别 技术判断其是否为视频播放页，对于判断出的视频播放页除去其包含的噪声信息后，将余 下的信息作为新闻视频；</p>
    <p>[0091]	检测和增强模块133，用于对所述新闻视频利用基于内容的重复检测技术进行重 复检测，利用基于视频压缩域的反向迭代投影法增强重复检测通过的新闻视频的质量，然 后，将所述新闻视频和对应的描述信息存入新闻视频数据库中。</p>
    <p>[0092]	所述的新闻视频网站评价模块12还可以包括：</p>
    <p>[0093]	新颖性评价模块123，用于利用基于内容的重复检测技术对从每个新闻视频网站 中新获取的新闻视频进行聚类，从每个聚类中选择一定数量的发现时间比较早的新闻视频 予以保留。然后，统计出保留下来的每个新闻视频网站中的所有新闻视频的总点击次数，进 而计算出平均每个新闻视频的点击次数。[0094]	根据所述包含的和所述当天的新闻视频相似的新闻视频数量设定每个新闻视频 网站的抓起时间间隔，新闻视频数量多的新闻视频网站对应的抓起时间间隔短。</p>
    <p>[0095]	按上述平均每个新闻视频的点击次数对各个新闻视频网站进行新颖性评价，将各 个新闻视频网站的新颖性评价结果存入新闻网站数据库中，作为各个新闻视频网站的新颖 性的度量依据。</p>
    <p>[0096]	原创性评价模块124，用于利用基于内容的重复检测技术对从每个新闻视频网站 中新获取的新闻视频进行聚类，从每个聚类中选择一定数量的发现时间比较早的新闻视频 予以保留，其余的新闻视频作为重复的新闻视频。统计出每个新闻视频网站包含的总视频 数量和重复视频数量，进而计算出每个新闻视频网站的重复视频比例。</p>
    <p>[0097]	按上述每个新闻视频网站的重复视频比例对各个新闻视频网站进行原创性评价， 将各个新闻视频网站的原创性评价结果存入新闻网站数据库中，作为各个新闻视频网站的 原创性的度量依据。</p>
    <p>[0098]	本领域普通技术人员可以理解实现上述实施例方法中的全部或部分流程，是可 以通过计算机程序来指令相关的硬件来完成，所述的程序可存储于一计算机可读取存储 介质中，该程序在执行时，可包括如上述各方法的实施例的流程。其中，所述的存储介质 可为磁碟、光盘、只读存储记忆体（Read-Only Memory, ROM)或随机存储记忆体（Random AccessMemory, RAM)等。</p>
    <p>[0099]	综上所述，本发明实施例有效地解决了互联网新闻视频自动、准确、及时的搜索与 集成的问题，可以快速、准确地识别出新闻视频网站，可以自动、及时地发现和集成新闻视频。</p>
    <p>[0100]	本发明实施例提出一种面向电视新闻门户的互联网新闻视频搜索与集成的系统 和方法，可以为面向电视新闻门户的视频点播系统提供丰富的和高质量的互联网新闻视频 资源，可以为电视新闻门户提供必须的新闻视频素材及描述信息。</p>
    <p>[0101]	以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此， 任何熟悉本技术领域的技术人员在本发明揭露的技术范围内，可轻易想到的变化或替换， 都应涵盖在本发明的保护范围之内。因此，本发明的保护范围应该以权利要求的保护范围 为准。</p>
    <p>12</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101065749A?cl=zh">CN101065749A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年11月25日</td><td class="patent-data-table-td patent-date-value">2007年10月31日</td><td class="patent-data-table-td ">琳达&#183;劳逊</td><td class="patent-data-table-td ">资源管理系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101599089A?cl=zh">CN101599089A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年7月17日</td><td class="patent-data-table-td patent-date-value">2009年12月9日</td><td class="patent-data-table-td ">中国科学技术大学</td><td class="patent-data-table-td ">视频服务网站内容更新信息的自动搜索与抽取系统及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《Signal Processing,ICSP 2008》 20081208 Ming Zhu,etc Effective Video Content Abstraction by Similar Shots Clustering 第1445-1448页 1-10 , 2</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《计算机仿真》 20080831 朱明等 基于多超级节点的PMDN资源搜索策略 第131-135页 1-10 第25卷, 第8期 2</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102117267A?cl=zh">CN102117267A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年2月25日</td><td class="patent-data-table-td patent-date-value">2011年7月6日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">一种信息显示方法、装置及电子设备</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=60iNBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年1月12日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年3月9日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年5月23日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">COR</td><td class="patent-data-table-td ">Bibliographic change or correction in the description</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECT: ADDRESS; FROM: 230026 HEFEI, ANHUI PROVINCE TO: 230001 HEFEI, ANHUI PROVINCE</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ANHUI GUANGXING COMMUNICATION TECHNOLOGY CO., LTD.</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20130821</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: UNIVERSITY OF SCIENCE AND TECHNOLOGY OF CHINA</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/3889d9683dcbeaca96c6/CN101944111A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E6%96%B0%E9%97%BB%E8%A7%86%E9%A2%91%E7%9A%84%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE.pdf?id=60iNBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2ertUzbSRJ6x9RNr5OZc21NRNrAA"},"sample_url":"https://www.google.com/patents/reader?id=60iNBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>