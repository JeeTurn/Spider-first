<!DOCTYPE html><html><head><title>专利 CN102645968A - 一种通讯终端及人机交互的方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种通讯终端及人机交互的方法"><meta name="DC.contributor" content="罗义军" scheme="inventor"><meta name="DC.contributor" content="中兴通讯股份有限公司" scheme="assignee"><meta name="DC.date" content="2011-2-17" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供了一种通讯终端及人机交互的方法，所述方法包括下述步骤：通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；对输入的面部信息进行身份的判别；若判别通过，通讯终端解锁进入应用。本发明通过在通讯终端被唤醒后，对摄像头输入的用户面部信息进行身份判别，若判别通过，则通讯终端解锁进入应用，实现了通讯终端和用户之间的人机交互及情感交流，提升了用户的使用体验。"><meta name="DC.date" content="2012-8-22"><meta name="DC.relation" content="CN:101494690:A" scheme="references"><meta name="DC.relation" content="CN:101674363:A" scheme="references"><meta name="DC.relation" content="CN:201639634" scheme="references"><meta name="DC.relation" content="CN:201742464" scheme="references"><meta name="DC.relation" content="US:5668573" scheme="references"><meta name="citation_patent_publication_number" content="CN:102645968:A"><meta name="citation_patent_application_number" content="CN:201110039946"><link rel="canonical" href="https://www.google.com/patents/CN102645968A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102645968A?cl=zh"/><meta name="title" content="专利 CN102645968A - 一种通讯终端及人机交互的方法"/><meta name="description" content="本发明提供了一种通讯终端及人机交互的方法，所述方法包括下述步骤：通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；对输入的面部信息进行身份的判别；若判别通过，通讯终端解锁进入应用。本发明通过在通讯终端被唤醒后，对摄像头输入的用户面部信息进行身份判别，若判别通过，则通讯终端解锁进入应用，实现了通讯终端和用户之间的人机交互及情感交流，提升了用户的使用体验。"/><meta property="og:title" content="专利 CN102645968A - 一种通讯终端及人机交互的方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102645968A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102645968A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102645968A&amp;usg=AFQjCNEa8tS3MVdteHpFVOBlh7svcEDk7Q" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/096660dd87aa2012366e/CN102645968A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/096660dd87aa2012366e/CN102645968A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102645968A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102645968A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102645968A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102645968B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102645968A?cl=zh" style="display:none"><span itemprop="description">本发明提供了一种通讯终端及人机交互的方法，所述方法包括下述步骤：通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；对输入的面部信息进行身份的判别；若判别通过，通讯终端解锁进入应用。本发明通过在通讯...</span><span itemprop="url">https://www.google.com/patents/CN102645968A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102645968A - 一种通讯终端及人机交互的方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102645968A - 一种通讯终端及人机交互的方法" title="专利 CN102645968A - 一种通讯终端及人机交互的方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102645968 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110039946</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年8月22日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年2月17日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年2月17日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102645968B?hl=zh-CN&amp;cl=zh">CN102645968B</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2012109815A1?hl=zh-CN&amp;cl=zh">WO2012109815A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110039946.5, </span><span class="patent-bibdata-value">CN 102645968 A, </span><span class="patent-bibdata-value">CN 102645968A, </span><span class="patent-bibdata-value">CN 201110039946, </span><span class="patent-bibdata-value">CN-A-102645968, </span><span class="patent-bibdata-value">CN102645968 A, </span><span class="patent-bibdata-value">CN102645968A, </span><span class="patent-bibdata-value">CN201110039946, </span><span class="patent-bibdata-value">CN201110039946.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%BD%97%E4%B9%89%E5%86%9B%22">罗义军</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%85%B4%E9%80%9A%E8%AE%AF%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">中兴通讯股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102645968A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102645968A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102645968A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110039946&amp;usg=AFQjCNH-TSFHUpJ0vA4YZWWrWUT8HhbNcA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102645968A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFvhw0klI6DHStpiq6o1wXPAOfHJw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114730624" lang="ZH" load-source="patent-office">一种通讯终端及人机交互的方法</invention-title>
      </span><br><span class="patent-number">CN 102645968 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA99548188" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供了一种通讯终端及人机交互的方法，所述方法包括下述步骤：通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；对输入的面部信息进行身份的判别；若判别通过，通讯终端解锁进入应用。本发明通过在通讯终端被唤醒后，对摄像头输入的用户面部信息进行身份判别，若判别通过，则通讯终端解锁进入应用，实现了通讯终端和用户之间的人机交互及情感交流，提升了用户的使用体验。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(15)</span></span></div><div class="patent-text"><div mxw-id="PCLM44886828" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种人机交互的方法，其特征在于，所述方法包括：  通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；  对输入的面部信息进行身份的判别；  若判别通过，通讯终端解锁进入应用。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的方法，其特征在于，所述对输入的面部信息进行身份的识别为：  通讯终端将输入的面部信息与预先存储的用户特征数据进行比对，当比对通过时，则判别通过；否则为判别未通过。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求I所述的方法，其特征在于，在对用户的身份进行判别之后，所述方法还包括：  若判别未通过，提示用户进行密码的输入，当密码输入错误时，通讯终端做出告警提示。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求I所述的方法，其特征在于，所述通讯终端解锁进入应用之后，所述方法还包括：  所述摄像头输入用户的面部信息；  对输入的面部信息进行表情的判别；  若判别成功，则确认用户的心情，并按照用户的心情进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的方法，其特征在于，所述对输入的面部信息进行表情的判别为：  通讯终端识别的对象锁定为用户，将输入的面部信息与预先存储的表情特征数据进行比对，当比对通过时，则判别成功；否则为判别未成功。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求4所述的方法，其特征在于，在对输入的面部信息进行表情的判别之后，所述方法还包括：  若判别未成功，通讯终端提示用户进行心情选择，并根据用户输入的选择信息，确认用户的心情，按照用户的心情进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求4或6所述的方法，其特征在于，所述按照用户的心情进行交互为：  按照用户的心情，更换用户界面UI颜色主体、改变通讯终端的灯光颜色、显示预先设置的语言和/或图标、演示预设的声音的一种或几种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求4所述的方法，其特征在于，所述对输入的面部信息进行表情的判别的时间间隔为大于I个小时。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9.	一种通讯终端，包括摄像头，其特征在于，所述通讯终端还包括：判别单元、解锁单元；其中，  摄像头，用于在通讯终端被唤醒后，输入用户的面部信息；  判别单元，用于对所述摄像头输入的面部信息进行身份的判别；  解锁单元，用于当所述判别单元进行的身份的判别通过时，解锁通讯终端进入应用。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的通讯终端，其特征在于，所述判别单元具体用于对所述摄像头输入的面部信息与预先存储的用户特征数据进行比对，当比对通过时，则判别通过；否则为判别未通过。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求9所述的通讯终端，其特征在于，所述通讯终端还包括：提示单元，用于当所述判别单元进行的身份的判别未通过时，提示用户进行密码的输入，当密码输入错误时，做出告警提示。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求9至11任一所述的通讯终端，其特征在于，所述通讯终端还包括交互单元；其中，  所述摄像头，还用于在通讯终端解锁进入应用后，再次输入用户的面部信息；  所述判别单元，还用于对所述摄像头输入的面部信息进行表情的判别；  所述交互单元，用于当所述判别单元进行的表情的判别成功时，确认用户的心情，并按照用户的心情进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的通讯终端，其特征在于，所述判别单元具体用于锁定识别的对象为用户，将所述摄像头输入的面部信息与预先存储的表情特征数据进行比对，当比对通过时，则判别成功；否则为判别未成功。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求12所述的通讯终端，其特征在于，所述提示单元还用于当所述判别单元进行的表情的判别未成功时，提示用户进行心情的选择；  相应地，所述交互单元根据提示单元接收到的用户输入的选择信息，确认用户的心情，按照用户的心情进行交互。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求9所述的通讯终端，其特征在于，所述通讯终端的前壳采用透光材料注塑，并喷有半透明油漆、或者采用透光真空镀；  所述通讯终端的触摸板丝印半透明油漆、或者采用透光真空镀。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES51267644" lang="ZH" load-source="patent-office" class="description">
    <p>一种通讯终端及人机交互的方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及通讯技术领域，尤其涉及一种通讯终端及人机交互的方法。</p>
    <p>背景技术</p>
    <p>[0002]	计算机人脸表情识别技术是近几十年才逐渐发展起来的，现在逐渐成为科研的热点。最早的人脸表情研究是Suwa和Sugie等人于1978年对表情识别所做的一个最初的尝试，他跟踪一段脸部视频动画，得到每帧图片上20个关键的运动规律，将此运动规律与预先建立的不同表情的关键点运动模型相比较，这是一种初步尝试。到1981年有人用仿生学方法从肌肉角度的观点为面部表情建立模型。</p>
    <p>[0003]	起初Ekman和Frieman系统建立了一个由上千幅不同人脸表情的图像库。近来美国CMU机器人研究所和心理学系共同建立了 Cohn-Kanade、AU-Coded人脸表情库。现有210 个18岁到50岁成年人的脸部表情图像序列。CMU还建立有PIE表情库，包括68人的41368幅图像。加州大学圣克鲁兹分校知觉实验室的人脸运动表情图像是基于FACE的主要用于神经网络方法分类面部行为的训练图像。然而目前越来越普及使用的通讯终端还不能够很好地实现人机交互，尤其是一种情感上的交互，以满足用户更好地使用体验。</p>
    <p>发明内容</p>
    <p>[0004]	有鉴于此，本发明的主要目的在于提供一种通讯终端及人机交互的方法，实现了通讯终端和用户之间的人机交互及情感交流。</p>
    <p>[0005]	为达到上述目的，本发明的技术方案是这样实现的：</p>
    <p>[0006]	一种人机交互的方法，所述方法包括：</p>
    <p>[0007]	通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；</p>
    <p>[0008]	对输入的面部信息进行身份的判别；</p>
    <p>[0009]	若判别通过，通讯终端解锁进入应用。</p>
    <p>[0010]	进一步地，所述对输入的面部信息进行身份的识别为：</p>
    <p>[0011]	通讯终端将输入的面部信息与预先存储的用户特征数据进行比对，当比对通过时，则判别通过；否则为判别未通过。</p>
    <p>[0012]	进一步地，在对用户的身份进行判别之后，所述方法还包括：</p>
    <p>[0013]	若判别未通过，提示用户进行密码的输入，当密码输入错误时，通讯终端做出告警提示。</p>
    <p>[0014]	进一步地，所述通讯终端解锁进入应用之后，所述方法还包括：</p>
    <p>[0015]	所述摄像头输入用户的面部信息；</p>
    <p>[0016]	对输入的面部信息进行表情的判别；</p>
    <p>[0017]	若判别成功，则确认用户的心情，并按照用户的心情进行交互。</p>
    <p>[0018]	其中，所述对输入的面部信息进行表情的判别为：</p>
    <p>[0019]	通讯终端识别的对象锁定为用户，将输入的面部信息与预先存储的表情特征数据进行比对，当比对通过时，则判别成功；否则为判别未成功。</p>
    <p>[0020]	进一步地，在对输入的面部信息进行表情的判别之后，所述方法还包括：</p>
    <p>[0021]	若判别未成功，通讯终端提示用户进行心情选择，并根据用户输入的选择信息，确认用户的心情，按照用户的心情进行交互。</p>
    <p>[0022]	其中，所述按照用户的心情进行交互为：</p>
    <p>[0023]	按照用户的心情，更换用户界面Π颜色主体、改变通讯终端的灯光颜色、显示预先设置的语言和/或图标、演示预设的声音的一种或几种。</p>
    <p>[0024]	其中，所述对输入的面部信息进行表情的判别的时间间隔为大于I个小时。 </p>
    <p>[0025]	一种通讯终端,包括摄像头,所述通讯终端还包括：判别单元、解锁单元；其中，</p>
    <p>[0026]	摄像头，用于在通讯终端被唤醒后，输入用户的面部信息；</p>
    <p>[0027]	判别单元，用于对所述摄像头输入的面部信息进行身份的判别；</p>
    <p>[0028]	解锁单元，用于当所述判别单元进行的身份的判别通过时，解锁通讯终端进入应用。</p>
    <p>[0029]	其中，所述判别单元具体用于对所述摄像头输入的面部信息与预先存储的用户特征数据进行比对，当比对通过时，则判别通过；否则为判别未通过。</p>
    <p>[0030]	进一步地，所述通讯终端还包括：提示单元，用于当所述判别单元进行的身份的判别未通过时，提示用户进行密码的输入，当密码输入错误时，做出告警提示。</p>
    <p>[0031]	进一步地,所述通讯终端还包括交互单元；其中，</p>
    <p>[0032]	所述摄像头，还用于在通讯终端解锁进入应用后，再次输入用户的面部信息；</p>
    <p>[0033]	所述判别单元，还用于对所述摄像头输入的面部信息进行表情的判别；</p>
    <p>[0034]	所述交互单元，用于当所述判别单元进行的表情的判别成功时，确认用户的心情，并按照用户的心情进行交互。</p>
    <p>[0035]	其中，所述判别单元具体用于锁定识别的对象为用户，将所述摄像头输入的面部信息与预先存储的表情特征数据进行比对，当比对通过时，则判别成功；否则为判别未成功。</p>
    <p>[0036]	其中，所述提示单元还用于当所述判别单元进行的表情的判别未成功时，提示用户进行心情的选择；</p>
    <p>[0037]	相应地，所述交互单元根据提示单元接收到的用户输入的选择信息，确认用户的心情，按照用户的心情进行交互。</p>
    <p>[0038]	其中，所述通讯终端的前壳采用透光材料注塑，并喷有半透明油漆、或者采用透光</p>
    <p>真空镀；</p>
    <p>[0039]	所述通讯终端的触摸板丝印半透明油漆、或者采用透光真空镀。</p>
    <p>[0040]	本发明通过在通讯终端被唤醒后，对摄像头输入的用户面部信息进行身份判别，若判别通过，则通讯终端解锁进入应用，实现了通讯终端和用户之间的人机交互及情感交流，提升了用户的使用体验。</p>
    <p>附图说明</p>
    <p>[0041]	图I为本发明提供的人机交互的方法的实现流程图；</p>
    <p>[0042]	图2为本发明提供的通讯终端的结构示意图。具体实施方式</p>
    <p>[0043]	本发明的基本思想为：通讯终端被唤醒后，通讯终端的摄像头输入用户的面部信息；对输入的面部信息进行身份的判别；若判别通过，通讯终端解锁进入应用。</p>
    <p>[0044]	为使本发明的目的、技术方案和优点更加清楚明白，以下举实施例并参照附图，对本发明进一步详细说明。</p>
    <p>[0045]	图I示出了本发明人机交互的方法的实现流程，如图I所示，所述方法包括下述步骤：</p>
    <p>[0046]	步骤101，当通讯终端检测到按键的按压信息时，通讯终端被唤醒；</p>
    <p>[0047]	具体地，当用户需要使用通讯终端时，通过按压任意键进行通讯终端的唤醒操作。</p>
    <p>[0048]	步骤102，通讯终端的摄像头对用户进行拍照，输入用户的面部信息； </p>
    <p>[0049]	本步骤中，具体可以通过通讯终端的前置摄像头对用户拍照，进行面部信息的输入，同时，一般可以将摄像头对用户进行拍照的像素设置为300X400像素的格式，以减小通讯终端CPU的负担。</p>
    <p>[0050]	步骤103，通讯终端对输入的面部信息进行身份的判别，若判别未通过，执行步骤104 ;若判别通过，执行步骤106 ；</p>
    <p>[0051]	本步骤中，通讯终端将输入的面部信息与预先存储的用户特征数据进行比对，若存在多于预设个数的特征数据吻合，则比对通过，认为该用户的身份判别通过；否则为判别未通过；其中，预先存储的用户的特征数据可以通过运用摄像头输入用户不同角度的面部信息，其中不同角度包括正视、侧视、俯视、仰视等，将所述摄像头输入的一组面部信息保存为用户的特征数据。</p>
    <p>[0052]	步骤104，提示用户进行密码的输入；</p>
    <p>[0053]	通讯终端进入密码输入页面，提示用户进行密码的输入，当密码输入正确，则通讯终端解锁进入应用，否则，执行步骤105。</p>
    <p>[0054]	步骤105，当密码输入错误时，通讯终端做出告警提示；</p>
    <p>[0055]	具体地，一般可以设置当密码输入3次连续失败时，通讯终端可以通过提示音乐或警报进行告警，以起到保护隐私以及防盗的目的。</p>
    <p>[0056]	步骤106，通讯终端解锁，进入应用；</p>
    <p>[0057]	步骤107，通讯终端的摄像头对用户进行拍照，输入用户的面部信息；</p>
    <p>[0058]	本步骤中，具体可以通过通讯终端的前置摄像头在用户的使用过程中对用户拍照，进行面部信息的输入，同时，一般可以将摄像头对用户进行拍照的像素设置为300X400像素的格式，以减小通讯终端CPU的负担。</p>
    <p>[0059]	步骤108，通讯终端对输入的面部信息进行表情的判别，若判别未成功，则执行步骤109 ;若判别成功，则执行步骤110 ；</p>
    <p>[0060]	本步骤中，为了提高脸部表情识别的效率和准确性，可以将通讯终端进行识别的对象锁定为用户，并且在识别的过程中可以不需要考虑不同长相、不同肤色的影响，来减小表情识别难度；也可以设置为只进行快乐、常态、失意三种简单表情的识别；具体为，通讯终端将所述面部信息与预设的简单表情的特征数据进行比对，若存在多于预设个数的特征数据吻合，则比对通过时，此时为判别成功，否则为判别未成功。[0061]	若输入的面部信息为无效信息，可以触发摄像头间隔5分钟或10分钟等时长后，再次对用户进行拍照，进行用户面部信息的输入；</p>
    <p>[0062]	当输入的面部信息多次为无效信息或面部信息有效但多次不能确认判别成功时，则执行步骤109。</p>
    <p>[0063]	步骤109，通讯终端提示用户进行心情选择；</p>
    <p>[0064]	本步骤中，通讯终端可以通过弹出对话框来供用户进行心情的选择，接收到用户输入的选择信息后，执行步骤110。</p>
    <p>[0065]	步骤110，确认用户的心情，并按照用户的心情进行交互；</p>
    <p>[0066]	本步骤中，可以根据确认得到的心情的不同，更换适当的用户界面（UserInterface, UI)颜色主体，通过灯光控制改变通讯终端局部（如上壳、触摸板等）的颜色，并进行相关智能动作的交互；</p>
    <p>[0067]	具体地，UI颜色主体的内容包括：除应用程序图标外的所有界面，如背景、系统图标、工具条等等。UI交互可以选用主色调为黑白的普通色调的UI方案，同时可以增加多个颜色主体的Π，如增加红色主体和蓝色主体的Π，使得UI可在黑白主体、红色主体、蓝色主体之间根据确认的用户的心情进行切换；如当确认得到的用户心情为常态时，则Π为黑白主体的界面；当确认得到的用户心情为快乐、开心或兴奋等状态时，UI为红色主体的界面；当确认得到的用户心情为失意、伤心等状态时，UI为蓝色主体的界面。</p>
    <p>[0068]	其中，通过灯光控制改变通讯终端局部（如上壳、触摸板等）的颜色的实现可以通过对通讯终端的硬件进行设计实现，本发明实施例中以直板触摸屏通讯终端进行具体说明：通讯终端的前壳可以采用透光材料注塑，并喷涂半透明油漆，或者采用透光真空镀；触摸板（TP)丝印半透明油漆，或者采用透光真空镀；在通讯终端的主板上布置有三色灯或多色灯，运用灯光来改变前壳和TP的颜色；为了使灯光均匀，可以选用呼吸灯，即在通讯终端主板上均匀布置多个呼吸灯，同时在布置的同时需要将灯的遮光板因素考虑在内，以避免灯光直接从前壳、TP透出，造成前壳、TP的透光效果不均匀。</p>
    <p>[0069]	另外，本步骤中还可以包括在Π适当区域内增加文档显示功能，用以与用户进行情感交流，如根据确认得到的用户心情，自动显示预先设置的语言和/或图标等与用户进行互动；应当理解，若通讯终端所进行的表情的判别设置为只进行快乐、常态、示意三种简单表情的识别时，则此处可以适应地设置相对于上述三种简单表情的语言和/或图标；</p>
    <p>[0070]	同理，也可以演示预设的用于情感表达的声音与上述文档显示配合，增强用户的使用体验。</p>
    <p>[0071]	应当理解，本发明实施例中，为了减少摄像头拍照时的耗电量，可以设置通讯终端进行表情判别的时间间隔为大于I小时，这样，例如当用户在使用通讯终端的过程中，在九点整的时刻点，通讯终端进行了表情判别，则在前述设置的时间间隔为大于I个小时的情况下，只有用户在十点之后的时刻，再进行通讯终端的使用时，该通讯终端才会再次进行用户的表情判别。</p>
    <p>[0072]	图2示出了本发明提供的通讯终端的结构示意，如图2所示，所述通讯终端包括摄像头21、判别单元22、及解锁单元23 ;其中，</p>
    <p>[0073]	摄像头21，用于在通讯终端被唤醒后，输入用户的面部信息；具体地，当通讯终端 的CPU检测到通讯终端的按键被按压时，则通讯终端被唤醒，并且，在本发明实施例中，摄像头21对用户进行拍照的像素设置为300X400像素的格式，以减小通讯终端CPU的负担；</p>
    <p>[0074]	判别单元22，用于对所述摄像头21输入的面部信息进行身份的判别；</p>
    <p>[0075]	解锁单元23，用于当所述判别单元22进行的身份的判别通过时，解锁通讯终端进入应用。</p>
    <p>[0076]	进 一步地，所述判别单元22具体用于对所述摄像头21输入的面部信息与预先存储的用户特征数据进行比对，当比对通过时，则判别通过；否则为判别未通过；具体地，判别单元22将输入的面部信息与预先存储的用户特征数据进行比对，若存在多余预设个数的特征数据相吻合，则比对通过，认为该用户的身份判别通过；否则为判别未通过；其中，预先存储的用户的特征数据可以通过运用摄像头21输入用户不同角度的面部信息，其中不同角度包括正视、俯视、仰视等，将所述摄像头21输入的一组面部信息保存为用户的特征数据。</p>
    <p>[0077]	进一步地，所述通讯终端还包括：提示单元24，用于当所述判别单元22进行的身份的判别未通过时，提示用户进行密码的输入，当密码输入错误时，做出告警提示，具体可以通过音乐或警报做出告警提示；当密码输入正确，则解锁单元23解锁通讯终端进入应用。</p>
    <p>[0078]	进一步地,所述通讯终端还包括交互单元25 ;其中，</p>
    <p>[0079]	所述摄像头21，还用于在解锁单元23对通讯终端解锁进入应用后，再次输入用户的面部信息，在本发明实施例中，摄像头21对用户进行拍照的像素设置为300X400像素的格式，以减小通讯终端CPU的负担；</p>
    <p>[0080]	所述判别单元22，还用于对所述摄像头21输入的面部信息进行表情的判别；</p>
    <p>[0081]	所述交互单元25，用于当所述判别单元22进行的表情的判别成功时，确认用户的心情，并按照用户的心情进行交互。</p>
    <p>[0082]	其中，所述判别单元22具体用于锁定识别的对象为用户，将所述摄像头21输入的面部信息与预先存储的表情特征数据进行比对，当比对通过时，则判别成功；否则为判别未成功；具体地，在判别单元进行识别的过程中可以不需要考虑不同长相、不同肤色的影响，来减小表情识别难度；也可以设置为只进行快乐、常态、失意三种简单表情的识别；本发明实施例中，判别单元22将所述面部信息与预设的简单表情的特征数据进行比对，若存在多于预设个数的特征数据吻合，则比对通过时，此时为判别成功，否则为判别未成功。</p>
    <p>[0083]	若摄像头21输入的面部信息为无效信息，判别单元22还可以触发摄像头间隔5分钟或10分钟等时长后，再次对用户进行拍照，进行用户面部信息的输入。</p>
    <p>[0084]	其中，所述提示单元24还用于当所述判别单元22进行的表情的判别未成功时，提示用户进行心情的选择；其中，判别单元22进行的表情的判别未成功的情形包括摄像头21输入的面部信息多次为无效信息、或面部信息有效但多次不能判别成功等情形。</p>
    <p>[0085]	相应地，所述交互单元25根据提示单元24接收到的用户输入的选择信息，确认用户的心情，按照用户的心情进行交互；具体地，本发明实施例中，交互单元25可以根据确认得到的心情的不同，更换适当的Π颜色主体，通过灯光控制改变通讯终端局部（如上壳、触摸板等）的颜色，并进行相关智能动作的交互；</p>
    <p>[0086]	具体地，UI颜色主体的内容包括：除应用程序图标外的所有界面,如背景、系统图标、工具条等等。UI交互可以选用主色调为黑白的普通色调的UI方案，同时可以增加多个颜色主体的Π，如增加红色主体和蓝色主体的Π，使得Π可在黑白主体、红色主体、蓝色主体之间根据确认的用户的心情进行切换；如当确认得到的用户心情为常态时，则Π为黑白主体的界面；当确认得到的用户心情为快乐、开心或兴奋等状态时，UI为红色主体的界面；当确认得到的用户心情为失意、伤心等状态时，UI为蓝色主体的界面。</p>
    <p>[0087]	交互单元25还可以控制灯光颜色的变换来改变通讯终端局部（如上壳、触摸板等）的颜色，如当确认的用户的心情为开心时，交互单元25将灯光颜色变换为红色，其中，可以通过对通讯终端的硬件进行设计实现，本发明实施例中以直板触摸屏通讯终端进行具体说明：通讯终端的前壳可以采用透光材料注塑，并喷涂半透明油漆，或者采用透光真空镀；触摸板（TP)丝印半透明油漆，或者采用透光真空镀；在通讯终端的主板上布置有三色灯或多色灯，运用灯光来改变前壳和TP的颜色；为了使灯光均匀，可以选用呼吸灯，即在通讯终端主板上均匀布置多个呼吸灯，同时在布置的同时需要将灯的遮光板因素考虑在内，以避免灯光直接从前壳、TP透出，造成前壳、TP的透光效果不均匀。</p>
    <p>[0088]	另外，交互单元25还可以在UI适当区域内增加文档显示功能，用以与用户进行情感交流，如根据确认得到的用户心情，自动显示预先设置的语言和/或图标等与用户进行 互动；应当理解，若判别单元22所进行的表情的判别设置为只进行快乐、常态、示意三种简单表情的识别时，则此处可以适应地设置相对于上述三种简单表情的语言和/或图标；</p>
    <p>[0089]	同理，交互单元25也可以演示预设的用于情感表达的声音与上述文档显示配合，增强用户的使用体验。</p>
    <p>[0090]	应当理解，本发明实施例中，为了减少摄像头21拍照时的耗电量，可以设置通讯终端进行表情判别的时间间隔为大于I小时，这样，例如当用户在使用通讯终端的过程中，在九点整的时刻点，通讯终端进行了表情判别，则在前述设置的时间间隔为大于I个小时的情况下，只有用户在十点之后的时刻，再进行通讯终端的使用时，该通讯终端才会再次进行用户的表情判别。</p>
    <p>[0091]	以上所述，仅为本发明的较佳实施例而已，并非用于限定本发明的保护范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101494690A?cl=zh">CN101494690A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年2月24日</td><td class="patent-data-table-td patent-date-value">2009年7月29日</td><td class="patent-data-table-td ">青岛海信移动通信技术股份有限公司</td><td class="patent-data-table-td ">一种移动终端及其解锁方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101674363A?cl=zh">CN101674363A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年9月23日</td><td class="patent-data-table-td patent-date-value">2010年3月17日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">移动设备及通话方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201639634U?cl=zh">CN201639634U</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月9日</td><td class="patent-data-table-td patent-date-value">2010年11月17日</td><td class="patent-data-table-td ">杨巨成;解山娟;方志军;杨勇</td><td class="patent-data-table-td ">具有多种生物识别功能的手机</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN201742464U?cl=zh">CN201742464U</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年8月6日</td><td class="patent-data-table-td patent-date-value">2011年2月9日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">具有看护婴儿功能的移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5668573">US5668573</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">1995年6月6日</td><td class="patent-data-table-td patent-date-value">1997年9月16日</td><td class="patent-data-table-td ">Sextant Avionique</td><td class="patent-data-table-td ">Management method for a man-machine interaction system</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103440446A?cl=zh">CN103440446A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年8月23日</td><td class="patent-data-table-td patent-date-value">2013年12月11日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">智能终端私密内容保护解锁操作方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104023125A?cl=zh">CN104023125A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年5月14日</td><td class="patent-data-table-td patent-date-value">2014年9月3日</td><td class="patent-data-table-td ">上海卓悠网络科技有限公司</td><td class="patent-data-table-td ">根据用户情绪自动切换系统场景的方法及终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003010000">G06F3/01</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=mXGaBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M1/67">H04M1/67</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年8月22日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年10月3日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年1月13日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/096660dd87aa2012366e/CN102645968A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E9%80%9A%E8%AE%AF%E7%BB%88%E7%AB%AF%E5%8F%8A%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E7%9A%84%E6%96%B9.pdf?id=mXGaBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2mRdBP_xjO5NEaTHtlam3KahgDtA"},"sample_url":"https://www.google.com/patents/reader?id=mXGaBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>