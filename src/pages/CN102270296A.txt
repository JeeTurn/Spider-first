<!DOCTYPE html><html><head><title>专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="结合文字识别和图像匹配交换名片信息的方法"><meta name="DC.contributor" content="罗希平" scheme="inventor"><meta name="DC.contributor" content="上海合合信息科技发展有限公司" scheme="assignee"><meta name="DC.date" content="2011-7-5" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用在由网站服务器、第一、第二客户端构建的网络系统中，该方法至少包括：第一客户端将获取的第二客户端用户的名片图像上的文字信息和图像特征后上传至网站服务器，网站服务器从名片资料库中检索出与该文字信息相匹配的所有预存名片，并进行图像特征匹配，然后根据图像特征的相似度选取出候选名片，并判断该候选名片是否属于该第二客户端用户，若是，则在第二客户端应允后，网站服务器将第二客户端用户的名片信息发送给第一客户端，同时也将第一客户端的名片信息发送至第二客户端；若否，则结束步骤，以此来确保名片信息交换的准确率和识别速度，并进一步保护名片主人的隐私。"><meta name="DC.date" content="2011-12-7"><meta name="DC.relation" content="CN:101882227:A" scheme="references"><meta name="DC.relation" content="CN:1413861:A" scheme="references"><meta name="DC.relation" content="EP:1796019:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102270296:A"><meta name="citation_patent_application_number" content="CN:201110186950"><link rel="canonical" href="https://www.google.com/patents/CN102270296A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102270296A?cl=zh"/><meta name="title" content="专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法"/><meta name="description" content="本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用在由网站服务器、第一、第二客户端构建的网络系统中，该方法至少包括：第一客户端将获取的第二客户端用户的名片图像上的文字信息和图像特征后上传至网站服务器，网站服务器从名片资料库中检索出与该文字信息相匹配的所有预存名片，并进行图像特征匹配，然后根据图像特征的相似度选取出候选名片，并判断该候选名片是否属于该第二客户端用户，若是，则在第二客户端应允后，网站服务器将第二客户端用户的名片信息发送给第一客户端，同时也将第一客户端的名片信息发送至第二客户端；若否，则结束步骤，以此来确保名片信息交换的准确率和识别速度，并进一步保护名片主人的隐私。"/><meta property="og:title" content="专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102270296A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102270296A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102270296A&amp;usg=AFQjCNHxAcMoc9_VFNlZzONqCve8bLdyxg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/856e4ff0478e34763a15/CN102270296A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/856e4ff0478e34763a15/CN102270296A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102270296A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102270296A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102270296A?cl=zh" style="display:none"><span itemprop="description">本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用在由网站服务器、第一、第二客户端构建的网络系统中，该方法至少包括：第一客户端将获取的第二客户端用户的名片图像上的文字信息和图像特征后上传至网...</span><span itemprop="url">https://www.google.com/patents/CN102270296A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法" title="专利 CN102270296A - 结合文字识别和图像匹配交换名片信息的方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102270296 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110186950</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年12月7日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年7月5日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年7月5日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP2731048A1?hl=zh-CN&amp;cl=zh">EP2731048A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2731048A4?hl=zh-CN&amp;cl=zh">EP2731048A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US9298708?hl=zh-CN&amp;cl=zh">US9298708</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140126825?hl=zh-CN&amp;cl=zh">US20140126825</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2013004035A1?hl=zh-CN&amp;cl=zh">WO2013004035A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110186950.4, </span><span class="patent-bibdata-value">CN 102270296 A, </span><span class="patent-bibdata-value">CN 102270296A, </span><span class="patent-bibdata-value">CN 201110186950, </span><span class="patent-bibdata-value">CN-A-102270296, </span><span class="patent-bibdata-value">CN102270296 A, </span><span class="patent-bibdata-value">CN102270296A, </span><span class="patent-bibdata-value">CN201110186950, </span><span class="patent-bibdata-value">CN201110186950.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%BD%97%E5%B8%8C%E5%B9%B3%22">罗希平</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%8A%E6%B5%B7%E5%90%88%E5%90%88%E4%BF%A1%E6%81%AF%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">上海合合信息科技发展有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102270296A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102270296A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102270296A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (9),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110186950&amp;usg=AFQjCNGXdmYcyG7lT1e_yKYzbw7Un4jFgA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102270296A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGiZXgApcSgTwwmnR6q-picWMtVVQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT104786792" lang="ZH" load-source="patent-office">结合文字识别和图像匹配交换名片信息的方法</invention-title>
      </span><br><span class="patent-number">CN 102270296 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA86691371" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用在由网站服务器、第一、第二客户端构建的网络系统中，该方法至少包括：第一客户端将获取的第二客户端用户的名片图像上的文字信息和图像特征后上传至网站服务器，网站服务器从名片资料库中检索出与该文字信息相匹配的所有预存名片，并进行图像特征匹配，然后根据图像特征的相似度选取出候选名片，并判断该候选名片是否属于该第二客户端用户，若是，则在第二客户端应允后，网站服务器将第二客户端用户的名片信息发送给第一客户端，同时也将第一客户端的名片信息发送至第二客户端；若否，则结束步骤，以此来确保名片信息交换的准确率和识别速度，并进一步保护名片主人的隐私。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM37135135" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种结合文字识别和图像匹配交换名片信息的方法，应用于至少由网站服务器、第一客户端及第二客户端构建的网络系统中，所述网站服务器具有预存名片信息的名片资料库，所述第一及第二客户端具有名片图像撷取、文字信息识别及图像特征提取功能，其特征在于，所述交换名片信息的方法至少包括以下步骤：1)所述第一客户端撷取所述第二客户端用户的名片图像后，识别所述名片图像上的文字信息，并提取图像特征；2)所述第一客户端将识别的文字信息和提取的图像特征上传至所述网站服务器，并发送名片识别请求；3)所述网站服务器接受到该名片识别请求后，依据所述文字信息从所述名片资料库中检索与该文字信息相匹配的所有预存名片，并将检索出的各该预存名片的名片图像分别与所述第二客户端用户的名片图像进行图像特征匹配，根据图像特征的相似度，对应每一预存名片生成一个相似程度的度量值；4)所述网站服务器将所有预存名片中度量值最大的一张名片作为候选名片；5)判断所述候选名片是否属于所述第二客户端用户，若是，则所述网站服务器向所述第二客户端发出交换请求，在所述第二客户端应允后，所述网站服务器将第二客户端用户的名片信息发送给所述第一客户端，同时也将所述第一客户端的名片信息发送至第二客户端；若否，则结束步骤。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：所述名片信息包括名片图像、文字信息、以及名片主人的图像、音频、或视频信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：所述文字信息为名片上的姓名、职称、电话、传真、地址、邮编、电子信箱、网站地址、产品信息中的至少一种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤1)中，所述第一客户端是通过数码拍摄装置或扫描装置撷取所述第二客户端用户的名片图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤1)中，所述第一客户端是利用光学字符识别技术识别所述名片图像上的文字信息和提取图像特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：所述网站服务器预设有用于与所述度量值相比对的参照值，且所述度量值与参照值均为整数，于步骤5)中，当所述网站服务器判断所述候选名片是否属于所述第二客户端用户时，为判断所述度量值是否大于所述参照值，若是，则所述网站服务器向所述第二客户端发出交换请求，若否，则结束步骤。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤幻中，所述网站服务器接受到该名片识别请求后，依据所述文字信息从所述名片资料库中未检索到与该文字信息相匹配的所有预存名片时，则结束步骤。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤3)中，所述图像特征匹配是匹配所述预存名片的名片图像和第二客户端用户的名片图像二者的特征点和各该特征点对应的特征向量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤幻中，所述网站服务器向所述第二客户端发出交换请求，当所述第二客户端未应允时，则结束步骤。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求1所述的结合文字识别和图像匹配交换名片信息的方法，其特征在于：于步骤5)中，所述网站服务器将第一客户端的名片信息发送至第二客户端时，同时将所述第一客户端的名片信息注册于所述网站服务器，并保存至所述名片资料库中。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES42790130" lang="ZH" load-source="patent-office" class="description">
    <p>结合文字识别和图像匹配交换名片信息的方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及一种属于图像处理和网络应用的技术领域，特别是涉及一种结合文字识别和图像匹配来确认名片主人并交换名片信息的方法。</p>
    <p>背景技术</p>
    <p>[0002]	名片是人们经常使用的一种记载和传递联系方式的媒体，在日常商务活动中往往会涉及大量的名片交换，人们通过名片交换的方式来传递联系方式，跟其他人建立联系。</p>
    <p>[0003]	目前已经在手机和微机中广泛使用的名片识别技术，即利用图像处理和光学字符识别（OCR，Optical Character Recognition)的原理，对数码相机拍摄或扫描仪扫描得到的名片图像自动进行处理和识别，然后自动提取出其中的姓名、电话、E-mail等有用信息来加入到地址簿中去，为人们在电子设备中输入名片上记载的联系信息提供了很大的方便。 例如多普达Touch Diamond手机中预装的名片识别软件。</p>
    <p>[0004]	在目前的名片识别的应用实例中，如果用户A和用户B交换了名片，则他们需要分别手工或者使用名片识别软件去把对方的名片信息加入到自己的电子设备的联系人列表中去。</p>
    <p>[0005]	我们可以把名片识别得到的文字传给某个网站的服务器，利用识别出来的名片中的文字信息如姓名，电话号码，电子邮箱等等在该网站的注册用户中找到名片主人，进而与名片主人实现电子名片信息的交换，但是基于光学字符识别原理的名片识别技术识别结果是不可能达到100%的准确率的，把经过光学字符识别获得的可能包含错误的文字信息传递给特定网站的服务器，在很多情况下网站的服务器不能根据由光学字符识别得到的文字来唯一确定这些文字属于网站的哪一个注册用户保存的名片，或者是否属于网站的注册用户所保存的名片。比如说，有些公司的销售人员的名片，除了姓名不同其它的信息如公司名称，地址，联系电话，电子邮件地址等都是一样的，这个时候如果名片中的姓名的文字没有识别出来，网站的服务器就不可能根据其它文字信息来确定这张名片的主人是谁。</p>
    <p>[0006]	所谓的图像匹配是指判断两张图像中拍摄的物体是不是同一个物体，学术界对图像匹配的研究已经有很多年了，一般的做法是找出图像中所拍摄物体的一些特征点， 然后依据这些特征点周边一定范围内的像素值来得到一个特征向量，通过特征点和特征向量的匹配来判断图像中拍摄的物体是不是同一个物体，如论文“Speed-up Robust Feautre(SURF)，，（Herbert Bay,Andreas Ess,Tinne Tuytelaars,Luc Van Goo1,Computer Vision and Image Understanding 110(2008)346-359)中就比较详细描述了这样一种方法；在另一篇学术论文"Rate-efficient, real-time cd cover recognition on a camera-phone，，（Sam S. Tsai,David Chen,Jatinder Pal Singh,Bernd Girod,Proceeding of the 16th ACM international conference on Multimedia)中则描述了一个利用图像匹配来在10000张存在于数据库中的⑶封面图像中查找出与输入的图像最接近的那张⑶ 封面的实际系统。</p>
    <p>[0007]	把图像匹配的方法用到名片识别中来，简单直观的做法是对每张传送给网站服务器要求进行识别获得其中包含的文字的名片图像，提取特征然后用某种图像匹配的算法来在服务器包含的所有名片的图像中查找跟输入的名片图像最相似的那张名片，返回那张名片的文字信息给用户。但是，这种做法存在的问题主要是：</p>
    <p>[0008]	其一，图像匹配的方法速度太慢，由于服务器的数据库中保存的名片图像会非常庞大，一般可能需要从几百万，几千万，甚至几个亿的不同名片的图像中查找出与输入的图像相同的那张名片来，另一个方面，在实际应用中，网站的服务器可能每天需要处理几十万甚至几百万次的识别名片的请求，这个工作量是目前的计算硬件和图像匹配的算法几乎不可能完成的任务。</p>
    <p>[0009]	其二，图像匹配的方法准确率不够高。名片中包含了用户的姓名、电话号码、电子邮件、地址、公司名称和职务等等，这些都是隐私性比较强的信息，如果用户请求识别的是一张名片，而网站的服务器返回的是另一张名片对应的文字信息，就涉及到侵犯返回的那张名片主人的隐私了。所以用图像匹配的方法来做名片识别对识别准确率的要求可以说是 100%的，这里识别准确率我们是指100次成功得到了网站的服务器返回的文字信息的识别请求中，有多少次网站的服务器返回的文字信息确实就是要求进行识别的名片图像所包含的文字信息。但是，在保证识别准确率的前提下，拒识率还要越低越好，否则这个名片识别就失去了实际使用的价值了。上述的拒识率我们是指提交给网站的服务器的100次名片识别请求中，有多少次被网站的服务器告知不能识别，不能识别的原因可能是网站的服务器中没有保存所提交的那张图像所拍摄的名片的图像和对应的文字信息，也可能是网站的服务器不能确定所提交的那张图像拍摄的是哪张名片，因而拒绝返回对应的文字信息。目前的图像匹配算法要保证识别准确率100%，但是，其拒识率通常会比较高。</p>
    <p>[0010]	因而，如何提供一种可以结合文字识别和图像匹配的名片信息交换技术，以解决现有技术中的种种问题，已经成为本技术领域从业者亟待解决的问题。</p>
    <p>发明内容</p>
    <p>[0011]	鉴于以上所述现有技术的缺点，本发明的目的在于提供一种结合文字识别和图像匹配交换名片信息的方法，用以确保名片信息交换的准确率和识别速度，并能够进一步保护名片信息的隐私性。</p>
    <p>[0012]	为实现上述目的及其他相关目的，本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用于至少由网站服务器、第一客户端及第二客户端构建的网络系统中， 所述网站服务器具有预存名片信息的名片资料库，所述第一及第二客户端具有名片图像撷取、文字信息识别及图像特征提取功能，其特征在于，所述交换名片信息的方法至少包括以下步骤：1)所述第一客户端撷取所述第二客户端用户的名片图像后，识别所述名片图像上的文字信息，并提取图像特征；幻所述第一客户端将识别的文字信息和提取的图像特征上传至所述网站服务器，并发送名片识别请求；；3)所述网站服务器接受到该名片识别请求后，依据所述文字信息从所述名片资料库中检索与该文字信息相匹配的所有预存名片，并将检索出的各该预存名片的名片图像分别与所述第二客户端用户的名片图像进行图像特征匹配，根据图像特征的相似度，对应每一预存名片生成一个相似程度的度量值；4)所述网站服务器将所有预存名片中度量值最大的一张名片作为候选名片力）判断所述候选名片是否属于所述第二客户端用户，若是，则所述网站服务器向所述第二客户端发出交换请求，在所述第二客户端应允后，所述网站服务器将第二客户端用户的名片信息发送给所述第一客户端，同时也将所述第一客户端的名片信息发送至第二客户端；若否，则结束步骤。</p>
    <p>[0013]	在本发明的交换名片信息的方法中，所述名片信息包括名片图像、文字信息、以及名片主人的图像、音频、或视频信息。所述文字信息为名片上的姓名、职称、电话、传真、地址、邮编、电子信箱、网站地址、产品信息中的至少一种。</p>
    <p>[0014]	在本发明的交换名片信息的方法的步骤1)中，所述第一客户端是通过数码拍摄装置或扫描装置撷取所述第二客户端用户的名片图像。所述第一客户端是利用光学字符识别技术识别所述名片图像上的文字信息和提取图像特征。</p>
    <p>[0015]	在本发明的交换名片信息的方法中，所述网站服务器预设有用于与所述度量值相比对的参照值，且所述度量值与参照值均为整数，于步骤5)中，当所述网站服务器判断所述候选名片是否属于所述第二客户端用户时，为判断所述度量值是否大于所述参照值，若是，则所述网站服务器向所述第二客户端发出交换请求，若否，则结束步骤。</p>
    <p>[0016]	在本发明的交换名片信息的方法的步骤幻中，所述网站服务器接受到该名片识别请求后，依据所述文字信息从所述名片资料库中未检索到与该文字信息相匹配的所有预存名片时，则结束步骤。所述图像特征匹配是匹配所述预存名片的名片图像和第二客户端用户的名片图像二者的特征点和各该特征点对应的特征向量。</p>
    <p>[0017]	在本发明的交换名片信息的方法的步骤幻中，所述网站服务器向所述第二客户端发出交换请求，当所述第二客户端未应允时，则结束步骤。所述网站服务器将第一客户端的名片信息发送至第二客户端时，同时将所述第一客户端的名片信息注册于所述网站服务器，并保存至所述名片资料库中。</p>
    <p>[0018]	如上所述，本发明的结合文字识别和图像匹配交换名片信息的方法，在识别名片图像时，将文字识别的结果结合图像特征来确定名片的主人是该网站的哪个注册用户，并与名片主人交换名片信息，从而实现了只要交换纸质名片的双方中有一方拍摄名片进行识别就可以使得双方都获得对方的电子名片信息，不但可以确保名片信息交换的准确率和识别速度，而且通过图像匹配的进一步确认保护了名片信息的隐私性。</p>
    <p>附图说明</p>
    <p>[0019]	图1显示为本发明的结合文字识别和图像匹配交换名片信息的方法流程示意图。 具体实施方式</p>
    <p>[0020]	以下通过特定的具体实例说明本发明的实施方式，本领域技术人员可由本说明书所揭示的内容轻易地了解本发明的其他优点与功效。本发明还可以通过另外不同的具体实施方式加以实施或应用，本说明书中的各项细节也可以基于不同观点与应用，在不背离本发明的精神下进行各种修饰或改变。</p>
    <p>[0021]	请参阅图1，显示为本发明的结合文字识别和图像匹配交换名片信息的方法流程示意图。需要说明的是，本实施例中所提供的图示仅以示意方式说明本发明的基本构想，遂图式中仅显示与本发明中有关的组件而非按照实际实施时的组件数目、形状及尺寸绘制， 其实际实施时各组件的型态、数量及比例可为一种随意的改变，且其组件布局型态也可能更为复杂。[0022]	如图所示，本发明提供一种结合文字识别和图像匹配交换名片信息的方法，应用于至少由网站服务器（未予以图示）、第一客户端及第二客户端（未予以图示）构建的网络系统中，所述网站服务器具有预存名片信息的名片资料库，在本实施例中，所述名片资料库中的所述名片信息包括名片图像、文字信息、以及名片主人的图像、音频、或视频信息，例如，包括用户名片的图像，用户的大头像，以及用户自己决定提供给他人的文字，图像，音频，视频等信息，其中，所述文字信息为名片上的姓名、职称、电话、传真、地址、邮编、电子信箱、网站地址、产品信息中的至少一种。</p>
    <p>[0023]	所述第一及第二客户端具有名片图像撷取、文字信息识别及图像特征提取功能， 在本实施例中，所述第一客户端具有数码拍摄装置或扫描装置，用以撷取名片图像，并可以利用光学字符识别技术识别所述名片图像上的文字信息和提取图像特征。在本实施例中， 所述第一及第二客户端可以是智能手机、平板电脑、PDA等具有数据处理功能的电子设备。</p>
    <p>[0024]	在本实施例中，所述网站服务器的网站为一个具有维护联系人信息功能的网站， 该网站的注册用户可以将自己的一张或多张名片的名片信息包括文字信息和名片图像一起保存到名片资料库，并与自己的账户相互关联，所保存的名片文字信息是经过用户自己或者网站管理人员的检查校正，保证正确的，所保存的对应同样的文字信息的名片图像可以有一张或者多张，例如同一个用户可能有多张名片，在这多张名片中只有公司和职务的信息是不同的，其它姓名、电话、电子信箱等信息都是相同的。</p>
    <p>[0025]	如图1所示，所述交换名片信息的方法至少包括以下步骤：</p>
    <p>[0026]	首先执行步骤Si，所述第一客户端撷取所述第二客户端用户的名片图像后，识别所述名片图像上的文字信息，并提取图像特征；在本实施例中，所述第一客户端是通过数码拍摄装置或扫描装置撷取所述第二客户端用户的名片图像，并利用光学字符识别技术识别所述名片图像上的文字信息和提取图像特征。接着执行步骤S2。</p>
    <p>[0027]	在步骤S2中，所述第一客户端将识别的文字信息和提取的图像特征经由有线或无线网络上传至所述网站服务器，并发送名片识别请求；接着执行步骤S3。</p>
    <p>[0028]	在步骤S3中，所述网站服务器接受到该名片识别请求后，依据所述文字信息从所述名片资料库中检索与该文字信息相匹配的所有预存名片，在本实施例中，所述网站服务器利用识别出来的文字信息在该网站的注册用户保存的名片的文字信息中进行检索，文字检索的目的是大幅度减少在下一步中需要依据图像特征来进行图像匹配的图像的数量，从而提高图像匹配的速度和匹配的准确率。所述利用识别出来的文字信息进行文字检索具体的做法就是在该网站的名片资料库中注册用户保存的名片的文字信息中查找跟识别出来的文字中包含的姓名、职称、电话、传真、地址、邮编、电子信箱、网站地址、产品信息中的至少一种完全一致的预存名片。接着执行步骤S4。</p>
    <p>[0029]	在步骤S4中，判断是否检索到，若是，则进至步骤S5，若否，则表明所述第二客户端用户的名片信息未注册在该网站中，也就是说，所述名片资料库中没有该第二客户端用户的名片信息，因而，则直接结束步骤。</p>
    <p>[0030]	需要说明的是，即使在步骤S4中利用识别出来的文字信息从所述名片资料库中进行检索之后，得到的是唯一的一张与第二客户端用户的名片图像中识别出来的文字一致的名片，也仍然需要到步骤S5中去进行验证，这是因为存在某些情况下网站服务器不能根据由光学字符识别得到的文字来唯一确定这些文字属于网站服务器所保存的名片中的哪一张，或者是否属于网站服务器所保存的名片。比如说，同一个用户可能有多张名片，在这多张名片中只有公司和职务的信息是不同的，其它姓名，电话，电子信箱这些信息都是相同的，这样如果对公司和职务的识别有误，只是正确的识别出了姓名，电话，电子信箱等信息， 网站服务器就不能唯一确定这些信息属于用户的哪一张名片。接着执行步骤S5。</p>
    <p>[0031]	在步骤S5中，将检索出的各该预存名片的名片图像分别与所述第二客户端用户的名片图像进行图像特征匹配，在本实施例中，所述图像特征匹配是匹配所述预存名片的名片图像和第二客户端用户的名片图像二者的特征点和各该特征点对应的特征向量。接着执行步骤S6。</p>
    <p>[0032]	在步骤S6中，根据图像特征的相似度，对应每一预存名片生成一个相似程度的度量值；在本实施例中，所述网站服务器预设有用于与所述度量值相比对的参照值，且所述度量值与参照值均为整数，当所述度量值大于所述参照值时，则表示所述度量值对应的那种候选名片为第二客户端用户的名片。换言之，所述度量值越大，则表示所述度量值对应的那种名片与第二客户端用户的名片越相似。接着执行步骤S7。</p>
    <p>[0033]	在步骤S7中，所述网站服务器将所有预存名片中度量值最大的一张名片作为候选名片，以确保下一步骤比对的精确度。接着执行步骤S8。</p>
    <p>[0034]	在步骤S8中，判断所述候选名片是否属于所述第二客户端用户，换言之，当所述网站服务器判断所述候选名片是否属于所述第二客户端用户时，为判断所述度量值是否大于所述参照值，若是，则进至步骤S9，若否，则意味着所述候选名片是不属于所述第二客户端用户，为确保该候选名片主人信息隐私不被泄露，则不再进行名片信息交换，则直接结束步骤。</p>
    <p>[0035]	在步骤S9中，所述网站服务器向所述第二客户端发出交换请求，接着执行步骤 S10。</p>
    <p>[0036]	在步骤SlO中，判断所述第二客户端是否应允交换请求，若是，则进至步骤Sl 1，若否，则表示所述第二客户端的用户不愿意和所述第一客户端的用户交换名片信息，为确保该第二客户端的用户的信息隐私不被泄露，则不再进行名片信息交换，则直接结束步骤。</p>
    <p>[0037]	在步骤Sll中，所述网站服务器将第二客户端用户的名片信息发送给所述第一客户端，同时也将所述第一客户端的名片信息发送至第二客户端，此时，如果该第一客户端的用户未将其名片信息注册至该网站中时，所述第一客户端将其的名片信息发送至第二客户端的同时，也可以注册于所述网站服务器，并保存至所述名片资料库中，以便在日后的名片信息交换中能被交换对象的客户端从网站中获取其名片信息。</p>
    <p>[0038]	综上所述，本发明的结合文字识别和图像匹配交换名片信息的方法，在识别名片图像时，将文字识别的结果结合图像特征来确定名片的主人是该网站的哪个注册用户，并与名片主人交换名片信息，从而实现了只要交换纸质名片的双方中有一方拍摄名片进行识别就可以使得双方都获得对方的电子名片信息，不但可以确保名片信息交换的准确率和识别速度，而且通过图像匹配的进一步确认保护了名片信息的隐私性。所以，本发明有效克服了现有技术中的种种缺点而具高度产业利用价值。</p>
    <p>[0039]	上述实施例仅例示性说明本发明的原理及其功效，而非用于限制本发明。任何熟悉此技术的人士皆可在不违背本发明的精神及范畴下，对上述实施例进行修饰或改变。因此，举凡所属技术领域中具有通常知识者在未脱离本发明所揭示的精神与技术思想下所完成的一切等效修饰或改变，仍应由本发明的权利要求所涵盖。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1413861A?cl=zh">CN1413861A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2002年8月29日</td><td class="patent-data-table-td patent-date-value">2003年4月30日</td><td class="patent-data-table-td ">珠海维中信息技术有限公司</td><td class="patent-data-table-td ">车牌自动识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101882227A?cl=zh">CN101882227A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年7月13日</td><td class="patent-data-table-td patent-date-value">2010年11月10日</td><td class="patent-data-table-td ">上海合合信息科技发展有限公司</td><td class="patent-data-table-td ">基于图像匹配和网络查询的识别方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1796019A1?cl=zh">EP1796019A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年12月11日</td><td class="patent-data-table-td patent-date-value">2007年6月13日</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Personal information retrieval using knowledge bases for optical character recognition correction</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102546645A?cl=zh">CN102546645A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年1月17日</td><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">深圳市乐唯科技开发有限公司</td><td class="patent-data-table-td ">一种基于音频信息实现对象匹配的系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102546645B?cl=zh">CN102546645B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年1月17日</td><td class="patent-data-table-td patent-date-value">2015年5月6日</td><td class="patent-data-table-td ">深圳市乐唯科技开发有限公司</td><td class="patent-data-table-td ">一种基于音频信息实现对象匹配的系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103778561A?cl=zh">CN103778561A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年10月23日</td><td class="patent-data-table-td patent-date-value">2014年5月7日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">一种社交互动方法及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K2209/01">G06K2209/01</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q10/10">G06Q10/10</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00979">G06K9/00979</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/3258">G06K9/3258</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00463">G06K9/00463</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30011">G06F17/30011</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=8XCbBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00483">G06K9/00483</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年12月7日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年1月25日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月27日</td><td class="patent-data-table-td ">C12</td><td class="patent-data-table-td ">Rejection of an application for a patent</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/856e4ff0478e34763a15/CN102270296A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%BB%93%E5%90%88%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E5%92%8C%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D%E4%BA%A4%E6%8D%A2.pdf?id=8XCbBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3xKIW198hlROcB94amwOr5gO5GCA"},"sample_url":"https://www.google.com/patents/reader?id=8XCbBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>