<!DOCTYPE html><html><head><title>专利 CN101467204A - 用于生物计量声纹认证的方法和系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="用于生物计量声纹认证的方法和系统"><meta name="DC.contributor" content="B&#183;萨尔纳" scheme="inventor"><meta name="DC.contributor" content="G&#183;迪玛伯欧" scheme="inventor"><meta name="DC.contributor" content="普提克斯科技股份有限公司" scheme="assignee"><meta name="DC.date" content="2006-5-26" scheme="dateSubmitted"><meta name="DC.description" content="提供了一种用于认证用户的方法(700)和系统(900)。该方法可包括：从用户接收一个或多个口头话语(702)；识别与该一个或多个口头话语相对应的短语(704)；从该短语的一个或多个口头话语标识用户的生物计量声纹(706)；确定与该设备相关联的设备标识符(708)；以及基于该短语、生物计量声纹和设备标识符来认证该用户(710)。手持式设备或用户的位置可用作用于准许访问一个或多个资源的标准(712)。"><meta name="DC.date" content="2009-6-24"><meta name="citation_patent_publication_number" content="CN:101467204:A"><meta name="citation_patent_application_number" content="CN:200680027372"><link rel="canonical" href="https://www.google.com/patents/CN101467204A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101467204A?cl=zh"/><meta name="title" content="专利 CN101467204A - 用于生物计量声纹认证的方法和系统"/><meta name="description" content="提供了一种用于认证用户的方法(700)和系统(900)。该方法可包括：从用户接收一个或多个口头话语(702)；识别与该一个或多个口头话语相对应的短语(704)；从该短语的一个或多个口头话语标识用户的生物计量声纹(706)；确定与该设备相关联的设备标识符(708)；以及基于该短语、生物计量声纹和设备标识符来认证该用户(710)。手持式设备或用户的位置可用作用于准许访问一个或多个资源的标准(712)。"/><meta property="og:title" content="专利 CN101467204A - 用于生物计量声纹认证的方法和系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101467204A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101467204A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101467204A&amp;usg=AFQjCNEyIIQclwdhkOlacAencodg5VthuQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/ca55a10ee2e6b3240c58/CN101467204A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/ca55a10ee2e6b3240c58/CN101467204A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101467204A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101467204A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101467204A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101467204B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101467204A?cl=zh" style="display:none"><span itemprop="description">提供了一种用于认证用户的方法(700)和系统(900)。该方法可包括：从用户接收一个或多个口头话语(702)；识别与该一个或多个口头话语相对应的短语(704)；从该短语的一个或多个口头话语标识用户的生物计量声纹(706)；确定与该设 ...</span><span itemprop="url">https://www.google.com/patents/CN101467204A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101467204A - 用于生物计量声纹认证的方法和系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101467204A - 用于生物计量声纹认证的方法和系统" title="专利 CN101467204A - 用于生物计量声纹认证的方法和系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101467204 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200680027372</td></tr><tr><td class="patent-bibdata-heading"> 专利合作条约 (PCT) 编号</td><td class="single-patent-bibdata">PCT/US2006/020907</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2009年6月24日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2006年5月26日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2005年5月27日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101467204B?hl=zh-CN&amp;cl=zh">CN101467204B</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1915294A2?hl=zh-CN&amp;cl=zh">EP1915294A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1915294A4?hl=zh-CN&amp;cl=zh">EP1915294A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7536304?hl=zh-CN&amp;cl=zh">US7536304</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8280740?hl=zh-CN&amp;cl=zh">US8280740</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8571867?hl=zh-CN&amp;cl=zh">US8571867</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070185718?hl=zh-CN&amp;cl=zh">US20070185718</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090206993?hl=zh-CN&amp;cl=zh">US20090206993</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130018657?hl=zh-CN&amp;cl=zh">US20130018657</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2006128171A2?hl=zh-CN&amp;cl=zh">WO2006128171A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2006128171A3?hl=zh-CN&amp;cl=zh">WO2006128171A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200680027372.7, </span><span class="patent-bibdata-value">CN 101467204 A, </span><span class="patent-bibdata-value">CN 101467204A, </span><span class="patent-bibdata-value">CN 200680027372, </span><span class="patent-bibdata-value">CN-A-101467204, </span><span class="patent-bibdata-value">CN101467204 A, </span><span class="patent-bibdata-value">CN101467204A, </span><span class="patent-bibdata-value">CN200680027372, </span><span class="patent-bibdata-value">CN200680027372.7, </span><span class="patent-bibdata-value">PCT/2006/20907, </span><span class="patent-bibdata-value">PCT/US/2006/020907, </span><span class="patent-bibdata-value">PCT/US/2006/20907, </span><span class="patent-bibdata-value">PCT/US/6/020907, </span><span class="patent-bibdata-value">PCT/US/6/20907, </span><span class="patent-bibdata-value">PCT/US2006/020907, </span><span class="patent-bibdata-value">PCT/US2006/20907, </span><span class="patent-bibdata-value">PCT/US2006020907, </span><span class="patent-bibdata-value">PCT/US200620907, </span><span class="patent-bibdata-value">PCT/US6/020907, </span><span class="patent-bibdata-value">PCT/US6/20907, </span><span class="patent-bibdata-value">PCT/US6020907, </span><span class="patent-bibdata-value">PCT/US620907</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22B%C2%B7%E8%90%A8%E5%B0%94%E7%BA%B3%22">B&#183;萨尔纳</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22G%C2%B7%E8%BF%AA%E7%8E%9B%E4%BC%AF%E6%AC%A7%22">G&#183;迪玛伯欧</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%99%AE%E6%8F%90%E5%85%8B%E6%96%AF%E7%A7%91%E6%8A%80%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">普提克斯科技股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101467204A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101467204A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101467204A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (6),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200680027372&amp;usg=AFQjCNHlnd0JYTS9uf20tPKpv1VyP2QISQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101467204A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGPuTv3x8pAa8bmdPa-e9w8IQIgyg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT75794823" lang="ZH" load-source="patent-office">用于生物计量声纹认证的方法和系统</invention-title>
      </span><br><span class="patent-number">CN 101467204 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA53549824" lang="ZH" load-source="patent-office">
    <div class="abstract">提供了一种用于认证用户的方法(700)和系统(900)。该方法可包括：从用户接收一个或多个口头话语(702)；识别与该一个或多个口头话语相对应的短语(704)；从该短语的一个或多个口头话语标识用户的生物计量声纹(706)；确定与该设备相关联的设备标识符(708)；以及基于该短语、生物计量声纹和设备标识符来认证该用户(710)。手持式设备或用户的位置可用作用于准许访问一个或多个资源的标准(712)。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(54)</span></span></div><div class="patent-text"><div mxw-id="PCLM13531964" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. 一种在设备上用于语音认证的方法，包括：从用户接收一个或多个口头话语；识别与所述一个或多个口头话语相对应的短语；根据所述短语的所述一个或多个口头话语标识生物计量声纹；确定与所述设备相关联的标识符；以及基于所述短语、所述生物计量声纹和所述设备标识符来认证所述用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. 如权利要求l所述的方法，其特征在于，所述标识还包括：确定一个或多个口头话语的变化性来创建所述生物计量声纹，其中所述生物计量声纹是一种声道结构，所述结构对于所述用户的声道而言在物理上是唯一的。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. 如权利要求1所述的方法，其特征在于，还包括：在对所述用户进行认证时，准许对与所述设备通信的一个或多个资源的访问。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. 如权利要求1所述的方法，其特征在于，还包括验证所述设备的位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. 如权利要求4所述的方法，其特征在于，所述设备包括用于标识所述设备的所述位置的全球定位系统（GPS)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. 如权利要求l所述的方法，其特征在于，还包括：接收所述用户的、标识所述用户的位置的第二口头话语；以及确认所述用户的所述位置与所接受位置相对应。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. 如权利要求l所述的方法，其特征在于，所述移动设备标识符是IMEI号。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. 如权利要求7所述的方法，其特征在于，所述IMEI号与数据库中的所述生物计量声纹相关联，所述数据库使用所述IMEI号来对所述生物计量声纹进行索引。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. 如权利要求1所述的方法，其特征在于，所述移动设备标识符是分配给所述设备的PIN。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. 如权利要求1所述的方法，其特征在于，所述设备是移动手持式设备、蜂窝电话、个人数字助理、膝上型设备、笔记本计算机、便携式音乐播放器和通信设备之一。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. 如权利要求l所述的方法，其特征在于，还包括：建立与至少一个认证服务器的连接；将用户配置文件发送到所述至少一个认证服务器；将所述用户配置文件与存储在所述至少一个认证服务器中的多个参考配置文 件进行比较；以及确定所述用户配置文件是否与所述多个参考配置文件之一相匹配以便认证所 述用户，其中用户配置文件包括短语、生物计量声纹和设备标识符中的至少之一。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. 如权利要求11所述的方法，其特征在于，所述认证的第一部分在所述设 备上发生，而所述认证的第二部分在所述认证服务器上发生。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. 如权利要求11所述的方法，其特征在于，所述认证服务器包括诸如web 层、业务层和数据库访问层的软件应用。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. 如权利要求ll所述的方法，其特征在于，所述比较包括-在识别所述短语时，估算所述口头话语之间的一个或多个声道结构差异，以及基于所述声道结构差异来匹配多个参考配置文件的一个或多个声道形状。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. 如权利要求14所述的方法，其特征在于，在所述口头话语的一个或多个 浊音片段处估算所述声道结构差异。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. 如权利要求14所述的方法，其特征在于，声道结构差异对应于用户声道 与多个口头话语相关联的有限物理变化。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. 如权利要求14所述的方法，其特征在于，所述声道结构差异是基于说明 话音频谱随时间动态变化的动量谱。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. 如权利要求17所述的方法，其特征在于，所述动量谱包括话音的一个或 多个语音片段段的上限和下限，使得所述上限和所述上限之间的所述话音频谱的变 化对应于唯一的声道结构。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. 如权利要求14所述的方法，其特征在于，所述声道结构被表示成具有作 为所述用户声道的一个或多个部分的特性的相应长度和面积的一个或多个部分。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. 如权利要求14所述的方法，其特征在于，还包括： 确定所重复的口头话语之间的差异是否落在失真范围内；以及 如果所述差异落在所述失真范围内，则判定声纹匹配。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. 如权利要求14所述的方法，其特征在于，所述比较还包括： 确定至少一个共振峰频率；确定至少一个反共振峰频率；以及估算所述共振峰频率与所述反共振峰频率之间的差异，以便表征声道结构中 的自然变化的一个方面。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. 如权利要求21所述的方法，其特征在于，所述估算所述共振峰频率与所 述反共振峰频率之间的差异补偿电话带宽。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. 如权利要求21所述的方法，其特征在于，较高的共振峰频率被着重以表 征说话人的发音风格的一个方面。</div>
    </div>
    </div> <div class="claim"> <div num="24" class="claim">
      <div class="claim-text">24. &#8212;种用于说话人证实的方法，包括： 响应于说话人的语音生成第一声纹； 响应于所述说话人的语音生成至少第二声纹； 标识所述第一声纹与所述第二声纹之间的差异； 确定所述差异是否对应于所述说话人声道的自然变化；以及 如果所述差异表示所述说话人声道中的自然变化，则认证所述说话人。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. 如权利要求24所述的方法，其特征在于，自然变化是在口头话语的发音 期间与所述说话人的发声姿态的变化相关的声道的物理变化，并且所述变化对于所 述说话人是唯一的。</div>
    </div>
    </div> <div class="claim"> <div num="26" class="claim">
      <div class="claim-text">26. &#8212;种用于生成生物计量声纹的系统，包括：语音处理器，用于从用户接收口头话语和所述口头话语的至少一次重复； 生物计量语音分析器，用于：从所述口头话语和所述至少一次重复来计算一个或多个声道形状，以及 基于所述口头话语和所述至少一次重复之间的不同发音来计算所述一个或多 个声道形状之间的声道结构差异。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. 如权利要求26所述的系统，其特征在于，所述语音处理器： 将口头话语分段成一个或多个发声帧； 从所述一个或多个发声帧生成一个或多个特征矢量； 从所述一个或多个特征矢量计算特征矩阵；以及 在所述一个或多个发声帧上对所述特征矩阵进行归一化。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. 如权利要求27所述的系统，其特征在于，所述语音处理器包括话音分析 器，用于：标识所述口头话语中的浊音和清音区段； 从所述浊音区段识别一个或多个音素；以及 标识所述发声帧中的所述一个或多个音素的位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. 如权利要求27所述的系统，其特征在于，所述语音处理器通过以下步骤 生成所述一个或多个特征矢量：将口头话语分段成一个或多个发声帧； 对所述一个或多个发声帧执行感知滤波器组分析； 从所述感知滤波器组分析计算线性预测系数（LPC); 将所述LPC变换成线谱对系数（LSP'S); 从所述LSP'S计算共振峰和反共振峰；以及 从所述共振峰和反共振峰创建特征矢量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30. 如权利要求29所述的系统，其特征在于，所述语音处理器： 从所述口头话语对应于所述一个或多个发声帧的多个部分的所述特征矢量计算特征矩阵，其中所述特征矩阵是所述一个或多个发声帧的级联；以及通过移除比预定长度短的发声帧以及移除对应于超出平均声道结构的声道结 构的发声帧来对所述特征矩阵归一化。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31. 如权利要求29所述的系统，其特征在于，所述执行感知滤波器组分析包 括来估算沿Bark频率标度的一个或多个频带中的话音能量和噪声能量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" class="claim">
      <div class="claim-text">32. 如权利要求31所述的系统，其特征在于，还包括在所述感知滤波器组分 析期间，通过丢弃具有不超出发声阈值的话音能量与噪声能量之比的滤波器组来抑 制背景噪声。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33. 如权利要求29所述的系统，其特征在于，所述计算线性预测系数包括将 预着重应用到所述话音信号。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" class="claim">
      <div class="claim-text">34. 如权利要求29所述的系统，其特征在于，所述特征矢量包括最小化说话 人自身的变化性以及最大化说话人之间的变化性的标识参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" class="claim">
      <div class="claim-text">35. 如权利要求30所述的系统，其特征在于，所述生物计量声纹分析器： 从所述特征矩阵计算一个或多个声道形状； 从所述一个或多个声道形状计算声道结构差异； 估算一个或多个音素的频谱中的变化性；以及 基于所述变化性来对声道结构差异建立变化范围。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" class="claim">
      <div class="claim-text">36. 如权利要求35所述的系统，其特征在于，所述生物计量语音分析器对照 所存储的所述说话人语音的特征矢量的标识参数来比较所述特征矢量的标识参数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" class="claim">
      <div class="claim-text">37. 如权利要求35所述的系统，其特征在于，所述生物计量语音分析器： 根据所述特征矢量来确定一个或多个声道横截面面积；以及对所述一个或多个声道横截面面积确定一个或多个声道长度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" class="claim">
      <div class="claim-text">38. 如权利要求37所述的系统，其特征在于，所述生物计量语音分析器： 计算变化范围以便对所述特征矩阵中的所述特征矢量生成变化矢量； 确定所述变化矢量的对数距离；以及基于所述对数距离建立阈值，其中所述阈值用于确定用以认证用户的声道结 构差异是否落在变化范围内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" class="claim">
      <div class="claim-text">39. 如权利要求38所述的系统，其特征在于，所述变化范围被表示成所述特 征矢量的均值和标准偏差。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40. 如权利要求38所述的系统，其特征在于，所述声纹语音分析器： 对所述个人声道形状确定变化范围； 对所述变化范围计算直方图；确定所述直方图的最大值； 基于所述最大值计算导矢；基于所述导矢计算个人直方图和第二变化范围；</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41. 如权利要求40所述的系统，其特征在于，所述生物计量语音分析器： 估算个人直方图来确定生物计量声纹是否匹配于所述多个生物计量声纹之一，以验证所述用户的身份生物计量，其中当所述个人直方图的第一多个图元被填满时，所述身份有效，以及其中 当所述个人直方图的第二多个图元被填满时，所述身份无效。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" class="claim">
      <div class="claim-text">42. 如权利要求41所述的系统，其特征在于，所述生物语音分析器： 计算对数距离；以及估算用于确定所述个人直方图的第一多个图元何时被填满的阈值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43. 如权利要求42所述的系统，其特征在于，所述阈值基于用户语音来调节。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" class="claim">
      <div class="claim-text">44. 如权利要求42所述的系统，其特征在于，还包括应用程序设计接口（API)， 它具有：生物计量声纹创建模块， 密码短语创建模块；以及 设备标识符模块，用于创建包括从所述生物计量声纹创建模块、所述密码短语创建模块和所述 设备标识符模块生成的生物计量声纹、密码短语和设备标识符的用户配置文件。</div>
    </div>
    </div> <div class="claim"> <div num="45" class="claim">
      <div class="claim-text">45. &#8212;种语音认证方法，包括：根据从用户接收到的一个或多个口头话语来确定一个或多个声道形状； 估算所述一个或多个声道形状之间的的声道差异；对照所存储的所述用户语音的参考声道形状的表示来比较所述声道差异；以及确定所述声道结构差异是否表示所述参考声道形状的自然变化，其中自然变 化是所述声道结构中可由所述用户在物理上发音的变化。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" class="claim">
      <div class="claim-text">46. 如权利要求45所述的方法，其特征在于，确定一个或多个声道形状还包括：从所述第一生物计量声纹的较低的共振峰来计算第一声道形状； 基于所述第一生物计量声道形状来确定声道结构差异； 标识提供最小声道结构差异的类似声道形状；以及 从所述第一生物计量声纹的较高共振峰形成所述类似声道形状。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" class="claim">
      <div class="claim-text">47. 如权利要求45所述的方法，其特征在于，还包括：确定所述口头话语的源，其中所述源是对麦克风说出所述口头话语的所述用 户、或回放对麦克风所说的口头话语的记录的设备之一；以及如果所述源是所述用户，则准许访问，而如果所述源是所述设备，则不准许 访问。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" class="claim">
      <div class="claim-text">48. 如权利要求47所述的方法，其特征在于，所述确定源还包括： 标识表示所述口头话语的声学信号是否是由数字记录设备生成的波形的特性，其中所述标识包括识别由所述数字记录设备给予的频谱倾斜。</div>
    </div>
    </div> <div class="claim"> <div num="49" class="claim">
      <div class="claim-text">49. 一种语音认证方法，包括：在呼叫期间，在交互式语音应答（IVR)系统上接收口头话语；响应于对所述口头话语的识别调用程序性动作，分析所述口头话语以标识提交所述口头话语的用户的声纹；以及 基于对所述声纹的认证，准许所述用户访问所述程序性动作。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" class="claim">
      <div class="claim-text">50. 如权利要求49所述的方法，其特征在于，还包括： 识别所述口头话语中的一个或多个号码；以及自动地输入所述一个或多个号码以访问所述IVR的特征， 由此所述程序性动作对在所述口头话语中识别到的所述一个或多个号码进行 拨号以访问所述特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="51" class="claim">
      <div class="claim-text">51. 如权利要求49所述的方法，其特征在于，还包括： 从用于提交所述口头话语的设备接收设备标识符；以及 在准许访问之前，证实所述设备对用户的注册。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="52" class="claim">
      <div class="claim-text">52. 如权利要求49所述的方法，其特征在于，还所述程序性动作是安全交易， 并且所述口头话语标识诸如帐号、银行电汇号码、电话号码、社会保障号码和pin 号的安全信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" class="claim">
      <div class="claim-text">53. 如权利要求52所述的方法，其特征在于，还包括： 在所述准许访问中，根据所述程序性动作将所述呼叫转发到呼叫中心；以及 在与所述呼叫中心连接时，调用所述呼叫中心的屏幕弹出以显示用户帐户信息o</div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" class="claim">
      <div class="claim-text">54. 如权利要求53所述的方法，其特征在于，所述交互式语音应答（IVR) 系统驻留在PBX、网关、语音服务器和因特网语音服务器之一上。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES18918977" lang="ZH" load-source="patent-office" class="description">
    <p>用于生物计量声纹认证的方法和系统</p>
    <p>发明领域</p>
    <p>本发明一般涉及话音识别，尤其涉及语音标识。 背景</p>
    <p>电子技术和软件的进步使得系统能够更有效地识别和标识个人。例如，诸如 相机的图像处理系统可捕捉个人的图像并根据图像来标识个人。指纹扫描系统可通 过触摸来捕捉用于标识个人的指纹。语音处理系统可通过它们的语音来标识个人。 这些技术提供在使用之前对用户的标识，以便确保系统安全和对该系统的代理访 问。</p>
    <p>语音标识（ID)系统已用于各种安全相关的应用中。有时称为语音认证的语 音ID是使用声纹和模式识别软件来验证说话人的一类用户认证。生物计量 (biometric)、语音ID的自适应依赖于以下前提：如同指纹和人眼虹膜的模式一 样，对于每个个人而言声音特性是唯一的。</p>
    <p>更多的人可通过移动设备和计算机的耦合在因特网上在线地彼此交互。移动 设备能够在线进行并建立与其它通信系统的连接。标识移动设备的用户是提供安全 访问的重要方面。然而，移动设备用户的标识通常是不实用的。因此，存在对用户 进行认证的需求。</p>
    <p>概述</p>
    <p>本发明的实施例涉及一种设备上的语音认证的方法。该方法可包括：从用户 接收一个或多个口头话语、识别与一个或多个口头话语相对应的短语、根据该短语 的一个或多个口头话语来标识生物计量声纹（biometric voice print)、确定与该设 备相关联的设备标识符、以及基于该短语、该生物计量声纹和设备标识符来认证用 户。可确定一个或多个口头话语的变化性来创建生物计量声纹。生物计量声纹是一 种声道结构，该结构在物理上对用户的声道是唯一的。在对用户进行认证时，可准 许对与设备通信的一个或多个资源的访问。可确定设备或用户的位置以便准予访</p>
    <p>9问。</p>
    <p>附图的简要描述</p>
    <p>在所附权利要求中具体阐述了被认为是新颖的系统的特征。本文的实施例可 通过参照以下描述、结合附图来理解，在这些附图中，类似附图标记表示类似要素， 并且其中：</p>
    <p>图1是根据本发明的配置的实施例的移动通信环境；</p>
    <p>图2是部署在图1中根据本发明配置的的实施例的移动通信系统环境内的语 音认证系统的示例性图示；</p>
    <p>图3是图2中根据本发明的配置的实施例的语音认证系统的示例性实现； 图4是根据本发明的配置的实施例的语音认证系统；</p>
    <p>图5是适用于根据本发明的配置的实施例的语音认证系统中的用户配置文件 创建的流程图；</p>
    <p>图5是适用于根据本发明的配置的实施例的语音认证系统的用户验证的流程</p>
    <p>图；</p>
    <p>图6是适用于根据本发明的配置的实施例的语音认证系统的用户配置文件创 建的流程图；</p>
    <p>图7是根据本发明的配置的实施例的设备上的语音认证的方法700; 图8是根据本发明的配置的实施例的语音认证算法；以及 图9是根据本发明的配置的实施例的语音认证系统。</p>
    <p>详细描述</p>
    <p>本文公开了本方法和系统的详细实施例。然而，应当理解，所公开的实施例 仅是示例性的，而且本发明可以不同形式来具体化。因此，本文所公开的特定结构 和功能细节不应当解释为限制，而是仅作为权利要求的基础，以及作为示教本领域 技术人员的典型依据以便以实际上任何适当的细节结构来多样地使用本发明的实 施例。此外，本文所用的术语和措辞并非旨在限制，而是旨在提供对本文的实施例 的可理解描述。</p>
    <p>本文所用的术语"一"被定义为一个或多个。本文所用的术语"多个"被定 义为两个或更多。本文所用的术语"另一"被定义为至少第二个或更多。本文所用 的术语"包括"和/或"具有"被定义为包括（即，开放式语言）。本文所用术语"耦合"被定义为连接，但是无需是直接连接，也无需是机械地连接。术语"抑制"可被定义为部分或完全减小或移除。术语"处理"可被定义为可执行预编程或己编程的指令集的大量合适的处理器、控制器、单元等。</p>
    <p>本文所用的术语"程序"、"软件应用"等被定义为设计成在计算机系统上执行的指令序列。程序、计算机程序或软件应用可包括子例程、函数、过程、对象方法、对象实现、可执行应用、源代码、对象代码、共享库/动态加载库和/或设计成在计算机系统上执行的其它指令序列。</p>
    <p>本发明的实施例涉及一种用于认证用户的系统和方法。该方法可包括从用户接收一个或多个口头话语、识别与一个或多个口头话语相对应的短语、根据该短语的一个或多个口头话语的变化性标识生物计量声纹、确定与该设备相关联的设备标识符、以及基于该短语、该生物计量声纹和设备标识符来认证用户。</p>
    <p>本发明的实施例还包括可基于用户的唯一声纹、用于在生成声纹期间的说出的短语、以及用户的例如IMEI号的手持式设备的标识符的认证系统。在一个实现中，手持式设备或用户的位置可用作批准接入一个或多个资源的附加标准。例如，该系统可通过使用生物计量特征一即，用户的语音一的更加稳定的方法来替代当前</p>
    <p>用户标识的"社会保障号码/母亲姓名（mother's maiden name)"模型。</p>
    <p>参看图1，示出了用于语音认证的移动通信环境100。移动通信环境100可包括语音认证服务器130、数据库130和一个或多个移动设备102。可用于标识移动设备102的用户的用户配置文件可被存储在数据库130上。用户配置文件可包括密码短语、生物计量声纹和设备标识符。服务器130可将用户配置文件与存储在数据库140上的其它用户配置文件作对比，以便认证用户的语音。例如，移动设备102的用户可向移动设备说话，以便访问该移动设备可用的一个或多个资源。在认证用户的语音时，可授予对一个或多个资源的访问。例如，资源可以是服务器、PBX或任何其它适合的通信系统。资源可提供设备可用的特征或服务，诸如音乐下载、在线博弈、订阅、游戏等。资源可提供对诸如个人信息、远程服务器或主存财务数据或商业数据的数据存储的安全或非安全web站点的访问，但本文并不限于此。</p>
    <p>服务器130可确认由用户讲出的密码短语是否为正确的密码短语，以及与该短语的发音相关联的生物计量声纹是否正确地匹配于数据库中的用户配置文件。具体地，生物计量声纹通过在密码短语的一个或多个发音期间分析用户的说话风格中的一个或多个变化性来捕捉。例如，语音认证服务器130可确定在密码短语的发音期间捕捉到的用户语音的特性是否与数据库140中的一个或多个生物计量声纹相匹配以便认证对一个或多个资源的访问。服务器130还可验证移动设备102是被授权用于访问资源的设备以及是与用户的生物计量声纹相关联的设备。具体地，服务器130可证实对移动设备102说话的用户与移动设备相关联。在一个实施例中，服务器130可确定设备通过与捕捉到的生物计量声纹相关联的IMEI号来对用户进行注册。IMEI号是设备标识符，它对于该移动设备是唯一的。在另一配置中，服务器130可确定设备102的位置以授权对一个或多个资源的访问。例如，移动设备102可包括用于标识该设备的位置的全球定位系统（GPS)。或者，服务器可基于由用户所声明的位置来授权对资源的访问。例如，用户可说出其位置，而服务器130可确定所讲的位置是否对应于所授权或接受的设备或用户的位置。可在移动设备102或服务器130上处理用户语音以证实用户的身份。</p>
    <p>移动通信环境100可在射频（RF)通信网络或链路上提供与系统上的一个或多个语音认证服务器130的无线连通性。服务器130可以是网关、PBX或能够支持语音和数据传送的任何其它电信网络设备。网络100中的通信可使用采用任何合适协议（例如TCP/IP、 HTTP、 HTTPS、 SIP等）的无线、铜线和/或光纤连接来建立。在一个实施例中，移动设备102可使用诸如CDMA、 TDMA、 OFDM、 GSM等的标准通信协议与基地接收机110通信。基站接收机110进而可经由分组交换链路将移动设备102连接到因特网120。因特网120可支持用于向移动设备102提供媒体或内容的应用服务和服务层。应用服务层可包括基于财务或商业的应用的数据库访问。移动设备160还可使用无线通信通道来通过因特网120连接到其它通信设备。移动设备160可在网络上与服务器130建立连接，以及与其它移动设备建立连接以交换语音、数据和媒体。服务器可直接或经由因特网120主存可通过移动设备102访问的应用服务。</p>
    <p>移动设备102可向移动通信环境100上的服务器130或其它远程服务器发送和接收数据。例如，移动设备160还可经由WLAN连接到因特网120。无线局域接入网络（WLAN)提供对局域地理区域内的移动通信环境的无线接入。WLAN通常由也称为基站的接入点104的群集构成。移动通信设备102可与基站区域内的诸如膝上型设备103的其它WLAN站通信以交换语音、数据和媒体。在典型的WLAN实现中，物理层使用诸如802.11b或802.11gWLAN技术的各种技术。物理层可使用红外线、2.4 GHz频带上的跳频扩频、或2.4GHz频带上的直接序列扩频。</p>
    <p>移动设备102可经由电路交换射频连接110或基于分组的WLAN AP 104来向服务器130发送或从其接收数据，但本发明并不限于此。值得注意的是，数据可包括可在一个或多个语音认证服务器之间共享以准许用户访问一个或多个资源的用</p>
    <p>户配置文件。可理解，语音可表示成可被发送到移动设备160或从其发送的语音分组以提供语音通信。例如，移动设备160的用户可启动对服务器或膝上型设备103的呼叫以访问该移动设备可用的一个或多个特征。语音数据可在移动通信环境100上传送，由此提供语音通信。移动设备160可以是蜂窝电话、个人数字助理、便携式音乐播放器或任何其它类型的通信设备。</p>
    <p>参看图2,示出了部署在移动通信环境100内的语音认证系统200的示例性图示。语音认证系统200可包括语音认证服务器130、接口 150和数据库140。服务器130可通过接口 150来访问数据库140以检索用户配置文件。接口可包括web层152、业务层154和数据访问层156。应当注意，接口 150仅是涉及网络上的数据处理的传输层的示例。接口 150所具有的组件可比所示的数量更多或更少，并且并不限于所示那些。</p>
    <p>数据库140可包括用于语音认证的多个用户配置文件142。用户配置文件142可能对于用户是唯一的，以及可能对于设备是唯一的。用户配置文件142可包括生物计量声纹144、密码短语146和移动设备标识符148。密码短语146可以是由用户特别选定的、要在语音认证期间回答的一个或多个单词。当用户将密码短语讲入移动设备102时，用户语音的声纹可被捕捉并存储在用户配置文件142中。生物计量声纹142标识用户说话风格的特征，这些特征对于用户而言是唯一的。具体地，生物计量声纹142表示声道结构差异，该结构在物理上对用户的声道是唯一的。即，用户的声道能够进行物理上的变化，这些变化取决于用户声道的物理形态。在对于个人而言是唯一的密码短语的发音期间，生物计量声纹捕捉与声道的这些特性变化相关联的物理特征。用户的声道结构包括食道、咽、喉、嘴、舌和嘴唇。这些物理属性可在表达密码短语时的话音产生期间进行特定的物理变化，该变化是用户的发声和说话风格的特征。具体地，可测量这些物理属性在口头话语的一个或多发音期间的变化量以证实用户的身份。</p>
    <p>参照图3，示出了语音认证系统200的示例性实现300。示例性实现300包括诸如移动电话或其它移动计算设备的手持式设备102、以及与该手持式设备在移动通信环境100下通信的语音认证服务器130。服务器130可以是任何合适的计算或网络服务器。在服务器130上运行的软件可包括用于与手持式设备通信的web层152 (参见图2)、业务层（154)以及用于存储和检索数据的数据访问层（154)，</p>
    <p>13但并不限于这些。服务器130还可包括监视页面，该页面允许管理员访问服务器。</p>
    <p>例如，用户可通过监视页面更新其配置文件。语音认证服务器130提供用户配置文</p>
    <p>件创建、用户配置文件维护和用户认证。例如，用户配置文件可根据生物计量声纹、</p>
    <p>密码短语和设备标识符来生成，并存储在声纹数据库140中，如图2中所述。用户配置文件的维护允许用户更新或改变其配置文件细节，诸如他们的生物计量声纹、以及口令和关联信息。用户认证允许参照先前所创建的声纹来认证用户。认证可使用用户的记录语音、以及提供给用户的手持式设备IMEI或PIN来执行。例如，取代IMEI，可将PIN分配给移动设备以使该设备与用户配置文件相关联。</p>
    <p>除先前图2中所示的系统组件之外，示例性实现300可包括插入在语音认证服务器130与图1的现有呼叫处理移动通信环境100之间的网关145。在一种配置中，服务器BO可支持订户顺应性、LDAP和审计索引。在一种配置中，网关145可使用由移动设备120提供的GPS定位数据中的信息以验证呼叫者的位置。生物计量声纹识别与位置验证能力的组合形成针对诸如博&#31357;（可以是例如仅在某些州或地区允许）、或者贸易（可以是例如在某些管辖区域内不允许的某些物品的销售）之类应用的特别便利的解决方案。网关145可从GPS数据识别设备的位置以确定呼叫者的位置。</p>
    <p>网关145还可在移动通信环境100中执行呼叫匹配和路由。例如，如本领域中所公知的，网关可支持用于与用户相关联地标识呼叫号码和被叫号码的ANI和DNIS。用户可通过该用户呼叫所使用的号码来标识，或者通过该用户所呼叫的号码来标识。在一个预期配置中，呼叫信息可作为用户配置文件的一部分被包括，并用于验证用户的身份。在实践中，语音认证服务器130可通过向网关145查询呼叫者标识信息和位置信息来参照存储在数据库130上的用户配置文件认证对移动设备160说话的用户。</p>
    <p>参照图4，示出了示例性语音认证系统200。语音认证系统200可包括连接到语音认证服务器130的移动设备102。认证服务器130可包括认证servlet (小服务程序）420、配置文件管理模块420、验证模块420和声纹数据库140。这些模块可驻留在服务器130上或移动通信环境100内的其它服务器上的远程位置处。图4涉及基于客户机-服务器架构，但本发明的诸方面并不限于此配置。语音认证的原理可等效地应用于分布式网络以及对等网络。</p>
    <p>应当注意：某些组件转自图1，并且提供这些组件仅为示出用于将语音认证系统200集成到移动通信环境100 (参见图l)内的一个实施例。在实践中，语音认证系统200可基于对用户语音的认证准许移动设备的用户访问该设备可用的一々或多个资源以便访问这些资源或服务。语音认证系统200并不限于所示程序模块或该程序模块的架构。程序模块仅呈现为用于部署本文所述的本发明的语音认证诸方面的一个实施例。</p>
    <p>语音认证系统200可包括在移动设备（102)上运行的应用410。该应用可以是以诸如C、 C++、 Java、 Voic (语音）XML、 Visual Basic等程序设计语言编写的软件。例如，应用410可以是用于向安全web站点发送或从其发送机密或安全信息的财务或商业应用。机密信息可以是语音、音频、视频或数据的形式。应用410可获得对由该移动设备支持的底层通信协议的访问。例如，应用410可以是Java2微型版（J2ME) applet (小应用程序），它具有支持HTTP的、到一个或多个通信地连接到移动设备410的服务器的套接字（socket)连接。通信协议可通过本地C接口来支持。例如，J2ME可访问移动设备上410上的本地C代码以便连接到服务器（130)。</p>
    <p>应用410可与在语音认证服务器130 (参见图1)上的认证servlet 420通信。认证servlet可用作移动设备客户端102的前端，并基于请求类型将请求引导到语音认证服务器130。例如，请求类型可以是如前所述的用户配置文件创建、用户配置文件更新或用户配置认证。基于请求类型，认证servlet 420可调用适当的配置文件管理功能。即，在确定请求类型时，配置文件管理模块420可与应用410通信以执行相关联的请求。</p>
    <p>在一种配置中，认证servlet 420和应用420可经由安全HTTP连接412通信。认证servlet 420可通信地耦合到用于认证用户的验证模块430。在一种配置中，认证servlet 420可经由Java本地接口 （JNI) 414与验证模块430通信。JNI 414在程序组件之间提供程序设计语言翻译。例如，认证servlet 420可以Java编写，而验证模块430可以C编写。JNI 414提供了从一种格式向另一格式传输数据同时保留代码和数据的结构方面的接口。验证模块430可向应用410传送信息或从其接收信息。值得注意的是，移动设备102、 HTTPS 412、认证servlet 420和JNI 414在语音认证服务器（130)上的验证模块420与移动设备102上的应用（410)之间建立通信通道。</p>
    <p>在实践中，移动设备102可将用户配置文件142 (参见图2)发送到验证模块420。例如，当用户期望访问供给移动设备的一个或多个资源或服务时，移动设备102可引入应用410。当用户创建用户配置文件时，移动设备也可引入该应用。例如，应用410可以是要求用户说出密码短语的J2ME应用。应用410还可访问移动设备102上的诸如IMEI号的设备标识符。该信息可用于创建用户配置文件。在特定设备中，IMEI号提取机制可不通过J2ME来支持。因此，这些设备可包括供用户键入该用户易于记住并用于认证的短PIN的装置。如果不支持IMEI号，则可要求用户键入PIN，然后该PIN可用于批准发送所存储的IMEI号。</p>
    <p>在一种配置中，移动设备102可包括用于证实密码短语的话音识别引擎。可理解地，语音识别引擎仅评估短语被识别但并非用户的身份。因此，可在移动手持式设备上执行语音认证的第一方面；即，验证密码短语。可在服务器上评估生物计量声纹认证和设备标识符。因而，可在服务器上执行语音认证的第二方面。</p>
    <p>或者，可在服务器130上执行包括话音识别的整个语音认证。在这种情况中，应用410可创建包括密码短语（144)、生物计量声纹（146)和IDEI (148)的用户配置文件142 (参见图2)。在说出口令短语时，J2ME应用410可将用户配置文件发送到验证服务器。在一种配置中，J2ME应用410可对口头话语(即，密码短语）执行语音处理，并在创建用户配置文件并将其发送到验证模块430之前对生物计量语音的一个或多个特性进行编码。编码可压&#32302;语音数据以减小发送口头话语所需的语音分组的大小。例如，语音数据可使用本领域中众所周知的声码器（vocoder)来压&#32302;。在第二配置中，口头话语可以非压&#32302;格式发送到验证模块430。例如，可以脉冲编码调制（PCM)格式或微软波形格式（Microsoft Wave Format)   (WAV)来发送。</p>
    <p>配置文件管理模块420可与servlet 420通信以评估存储在声纹数据库140中的一个或多个用户配置文件。配置管理模块420可创建、更新和删除用户配置文件。配置文件管理模块420还可与其它配置文件管理系统同步。例如，配置文件管理模块420可曝露API以便在成功认证用户之后与外部系统集成。在一种配置中，应用程序设计接口 （API)允许应用开发者快速地根据本文所讨论的语音认证系统的诸方面来集成其应用。例如，参看图2， API可包括用于创建生物计量声纹的模块（144)、用于创建密码短语的模块（142)和用于标识设备的模块（146) 。 API向认证servlet420提供接口以访问声纹创建和认证服务。</p>
    <p>配置文件管理模块420可经由Java数据库连接（JDBC) 416接口来与声</p>
    <p>16纹数据库140通信。JDBC 416可提供用于从声纹数据140检索和向其存储数据的数据访问。例如，声纹数据库140可以是由如本领域中所公知可被索引成行列格式化的关系数据库。JDBC 140提供了在声纹数据库140内定位报头和字段的结构化&#26619;询语言。配置文件管理模块420可针对生物计量声纹解析用户配置文件并将该生物计量声纹与声纹数据库140中的其它声纹作比较。在一种配置中，生物计量声纹可使用供以索引的移动手持式设备的IMEI号来存储。值得注意的是，声纹数据库140包括来自具有经注册声纹的多个用户的一个或多个参考声纹。在确定与声纹的匹配时，配置文件管理模块420可准许用户对一个或多个资源的访问。例如，配置文件管理模块420可允许到一个或多个安全站点、商业数据库、财务中心等的套接字连接。</p>
    <p>参照图5，示出了用户配置文件创建的流程图。用户配置文件创建可包含比所示步骤更多或更少的步骤。将参照图4描述这些步骤。在步骤501，用户启动该应用。例如，参照图4，用户激活J2ME应用410。或者，用户可访问web站点、语音邮件、或者请求要求诸如登录屏幕的认证的服务。在这种情况中，设备可自动地启动用于对用户授权的J2ME应用410。在步骤502，提示用户记录其用于声纹创建的语音。用户可提交用户将在语音认证期间陈述的特定短语。在步骤503，用户使用所提供的应用（410)来记录他们的语音。在步骤504，用户可输入PIN号。再次地，如果应用不从设备检索IMEI号，则可能需要PIN号。如果应用410可访问IMEI，则可不需要PIN号。在步骤505，提示用户注册其配置文件。例如，用户可选择在声纹数据库上存储最新创建的甩户配置文件以备将来的检索。在步骤506，注册细节连同所记录的语音被发送到认证服务器。在507，认证服务器（130)创建用户声纹。在步骤508，认证服务器（130)使用用户声纹和IMEI (或PIN)来创建用户配置文件。例如，用户配置文件可被存储在声纹数据库（140)中。在509，认证服务器（130)使用肯定确认来向用户作出响应。</p>
    <p>参照图6，示出了通过语音认证600来验证用户的流程图。认证600可包含比所示步骤的数量更多或更少的步骤。还将参照图4以便描述与实践这些步骤相关联的组件。在步骤601，用户启动应用。应用还可基于用户动作一诸如访问需要认证的特征或服务一来自动启动。在步骤602，提示用户记录其语音用以声纹验证。这是与在用户配置文件创建500期间被记录的相同的短语。在步骤603，用户使用所提供的应用（140)来记录其语音。在步骤604，用户入用于在用户配置文件创建500期间向认证服务器注册的PIN。在步骤605，认证细节连同所记录的语音被发送到认证服务器（130)。在步骤606，认证服务器使用用户PIN检索用户的声纹。在步骤607，认证服务器（130)使用验证模块来对照一个或多个所存储的声纹来验证用户所记录的语音。在步骤608，认证服务器向用户作出响应。在步骤609，如果认证成功，则用户可进一步进行服务或应用。在步骤610，如果认证不成功，则提示用户认证失败，并且应用退出。</p>
    <p>参照图7，示出了用于设备上的语音认证的方法700。该方法可包括从用户接收一个或多个口头话语（702)、识别与一个或多个口头话语相对应的短语（704)、根据该短语的一个或多个口头话语的变化性来标识用户的生物计量声纹（706)、确定与设备相关联的设备标识符（708)、以及基于该短语、生物计量声纹和设备标识符来认证用户（710)。具体地，在一种配置中，用户多次说出口头话语（例如密码短语）。可评估用户语音的变化以确定用户声道构造中的变化。在一种配置中，可确定设备或用户的位置（712)以便如先前图3中所述地准许访问。</p>
    <p>可在生物计量声纹中捕捉声道结构的变化，并与声纹数据库上的多个参考声纹作比较以标识匹配。即，响应于说话人的语音可生成第一声纹和至少第二声纹，第一声纹与第二声纹之间的差异可被标识，以及可判定该差异是否对应于说话人的声道的自然变化。值得注意的是，生物计量声纹是一种声道结构，该结构在物理上对用户的声道是唯一的。因此，如果差异表示说话人声道中的自然变化，则可认证说话人。</p>
    <p>例如，再次参看图3，实现语音认证方法700的设备102可建立到至少一个认证服务器的连接、向至少一个认证服务器发送用户配置文件、将用户配置文件与存储在至少一个认证服务器上的多个参考配置文件作比较、以及判定用户配置文件是否与用于认证用户的多个参考配置文件之一匹配。在识别到短语时，语音认证服务器或设备可评估口头话语之间的一个或多个声道结构差异。来自多个参考配置文件的一个或多个声道形状可基于声道结构差异来匹配。</p>
    <p>在前述中，提供了用于实践方法步骤700的语音认证系统的详细描述。具体地，参照图8，示出了语音认证系统的语音认证方面的算法800。该算法800是用于基于生物计量声纹分析证实用户的身份的底层语音处理方法的上层描述。这样，应当注意，算法800可包含比所示步骤数量更多或更少的步骤。实际上，每个步骤还可包含附图中未示出但在本说明书中阐述的步骤。在描述方法800时，将参照图4。</p>
    <p>在步骤802，言语话语可被分段成发声帧。例如，参照图4，用户讲入移动设 备102的密码短语（例如，口头话语）可被分割成浊音段和清音段。即，对应于诸 如元音的周期部分的部分可被归类为浊音，而对应于诸如辅音的非周期部分可归类 为清音。在步骤804，可根据浊音部分来计算线性预测编码（LPC)系数，并且在 步骤806，将其转换成线谱对（LSP) 。 LSP系数适用于压&#32302;和编码。在步骤808， 可根据LSP系数来计算共振峰。共振峰是话音频谱中对应于通过发声过程"形成" 的共振和静音的那些部分。具体地，人体话音生成系统的诸如喉、舌、嘴和嘴唇的 物理结构形成空腔，该空腔在从肺发射的压力波中形成共振。频域中的共振峰表示 在发声帧的发音过程中的用户声道形态的特征。在步骤810，在LPC/LSP分析期 间所提取的关于共振峰结构和特性的信息可被包括在特征矩阵中。在步骤812，特 征矩阵可被归一化。归一化的一个方面可包括移除背景噪声。归一化的第二方面可 包括说明声道结构的长度和面积。在步骤814，可从特征矩阵计算声纹和阈值。生 物计量声纹可包括表1中所示的特征。_</p>
    <p>1. 参考矩阵。用于声纹计算的特征矩阵之一。</p>
    <p>2. 自适应距离阈值（对数距离，LD)</p>
    <p>3. 特征矩阵中的每个特征矢量的变化范围。变化范围包括每个特征矢量值的最大 值和最小值。</p>
    <p>4. 从三个特征矩阵计算的两个平均值矢量。</p>
    <p>5. 通过对矩阵的行进行和求以及平均来计算平均矢量。</p>
    <p>6. 平均特征变化矢量。</p>
    <p>7. 平均特征差分矢量。_</p>
    <p>表l</p>
    <p>在实践中，用户可递交与在语音登记期间使用的密码短语相对应的口头话语； 即，在用户向语音认证服务器注册他们的生物计量声纹时。例如，在登记期间，用 户说出同一密码短语三次。针对密码短语的每一记录计算特征矢量矩阵。特征矩阵 是表示说话人的语音的特征的数值矩阵。在该情况中，三个特征矩阵用于形成生物 计量声纹。例如，参照表l中列出的所枚举的声纹，包括均值和范围的各个特征被 用在声纹中。表l的特征与三个矩阵结合使用，以定义声纹。例如，特征矩阵定义 了语音的特征，而表1的属性描述声道结构的变化。例如，表1的属性表示声道形状。值得注意的是，通过标识表1的生物计量声纹中定义的每个语音帧的特征矢量 的范围来捕捉密码短语的发音中的变化。例如，表1中的生物计量声纹的索引3 对一个或多个特征矢量的每个元素标识最大值和最小值。例如，范围可在密码短语 的发音期间标识自然发生的共振峰的振幅变化、共振峰的带宽变化、共振峰位置变 化，这对说出密码短语的用户是特殊的。</p>
    <p>在验证期间，用户说出对应于密码短语的同一口头话语，并且生成生物计量 声纹。对照先前存储的声纹来比较生物计量声纹以标识匹配。在验证过程中，还使 用在注册中所用的语音认证算法800来从所说短语计算特征矩阵。对照存储在声纹 数据库中的一个或多个参考矩阵来比较此特征矩阵。可针对生物计量声纹的每个特 征矩阵计算对数距离。如果对数距离小于预定阈值水平，则匹配可被确定，并且说 话人可被标识。验证过程的一个独特方面包括设置比较阈值水平，该水平取决于来 自声纹的阈值。该阈值取决于说话人自身的变化性，并可基于用户的语音来调节。 或者，阈值可设置被设置成阈值无关，并且不基于用户的语音来调节。</p>
    <p>在一个实现中，生成声纹的方法800可由手持式设备执行，而对用户授权一 用户的方法700可由与该手持式设备通信的服务器执行。参看图9，它示出了用于 实践生成该声纹的方法800的语音认证系统900的各种组件的图示。语音认证系统 900可包括语音处理器144和生物计量声纹分析器148。语音处理器144可从用户 接收口头话语和该口头话语的至少一次重复。生物计量语音分析器146可根据口头 话语及其至少一次重复来计算一个或多个声道形状，并基于口头话语及其至少一次 重复的不同发音来计算一个或多个声道形状之间的声道结构差异。声道结构差异对 应于与一个或多个口头话语相关联的用户声道的有限物理变化。例如，声道结构差 异可基于说明话音频谱随时间动态变化的动量谱。动量谱可包括话音的一个或多个 语音片断的下限和上限，使得上限与下限之间的话音频谱中的变化对应于唯一的声 道结构。</p>
    <p>在一个配置中，尽管并非必需，但是语音处理器144可包括话音识别器146。 话音识别器146可证实由用户在语音认证期间所说的短语。在一个方面中，话音识 别器146还可标识口头话语中的浊音和清音区段、从浊音区段识别一个或多个音素 (phoneme)、以及标识一个或多个音素在发声帧（例如，浊音段）中的位置。 语音处理器可将口头话语分段成一个或多个发声帧、从一个或多个发声帧生成 一个或多个特征矢量、从一个或多个特征矢量计算特征矩阵、以及在一个或多 个发声帧上对特征矩阵进行归一化。例如，可针对每个所说短语计算特征矩阵。口头话语可被分割成具有5与20ms之间的时间长度的一个或多个话音帧。</p>
    <p>语音处理器可标识话音帧中的绝对最小值和最大值。可将这些值与预定阈</p>
    <p>值比较。如果最大值和最小值小于振幅水平，则帧可被分类成不具有语音分量，</p>
    <p>而算法800进行到下一帧。如果最大值和最小值大于振幅水平，则可对话音帧</p>
    <p>信号计算自相关函数。如果一个或多个预指定自相关项小于预定阈值，则帧被</p>
    <p>认为缺少浊音信号，而算法800进行到下一帧。</p>
    <p>快速傅立叶变换（FFT)可应用到浊音加窗话音帧。该话音帧可与加权窗</p>
    <p>口相乘以说明频率分析之前的非连续性。FFT将N个样本的每个帧从时域变换</p>
    <p>到频域。在此步骤之后获得的结果是振幅谱或频谱。</p>
    <p>人体对话音信号的声音的频率成分的感知并不遵循线性标度。因此，Bark</p>
    <p>(巴克）标度可应用到振幅谱，以便从线性频率标度转换到接近人体听觉灵敏 度的标度。即，可对一个或多个发声帧执行感知滤波器组分析（perceptual filter bank analysis)。 一种用于模拟Bark频率的方法是使用滤波器组，每个期望 Mel (美）频率分量一个滤波器。滤波器组可具有三角形带通频率响应。间距 以及带宽由Bark频率间隔来确定。Bark频谱系数的个数IBR取决于频率范围。 电话信道频率范围3400Hz与17个Bark匹配。因此，0-3400Hz频率范围与17 个一Bark带宽滤波器匹配。每个滤波器带可具有三角形带通频率响应，并且间 距以及带宽可由常数Bark频率间隔来确定。根据Bark标度来移位的频谱频率 可称为Bark频谱。</p>
    <p>在Bark标度频率组上，Bark频谱XF(n,k)可乘以加权因子，而且对所有加 权因子的乘积可被求和以获得每个频带的能量。可对口头话语的每个话音帧计 算能量矩阵。例如，所说密码短语可被表示成矩阵E(m,i)。为了移除某些非期 望脉冲噪声，可使用三点中值滤波器（three-point median filter)来进行平滑。 经平滑的能量Es(m，i)可通过移除背景噪声的频率能量来归一化以获得与话音 信号Ev(m,i)相关联的原始能量。在一种配置中，背景噪声能量E。(m,i)可通过 对最初的8个话音帧的能量求平均值来估算。</p>
    <p>通过使用第m个帧Ev(m，i)的第i个频带的经平滑和归一化的能量，可计算</p>
    <p>21在第i个频带的话音信号的总能量：</p>
    <p>W)-gK(附，!')l</p>
    <p>阈值可按如下计算：</p>
    <p>如果T(i)&gt;1.5，则频带可维持完好，因为可认为存在比噪声更多的话音。 相反，如果阈值较小，则频带可被认为存在过多噪声，并且不被用于进一步的 计算。因此，当更多的频带超过1.5阈值时，反映了更高的话音内容。超过阈 值的频带可作为新的频带计数来计数。即，感知滤波器组分析包括估算沿Bark 频率标度的一个或多个频带中的话音能量和噪声能量。在感知滤波器组分析期 间，可通过丢弃话音能量与噪声能量之比不超过发声阈值的滤波器组来抑制背 景噪声。可使用新的频带计数来计算总信号能量：</p>
    <p>啦</p>
    <p>五。o)-2l五"w力l</p>
    <p>可对每个Ea(m)确定最小值和最大值。自适应发声分段阈值也可基于所确</p>
    <p>定的最小值和均方根项来计算：</p>
    <p>Tv = EaMin+0.3*RMS RMS-E"m)的标准偏差</p>
    <p>Ea(m)&gt; Tv的帧被分类为发声，并且可仅使用发声帧来计算新的矩阵。值 得注意的是，前述语音处理技术用于标识话音的语音片段，并基于话音的浊音 部分来计算特征矩阵。话音的浊音部分可包括可在口头话语中标识和定位的音 素。例如，参照图9，话音识别器146可标识音素。</p>
    <p>接着是浊音活度分析，可从感知滤波器组分析计算线性预测系数（LPC)。 预加重（pre-emphasis)可被应用到Ev(m,i)以减小频谱的动态范围。这改进了 LPC分析算法的数值属性。找到振幅频谱的最大值，并且可将该最大值之后的 所有点乘以加权系数。然后，可将LPC转换成线谱对系数（LSP's)。可从LSP's 计算共振峰和反共振峰，并且可从共振峰和反共振峰计算特征矢量。在确定共 振峰和反共振峰时，可计算每个话音帧的特征矢量。可针对表示口头话语的浊 音片段的特征矢量创建特征矩阵。特征矩阵可包括共振峰位置、共振峰振幅、 共振峰带宽、反共振峰位置、反共振峰振幅、反共振峰带宽、相位信息、平均 振幅信息、差分信息和动态特征。具体地，沿Bark标度表示出共振峰和反共振峰信息。可估算共振峰和反共振峰信息中的差异，以便表征声道结构中自然变 化的一个方面。g卩，可对一个或多个特征矢量来估算失真，以标识由类似声道 结构生成的声纹匹配。</p>
    <p>可从特征矩阵计算声道频谱。具体地，使用在口头话语的一次或多次重复 之间具有类似特性的共振峰来创建声道频谱。g卩，使用实质上有助于发声结构</p>
    <p>的一致表示的共振峰来创建声道频谱。声道频谱可从LPC或从自相关函数来计 算。对应于声道结构的声道形状中的变化可根据声道频谱中的变化来标识。具 体地，声道结构可被表示成具有相应长度和面积的一个或多个部分，该长度和 面积表征用户声道的一个或多个部分。声道结构差异对应于与一个或多个口头 话语相关联的用户声道的有限物理变化。例如，声道结构差异可基于说明话音 频谱随时间动态变化的动量谱。频谱振幅和频谱相位可发生动态变化。动量谱 可包括话音的一个或多个片断的下限和上限，从而话音频谱在下限与上限之间 的变化对应于唯一的声道结构。表1中呈现了特征矩阵的上限和下限。</p>
    <p>例如，参照图9，语音处理器944从与一个或多个发声帧相对应的口头话 语的多个部分的特征矢量来计算特征矩阵，其中特征矩阵是一个或多个发声帧 的特征矢量的级联。语音处理器944还通过移除比预定长度短的发声帧以及移 除与超出平均声道结构的声道结构相对应的发声帧来对特征矩阵进行归一化。 声道频谱可通过特征矩阵中的大量特征来表征或表示。从语音数据库的统计研 究选择这些特征的属性，以最小化说话人自身的变化性，而最大化说话人之间 的变化性。</p>
    <p>可理解地，在语音认证期间，生物计量语音分析器（参见图9)对照所存 储的说话人语音的特征矢量的标识参数来比较特征矢量的标识参数。这些参数 包括在表1的生物计量声纹中所捕捉的共振峰信息和反共振峰信息。值得注意 的是，生物计量声纹包括三个特征矩阵（与短语的三次重复相关联）以及表1 中表征用户声道形状的属性。即，声道形状通过特征矩阵来表征并可根据其来 计算。</p>
    <p>在计算特征矩阵以确定声道形状的过程中，将从该特征矩阵中所指定的最 初三个共振峰生成第一声道形状。声道形状曲线可从共振峰开始按0.2cm的增 量来计算。还可对发声帧计算声道长度。例如，生物计量语音分析器从第一生 物计量声纹的较低共振峰计算第一声道形状、基于该第一声道形状确定声道结 构的差异、标识提供最小声道结构差异的类似声道形状、以及从该第一生物计量声纹的较高共振峰形成类似声道形状。着重较大共振峰频率来表征说话人的 发音风格的一个方面。</p>
    <p>再次参看图9，生物计量语音分析器944根据特征矢量来确定一个或多个</p>
    <p>声道横截面面积，并且对一个或多个声道横截面面积确定一个或多个声道长</p>
    <p>度。而且，当确定声道形状时，可考虑通信带宽。例如，可针对通常在140Hz 到4.6KHz之间的电话带宽来调节共振峰频率：Fl =640、 F2=1730、 F3=2860 和F4=3340。声道的横截面可基于经补偿的共振峰频率位置来更新。可基于话 音的一个或多个发声帧对声道形状确定声道横截面的平均值。例如，可为浊音 话音中声道形状的变化相对恒定的音素区域确定断面。</p>
    <p>可基于声道形状的变化性来创建变化范围以便为特征矩阵中的特征矢量 产生变化矢量。例如，生物计量语音分析器944计算变化矢量的对数距离，并 基于该对数距离确定阈值。该阈值用于确定对用户进行认证的声道结构差异是 否落在变化范围内。变化范围可被表示成诸如表1中所示的特征矢量的平均值 和标准偏差。生物计量语音分析器944还对变化范围计算直方图，基于最大值 计算导矢，并且基于矢量导矢计算个人直方图和第二变化范围。</p>
    <p>在验证期间，生物计量语音分析器944估算个人直方图以判定生物计量生 物是否与用于验证用户的身份的所述多个生物计量声纹之一相匹配。当个人直 方图的第一多个面元（bin)被填满，则身份有效，而其中当个人直方图的第二 多个面元被填满，则身份无效。值得注意的是，表1生物计量声纹中的特征信 息用于生成个人直方图，以确定用户声道形状何时与个人直方图相匹配。直方 图统计地标识生物计量声纹的特征是否为人们说话的特征。即，说话人声道形 状的变化可被估算并统计地与关联于特定用户声道结构的变化作比较。再次 地，可提供口头话语的多次递交以确定声道结构差异；即，声道形状的变化。 个人直方图提供了一种用于对用户分类和认证的实用检测方法。例如，在验证 期间，生物计量语音分析器计算对数距离，并估算用于确定个人直方图的第一 多个面元何时被填满的阈值。该阈值还可基于用户语音来调节。</p>
    <p>以上己参照具体实施例描述了益处、其它优点和问题的解决方案。然而， 益处、优点、问题的解决方案以及可使任何益处、优点或方案出现或变得显著 的任何元素不应当解释为任何或所有权利要求的关键、必需或本质特征或元 素。如本文所用的术语"包括"、"包含"或其任何变体旨在涵盖非排除性包 括，从而包括一系列元素的进程、方法、物品或装置并非仅包括那些元素，而是可包括未明确列出或这些进程、方法、物品或装置所固有的其它元素。还应 当理解，诸如第一和第二、顶部和底部等的关系术语如果有也仅用于区分不同 实体或动作，而并非一定要求或暗示这些实体或动作之间的任何实际的这种关 系或次序。</p>
    <p>可适当地在硬件、软件或硬件和软件的组合中实现本发明的实施例。适于 执行本文所述方法的任何类型的计算机系统或其它装置都是合适的。硬件和软 件的典型组合可以是具有计算机程序的通信设备，当加载和执行该程序时，可 控制该移动通信设备使其执行本文所述方法。本发明和系统的部分还可嵌入到 计算机程序产品中，该部分包括使得能够实现本文所述的方法的所有特征，而 且其被加载到计算机系统中时，能够执行这些方法。</p>
    <p>虽然已经示出并描述了本发明的优选实施例，但是应当明白，本发明的实 施例并不限于此。对于本领域技术人员而言，可进行许多更改、改变、变化、 替代或等效方案而不背离如由所附权利要求所定义的本发明的实施例的精神 和范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103237030A?cl=zh">CN103237030A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年4月25日</td><td class="patent-data-table-td patent-date-value">2013年8月7日</td><td class="patent-data-table-td ">深圳市中兴移动通信有限公司</td><td class="patent-data-table-td ">基于生物识别的用户认证方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104094132A?cl=zh">CN104094132A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月30日</td><td class="patent-data-table-td patent-date-value">2014年10月8日</td><td class="patent-data-table-td ">国际商业机器公司</td><td class="patent-data-table-td ">经由声波纹位置感知的基于区域的存在确定</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104184587A?cl=zh">CN104184587A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年8月8日</td><td class="patent-data-table-td patent-date-value">2014年12月3日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">声纹生成方法、服务器、客户端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104184587B?cl=zh">CN104184587B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年8月8日</td><td class="patent-data-table-td patent-date-value">2016年4月20日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">声纹生成方法、服务器、客户端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104541493A?cl=zh">CN104541493A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月5日</td><td class="patent-data-table-td patent-date-value">2015年4月22日</td><td class="patent-data-table-td ">苹果公司</td><td class="patent-data-table-td ">使用生物计量数据在设备之间进行无线配对和通信</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2011041977A1?cl=zh">WO2011041977A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年9月25日</td><td class="patent-data-table-td patent-date-value">2011年4月14日</td><td class="patent-data-table-td ">Dianyuan Xiong</td><td class="patent-data-table-td ">一种基于声纹识别和定位跟踪的交叉监控方法和系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0021320000">G06F21/32</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G07C0009000000">G07C9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0017100000">G10L17/10</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F21/32">G06F21/32</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L17/10">G10L17/10</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=PNdqBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07C9/00158">G07C9/00158</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2009年6月24日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年8月19日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年8月14日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/ca55a10ee2e6b3240c58/CN101467204A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%94%A8%E4%BA%8E%E7%94%9F%E7%89%A9%E8%AE%A1%E9%87%8F%E5%A3%B0%E7%BA%B9%E8%AE%A4%E8%AF%81%E7%9A%84%E6%96%B9%E6%B3%95.pdf?id=PNdqBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2-K2E4MwVxqp4FeurazFI45qAl5w"},"sample_url":"https://www.google.com/patents/reader?id=PNdqBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>