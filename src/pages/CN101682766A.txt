<!DOCTYPE html><html><head><title>专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="用于以分级流形式编码视频内容的装置和方法"><meta name="DC.contributor" content="克里斯托夫&#183;舍望斯" scheme="inventor"><meta name="DC.contributor" content="樊尚&#183;博特罗" scheme="inventor"><meta name="DC.contributor" content="热罗姆&#183;维耶龙" scheme="inventor"><meta name="DC.contributor" content="爱德华&#183;弗朗索瓦" scheme="inventor"><meta name="DC.contributor" content="汤姆逊许可公司" scheme="assignee"><meta name="DC.date" content="2008-5-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种以时间分级流形式编码视频内容的方法。所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行的第一场和第二场形成，每个所述第二逐行图像组的图像与所述第一隔行图像组的场相重合。所述方法包括下述步骤：按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场，其中M是大于1的整数，从而隔行图像的第二场紧随所述隔行图像的第一场之后编码，并且按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像作为。根据本发明的特征，所述第二预定编码顺序与所述第一预定编码顺序相同。"><meta name="DC.date" content="2010-3-24"><meta name="citation_patent_publication_number" content="CN:101682766:A"><meta name="citation_patent_application_number" content="CN:200880018814"><link rel="canonical" href="https://www.google.com/patents/CN101682766A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101682766A?cl=zh"/><meta name="title" content="专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法"/><meta name="description" content="本发明涉及一种以时间分级流形式编码视频内容的方法。所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行的第一场和第二场形成，每个所述第二逐行图像组的图像与所述第一隔行图像组的场相重合。所述方法包括下述步骤：按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场，其中M是大于1的整数，从而隔行图像的第二场紧随所述隔行图像的第一场之后编码，并且按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像作为。根据本发明的特征，所述第二预定编码顺序与所述第一预定编码顺序相同。"/><meta property="og:title" content="专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101682766A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101682766A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101682766A&amp;usg=AFQjCNFACMJAZQZUQoi0yLMAoOewEmTpqA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/075537ef0e0cf3506247/CN101682766A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/075537ef0e0cf3506247/CN101682766A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101682766A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101682766A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101682766A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101682766B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101682766A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种以时间分级流形式编码视频内容的方法。所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行的第一场和第二场形成，每个所述第二逐行图像组的图像与所述第一隔行图像组的场相...</span><span itemprop="url">https://www.google.com/patents/CN101682766A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法" title="专利 CN101682766A - 用于以分级流形式编码视频内容的装置和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101682766 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200880018814</td></tr><tr><td class="patent-bibdata-heading"> 专利合作条约 (PCT) 编号</td><td class="single-patent-bibdata">PCT/EP2008/056668</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年3月24日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2008年5月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年6月5日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101682766B?hl=zh-CN&amp;cl=zh">CN101682766B</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2163098A1?hl=zh-CN&amp;cl=zh">EP2163098A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2163098B1?hl=zh-CN&amp;cl=zh">EP2163098B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2008148708A1?hl=zh-CN&amp;cl=zh">WO2008148708A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200880018814.0, </span><span class="patent-bibdata-value">CN 101682766 A, </span><span class="patent-bibdata-value">CN 101682766A, </span><span class="patent-bibdata-value">CN 200880018814, </span><span class="patent-bibdata-value">CN-A-101682766, </span><span class="patent-bibdata-value">CN101682766 A, </span><span class="patent-bibdata-value">CN101682766A, </span><span class="patent-bibdata-value">CN200880018814, </span><span class="patent-bibdata-value">CN200880018814.0, </span><span class="patent-bibdata-value">PCT/2008/56668, </span><span class="patent-bibdata-value">PCT/EP/2008/056668, </span><span class="patent-bibdata-value">PCT/EP/2008/56668, </span><span class="patent-bibdata-value">PCT/EP/8/056668, </span><span class="patent-bibdata-value">PCT/EP/8/56668, </span><span class="patent-bibdata-value">PCT/EP2008/056668, </span><span class="patent-bibdata-value">PCT/EP2008/56668, </span><span class="patent-bibdata-value">PCT/EP2008056668, </span><span class="patent-bibdata-value">PCT/EP200856668, </span><span class="patent-bibdata-value">PCT/EP8/056668, </span><span class="patent-bibdata-value">PCT/EP8/56668, </span><span class="patent-bibdata-value">PCT/EP8056668, </span><span class="patent-bibdata-value">PCT/EP856668</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%A4%AB%C2%B7%E8%88%8D%E6%9C%9B%E6%96%AF%22">克里斯托夫&#183;舍望斯</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%A8%8A%E5%B0%9A%C2%B7%E5%8D%9A%E7%89%B9%E7%BD%97%22">樊尚&#183;博特罗</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%83%AD%E7%BD%97%E5%A7%86%C2%B7%E7%BB%B4%E8%80%B6%E9%BE%99%22">热罗姆&#183;维耶龙</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%88%B1%E5%BE%B7%E5%8D%8E%C2%B7%E5%BC%97%E6%9C%97%E7%B4%A2%E7%93%A6%22">爱德华&#183;弗朗索瓦</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B1%A4%E5%A7%86%E9%80%8A%E8%AE%B8%E5%8F%AF%E5%85%AC%E5%8F%B8%22">汤姆逊许可公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101682766A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101682766A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101682766A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (19),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200880018814&amp;usg=AFQjCNHe9mBl1Km5eNn5IuCn9RDO2yc_qg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101682766A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFstgUl7Pe5Sxse0i3zsFFBu8gecA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT94173857" lang="ZH" load-source="patent-office">用于以分级流形式编码视频内容的装置和方法</invention-title>
      </span><br><span class="patent-number">CN 101682766 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA75250178" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种以时间分级流形式编码视频内容的方法。所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行的第一场和第二场形成，每个所述第二逐行图像组的图像与所述第一隔行图像组的场相重合。所述方法包括下述步骤：按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场，其中M是大于1的整数，从而隔行图像的第二场紧随所述隔行图像的第一场之后编码，并且按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像作为。根据本发明的特征，所述第二预定编码顺序与所述第一预定编码顺序相同。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(4)</span></span></div><div class="patent-text"><div mxw-id="PCLM31582292" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种以包括底层和增强层的时间分级流形式编码视频内容的方法，所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行的第一场和第二场形成，每个所述第二逐行图像组的图像与所述第一隔行图像组的场相重合，所述方法包括下述步骤：    按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场作为底层(10)，其中M是大于1的整数，从而隔行图像的第二场紧随所述隔行图像的第一场之后编码，并且    按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像作为增强层(20)，其特征在于，    所述第二预定编码顺序与所述第一预定编码顺序相同。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. 根据权利要求l所述方法，其中所述第一隔行图像组的图像的第二 场以高于所述图像的第一场编码的时间级的时间级编码，并且与所述第二 场重合的第二逐行图像组的图像以高于与所述第一场重合的第二逐行图 像组的图像编码的时间级的时间级编码。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. 根据权利要求1或2所述方法，其中以给定时间级编码的场根据在低于或者等于给定时间级的时间级先前编码的场完全或者部分编码。</div>
    </div>
    </div> <div class="claim"> <div num="4" class="claim">
      <div class="claim-text">4. 一种以包括底层和增强层的时间分级流形式编码视频内容的装置， 所述内容由第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图 像组由隔行的第一场和第二场形成，每个第二逐行图像组的图像与第一隔 行图像组的场相重合，所述方法包括下述步骤：第一编码装置（64)，用于按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场作为底层，.其中M是大于1的整数，从而隔行图像的第 二场紧随所述隔行图像的第一场之后编码，和第二编码装置（68)，用于按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像作为增强层，其特征在于， 所述第二预定编码顺序与所述第一预定编码顺序相同。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES36881887" lang="ZH" load-source="patent-office" class="description">
    <p>用于以分级流形式编码视频内容的装置和方法</p>
    <p>技术领域</p>
    <p>本发明总体上涉及以时间分级流形式编码视频内容的领域。具体而 言，本发明涉及用于以时间分级流形式编码视频内容的装置和方法，其中</p>
    <p>所述视频内容由第一隔行图像组（a first group of interlaced pictures)和第 二逐行图像组（a second group of progressive pictures)表示，所述隔畔亍图 像由隔行的（interlaced)第一场和第二场形成。</p>
    <p>背景技术</p>
    <p>多层编码（multi-layer coding)方法适于以编码数据的分级流形式 编码视频内容。可分级性（scalability)表示对信息进行分级以使该信 息能够以数个分辨率和/或质量和/或时间频率等级编码的能力。由这种类 型的编码方法产生的数据流一般被分为数个层，具体而言是底层（base layer)以及一个或多个增强层（enhancement layer)。这种编码方法能 够使视频内容以单一流形式编码但例如适于接收装置的各种能力（从CPU 意义而言显示装置的特征等方面）。第一接收装置只能解码所述流关于底 层的一部分，而更有效的第二接收装置解码整个流。这种编码方法对于以 单一流形式编码图像特别有效，其中底层相对于内容的第一版本，例如HD 1080i30Hz版本，增强层相对于相同视频内容的第二版本，例如HD 1080p 60Hz版本。这种编码数据流非常适合用能够以HD 1080i 30Hz格式重建 (reconstruct)内容 现有解码平台来解码。此相同内容将来还能够用以HD 1080p 60Hz格式重建内容的未来解码平台来解码。现有平台只解码 所述流相对于底层的部分，而未来的平台将解码整个流。</p>
    <p>这种编码方法适于通过采用名为层间预测（inter-layer prediction) 的工具由底层图像部分编码增强层图像或图像的部分（例如块或宏块）。 这种工具在2007年1月出版的名为"Joint Draft 9 of SVC amendment" 的ISO/IEC MPEG和ITU-T VCEG的文件JVT-V201中定义。i亥文件描述了 MPEG-4AVC与可分级性相关的SVC扩展。更具体地，增强层图像的图像数 据块被空间预测（帧内编码模式）或时间预测（帧间编码模式）。在后一 种情况下，根据标准预测模型从增强层的图像块（例如双向预测模型 (bidirectional prediction mode)、直接予员测模型（direct prediction mode)、预期预测模型（anticipated prediction mode)等）进行预观U， 或者根据层间预测模型从底层的图像块进行预测。在后一种情况下，运动 数据（例如将宏块划分为块，可能的运动矢量和参考图像索引）以及与增 强层的图像块相关的可能的图像数据从与底层的图像块相关的图像数据 的运动数据分别推导（deduced)或继承（inherited)而来。</p>
    <p>并且，已知某些编码方法适于根据用于逐行图像的例如图l所示层次 图像组GOP (Group Of Pictures)结构每GOP地编码视频内容。在图1 中，根据二元图像间时间相依性结构（M.Flierl et B. Girod， "Generalized B Pictures and the Draft JVT/H. 264 Video Compression standard" ， IEEE Trans, on Circuits and Systems for Video Technology' vol. 13， pp. 587-597， 2003年7月）对G0P进行编码。图像之间的时间 相依性由虚线显示。图像2时间相依于图像0和4， SP，图像2或图像2</p>
    <p>5的一部分可以根据图像0和4通过时间预测进行编码。根据这种结构，图</p>
    <p>像在多个时间级（temporal level)上被编码，给定时间级上的图像只能 够根据低时间级或者相同时间级的图像以及先前编码的其自身来进行编 码。这种结构被称为二元（dyadic),当给定时间级位于频率F，如果下一 时间级的图像被加入，则获得等于前一频率两倍的频率，即2F。这种结构 的优点是能够通过提供高压&#32302;比产生时间分级数据流。事实上，通过忽略 较高时间级，即通过不解码与这些时间级相关的编码数据流，相对于通过 解码整个编码数据流而重建的视频的时间频率，此视频的时间频率将减 小。为了达到此目的， 一项时间级信息被插入至流中。该信息特别地由解 码方法使用以识别与给定时间级相关的编码数据分组（data packet),并 因而识别需忽略的编码数据分组以在给定频率重建视频内容。根据SVC标 准，时间级信息编码于每个NAL (网络适配层）型分组的头（header)中。</p>
    <p>在隔行视频的情况下，每个图像由隔行的第一场和第二场形成。当隔 行视频以图像模式编码时，图像的两场同时编码。当隔行视频以场模式编 码时，图像的两场连续地编码，即第二场紧随在第一场之后编码。这种类 型编码的有益之处在于能够降低解码器需要的存储空间。事实上，如果同 一图像的两场未连续编码，如果需要，在解码器侧，将重建的第一场存储 在存储器中，直至第二场本身被重建，从而能够恢复整个图像。这种方法 需要更多的存储空间。</p>
    <p>如果所述第一场是所谓的奇场或顶场（TOP场），则第二场是偶场或底 场（BOTTOM场），反之亦然。在逐行视频的情况下使用图1所示层次G0P 结构，在以场模式编码的隔行视频情况下，用组成图像的两场替换图像，如图2所示。在此图中，顶场由实线显示，底场用虚线显示。在图2中，</p>
    <p>系数为k的隔行图像由顶场kT和底场kB构成。在此图中，图像2的两场 2T和2B连续编码，即图像2的第二场紧随图像2的第一场编码。这使得 对图像2的编码并因而对于所述图像未来的解码不引入任何时间。在此图 中，场2T的全部或者部分都可以根据先前编码的场0T、 0B、 4T和4B编 码。请注意此场还可以以帧内模式（即独立于该序列的任何其他图像）全 部或者部分地编码。对于场2B，可以根据先前编码的场OT、 0B、 4T和4B 以及根据场2T编码。此结构在隔行的情况下具有与逐行的情况相同的优 点（即高压&#32302;率和时间分级性）。</p>
    <p>另外，在已知的多层编码方法中，底层和增强层根据图l和图2所示 的层次GOP结构进行编码。这种两层层次GOP结构（即隔行的底层和逐行 的增强层）示于图3。在此图中，增强层的逐行图像由系数k表示。时间 戳（timestamp)与增强层的每个图像以及底层的每个场相关联。在图3 中，具有相同时间戳的增强层的图像以及底层的场垂直地重合。增强层的 图像可以根据在底层中对应的即具有相同的时间戳的场利用层间预测工 具进行编码，或者根据增强层的一个或多个先前编码的图像甚至独立于该 序列的其他图像进行编码（帧内编码）。例如，增强层的图像2可以由底 层的场1T的数据利用层间预测方法进行全部或者部分编码。但是，当这 种结构用于SVC标准的范畴之内时,增强层的某些图像不能利用层间预测。 时间级3的图像就是这种情况。事实上，SVC标准只允许相同时间级的图 像之间的层间预测。但是，图像1位于时间级3，而相同时间戳的场即场 0B位于时间级0。并且，通过"型（profile)"的定义，SVC标准限制了适于存储参考图像的存储空间。由于存储空间的这种限制，在增强层的图 像的编码过程中，图像0B不再出现在所述参考图像存储器中。事实上，</p>
    <p>图像和帧是按照下面的顺序编码：0T、 0B、 0、 4B、 4T、 8、 2T、 2B、 4、 1T、 1B、 2、 3T、 3B、 6、 1、 3、 5、 7、 9。因此，假设参考图像存储器的 容量能够存储4个参考图像，则在图像1的编码过程中无法使用图像0T、 0B和0作为参考。为了在图像1与对应的场OB之间进行层间预测，必须 在存储器中存储15个参考图像。这种无法通过层间预测编码增强层的某 些图像的事实对于编码性能有负面影响。</p>
    <p>发明内容</p>
    <p>本发明的目的是克服现有技术的至少一个缺点。</p>
    <p>本发明涉及一种以时间分级流形式编码视频内容的方法。所述内容由 第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行 的第一场和第二场形成，每个第二逐行图像组的图像与第一隔行图像组的 场相重合。所述方法包括下述步骤：</p>
    <p>按照第一预定编码顺序在M个时间级上编码第一隔行图像组的场，其 中M是绝对大于1的整数，从而隔行图像的第二场紧随隔行图像的第一场</p>
    <p>之后编码，并且</p>
    <p>按照第二预定编码顺序在M个时间级上编码第二逐行图像组的图像。 根据本发明，第二预定编码顺序与第一预定编码顺序相同。 优选地，所述方法使增强层的每个图像根据底层的场通过层间预测进 行完全或者部分编码。</p>
    <p>根据本发明的另外一个方面，以绝对高于第一隔行图像组的图像的第一场编码的时间级的时间级编码第一隔行图像组的图像的第二场，并且以 绝对高于与第一场重合的第二逐行图像组的图像编码的时间级的时间级 编码与第二场重合的第二逐行图像组的图像。</p>
    <p>根据本发明，根据在低于或者等于给定时间级的时间级先前编码的场 完全或者部分编码以给定时间级编码的场。</p>
    <p>本发明涉及一种以时间分级流形式编码视频内容的装置。所述内容由 第一隔行图像组和第二逐行图像组表示，其中所述第一隔行图像组由隔行 的第一场和第二场形成，每个第二逐行图像组的图像与第一隔行图像组的 场相重合。所述装置包括：</p>
    <p>第一编码装置，用于按照第一预定编码顺序在M个时间级上编码第一 隔行图像组的场，其中M是绝对大于1的整数，从而隔行图像的第二场紧 随隔行图像的第一场之后编码，并且</p>
    <p>第二编码装置，用于按照第二预定编码顺序在M个时间级上编码第二</p>
    <p>逐行图像组的图像。</p>
    <p>根据本发明，第二预定编码顺序与第一预定编码顺序相同。</p>
    <p>附图说明</p>
    <p>通过下面参照附图对本发明实施方式的详细说明，本发明的上述方 面、特点和优势将得到更清楚的理解。其中：</p>
    <p>图r是根据现有技术的逐行图像组的层次结构；</p>
    <p>图2是根据现有技术的隔行图像组的层次结构；</p>
    <p>图3是根据现有技术的图像组的多层结构；</p>
    <p>图4是根据本发明第一实施方式的图像组的多层结构；图5是根据本发明第二实施方式的图像组的多层结构； .图6示出了根据本发明的编码方法；图7示出了根据本发明的编码装置；图8示出了根据本发明另一方式的编码装置。具体实M^r式本发明涉及一种以时间分级流形式编码视频内容的方法和装置。所述 内容由第一隔行图像组和第二逐行图像组表示，即所述第一隔行图像组由 隔行的第一场和第二场形成，每个第二逐行图像组的图像与第一隔行图像 组的场时间相重合，即具有相同时间戳。被称为底层图像的所述第一隔行 图像组的图像以底层的形式编码，被称为增强层图像的所述第二逐行图像 组的图像以增强层的形式编码。下面将参照图4和图6说明本发明的第一实施方式，其中具有第一M/2 隔行图像组、即M场，以及第二M逐行图像组，其中M是正整数。在图4 和图6中，M=10。 10个图像或场根据层次GOP的二元结构在3个时间级0， 1和2上编码。本发明包括底层的隔行图像的场模式的编码步骤10。例如， 底层的图像根据IS0/IEC文件14496-10: 2005中定义的MPEG-4 AVC编码， 时间相依性由根据图2定义的G0P结构确定。底层的帧按照预定的编码顺 序进行编码。在本实施例中，时间级O的场在更高时间级的场之前按照下 面的顺序进行编码：0T、 0B、 4T和4B。然后时间级1的场按照下面的顺 序编码：2T和2B并可以根据时间级0的场进行编码。随后，时间级2的 场按照下面的顺序进行编码：1T、 1B、 3T和3B。场1T根据先前编码的较 低层的帧完全或部分编码并且在其编码时仍存储在存储器中。类似地，场1B、 3T和3B根据较低时间级的场或者根据相同的先前编码的时间级进行 编码。本发明的步骤10与根据图2所示的现有技术的方法的底层编码方 法相同。根据本发明，在步骤20中，增强层的图像根据图1和图3中所示的 现有技术的标准层次GOP结构进行编码。根据此目的，对图3中所示的G0P 结构进行修改，使增强层图像按照与底层的场相同的编码顺序进行编码。 与底层相同图像的两场时间重合的增强层的两个图像连续编码，第二图像 紧随在第一图像之后编码，这与标准结构是不同的。例如，采用标准层次 G0P结构，图像1并非紧随在图像0之后编码。事实上，在图像0和1之 间，图像8、 4、 2和6被编码。新的层次GOP结构使得增强层的图像能够按照与底层相同的编码顺序 成对编码，即与底层的图像的第二场具有相同时间戳的增强层的图像紧随 与底层的图像的第一场具有相同时间戳的增强层的图像编码。在此实施方 式中，图像和帧按照下述顺序编码：0T、 0B、 0、 1、 4T、 4B、 8、 9、 2T、 2B、 4、 5、 1T、 1B、 2、 3、 3T、 3B、 6、 7。底层的图像因而按照下述顺序 编码：0、 1、 8、 9、 4、 5、 2、 3、 6、 7，与底层的场的编码顺序相同，即 0T、 0B、 0、 1、 4T、 4B、 2T、 2B、 1T、 1B、 3T、 3B。因此，假设参考图像 存储器具有存储4个参考图像的容量，因而在图像1的编码过程中可以利 用图像0T、 0B和0作为参考，而这与图3所示的二元G0P结构不同。在 后一种情况中，需要存储15个参考图像以使得图像1能够受益于层间预 测。因此，系数2k的增强层图像能够受益于k顶场的层间预测，而图像 2k+l受益于k底场的层间预测。因为图像2k和图像2k+l连续编码，即与底层的场具有相同编码顺序，k底场不可用的问题不会产生。因而具有奇 数系数的图像能够受益于其对应的底场（图4中灰色矩形所示）的层间预 测，这使得视频内容的编码效率得以提高。这种GOP结构给予用于增强层 的全部图像的层间预测优先级。但是，虽然其通过除去（shedding)更高时间级即时间级2的图像获 得时间可分级性，时间可分级性没有图3所示G0P结构精细，因为两个连 续图像需要被除去，例如图像2和3以及图像6和7。根据本发明的另外一个方面，在参照图5的说明中，与图像和场相关 联的时间级相应于图4所示的图像和场的时间级进行修改。在SVC标准框 架内，时间级如上所述编码在每个NAL单元的头中。根据本发明，对于底 层的每个图像，时间级与所述图像的第二场即底场相关联，其高于与所述 图像的第一场即顶场相关联的时间级。例如，时间级0与场OT相关联， 时间级3与场0B相关联，时间级1与场2T相关联，时间级4与场2B相 关联。类似地，对于增强层的每个图像对，时间级相关联于与所述底层的 图像的第二场（即图5中的底场）重合的所述对，其高于相关联于与所述 底层的图像的第一场（即图5中的顶场）重合的所述对的图像的时间级。 更一般而言，高于底层的顶场的时间级并分别高于偶数系数增强层图像的 时间级的时间级被分配给底层的全部底场和奇数系数增强层的全部图像。 一般而言，时间级因而按照下列方式与图像和帧相关：对于i=0至N-l，其中N是满足下列条件的正整数2N+2=M，即 N二log(M-2)/log2。对于底层，对于满足k*2N&#8212;1处于0和2N-1之间的任何系数k:时间级i与系数k*2N&#8212;1的顶场相关联； 时间级i+N分配给系数k*2N&#8212;i的底场。对于增强层，对于满足k*2N+1&#8212;'处于0和2X+1-1之间的任何系数k: 时间级i与系数k*2N+1&#8212;i的图像相关联；时间级i+N与系数l+k*2N+1&#8212;i的图像相关联。并且，为了符合svc编码标准的规定，给定时间级的场或图像不能根据更高时间级的图像或者根据先前未编码的图像编码。例如，根据本发明，与时间级3相关联的图像1不能用作与时间级2相关联的图像2的时间参 考。有利地，通过不解码与最高时间级（即时间级3、 4和5)对应的NAL 单元可以获得与图3所示的二元G0P结构相同的时间分级性。因此，通过 将时间级与图像和场相关联，增强层的全部图像可以通过利用层间预测由 底层的相应场进行编码，同时保持更好精细度的时间可分级性。请参看图7，本发明涉及编码装置6。图7中只示出本发明的主要元 件。现有技术的视频编码器中对于本领域普通技术人员已知的元件（例如 运动估计模块、运动补偿模块等）在图中未示出。所示模块均为功能单元， 在可以对应或者不对应物理上可以区分的单元。例如，这些模块或者其中 的部分模块可以分组为单一部件或者构成同一软件的功能。另一方面，某 些模块可以构成不同的物理实体。所述编码装置包括第一输入60、第二输 入62、第一编码模块64、第一存储器66、第二存储器67、第二编码模块 68、复用模块70和输出72。第一输入60用于接收表示视频内容的第一隔行图像组II，称为底层 图像。第二输入62用于接收表示相同视频内容的第二逐行图像组I2，称为增强层图像。第一编码模块64用于从第一输入60接收底层的隔行图像 并以第一流si的形式按照场模式编码所述图像。底层的图像例如根据视 频编码标准MPEG-4 AVC编码，场之间的时间相依性由图2所示层次G0P 结构确定。出于此目的，按照预定的编码顺序对所述场进行编码。场可以 根据先前编码的场完全或者部分编码，并重建以及存储在第一存储器66 中。在编码并重建之后，场可以存储在第一存储器66和第二存储器67中。 第一编码模块执行根据本发明方法的步骤10。</p>
    <p>根据本发明的重要特征，第二编码模块68用于从第二输入62接收增 强层的逐行图像并以第一流S2的形式按照与底层的场相同的编码顺序编 码所述图像。与底层的相同图像的两场时间重合的增强层的两个图像连续 编码，第二图像紧随在第一图像之后编码，这与标准结构不同。例如，采 用标准层次GOP结构，图像1不是紧随在图像0之后编码。事实上，在图 像0和1之间，图像8、 4、 2和6被编码。在编码并重建之后，场可以存 储在第二存储器66中。第二编码模块执行根据本发明方法的步骤20。</p>
    <p>复用模块70接收第一编码模块64和第二编码模块68的流Sl和S2 并将流Sl和S2复用为单一流S，该流S被发送至输出72。</p>
    <p>根据图8所示的不同实施方式，编码装置7包括单一输入80，用于接 收第二图像组。所述编码装置7还包括处理模块82，用于由第一图像组产 生第二图像组I2。</p>
    <p>根据本发明的另外一个方面，编码装置6用于根据本发明所述方法将 时间级与底层的场以及增强层的图像相关联。</p>
    <p>当然，本发明并不局限于所述实施方式。具体而言，本领域普通技术人员可以对所述实施方式进行任何改变以将其结合以获得各种优点。显 然，在SVC视频编码标准的框架内对本发明进行了说明，但是本发明并不 局限于所属标准。本发明以两层为例进行了说明，即隔行图像的底层和逐 行图像的增强层，但是本发明也可以扩展至数个增强层。另外，在将底层 图像编码为场模式的框架内对本发明进行了说明，其中顶图像（top picture)在底图像（bottom picture)之前编码（"顶场优先"模式）， 但本发明也可以按照相同方式应用于将底层图像编码为场模式的情况，其 中底图像在顶图像之前编码（"底场优先"模式）。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103313054A?cl=zh">CN103313054A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月22日</td><td class="patent-data-table-td patent-date-value">2013年9月18日</td><td class="patent-data-table-td ">中国科学院声学研究所</td><td class="patent-data-table-td ">可伸缩视频编码svc视频的传输调度方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103313054B?cl=zh">CN103313054B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月22日</td><td class="patent-data-table-td patent-date-value">2016年5月4日</td><td class="patent-data-table-td ">中国科学院声学研究所</td><td class="patent-data-table-td ">可伸缩视频编码svc视频的传输调度方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0007460000">H04N7/46</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0007500000">H04N7/50</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0007260000">H04N7/26</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/59">H04N19/59</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/577">H04N19/577</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/16">H04N19/16</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/31">H04N19/31</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/61">H04N19/61</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/187">H04N19/187</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/114">H04N19/114</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=KyN4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/172">H04N19/172</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">H04N7/26A8P</span>, <span class="nested-value">H04N7/46S</span>, <span class="nested-value">H04N7/26A8Y</span>, <span class="nested-value">H04N7/26E2</span>, <span class="nested-value">H04N7/50</span>, <span class="nested-value">H04N7/46E</span>, <span class="nested-value">H04N7/26A4C6</span>, <span class="nested-value">H04N7/26A6S4</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年3月24日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年7月21日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/075537ef0e0cf3506247/CN101682766A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%94%A8%E4%BA%8E%E4%BB%A5%E5%88%86%E7%BA%A7%E6%B5%81%E5%BD%A2%E5%BC%8F%E7%BC%96%E7%A0%81%E8%A7%86%E9%A2%91%E5%86%85.pdf?id=KyN4BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2AHwgigrHWDbl7XVABdASo0fJKIg"},"sample_url":"https://www.google.com/patents/reader?id=KyN4BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>