<!DOCTYPE html><html><head><title>专利 CN103049728A - 基于二维码的增强现实方法、系统及终端 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_50a6672b5f82ffbd39b7a9e87fd4594c/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_50a6672b5f82ffbd39b7a9e87fd4594c__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于二维码的增强现实方法、系统及终端"><meta name="DC.contributor" content="柳寅秋" scheme="inventor"><meta name="DC.contributor" content="李薪宇" scheme="inventor"><meta name="DC.contributor" content="宋海涛" scheme="inventor"><meta name="DC.contributor" content="成都理想境界科技有限公司" scheme="assignee"><meta name="DC.date" content="2012-12-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于二维码的增强现实方法，以二维码作为增强现实系统中的识别与定位标识，对真实场景图像中的二维码进行解码与再编码直接生成与之码制一致的二维码正视图，分别对二维码正视图的定位模组区域以及场景图像中的二维码图像的定位模组区域进行对应角点检测及提取，以计算单应性矩阵时，相应的，本发明还公开了基于二维码的增强现实系统及移动终端，既打破了传统增强现实应用中，必须在数据库中预先存储对应样本图像才能进行跟踪匹配的局限性，又避免了使用传统标识物的时候向远程服务器的模板查询与匹配步骤，能够减少因网络传输问题造成的系统响应延迟，节约用户的网络通信流量。"><meta name="DC.date" content="2013-4-17"><meta name="DC.relation" content="CN:102497331:A" scheme="references"><meta name="DC.relation" content="CN:102799883:A" scheme="references"><meta name="DC.relation" content="CN:102800065:A" scheme="references"><meta name="DC.relation" content="CN:102821323:A" scheme="references"><meta name="DC.relation" content="US:20120327117:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103049728:A"><meta name="citation_patent_application_number" content="CN:201210586767"><link rel="canonical" href="https://www.google.com/patents/CN103049728A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103049728A?cl=zh"/><meta name="title" content="专利 CN103049728A - 基于二维码的增强现实方法、系统及终端"/><meta name="description" content="本发明公开了一种基于二维码的增强现实方法，以二维码作为增强现实系统中的识别与定位标识，对真实场景图像中的二维码进行解码与再编码直接生成与之码制一致的二维码正视图，分别对二维码正视图的定位模组区域以及场景图像中的二维码图像的定位模组区域进行对应角点检测及提取，以计算单应性矩阵时，相应的，本发明还公开了基于二维码的增强现实系统及移动终端，既打破了传统增强现实应用中，必须在数据库中预先存储对应样本图像才能进行跟踪匹配的局限性，又避免了使用传统标识物的时候向远程服务器的模板查询与匹配步骤，能够减少因网络传输问题造成的系统响应延迟，节约用户的网络通信流量。"/><meta property="og:title" content="专利 CN103049728A - 基于二维码的增强现实方法、系统及终端"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103049728A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103049728A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=f1vwBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103049728A&amp;usg=AFQjCNG_4w6VCx5c39kRPTwnBMusyxZ_xg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/96be616b076e332532e2/CN103049728A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/96be616b076e332532e2/CN103049728A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103049728A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103049728A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN103049728A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN103049728B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103049728A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于二维码的增强现实方法，以二维码作为增强现实系统中的识别与定位标识，对真实场景图像中的二维码进行解码与再编码直接生成与之码制一致的二维码正视图，分别对二维码正视图的定位模组区域以及场...</span><span itemprop="url">https://www.google.com/patents/CN103049728A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103049728A - 基于二维码的增强现实方法、系统及终端</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103049728A - 基于二维码的增强现实方法、系统及终端" title="专利 CN103049728A - 基于二维码的增强现实方法、系统及终端"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103049728 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210586767</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年4月17日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年12月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年12月30日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103049728B?hl=zh-CN&amp;cl=zh">CN103049728B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210586767.8, </span><span class="patent-bibdata-value">CN 103049728 A, </span><span class="patent-bibdata-value">CN 103049728A, </span><span class="patent-bibdata-value">CN 201210586767, </span><span class="patent-bibdata-value">CN-A-103049728, </span><span class="patent-bibdata-value">CN103049728 A, </span><span class="patent-bibdata-value">CN103049728A, </span><span class="patent-bibdata-value">CN201210586767, </span><span class="patent-bibdata-value">CN201210586767.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9F%B3%E5%AF%85%E7%A7%8B%22">柳寅秋</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E8%96%AA%E5%AE%87%22">李薪宇</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AE%8B%E6%B5%B7%E6%B6%9B%22">宋海涛</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%88%90%E9%83%BD%E7%90%86%E6%83%B3%E5%A2%83%E7%95%8C%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">成都理想境界科技有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103049728A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103049728A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103049728A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=f1vwBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210586767&amp;usg=AFQjCNEEPuJzrtkjUIMkTLysp5L_O7Vj2A"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=f1vwBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103049728A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNF81UcmV7vqzY6VTFjUHFRFI03muw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT123276431" lang="ZH" load-source="patent-office">基于二维码的增强现实方法、系统及终端</invention-title>
      </span><br><span class="patent-number">CN 103049728 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA110159470" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于二维码的增强现实方法，以二维码作为增强现实系统中的识别与定位标识，对真实场景图像中的二维码进行解码与再编码直接生成与之码制一致的二维码正视图，分别对二维码正视图的定位模组区域以及场景图像中的二维码图像的定位模组区域进行对应角点检测及提取，以计算单应性矩阵时，相应的，本发明还公开了基于二维码的增强现实系统及移动终端，既打破了传统增强现实应用中，必须在数据库中预先存储对应样本图像才能进行跟踪匹配的局限性，又避免了使用传统标识物的时候向远程服务器的模板查询与匹配步骤，能够减少因网络传输问题造成的系统响应延迟，节约用户的网络通信流量。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM52602549" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	�种基于ニ维码的增强现实方法，其特征在干，包括：  摄像模块捕获含有ニ维码的真实场景图像；  扫描场景图像中的ニ维码，并对ニ维码进行解码，获得ニ维码的编码信息，所述编码信息包括：码制及资源信息；  根据ニ维码的编码信息，用与之相同的码制进行编码，生成与场景图像中的ニ维码码制一致的ニ维码正视图；同时解析所述资源信息，以获取ニ维码对应的虚拟信息；  分别对ニ维码正视图的定位模组区域以及摄像模块捕获的场景图像中的ニ维码图像的定位模组区域进行角点检测，井分别按相同顺序对二者上提取的角点进行排序，使得ニ者上提取的角点--对应；  根据所述二者上提取的对应角点的坐标值，计算单应性矩阵；  根据单应性矩阵，在真实场景中二维码位置处或ニ维码的一定偏移位置处，渲染并输出显示所述与ニ维码对应的虚拟信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求1所述的方法，其特征在干：  当解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；  当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，井根据虚拟信息类型用预设方式进行加载。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求2所述的方法，其特征在于：所述虚拟信息类型包括：视频、图像、文本、3D模型中的�种或多种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求1至3中任一项所述的方法，其特征在于：  所述真实场景图像中的ニ维码为常规QR ニ维码、常规Data Matrix ニ维码、定制QR ニ维码、定制Data Matrix ニ维码中的一种；  定制QR ニ维码或定制Data Matrix ニ维码中的资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度中的�种或多种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求1至3中任一项所述的方法，其特征在于，所述对ニ维码正视图的定位模组区域以及摄像模块捕获的场景图像中的ニ维码图像的定位模组区域进行角点检测之前，还包括：  根据码制确定ニ维码正视图的定位模组区域以及摄像模块捕获的场景图像中的ニ维码图像的定位模组区域。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6.	一种基于ニ维码的增强现实系统，其特征在干，包括：  摄像模块，用于捕获含有ニ维码的真实场景图像；  ニ维码解码模块，用于扫描场景图像中的ニ维码，并对ニ维码进行解码，获取ニ维码的编码信息，所述编码信息包括：码制、版本及资源信息；  ニ维码编码模块，用于根据所述ニ维码解码模块解析出来的编码信息，用与之相同的码制进行编码，生成与场景图像中的ニ维码码制一致的ニ维码正视图；  资源获取模块，用于解析所述编码信息中的资源信息，以获取ニ维码对应的虚拟信息；  角点提取模块，用于对ニ维码正视图的定位模组区域以及摄像模块捕获的场景图像中的ニ维码图像的定位模组区域进行角点检测，井分别按相同顺序对二者上提取的角点进行排序，使得二者上提取的角点--对应；单应性矩阵计算模块，用于根据角点提取模块所述提取的上述二者对应角点的坐标值，计算单应性矩阵；  渲染显示模块，用于根据单应性矩阵，在真实场景中二维码位置处或ニ维码的一定偏移位置处，渲染并输出显示所述与ニ维码对应的虚拟信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求6所述的系统，其特征在于，所述系统还包括：  定位模块，用于根据ニ维码解码模块解析出的码制确定ニ维码正视图的定位模组区域以及摄像模块捕获的场景图像中的ニ维码图像的定位模组区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.如权利要求6或7所述的系统，其特征在于：  所述真实场景图像中的ニ维码为常规QR ニ维码、常规Data Matrix ニ维码、定制QR ニ维码、定制Data Matrix ニ维码中的一种；  定制QR ニ维码或定制Data Matrix ニ维码中的资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度中的�种或多种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.如权利要求6或7所述的系统，其特征在于，  当所述资源获取模块解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；而当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，井根据虚拟信息类型用预设方式进行加载，所述虚拟信息类型包括：视频、图像、文本、3D模型中的�种或多种。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.	一种移动&#32066;端，其特征在于，所述移动&#32066;端包括权利要求6至9中任一项所述的基于ニ维码的增强现实系统。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES59662289" lang="ZH" load-source="patent-office" class="description">
    <p>基于二维码的增强现实方法、系统及终端</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及移动增强现实领域，尤其涉及一种基于二维码的增强现实方法、系统及移动终端。</p>
    <p>背景技术</p>
    <p>[0002]	二维码又称二维条码，是用某种特定的几何图形按一定规律在平面(二维方向上）分布黑白相间的图形来记录数据符号信息，其在代码编制上巧妙利用构成计算机内部逻辑基础的比特流概念，使用若干个与二进制相对应的几何形体来表示文字数值信息。</p>
    <p>[0003]	近年来，二维码得到了广泛应用，市面上专门用于扫描识别二维码的移动应用层出不穷，但这些应用扫描二维码后，均直接呈现出二维码解析后所得到的文字信息或视频、网页等资源链接网址，使用起来不够炫。</p>
    <p>[0004]	在二维码使用越来越普遍的同时,增强现实技术（AR, Augumented Reality)开始慢慢进入公众视线，其核心是将虚拟信息实时叠加到真实环境呈现的场景中，利用虚拟信息对真实场景进行补充、增强，让虚拟信息在真实世界中同步展示。现有的增强现实技术中，要实现将虚拟信息叠加到真实场景上，必须计算摄像机与真实场景间的相对位置关系，即通过真实场景图像与样本图像进行配准，得到单应性矩阵。因此对于现有的增强现实技术，如果移动终端或增强现实服务器端没有存储某真实场景的样本图像或该样本图像的特征点信息，则无法实现虚拟信息与该真实场景的融合。</p>
    <p>发明内容</p>
    <p>[0005]	本发明的目的是提供一种基于二维码的增强现实方法、系统及移动终端，在没有样本图像的情况下，通过解码场景图像中二维码及重新编码生成与场景图像中的二维码码制一致的二维码正视 图，及对二维码正视图的定位模组区域和摄像模块捕获的场景图像中的二维码图像的定位模组区域进行对应角点检测，计算单应性矩阵，实现在真实场景二维码位置处或二维码的一定偏移位置处，呈现二维码相关的视频、图像、文本、3D模型的多媒体信息。</p>
    <p>[0006]	为了实现上述发明目的，本发明提供了一种基于二维码的增强现实方法，包括：</p>
    <p>[0007]	摄像模块捕获含有二维码的真实场景图像；</p>
    <p>[0008]	扫描场景图像中的二维码，并对二维码进行解码，获得二维码的编码信息，所述编码信息包括：码制及资源信息；</p>
    <p>[0009]	根据二维码的编码信息，用与之相同的码制进行编码，生成与场景图像中的二维码码制一致的二维码正视图；同时解析所述资源信息，以获取二维码对应的虚拟信息；</p>
    <p>[0010]	分别对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测，并分别按相同顺序对二者上提取的角点进行排序，使得二者上提取的角点--对应；</p>
    <p>[0011]	根据所述二者上提取的对应角点的坐标值，计算单应性矩阵；[0012]	根据单应性矩阵，在真实场景中二维码位置处或二维码的一定偏移位置处，渲染并输出显示所述与二维码对应的虚拟信息。</p>
    <p>[0013]	优选的，当解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，并根据虚拟信息类型用预设方式进行加载。</p>
    <p>[0014]	优选的，所述虚拟信息类型包括：视频、图像、文本、3D模型中的一种或多种。</p>
    <p>[0015]	优选的，所述真实场景图像中的二维码为常规QR 二维码、常规Data Matrix 二维码、定制QR 二维码、定制Data Matrix 二维码中的一种；其中，定制QR 二维码或定制DataMatrix 二维码中的资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度中的一种或多种。</p>
    <p>[0016]	其中，对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测之前，还包括：根据码制确定二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域。</p>
    <p>[0017]	相应的，本发明还提供了一种基于二维码的增强现实系统，包括：</p>
    <p>[0018]	摄像模块，用于捕获含有二维码的真实场景图像；</p>
    <p>[0019]	二维码解码模块，用于扫描场景图像中的二维码，并对二维码进行解码，获取二维码的编码信息，所述编码信息包括：码制、版本及资源信息；</p>
    <p>[0020]	二维码编码模块，用于根据所述二维码解码模块解析出来的编码信息，用与之相同的码制进行编码，生成与场景图像中的二维码码制一致的二维码正视图；</p>
    <p>[0021]	资源获取模块，用于解析所述编码信息中的资源信息，以获取二维码对应的虚拟信息；</p>
    <p>[0022]	角点提取模块，用于对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测，并分别按相同顺序对二者上提取的角点进行排序，使得二者上提取的角点一一对应；</p>
    <p>[0023]	单应性矩阵计算模块，用于根据角点提取模块所述提取的上述二者对应角点的坐标值，计算单应性矩阵；</p>
    <p>[0024]	渲染显示模块，用于根据单应性矩阵，在真实场景中二维码位置处或二维码的一定偏移位置处，渲染并输出显示所述与二维码对应的虚拟信息。</p>
    <p>[0025]	优选的，所述系统还包括：定位模块，用于根据二维码解码模块解析出的码制确定二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域。</p>
    <p>[0026]	优选的，所述真实场景图像中的二维码为常规QR 二维码、常规Data Matrix 二维码、定制QR 二维码、定制Data Matrix 二维码中的一种；其中，定制QR 二维码或定制DataMatrix 二维码中的资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度中的一种或多种。</p>
    <p>[0027]	优选的，当所述资源获取模块解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；而当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，并根据虚拟信息类型用预设方式进行加载，所述虚拟信息类型包括：视频、图像、文本、3D模型中的一种或多种。[0028]	相应的，本发明还提供了一种移动终端，所述移动终端包括上述的基于二维码的增强现实系统。</p>
    <p>[0029]	与现有技术相比，本发明具有如下有益效果：</p>
    <p>[0030]1、本发明直接将场景图像中的二维码解码与再编码，重新生成与场景图像中二维码一致的二维码正视图，由于同一码制生成的二维码定位模组区域相同，因此分别对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测，即可计算单应性矩阵，不需要数据库中存储二维码样本图像，对任意二维码均适用，打破了传统增强现实应用中，必须在数据库中预先存储对应样本图像才能进行跟踪匹配的局限性。</p>
    <p>[0031]	2、本发明在计算单应性矩阵时，仅通过对定位模组区域进行角点检测，容错能力强，例如二维码再编码发生数据编码错误时，不影响单应性矩阵的计算，另外对二维码中间有小图标的情形也能适用。</p>
    <p>[0032]	3、本发明由于不需要样本图像，因此避免了从远程服务器的查询与匹配步骤，能够减少因网络传输问题造成的系统响应延迟，节约用户的网络通信流量。</p>
    <p>[0033]	4、本发明深度挖掘二维码作为信息入口的应用潜力，使二维码的相关信息、资源以更加生动的形式呈现给用户。</p>
    <p>附图说明</p>
    <p>[0034]	为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动性的前提下，还可以根据这些附图获得其他的附图：</p>
    <p>[0035]	图1为本发明实施例基于二维码的增强现实方法流程示意图；</p>
    <p>[0036]	图2为根据图1方法进行虚拟信息叠加的过程及效果示意图；</p>
    <p>[0037]	图3为QR 二维码与Data Matrix 二维码定位模组位置示意图；</p>
    <p>[0038]	图4为QR 二维码与Data Matrix 二维码根据定位模组确定正方向示意图；</p>
    <p>[0039]	图5为中间具有小图标的QR 二维码示意图。</p>
    <p>具体实施方式</p>
    <p>[0040]	下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。</p>
    <p>[0041]	本领域技术人员应知：在增强现实过程中，将虚拟信息准确的叠加在目标物体之上，需要对摄像机的姿态进行计算，来确定从目标物体的坐标系到图像坐标系的单应性矩阵。</p>
    <p>[0042]	本申请的发明人发现，现有增强现实一般都是通过真实场景图像与样本图像进行配准，得到单应性矩阵。这种方式要求对能够进行增强现实的图像，必须在移动终端或服务器端存储其用于配准的样本图像，如果移动终端或增强现实服务器端没有存储某真实场景的样本图像或该样本图像的特征点信息，则无法实现虚拟信息与该真实场景的融合，增强现实技术的推广被样本图像所限制。另外样本图像存储于移动终端会占用终端存储空间，且不能满足海量标识物的存储；而若将样本图像存储于远程服务器，样本图像的检索与下载会延迟系统响应且浪费用户的网络通信流量。</p>
    <p>[0043]	本申请的发明人发现，二维码具有易用性和普及性，且二维码作为信息入口，可以由任何信息生成，其可以携带任意一段文本或任意资源的URI，最重要的一点是：二维码解码后能再根据相同的码制重新编码生成与之前二维码码制一致的二维码正视图。可以用解码再编码后生成的二维码正视图作为样本图像与场景中的二维码进行特征点跟踪匹配，计算单应性矩阵。</p>
    <p>[0044]	然而在现实生活中，我们会发现如图5所示的二维码，其中间有一个小图标遮挡了二维码的中心区域，虽然二维码具有纠错能力，能够在具有小图标遮挡一定区域的情况下正确解码，然后再编码生成与原二维码包含数据一致的二维码正视图，但该正视图中不会存在原二维码中的遮挡小图标，如果此时用生成的二维码正视图与场景中的二维码进行全图特征点跟踪匹配，计算单应性矩阵，可能会产生误差，使得虚拟信息不能完全准确的叠加到场景图像中的二维码上。</p>
    <p>[0045]	因此，本发明技术方案不对生成的二维码正视图与场景中的二维码进行特征点跟踪匹配，而选取了在二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测来计算单应性矩阵。所述二维码的定位模组，也称为寻象图形，例如QR 二维码中，寻象图形包括三个相同的位置探测图形，分别位于符号的左上角、右上角和左下角，如图3QR 二维码所示，每个位置探测图形可以看作是由3个重叠的同心的正方形组成，它们分别为7X7个深色模块、5X5个浅模块和3X3个深色模块。</p>
    <p>[0046]	下面结合附图详细介绍本发明介绍方案。</p>
    <p>[0047]	参见图1、图2，为本发明实施例基于二维码的增强现实方法流程示意图，包括如下SlOl&#12316;S106步骤：</p>
    <p>[0048]	SlOl :摄像模块捕获`含有二维码的真实场景图像，所述二维码可以为常规二维码，也可以为定制二维码，常规二维码指资源信息中包含一个文本字段或URI链接的网络二维码，定制二维码指其资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度等其他一些设置信息中的一种或多种；</p>
    <p>[0049]	S102:扫描场景图像中的二维码，并对二维码进行解码，获得二维码的编码信息，所述编码信息包括：码制及资源信息，所述资源信息指扫描二维码得到的相关信息；</p>
    <p>[0050]	S103 :根据二维码的编码信息，用与之相同的码制和版本进行编码，生成与场景图像中的二维码码制一致的二维码正视图；同时解析所述资源信息，以获取二维码对应的虚拟信息，二维码对应的资源信息可能为文本信息，也可能为资源URI，当为资源URI时，访问UIR地址，获取URI对应的虚拟信息内容；</p>
    <p>[0051]	S104:分别对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测，并分别按相同顺序对二者上提取的角点进行排</p>
    <p>序，使得二者上提取的角点--对应，至少提取4组对应角点在计算单应性矩阵时,取点越</p>
    <p>多，计算结果越精确；</p>
    <p>[0052]	其中，二维码的定位模组区域的确定是根据码制确定的，定位模组对于同种码制不同版本不同数据的二维码均是相同的，将二维码图像的定位模组作为感兴趣区域ROI，进行FAST、Harris、Sh1-Thomas等角点检测。由于二维码的定位模组在二维码图像中位置固定，可以利用二维码的定位模组来计算二维码图像的主方向，对ROI区域检测到的角点族进行排序，以从主方向起按照顺时针或逆时针顺序排列所有角点。保证在计算单应性矩阵时，二维码图像与其正视图各角点&#8212;&#8212;对应。参见图3、图4分别为QR 二维码、Data Matrix二维码的模组区域示意图，图4显示了如何通过模组区域判断二维码图像的主方向，对ROI区域检测到的角点逐点进行排序，以从主方向起按照顺时针或逆时针顺序排列所有角点，以保证在计算单应性矩阵时，二维码图像与其正视图各角点一一对应。</p>
    <p>[0053]	S105 :根据所述二者上提取的对应角点的坐标值，计算单应性矩阵；</p>
    <p>[0054]	真实场景中的二维码为平面物体，其确定了一个世界坐标系，经过解码再编码生成的二维码正视图属于图像坐标系，以分别在二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域分别提取4个角点为例，可以将这四个角点在世界坐标系上的坐标与图像坐标系上的坐标建立起如下对应关系：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN103049728A/CN103049728AD00081.png"> <img id="idf0001" file="CN103049728AD00081.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN103049728A/CN103049728AD00081.png" class="patent-full-image" alt="Figure CN103049728AD00081"> </a> </div>
    <p>[0056]	其中，（u，v)表示角点的图像坐标，(xffl, ym，zffl)表示角点在世界坐标系上的坐标，均为已知参数，H表示待计算的单应性矩阵。</p>
    <p>[0057]	S106:根据单应性矩阵，在真实场景中二维码位置处或二维码的一定偏移位置处，渲染并输出显示所述与二维码对应的虚拟信息。</p>
    <p>[0058]	本步骤中，若二维码为常规二维码，直接将虚拟信息叠加到二维码位置处；而若二维码为定制二维码，其资源信息中设定了资源加载界面尺寸、渲染位置偏移度等，则根据设定的尺寸及偏移度将虚拟信息叠显示在距目标位置设定偏移位置处。</p>
    <p>[0059]	本步骤中，当解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，并根据虚拟信息类型用预设方式进行加载，所述虚拟信息类型包括：视频、图像、文本、3D模型中的一种或多种，例如：虚拟信息为文本信息时，将文本内容直接作为纹理进行渲染；当虚拟信息为3D模型时，需要先对3D模型进行解析；当虚拟信息为视频信息时，需要先对视频进行解码，将视频各帧图像作为纹理，按序列逐帧映射到所述3D模型上，进行视频加载渲染。</p>
    <p>[0060]	本发明实施例方法，由于定位模组对于同种码制不同版本不同数据的二维码均是相同的，因此本发明实施例只对定位模组区域进行角点检测，容错能力强，例如二维码再编码发生数据编码错误时，不影响单应性矩阵的计算，另外对二维码中间有小图标的情形也能适用，例如图5这种中间有小图标的二维码。</p>
    <p>[0061]	本发明还提出了一种基于二维码的增强现实系统，包括：摄像模块、二维码解码模块、二维码编码模块、资源获取模块、角点提取模块、单应性矩阵计算模块及渲染显示模块，其中：</p>
    <p>[0062]	所述摄像模块，用于捕获含有二维码的真实场景图像；</p>
    <p>[0063]	所述二维码解码模块，用于扫描场景图像中的二维码，并对二维码进行解码，获取二维码的编码信息，所述编码信息包括：码制、版本及资源信息；</p>
    <p>[0064]	所述二维码编码模块，用于根据所述二维码解码模块解析出来的编码信息，用与之相同的码制和版本进行编码，生成与场景图像中的二维码码制一致的二维码正视图；</p>
    <p>[0065]	所述资源获取模块，用于解析所述编码信息中的资源信息，以获取二维码对应的虚拟息;</p>
    <p>[0066]	所述角点提取模块，用于对二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域进行角点检测，并分别按相同顺序对二者上提取的角点进行排序，使得二者上提取的角点--对应；</p>
    <p>[0067]	所述单应性矩阵计算模块，用于根据角点提取模块所述提取的上述二者对应角点的坐标值，计算单应性矩阵；</p>
    <p>[0068]	所述渲染显示模块，用于根据单应性矩阵，在真实场景中二维码位置处或二维码的一定偏移位置处，渲染并输出显示所述与二维码对应的虚拟信息，当所述资源获取模块解析所述资源信息得到的是文本内容时，将文本内容作为纹理进行渲染；而当解析所述资源信息得到的是资源URI，则访问该URI获取虚拟信息，并根据虚拟信息类型用预设方式进行加载，所述虚拟信息类型包括：视频、图像、文本、3D模型中的一种或多种。</p>
    <p>[0069]	其中，所述系统还包括定位模块，用于根据二维码解码模块解析出的码制确定二维码正视图的定位模组区域以及摄像模块捕获的场景图像中的二维码图像的定位模组区域，以便所述角点提取模块进行准确的角点 提取。</p>
    <p>[0070]	由于本实施例基于二维码的增强现实系统，是与前面施例基于二维码的增强现实方法对应的系统，因此不对其做过于详细的赘述，具体细节特征参见前面描述。</p>
    <p>[0071]	本发明实施例中的方法及系统，对QR 二维码、Data Matrix 二维码进行增强现实效果较好，另外二维码可以为常规QR 二维码、常规Data Matrix 二维码，也可以为定制QR二维码、定制Data Matrix 二维码。</p>
    <p>[0072]	所谓常规QR 二维码、常规Data Matrix 二维码是指二维码来源于互联网，其内包含的资源信息一般为一个字符串，例如为一段文本或者二维码相关资源的URI。</p>
    <p>[0073]	所谓定制QR 二维码或定制Data Matrix是指，按照某种统一格式形成的资源标识，即二维码中的资源信息包括资源标识符、资源类型、资源加载界面尺寸、渲染位置偏移度等其他一些设置信息中的一种或多种。例如，I D:xxx_UR1:xxx_TYPE:xxx_WIDTH:xxx_HEIGHT:xxx_0FFSET: xxx，通过ID和URI确定资源地址（该地址可能在远程服务器，也可能在客户端本地)，通过资源类型可以预先设置相关资源的加载方式（图片、文本、音频、视频和3D模型的加载方式各不相同)，其他设置信息包括了资源加载界面的尺寸以及渲染位置相对于~■维码的偏移等等。</p>
    <p>[0074]	本发明还提出了一种移动终端，所述移动终端包括上述的基于二维码的增强现实系统。</p>
    <p>[0075]	本发明以二维码作为增强现实系统中的识别与定位标识，通过二维码的解码与再编码直接生成二维码正视图，从二者的定位模组区域提取对应角点，用于单应性矩阵的计算，既打破了传统增强现实应用中，必须在数据库中预先存储对应样本图像才能进行跟踪匹配的局限性，又避免了使用传统标识物的时候向远程服务器的模板查询与匹配步骤，能够减少因网络传输问题造成的系统响应延迟，节约用户的网络通信流量。[0076]	本说明书中公开的所有特征，或公开的所有方法或过程中的步骤，除了互相排斥的特征和/或步骤以外，均可以以任何方式组合。</p>
    <p>[0077]	本说明书(包括任何附加权利要求、摘要和附图）中公开的任一特征，除非特别叙述，均可被其他等效或具有类似目的的替代特征加以替换。即，除非特别叙述，每个特征只是一系列等效或类似特征中的一个例子而已。</p>
    <p>[0078]	本发明并不局限于前述的具体实施方式。本发明扩展到任何在本说明书中披露的新特征或任何新的组合，以及披露的任一新的方法或过程的步骤或任何新的组合。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102497331A?cl=zh">CN102497331A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月16日</td><td class="patent-data-table-td patent-date-value">2012年6月13日</td><td class="patent-data-table-td ">于凯</td><td class="patent-data-table-td ">一种信息提供方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102799883A?cl=zh">CN102799883A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月29日</td><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">广州中国科学院先进技术研究所</td><td class="patent-data-table-td ">一种从视频图像中提取运动目标的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102800065A?cl=zh">CN102800065A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月13日</td><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">苏州梦想人软件科技有限公司</td><td class="patent-data-table-td ">基于二维码识别跟踪的增强现实设备及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102821323A?cl=zh">CN102821323A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月1日</td><td class="patent-data-table-td patent-date-value">2012年12月12日</td><td class="patent-data-table-td ">成都理想境界科技有限公司</td><td class="patent-data-table-td ">基于增强现实技术的视频播放方法、系统及移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120327117">US20120327117</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月4日</td><td class="patent-data-table-td patent-date-value">2012年12月27日</td><td class="patent-data-table-td ">Limitless Computing, Inc.</td><td class="patent-data-table-td ">Digitally encoded marker-based augmented reality (ar)</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103530590A?cl=zh">CN103530590A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年10月19日</td><td class="patent-data-table-td patent-date-value">2014年1月22日</td><td class="patent-data-table-td ">高韬</td><td class="patent-data-table-td ">Dpm二维码识别系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103530590B?cl=zh">CN103530590B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年10月19日</td><td class="patent-data-table-td patent-date-value">2016年2月24日</td><td class="patent-data-table-td ">高韬</td><td class="patent-data-table-td ">Dpm二维码识别系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103544724A?cl=zh">CN103544724A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月27日</td><td class="patent-data-table-td patent-date-value">2014年1月29日</td><td class="patent-data-table-td ">华夏动漫集团有限公司</td><td class="patent-data-table-td ">一种利用增强现实与卡片识别技术在移动智能终端实现虚拟动漫角色的系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015039601A1?cl=zh">WO2015039601A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年9月17日</td><td class="patent-data-table-td patent-date-value">2015年3月26日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">Methods, devices, terminal device and systems for pattern recognition</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=f1vwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0007100000">G06K7/10</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=f1vwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0019060000">G06K19/06</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年4月17日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年5月15日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年2月3日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/96be616b076e332532e2/CN103049728A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_50a6672b5f82ffbd39b7a9e87fd4594c.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E4%BA%8C%E7%BB%B4%E7%A0%81%E7%9A%84%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E%E6%96%B9%E6%B3%95_%E7%B3%BB.pdf?id=f1vwBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0frx88O_u9U08dO-MhCACAyRKk4Q"},"sample_url":"https://www.google.com/patents/reader?id=f1vwBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>