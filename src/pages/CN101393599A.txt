<!DOCTYPE html><html><head><title>专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种基于人脸表情的游戏角色控制方法"><meta name="DC.contributor" content="王阳生" scheme="inventor"><meta name="DC.contributor" content="王书昌" scheme="inventor"><meta name="DC.contributor" content="冯雪涛" scheme="inventor"><meta name="DC.contributor" content="汪晓妍" scheme="inventor"><meta name="DC.contributor" content="健 姚" scheme="inventor"><meta name="DC.contributor" content="中国科学院自动化研究所" scheme="assignee"><meta name="DC.contributor" content="北京盛开交互娱乐科技有限公司" scheme="assignee"><meta name="DC.date" content="2007-9-19" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开一种基于人脸分析技术的游戏角色控制方法，包括：对从图像输入设备获得的图像进行简单有效的预处理；通过统计学习方法进行人脸的检测和关键点定位；通过对定位的结果进行分析，得到人脸的姿态和表情信息，并将这些信息映射成对应的游戏控制指令，实现游戏中角色面部的实时控制功能。用玩家的人脸信息控制游戏角色，仅通过摄像头拍摄玩家的人脸，然后分析其在空间中的状态和表情信息，并将结果转化为游戏角色的控制指令，扩展了传统游戏的互动方式。本发明视频检测方法实时、鲁棒、易于实现和操作。本发明能使游戏用户以更自然、更智能的新方式进行交互操作，如采用自身头部姿态、脸部表情等，由此可使游戏更具交互性和沉浸感。"><meta name="DC.date" content="2009-3-25"><meta name="citation_patent_publication_number" content="CN:101393599:A"><meta name="citation_patent_application_number" content="CN:200710121978"><link rel="canonical" href="https://www.google.com/patents/CN101393599A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101393599A?cl=zh"/><meta name="title" content="专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法"/><meta name="description" content="本发明公开一种基于人脸分析技术的游戏角色控制方法，包括：对从图像输入设备获得的图像进行简单有效的预处理；通过统计学习方法进行人脸的检测和关键点定位；通过对定位的结果进行分析，得到人脸的姿态和表情信息，并将这些信息映射成对应的游戏控制指令，实现游戏中角色面部的实时控制功能。用玩家的人脸信息控制游戏角色，仅通过摄像头拍摄玩家的人脸，然后分析其在空间中的状态和表情信息，并将结果转化为游戏角色的控制指令，扩展了传统游戏的互动方式。本发明视频检测方法实时、鲁棒、易于实现和操作。本发明能使游戏用户以更自然、更智能的新方式进行交互操作，如采用自身头部姿态、脸部表情等，由此可使游戏更具交互性和沉浸感。"/><meta property="og:title" content="专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101393599A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101393599A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101393599A&amp;usg=AFQjCNF1MTQBwI0y213Nr8kt4quMuD9PIA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/227af6402b86a2479b05/CN101393599A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/227af6402b86a2479b05/CN101393599A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101393599A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101393599A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101393599A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101393599B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101393599A?cl=zh" style="display:none"><span itemprop="description">本发明公开一种基于人脸分析技术的游戏角色控制方法，包括：对从图像输入设备获得的图像进行简单有效的预处理；通过统计学习方法进行人脸的检测和关键点定位；通过对定位的结果进行分析，得到人脸的姿态和表情信息，...</span><span itemprop="url">https://www.google.com/patents/CN101393599A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法" title="专利 CN101393599A - 一种基于人脸表情的游戏角色控制方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101393599 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200710121978</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2009年3月25日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2007年9月19日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年9月19日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101393599B?hl=zh-CN&amp;cl=zh">CN101393599B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200710121978.3, </span><span class="patent-bibdata-value">CN 101393599 A, </span><span class="patent-bibdata-value">CN 101393599A, </span><span class="patent-bibdata-value">CN 200710121978, </span><span class="patent-bibdata-value">CN-A-101393599, </span><span class="patent-bibdata-value">CN101393599 A, </span><span class="patent-bibdata-value">CN101393599A, </span><span class="patent-bibdata-value">CN200710121978, </span><span class="patent-bibdata-value">CN200710121978.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E9%98%B3%E7%94%9F%22">王阳生</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E4%B9%A6%E6%98%8C%22">王书昌</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%86%AF%E9%9B%AA%E6%B6%9B%22">冯雪涛</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%B1%AA%E6%99%93%E5%A6%8D%22">汪晓妍</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%81%A5+%E5%A7%9A%22">健 姚</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80%22">中国科学院自动化研究所</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E4%BA%AC%E7%9B%9B%E5%BC%80%E4%BA%A4%E4%BA%92%E5%A8%B1%E4%B9%90%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北京盛开交互娱乐科技有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101393599A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101393599A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101393599A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (24),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200710121978&amp;usg=AFQjCNHD8oBuY10UQ5cJE64BLkUZg9NPCA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101393599A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFirQj3VM4PoE1IQSdlTGdlZaEcLw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT85004218" lang="ZH" load-source="patent-office">一种基于人脸表情的游戏角色控制方法</invention-title>
      </span><br><span class="patent-number">CN 101393599 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA109507689" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开一种基于人脸分析技术的游戏角色控制方法，包括：对从图像输入设备获得的图像进行简单有效的预处理；通过统计学习方法进行人脸的检测和关键点定位；通过对定位的结果进行分析，得到人脸的姿态和表情信息，并将这些信息映射成对应的游戏控制指令，实现游戏中角色面部的实时控制功能。用玩家的人脸信息控制游戏角色，仅通过摄像头拍摄玩家的人脸，然后分析其在空间中的状态和表情信息，并将结果转化为游戏角色的控制指令，扩展了传统游戏的互动方式。本发明视频检测方法实时、鲁棒、易于实现和操作。本发明能使游戏用户以更自然、更智能的新方式进行交互操作，如采用自身头部姿态、脸部表情等，由此可使游戏更具交互性和沉浸感。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(6)</span></span></div><div class="patent-text"><div mxw-id="PCLM51295100" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于人脸表情的游戏角色控制方法，其特征在于，包括如下步骤：</div>
      <div class="claim-text">步骤1：通过统计的方法对人脸目标样本进行学习，得到待检测玩家人脸目标的模式；</div>
      <div class="claim-text">步骤2：通过图像输入设备采集待检测玩家视频图像；</div>
      <div class="claim-text">步骤3：对待检测玩家视频图像进行预处理，生成预处理图像；</div>
      <div class="claim-text">步骤4：利用学习到的目标模式，在预处理图像上进行人脸检测和跟踪，生成人脸区域；</div>
      <div class="claim-text">步骤5：利用人脸特征点定位算法，在人脸区域上进行人脸对齐，得到人脸特征点位置；</div>
      <div class="claim-text">步骤6：在获得人脸特征点位置的基础上，进行表情分析，包括眼睛、嘴唇和眉毛的运动信息；</div>
      <div class="claim-text">步骤7：将人脸表情信息用于控制游戏角色。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的基于人脸表情的游戏角色控制方法，其特征在于：所述图像预处理采用像素的均值和方差算法来进行光线矫正。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的基于人脸表情的游戏角色控制方法，其特征在于：所述人脸检测和跟踪的步骤包括：</div>
      <div class="claim-text">步骤41：通过学习到的人脸模式，在预处理图像上搜索人脸目标；</div>
      <div class="claim-text">步骤42：通过模板匹配，对人脸局部进行跟踪，来实现整个人脸的跟踪。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的基于人脸表情的游戏角色控制方法，其特征在于：所述人脸对齐步骤包括：</div>
      <div class="claim-text">步骤51：通过主动外观模型，对预处理图像进行人脸特征点定位；</div>
      <div class="claim-text">步骤52：对人脸特征点的位置进行平滑处理。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的基于人脸表情的游戏角色控制方法，其特征在于：所述人脸表情分析包括：</div>
      <div class="claim-text">步骤61：通过主动外观模型，对人脸表情姿态进行判别；</div>
      <div class="claim-text">步骤62：通过历史运动图，对眉毛运动进行判别；</div>
      <div class="claim-text">步骤63：通过动态阀值法，对嘴唇状态进行判别；</div>
      <div class="claim-text">步骤64：通过神经网络的方法，对眼睛状态进行判别。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的基于人脸表情的游戏角色控制方法，其特征在于：所述游戏角色的驱动包括：</div>
      <div class="claim-text">步骤71：将人脸的姿态参数，用于控制动画角色的头部姿态；</div>
      <div class="claim-text">步骤72：将眉毛运动的位移信息，用于控制动画角色眉毛的运动；</div>
      <div class="claim-text">步骤73：将嘴唇的张开程度信息，用于控制动画角色嘴唇的张开程度；</div>
      <div class="claim-text">步骤74：将眼睛的睁开程度信息，用于控制动画角色眼睛的睁开程度。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES58338354" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">一种基于人脸表情的游戏角色控制方法</invention-title>
    <technical-field>
      <p>[0001] 技术领域</p>
      <p>[0002] 本发明涉及图像分析与识别技术领域，特别是基于人脸表情的交互方法。</p>
    </technical-field>
    <background-art>
      <p>[0003] 背景技术</p>
      <p>[0004] 近年来，随着计算机技术的革新，以计算机游戏为代表的数字娱乐产业飞速发展。作为一类特殊的应用软件，计算机游戏通过向游戏用户提供一系列的菜单选项和操作指令，实现用户与游戏之间的交互操作。用于游戏的传统人机交互方式有：鼠标键盘、游戏杆及专用游戏设备等，以手动和有线连接为主。伴随计算机游戏种类与内容的不断扩展丰富，其操作复杂性剧增，仍然仅采用传统交互方式，越来越难于控制。</p>
      <p>[0005] 鼠标和键盘是最常用的设备，它们将用户手的敲击、移动转化成电信号并最终成为一种供系统响应的事件。专用游戏设备是鼠标和键盘在功能上的扩展，但其原理大致相同。前者相比于后者的优越性体现在操作性上，如可玩性和方便性。</p>
      <p>[0006] 传统的交互方式基本上是以事件来驱动的，这是一种低层次的交互，因为它并不能理解游戏的内容，所以用户要实现一种有语义的控制往往需要一系列的低层次操作。</p>
    </background-art>
    <disclosure>
      <p>[0007] 发明内容</p>
      <p>[0008] 为了解决传统交互方式，缺乏语义理解的能力，本发明的目的是要用玩家的人脸表情来与游戏交互，作为一种针对传统的键盘鼠标所代表的交互方式的补充，为此，本发明提供了一种基于人脸表情的游戏角色控制方法。</p>
      <p>[0009] 为了实现上述目的，本发明提出的技术方案是一种基于玩家人脸表情的游戏角色控制方法其方法步骤如下：</p>
      <p>[0010] 步骤1：通过统计的方法对人脸目标样本进行学习，得到待检测玩家人脸目标的模式；</p>
      <p>[0011] 步骤2：通过图像输入设备采集待检测玩家视频图像；</p>
      <p>[0012] 步骤3：对待检测玩家视频图像进行预处理，生成预处理图像；</p>
      <p>[0013] 步骤4：利用学习到的目标模式，在预处理图像上进行人脸检测和跟踪，生成人脸区阈；</p>
      <p>[0014] 步骤5：利用人脸特征点定位算法，在人脸区域上进行人脸对齐，得到人脸特征点位置；</p>
      <p>[0015] 步骤6：在获得人脸特征点位置的基础上，进行表情分析，包括眼睛、嘴唇和眉毛的运动信息；</p>
      <p>[0016] 步骤7：将人脸表情信息用于控制游戏角色。</p>
      <p>[0017] 根据本发明的实施例，所述图像预处理步骤采用像素的均值和方差算法来进行光线矫正。</p>
      <p>[0018] 根据本发明的实施例，所述人脸检测和跟踪的步骤包括：</p>
      <p>[0019] 步骤41：通过学习到的人脸模式，在预处理图像上搜索人脸目标；</p>
      <p>[0020] 步骤42：通过模板匹配，对人脸局部进行跟踪，来实现整个人脸的跟踪。</p>
      <p>[0021] 根据本发明的实施例，所述人脸对齐步骤包括：</p>
      <p>[0022] 步骤51：通过主动外观模型，对预处理图像进行人脸特征点定位；</p>
      <p>[0023] 步骤52：对人脸特征点的位置进行平滑处理。</p>
      <p>[0024] 根据本发明的实施例，所述人脸表情分析包括：</p>
      <p>[0025] 步骤61：通过主动外观模型，对人脸表情姿态进行判别；</p>
      <p>[0026] 步骤62：通过历史运动图，对眉毛运动进行判别；</p>
      <p>[0027] 步骤63：通过动态阀值法，对嘴唇状态进行判别；</p>
      <p>[0028] 步骤64：通过神经网络的方法，对眼睛状态进行判别。</p>
      <p>[0029] 根据本发明的实施例，所述游戏角色的驱动包括：</p>
      <p>[0030] 步骤71：将人脸的姿态参数，用于控制动画角色的头部姿态；</p>
      <p>[0031] 步骤72：将眉毛运动的位移信息，用于控制动画角色眉毛的运动；</p>
      <p>[0032] 步骤73：将嘴唇的张开程度信息，用于控制动画角色嘴唇的张开程度；</p>
      <p>[0033] 步骤74：将眼睛的睁开程度信息，用于控制动画角色眼睛的睁开程度。</p>
      <p>[0034] 本发明的有益效果：采用玩家脸部的表情控制游戏角色，就是用玩家的表情信息作为传统的键盘鼠标交互方式的补充，来丰富人机交互的方式。它仅通过摄像头拍摄玩家人脸，在计算机中进行表情分析和识别，并将结果转化为游戏的控制指令，实现对游戏中角色表情的直接控制，以扩展传统的游戏交互方式。由于游戏对实时性要求高，因此视频检测方法必需实时、鲁棒。为便于用户使用，这种控制方法还必需易于实现和操作。本发明能使游戏用户期望能以更自然、更智能的新方式进行交互操作，如采用头部的运动、人脸五官的运动等表情运动，由此可使游戏更具交互性和沉浸感。随着计算机视觉技术的发展，应用视觉进行自然的人机交互已经成为可能，由于摄像头已经成为计算机常用的配置，这种技术的应用也就具有广阔的前景。</p>
    </disclosure>
    <description-of-drawings>
      <p>[0035] 附图说明</p>
      <p>[0036] 图1为本发明的基于玩家表情的游戏角色控制方法流程图。</p>
      <p>[0037] 图2为采用本发明方法的游戏角色控制示意图。</p>
      <p>[0038] 图3为本发明实施例Haar特征结构。</p>
      <p>[0039] 图4为本发明实施例人脸上一个显著的Haar特征。</p>
      <p>[0040] 图5为本发明实施例嘴唇状态的判别流程图。</p>
    </description-of-drawings>
    <mode-for-invention>
      <p>[0041] 具体实施方式</p>
      <p>[0042] 下面将结合附图对本发明加以详细说明，应指出的是，所描述的实施例仅旨在便于对本发明的理解，而对其不起任何限定作用。</p>
      <p>[0043] 根据本发明的图1所示，为本发明的基于玩家表情的游戏角色控制方法流程图，图2为采用本发明方法的游戏角色控制示意图，图中窗口右上角显示的是玩家的视频图像，窗口右下角是供玩家选择的用于贴到人脸上的虚拟人物和道具，窗口右边显示的是被驱动的动画人物，玩家可以做出睁闭眼、张闭嘴、挤眉毛等动作来驱动动画人物做相应的表情运动。</p>
      <p>[0044] 图1中所示具体实施步骤如下：</p>
      <p>[0045] 步骤1：离线学习：通过统计的方法对人脸目标样本进行学习，得到待检测玩家人脸目标的模式；</p>
      <p>[0046] 步骤2一步骤3：获取图像：通过高速图像捕获模块从图象输入设备实时获取待检测玩家视频图像；对待检测玩家视频图像进行预处理，生成预处理图像；</p>
      <p>[0047] 步骤4：基于统计的人脸检测和跟踪：考虑到算法的简便性与鲁棒性的要求，设计了基于统计学习的检测方法，另外通过对亮度的分析补偿，在预处理图像上搜索人脸目标；从而尽可能地消除光照变化的影响；当用人脸检测初始化后，在后续帧用模板匹配的方法进行人脸跟踪；</p>
      <p>[0048] 步骤5：人脸特征点对齐：在得到人脸区域后，就可以用主动外观模型进行人脸特征点的定位算法，在人脸区域上进行人脸对齐，得到各个人脸特征点位置；</p>
      <p>[0049] 步骤6：人脸表情分析：这里指的表情分析是指人五官的相对运动和状态。人头部的姿态可以用主动外观模型的参数来线性估计；眉毛的运动采用历史运动图来计算；人眼睛的运动采用基于Gabor特征的神经网络方法来判别；人脸的嘴唇状态采用动态阀值和矩估计的方法来得到。</p>
      <p>[0050] 步骤7：动画角色驱动：可以用由步骤6得到的表情数据来驱动动画角色。</p>
      <p>[0051] 本发明实现方法：需要的硬件为计算机及图像采集设备。</p>
      <p>[0052] 所述的角色即游戏中玩家控制的人物或动画等有表情动作的对象；人脸特征点对齐，即用算法自动找到人脸五官和轮廓的准确位置；头部的姿态指头部在空间中的三个方向的角度；表情信息指脸部五官的运动信息和状态信息；其它计算图像算法如Adaboost、历史运动图、Gabor特征、神经网络等，将会在后面详细介绍。</p>
      <p>[0053] 关键技术的实现过程：</p>
      <p>[0054] 一、本发明所述的人脸检测是通过基于Adaboost的统计学习方法来实现，它包括两个步骤：(1)获取人脸样本；(2)统计学习人脸模式。</p>
      <p>[0055] (1)人脸样本库的制作。人脸样本库包含正样本库和负样本库。用图像采集设备采集多个人分别在不同的光线，不同的背景下的多个姿态的人脸图片若干，然后手工剪裁出只包含一个人脸的区域，放缩到同一个尺寸下，再用进行预处理。这样就获得了可直接用于统计学习的人脸正样本库。负样本库的单个样本不包含人脸或包括人脸但不只一个。正样本库是事先制作好的，是固定的，而负样本是的统计学习过程中生成的，是变化的。</p>
      <p>[0056] (2)用于学习人脸模式的统计学习方法是Adaboost算法。</p>
      <p>[0057] Adaboost意为Adaptive&#160;Boost，是AT&amp;T实验室提出的一种自提升Boosting算法。它通过调用弱学习器不断学习训练样本中的难学习的样本，从而达到较高的泛化精度。</p>
      <p>[0058] 基于Adaboost的人脸检测算法是一种统计学习算法，它通过对Haar特征的统计来判别是不是人脸。Haar特征是Haar小波变化而来，其通过相邻区域的灰度差，也就是亮度关系来描述目标。图3所示的是四种非常简单的Haar特征，其中每一个框代表了图像子窗口，分别计算子窗口内所有灰色矩形区域内像素灰度值的和与所有白色矩形区域内像素灰度值的和，两者的差即为对应特征的值。人脸可以通过若干这样的Haar特征来描述。其物理意义是十分明确的，如图4，对人脸样本来说中间区域的应该比两侧区域亮，而非人脸样本不具有这样的特征，只要能找到足够多这样的特征，就能将人脸和非人脸分开。</p>
      <p>[0059] Adaboost算法的主要过程是：首先给样本集合，然后对该样本集合进行循环操作，每次循环首先得到一个弱分类器，然后计算该假设的错误率，根据该错误率改变每个例子的权重进入下一个循环，若干个弱分类级联组成一个强分类器。其具体过程如下：</p>
      <p>[0060] Adaboost算法流程：</p>
      <p>[0061] 给定样本(x1，y1)，…，(xn，yn)，对m个负样本，y1＝0；对l个正样本y1＝1，n＝m+l。</p>
      <p>[0062] 分别对负样本正样本初始化权</p>
      <p>[0063] t＝1，…，T</p>
      <p>[0064] 1.归一化权：</p>
      <p>[0065] </p>
      <p>[0066] 2.对于每一特征j，训练出一个弱分类器hj，计算出与之对应的错误率：</p>
      <p>[0067] </p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>[0068] 3.选择错误率</p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>最小的</p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>。</p>
      <p>[0069] 4.更新权，</p>
      <p>[0070] </p>
      <p>[0071] 其中，</p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>若分类正确，ej＝1，否则ej＝0。</p>
      <p>[0072] 最终T个弱分类器组成一个强分类器：</p>
      <p>[0073] </p>
      <p>
        <span class="patent-image-not-available"> </span>
      </p>
      <p>其中，</p>
      <p>[0074] 二、本发明所述的图像预处理步骤包括：采用像素的均值和方差算法来进行光线矫正。</p>
      <p>[0075] 具体地，图像的预处理方法：</p>
      <p>[0076] 对一幅图像，求取整幅图像灰度值的均值和方差。然后对于图像中每一个像素，将其灰度值减去均值然后除以方差得到的值作为新的灰度值，这样处理后的图像就是进行光线矫正好的图像。</p>
      <p>[0077] 三、本发明所述检测与跟踪的步骤包括：</p>
      <p>[0078] 步骤41：通过学习到的人脸模式，在经过预处理的图像上搜索人脸目标；</p>
      <p>[0079] 步骤42：通过对检测到的人脸进行特征分析，并建立人脸模板，对于后继图像帧用模板匹配算法来搜索当前的人脸区域。具体方法是：</p>
      <p>[0080] 步骤41由人脸模式检测人脸，过程如下：</p>
      <p>[0081] 在人脸可能出现的区域(由上一次检测的结果预测到)内，在不同尺度下取候选人脸图片的一系列有用Haar特征(由Adaboost算法得取)送入学习到的分类器，分类器输出其是否为人脸的判断结果。</p>
      <p>[0082] 步骤42用步骤41得到的结果，建立人脸模板。针对后继图像帧，以上一帧中人脸的位置为初始点，获得人脸区域，将此区域与模板作差，然后通过牛顿梯度下降算法最小化这个差值来更新人脸区域的相似变换参数，最后得到当前图像帧中人脸的位置。</p>
      <p>[0083] 四、本发明所述的人脸特征点对齐是用主动外观模型来实现。</p>
      <p>[0084] 步骤51：通过主动外观模型，对预处理图像进行人脸特征点定位；</p>
      <p>[0085] 步骤52：对人脸特征点的位置进行平滑处理。</p>
      <p>[0086] 主动外观模型是一种基于统计的形状对齐方法。为了便于描述，这里先介绍一种与之相关的算法，即主动形状模型。</p>
      <p>[0087] 主动形状模板是一种参数变形模板基于点分布模型的方法，它从训练集中学习到形状的一个统计模式，。这就是点分布模式，点分布模式然后用于将已经模板其通过变形匹配得到未变知的形状上。作为一种统计模型，它也分为训练和搜索两个阶段：</p>
      <p>[0088] 主动形状模板基本思想是主成分分析，即目标形状可以表达为一系列的基本形状的线性组合。训练的目的是找到这些基本形状。训练地过程很简单，即将训练集中的形状规范化后，进行特征值和特征向量分解，特征向量即为基本形状，特征值反映了样本形状在这个基本形状上的分布情况。形状模板的训练过程还需要对形状上每个特征点附近的梯度信息进行主成分分析，建立局部纹理模型，用于搜索过程中点的更新。</p>
      <p>[0089] 主动形状模板的搜索过程为：先初始化平均形状，然后每个点利用其附近的梯度信息与训练得到的梯度信息求明氏距离。在一点范围内，用明氏距离最小的点来更新这个点。最终平均形状被更新，投影到模型空间中(即投影到基本形状上)，就得到了模型空间中的一个形状实例。再将这个形状作为初始化形状重复以上过程，直至找到最终形状。</p>
      <p>[0090] 主动外观模板是主动形状模板的改进模型，主动形状模板只利用了形状信息和点局部的梯度信息，容易在匹配时失败。主动外观模型在统计形状模型的基础上，进一步对对象纹理(将人脸图像变形到平均形状得到的形状无关图像)进行统计建模，将对象的形状和纹理信息综合到了一个框架下。</p>
      <p>[0091] 搜索过程采用基于纹理预测参数变化的启发式搜索策略。假设模型参数变化及相似变换参数的变化与输入图像和模型纹理之间存在一定程度的线性关系，然后通过线性回归进行参数预测进而得到模型参数和相似变换参数。</p>
      <p>[0092] 五、本发明所述的表情分析主要包括以下几个部分：</p>
      <p>[0093] 所述人脸表情分析包括：</p>
      <p>[0094] 步骤61：通过主动外观模型，对人脸表情姿态进行判别；</p>
      <p>[0095] 步骤62：通过历史运动图，对眉毛运动进行判别；</p>
      <p>[0096] 步骤63：通过动态阀值法，对嘴唇状态进行判别；</p>
      <p>[0097] 步骤64：通过神经网络的方法，对眼睛状态进行判别。</p>
      <p>[0098] 头部姿态的获取：</p>
      <p>[0099] 主动外观模型中的形状模型包括了形状的姿态信息，试验表明，一个方向的姿态与某个形状参数存在近似的线性关系，因为游戏控制并不需要绝对精确的数据，所以这种近似是可取的。其计算公式如下：</p>
      <p>[0100] </p>
      <p>[0101] αyaw＝3.3b4</p>
      <p>[0102] αalt＝5.7b5</p>
      <p>[0103] 其中，b1，b2，b3，b4，b5为形状模型的前6个参数。</p>
      <p>[0104] 眉毛运动信息的获取：</p>
      <p>[0105] 眉毛的运动可以从两帧之间的差来感知。在应用中，可以假定眉毛不会长时间偏离原来的位置。这样其运动的趋势就可以用历史运动信息图来得到。历史运动图是一种很实用的运动分析方法。基本思想是求每帧的差分图，如果像素有运动就将其标定为一个值，同时将前若干帧的差分值减小一定量。这样，就可以得到一幅由明到暗的图像，亮的部分是最新的运动的位置，暗的部分是若干时间前运动留下的痕迹。这个由暗到明的方向正是运动的方向。</p>
      <p>[0106] 眼睛状态的判别：</p>
      <p>[0107] 实施例是采用基于Gabor特征的神经网络来判别眼睛状态的。Gabor特征是一种方便的局部特征，它可以看作一个对方向和尺度敏感的有方向性的显微镜，能够检测(响应)图像中一些具有相应的方向频率信息的、局部的显著特征，从而可以形成亮度图像的局部特征图谱，这些局部特征形成了原始输入图像的一种鲁棒、紧凑的特征表示。</p>
      <p>[0108] 它的表达式为：</p>
      <p>[0109] </p>
      <p>[0110] 其中，μ和v定义了Gabor核的方向和尺度，</p>
      <p>[0111] z＝(x，y)，kv＝kmax/fv，kmax＝π/2，φμ＝2πμ/8.</p>
      <p>[0112] 实施中选择了五个尺度(v∈{0，1，2，3，4，5})八个方向(μ∈{0，1，2，3，4，5，6，7})的Gabor特征。</p>
      <p>[0113] 神经网络是一种简单的分类器，本发明采取的是三层BP神经网络。输入层、隐藏层和输出层的神经元个数分别为120，15和2。</p>
      <p>[0114] 嘴唇状态的判别：</p>
      <p>[0115] 图5说明了嘴唇状态分析的整个流程：</p>
      <p>[0116] (1)人脸关键点定位算法可以定位到嘴唇的区域；</p>
      <p>[0117] (2)在嘴唇区域进行光线矫正后，用动态阀值法对其进行二值化；</p>
      <p>[0118] (3)利用嘴唇张开时，其内部的灰度应该比周围的暗来确定嘴唇内部的区域；</p>
      <p>[0119] (4)计算出包围嘴唇的椭圆的大小和方向。其计算公式如下：</p>
      <p>[0120] 其中，</p>
      <p>[0121] Mij＝∑x∑yxiyjI(x，y)，</p>
      <p>[0122] 其两个轴的长度可由下面的两个式子得到：</p>
      <p>[0123] 其中，</p>
      <p>[0124] </p>
      <p>[0125] 短轴与长轴的比值表明了嘴唇张开的程度。</p>
      <p>[0126] 六、本发明所述游戏角色控制是指用提取的表情信息控制游戏角色做相应的动作。所述游戏角色的控制驱动包括：</p>
      <p>[0127] 步骤71：将人脸的姿态参数，用于控制动画角色的头部姿态；</p>
      <p>[0128] 步骤72：将眉毛运动的位移信息，用于控制动画角色眉毛的运动；</p>
      <p>[0129] 步骤73：将嘴唇的张开程度信息，用于控制动画角色嘴唇的张开程度；</p>
      <p>[0130] 步骤74：将眼睛的睁开程度信息，用于控制动画角色眼睛的睁开程度。</p>
      <p>[0131] 在具体实现的过程中，提取到的表情信息要经过适当处理，这是从游戏稳定性的角度考虑，主要是为了抗噪声。可用的方法有平均法，卡尔曼滤波法等。</p>
      <p>[0132] 上面的描述是用于实现本发明及其实施例，因此，本发明的范围不应由该描述来限定。本领域的技术人员应该理解，在不脱离本发明的范围的任何修改或局部替换，均属于本发明权利要求来限定的范围。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101702199B?cl=zh">CN101702199B</a></td><td class="patent-data-table-td patent-date-value">2009年11月13日</td><td class="patent-data-table-td patent-date-value">2012年4月4日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">笑脸检测方法及装置、移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101825947A?cl=zh">CN101825947A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月4日</td><td class="patent-data-table-td patent-date-value">2010年9月8日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">智能控制移动终端的方法、装置及移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101959033A?cl=zh">CN101959033A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年6月7日</td><td class="patent-data-table-td patent-date-value">2011年1月26日</td><td class="patent-data-table-td ">日立民用电子株式会社</td><td class="patent-data-table-td ">广播接收装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101959033B?cl=zh">CN101959033B</a></td><td class="patent-data-table-td patent-date-value">2010年6月7日</td><td class="patent-data-table-td patent-date-value">2013年2月13日</td><td class="patent-data-table-td ">日立民用电子株式会社</td><td class="patent-data-table-td ">广播接收装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102156887A?cl=zh">CN102156887A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年3月28日</td><td class="patent-data-table-td patent-date-value">2011年8月17日</td><td class="patent-data-table-td ">湖南创合制造有限公司</td><td class="patent-data-table-td ">一种基于局部特征学习的人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102479388A?cl=zh">CN102479388A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年11月22日</td><td class="patent-data-table-td patent-date-value">2012年5月30日</td><td class="patent-data-table-td ">北京盛开互动科技有限公司</td><td class="patent-data-table-td ">基于人脸跟踪和分析的表情互动方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102566740A?cl=zh">CN102566740A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月16日</td><td class="patent-data-table-td patent-date-value">2012年7月11日</td><td class="patent-data-table-td ">富泰华工业（深圳）有限公司</td><td class="patent-data-table-td ">具有情绪识别功能的电子装置及其输出控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102693008A?cl=zh">CN102693008A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年5月14日</td><td class="patent-data-table-td patent-date-value">2012年9月26日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">信息的识别方法、装置及终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102693008B?cl=zh">CN102693008B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年5月14日</td><td class="patent-data-table-td patent-date-value">2015年11月25日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">信息的识别方法、装置及终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102750964A?cl=zh">CN102750964A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月30日</td><td class="patent-data-table-td patent-date-value">2012年10月24日</td><td class="patent-data-table-td ">西北工业大学</td><td class="patent-data-table-td ">基于表情的背景音乐控制方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102750964B?cl=zh">CN102750964B</a></td><td class="patent-data-table-td patent-date-value">2012年7月30日</td><td class="patent-data-table-td patent-date-value">2014年10月29日</td><td class="patent-data-table-td ">西北工业大学</td><td class="patent-data-table-td ">基于表情的背景音乐控制方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102934144A?cl=zh">CN102934144A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年5月20日</td><td class="patent-data-table-td patent-date-value">2013年2月13日</td><td class="patent-data-table-td ">微软公司</td><td class="patent-data-table-td ">脸部表情的实时动画</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103324938A?cl=zh">CN103324938A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月21日</td><td class="patent-data-table-td patent-date-value">2013年9月25日</td><td class="patent-data-table-td ">日电（中国）有限公司</td><td class="patent-data-table-td ">训练姿态分类器及物体分类器、物体检测的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103336577A?cl=zh">CN103336577A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月4日</td><td class="patent-data-table-td patent-date-value">2013年10月2日</td><td class="patent-data-table-td ">宁波大学</td><td class="patent-data-table-td ">一种基于人脸表情识别的鼠标控制方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103366782A?cl=zh">CN103366782A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年4月6日</td><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">在虚拟形象上自动播放表情的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103366782B?cl=zh">CN103366782B</a></td><td class="patent-data-table-td patent-date-value">2012年4月6日</td><td class="patent-data-table-td patent-date-value">2014年9月10日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">在虚拟形象上自动播放表情的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103605466A?cl=zh">CN103605466A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年10月29日</td><td class="patent-data-table-td patent-date-value">2014年2月26日</td><td class="patent-data-table-td ">四川长虹电器股份有限公司</td><td class="patent-data-table-td ">一种基于面部识别操控终端的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103677226A?cl=zh">CN103677226A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月4日</td><td class="patent-data-table-td patent-date-value">2014年3月26日</td><td class="patent-data-table-td ">北方工业大学</td><td class="patent-data-table-td ">表情识别输入方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104582187A?cl=zh">CN104582187A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2015年1月14日</td><td class="patent-data-table-td patent-date-value">2015年4月29日</td><td class="patent-data-table-td ">山东大学</td><td class="patent-data-table-td ">基于人脸识别和表情识别的记录与灯光控制系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104582187B?cl=zh">CN104582187B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2015年1月14日</td><td class="patent-data-table-td patent-date-value">2016年4月13日</td><td class="patent-data-table-td ">山东大学</td><td class="patent-data-table-td ">基于人脸识别和表情识别的记录与灯光控制系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2010124584A1?cl=zh">WO2010124584A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年4月22日</td><td class="patent-data-table-td patent-date-value">2010年11月4日</td><td class="patent-data-table-td ">Wuhan Guide Electric Co., Ltd.</td><td class="patent-data-table-td ">实景游戏装置及实现实景游戏的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2011137627A1?cl=zh">WO2011137627A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年9月30日</td><td class="patent-data-table-td patent-date-value">2011年11月10日</td><td class="patent-data-table-td ">Zte Corporation</td><td class="patent-data-table-td ">智能控制移动终端的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013149556A1?cl=zh">WO2013149556A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年3月25日</td><td class="patent-data-table-td patent-date-value">2013年10月10日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">在虚拟形象上自动播放表情的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015055047A1?cl=zh">WO2015055047A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年8月20日</td><td class="patent-data-table-td patent-date-value">2015年4月23日</td><td class="patent-data-table-td ">智尊应用程序开发有限公司</td><td class="patent-data-table-td ">游戏控制方法及设备</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0019000000">G06F19/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=A63F0013420000">A63F13/42</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=u29oBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2009年3月25日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年9月15日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年2月8日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/227af6402b86a2479b05/CN101393599A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E7%9A%84%E6%B8%B8%E6%88%8F%E8%A7%92%E8%89%B2.pdf?id=u29oBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2aEAmH11dC22cjTCtNGKnFKm63_A"},"sample_url":"https://www.google.com/patents/reader?id=u29oBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>