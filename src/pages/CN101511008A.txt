<!DOCTYPE html><html><head><title>专利 CN101511008A - 一种多分屏图像处理的方法和设备 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种多分屏图像处理的方法和设备"><meta name="DC.contributor" content="坚 吴" scheme="inventor"><meta name="DC.contributor" content="孔令波" scheme="inventor"><meta name="DC.contributor" content="奕 雷" scheme="inventor"><meta name="DC.contributor" content="黄建强" scheme="inventor"><meta name="DC.contributor" content="杭州华三通信技术有限公司" scheme="assignee"><meta name="DC.date" content="2009-4-10" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供一种多分屏图像处理的方法和设备，该方法应用于与两个以上终端设备连接的图像处理设备，包括：所述图像处理设备解码各终端设备发送的码流；所述图像处理设备确定解码获得的图像中的人脸区域；所述图像处理设备根据所述人脸区域确定所述图像的输出送显区域；所述图像处理设备将所述图像的输出送显区域拼接为多分屏显示图像并编码发送到相应的终端设备。本发明中，图像处理设备获取各终端设备发送的图像后，根据图像中的人脸区域确定图像的输出送显区域，进一步将图像的输出送显区域拼接为完整的多分屏显示图像，从而可以在多分屏会议中获取清楚的与会者的图像信息。"><meta name="DC.date" content="2009-8-19"><meta name="citation_patent_publication_number" content="CN:101511008:A"><meta name="citation_patent_application_number" content="CN:200910131236"><link rel="canonical" href="https://www.google.com/patents/CN101511008A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101511008A?cl=zh"/><meta name="title" content="专利 CN101511008A - 一种多分屏图像处理的方法和设备"/><meta name="description" content="本发明提供一种多分屏图像处理的方法和设备，该方法应用于与两个以上终端设备连接的图像处理设备，包括：所述图像处理设备解码各终端设备发送的码流；所述图像处理设备确定解码获得的图像中的人脸区域；所述图像处理设备根据所述人脸区域确定所述图像的输出送显区域；所述图像处理设备将所述图像的输出送显区域拼接为多分屏显示图像并编码发送到相应的终端设备。本发明中，图像处理设备获取各终端设备发送的图像后，根据图像中的人脸区域确定图像的输出送显区域，进一步将图像的输出送显区域拼接为完整的多分屏显示图像，从而可以在多分屏会议中获取清楚的与会者的图像信息。"/><meta property="og:title" content="专利 CN101511008A - 一种多分屏图像处理的方法和设备"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101511008A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101511008A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=JoNsBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101511008A&amp;usg=AFQjCNGlNZWgzBTAoUz89DTo9V4z6SMEBg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/1c4a79a61cc37977eb65/CN101511008A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/1c4a79a61cc37977eb65/CN101511008A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101511008A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101511008A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101511008A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101511008B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101511008A?cl=zh" style="display:none"><span itemprop="description">本发明提供一种多分屏图像处理的方法和设备，该方法应用于与两个以上终端设备连接的图像处理设备，包括：所述图像处理设备解码各终端设备发送的码流；所述图像处理设备确定解码获得的图像中的人脸区域；所述图像处理...</span><span itemprop="url">https://www.google.com/patents/CN101511008A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101511008A - 一种多分屏图像处理的方法和设备</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101511008A - 一种多分屏图像处理的方法和设备" title="专利 CN101511008A - 一种多分屏图像处理的方法和设备"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101511008 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200910131236</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2009年8月19日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2009年4月10日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2009年4月10日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101511008B?hl=zh-CN&amp;cl=zh">CN101511008B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200910131236.8, </span><span class="patent-bibdata-value">CN 101511008 A, </span><span class="patent-bibdata-value">CN 101511008A, </span><span class="patent-bibdata-value">CN 200910131236, </span><span class="patent-bibdata-value">CN-A-101511008, </span><span class="patent-bibdata-value">CN101511008 A, </span><span class="patent-bibdata-value">CN101511008A, </span><span class="patent-bibdata-value">CN200910131236, </span><span class="patent-bibdata-value">CN200910131236.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%9D%9A+%E5%90%B4%22">坚 吴</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%94%E4%BB%A4%E6%B3%A2%22">孔令波</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%A5%95+%E9%9B%B7%22">奕 雷</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%BB%84%E5%BB%BA%E5%BC%BA%22">黄建强</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%9D%AD%E5%B7%9E%E5%8D%8E%E4%B8%89%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">杭州华三通信技术有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101511008A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101511008A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101511008A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=JoNsBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200910131236&amp;usg=AFQjCNE0nl0Nd0-rQfiWkqubTgC45M4OmA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=JoNsBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101511008A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFRGvrObf7e4KSMNG0dVAcEoC6JtA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT85356395" lang="ZH" load-source="patent-office">一种多分屏图像处理的方法和设备</invention-title>
      </span><br><span class="patent-number">CN 101511008 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA61537782" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供一种多分屏图像处理的方法和设备，该方法应用于与两个以上终端设备连接的图像处理设备，包括：所述图像处理设备解码各终端设备发送的码流；所述图像处理设备确定解码获得的图像中的人脸区域；所述图像处理设备根据所述人脸区域确定所述图像的输出送显区域；所述图像处理设备将所述图像的输出送显区域拼接为多分屏显示图像并编码发送到相应的终端设备。本发明中，图像处理设备获取各终端设备发送的图像后，根据图像中的人脸区域确定图像的输出送显区域，进一步将图像的输出送显区域拼接为完整的多分屏显示图像，从而可以在多分屏会议中获取清楚的与会者的图像信息。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM22746982" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1、一种多分屏图像处理的方法，应用于与两个以上终端设备连接的图像处理设备，其特征在于，包括：所述图像处理设备解码各终端设备发送的码流；所述图像处理设备确定所述解码获得的图像中的人脸区域；所述图像处理设备根据所述人脸区域确定所述图像的输出送显区域；所述图像处理设备将所述图像的输出送显区域拼接为多分屏显示图像，并编码发送到相应的终端设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2、 如权利要求l所述的方法，其特征在于，所述图像处理设备确定解 码获得的图像中的人脸区域包括：所述图像处理设备建立人脸的图形信息数据库；所述图像处理设备将所述人脸的图形信息数据库中的图形信息与所述 图像中的图形信息进行匹配；所述图像处理设备将匹配成功的图形信息所在的区域确定为人脸区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3、 如权利要求1或2所述的方法，其特征在于，所述图像处理设备根 据所述人脸区域确定所述图像的输出送显区域包括：所述图像处理设备根据多分屏显示图像的长宽比，以所述人脸区域为 中心确定准输出送显区域；所述图像处理设备比较所述准输出送显区域的尺寸与预定输出图像尺 寸的大小；当所述准输出送显区域的尺寸大于所述预定输出图像尺寸时，所述图 像处理设备将所述准输出送显区域缩小为预定输出图像尺寸，作为所述&#22291; 像的输出送显区域；当所述待输出送显区域的尺寸小于所迷预定输出图像尺寸时，所述图 像处理设备以所述待输出送显区域为中心确定所述图像的输出送显区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4、 如权利要求3所述的方法，其特征在于，所述图像处理设备根据所 述人脸区域确定所述图像的输出送显区域还包括：当所述人脸区域不唯一时，或者当所述人脸区域没有互相连接时，所 述图像处理设备以所有人脸区域互相连接后的区域为中心确定准输出送显 区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5、 如权利要求1所述的方法，其特征在于，所述图像处理设备解码各 终端设备发送的码流之后，还包括：所述图像处理设备获取所述图像的运动矢量分布信息；所述图像处理设备根据所述图像的运动矢量分布信息预先判断所述图 像的人脸区域与上一时刻图像的人脸区域相比是否发生变化；当判断结果为否时，所述图像处理设备将上一时刻图像的输出送显区 域作为所述图像的输出送显区域；当判断结果为是时，所述图像处理设备确定所述解码获得的图像中的 人脸区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6、 如权利要求5所述的方法，其特征在于，所述图像处理设备确定所 述图像中的人脸区域之后，还包括：所述图像处理设备判断所述图像中的人脸区域是否处于上一时刻图像 的输出送显区域内；判断结果为是时，所述图像处理设备将所述上 一 时刻图像的输出送显 区域作为所述图像的输出送显区域；判断结果为否时，所述图像处理设备根据所述人脸区域确定所述图像 的输出送显区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7、 如权利要求5或6所述的方法，其特征在于，所述上一时刻图像具体为上一帧图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8、 如权利要求1所述的方法，其特征在于，所述图像处理设备确定所 述解码获得的图像中的人脸区域之后，还包括：所述图像处理设备获取所述图像的运动矢量分布信息； 所述图像处理设备根据所述图像的运动矢量分布信息确定发生运动的 图像区域；所述图像处理设备根据所述发生运动的图像区域和所述人脸区域确定输出送显区域，该输出送显区域包括该运动图像区域和人脸区域。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9、 一种图像处理设备，与两个以上终端设备连接，其特征在于，包括： 图像解码单元，用于解码各终端设备发送的码流；人脸确定单元，用于确定所述图像解码单元解码获得的图像中的人脸 区域；图像的输出送显区域；图像发送单元，用于将所述输出区域单元确定的图像的输出送显区域 拼接为多分屏显示图像，并编码发送到相应的终端设备。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10、 如权利要求9所述的图像处理设备，其特征在于，所述人脸确定 单元包括：图形建立子单元，用于建立人脸的图形信息数据库； 图形匹配子单元，用于将所述图形建立子单元建立的人脸的图形信息数据库中的图形信息，与所述图像中的图形信息进行匹配；区域确定子单元，用于当所述图形匹配子单元匹配成功时，将所述匹配成功的图形信息所在的区域确定为人脸区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11、 如权利要求9或IO所述的图像处理设备，其特征在于，所述输出 区域单元包括：准输出区域子单元，用于根据多分屏显示图像的长宽比以所述人脸区 域为中心确定准输出送显区域；区域比较子单元，用于比较所述准输出区域子单元确定的准输出送显 区域的尺寸与预定输出图像尺寸的大小；缩小子单元，用于当所述区域比较子单元的结果为所述准输出送显区 域的尺寸大于所述预定输出图像尺寸时，将所述准输出送显区域缩小为预 定输出图像尺寸，作为所述图像的输出送显区域；中心子单元，用于当所述区域比较子单元的结果为所述准输出送显区 域的尺寸小于所述预定输出图像尺寸时，以所述准输出送显区域为中心确 定所述图像的输出送显区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12、 如权利要求9所述的图像处理设备，其特征在于，还包括： 运动信息单元，用于获取所述图像的运动矢量分布信息； 第一判断单元，用于根据所述运动信息单元获取的运动矢量分布信息预先判断所述图像的人脸区域与上一时刻图像的人脸区域相比是否发生变 化；所述输出区域单元还用于，当所述第一判断单元的判断结果为否时， 将上一时刻图像的输出送显区域作为所述图像的输出送显区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13、 如权利要求12所述的图像处理设备，其特征在于，还包括： 第二判断单元，用于当所述第一判断单元的判断结果为是时，判断所述图像中的人脸区域是否处于所述上一时刻图像的输出送显区域内；所述输出区域单元还用于：当所述第二判断单元的判断结果为是时， 将所述上一时刻图像的输出送显区域作为所述图像的输出送显区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14、 如权利要求9所述的图像处理设备，其特征在于，还包括： 运动信息单元，用于获取所述图像的运动矢量分布信息； 运动区域单元，用于根据所述运动信息单元获取的运动矢量分布信息确定发生运动的图像区域；所述输出区域单元还用于：根据所述运动区域单元确定的发生运动的 图像区域和所述人脸确定单元确定的人脸区域确定输出送显区域，该输出 送显区域包括运动图像区域和人脸区域。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES27941661" lang="ZH" load-source="patent-office" class="description">
    <p>一种多分屏图像处理的方法和设备</p>
    <p>技术领域</p>
    <p>本发明涉及通信领域，尤其涉及一种多分屏图像处理的方法 和设备。</p>
    <p>背景技术</p>
    <p>随着世界经济的快速增长以及电子政务和企业信息化的迅速 推进，视频会议的发展越来越受到人们的重视。多方会议是视频 会议中的重要应用，与会者可以同时查看多个会场的信息，由此 产生将多个会场的信息同时显示给用户的需要，尤其是将多个会 场的信息同时显示在同一屏幕上，即多分屏显示的需要，这种使 用多分屏显示技术的多方会议称为多分屏会议。</p>
    <p>如图1所示，为现有技术中多分屏会议的典型系统架构图，</p>
    <p>包括MCU ( Multi-point Control Unit,多点控制单元）以及多台TE (Terminal Equipment,终端设备）。MCU是多分屏会议系统的核 心部分，为用户提供群组会议、多组会议的连接服务。具体的， MCU与多个TE连接，接收并解码各个TE发送的码流，获取各个 会场的图像信息；然后，MCU根据显示屏幕的大小将接收到各个 TE的图像进行缩小，再将各个缩小后的图像拼接成一个完整屏幕 大小的图像；并对该拼接后的图像进行编码，发送码流至各台TE。 各台TE接收到MCU发送的码流后，解码该码流获得多分屏显示 图像。</p>
    <p>以四分屏会议为例，图2是现有技术中四分屏会议图像显示示 意图，MCU将各个会场的图像缩小为原始图像的1/4,然后再拼 接成四分屏显示图像发送到各终端设备显示，即输出送显，具体 的，如图3所示，现有技术中实现四分屏会议的流程包括：</p>
    <p>6步骤s301,终端设备发送MG编码码流。</p>
    <p>步骤s302, MCU解码收到的MG编码码流，获得各会场的图像。</p>
    <p>步骤s303， MCU对解码得到的图像进行缩小，缩小到原屏幕 图像的l/4并拼接，获得多分屏显示图像。</p>
    <p>步骤s304, MCU对该多分屏显示图像进行编码，将编码得到 的码流发送到各终端设备。</p>
    <p>现有技术中存在的问题在于：多分屏显示图像的获取需要根 据显示区域对原图像进行缩小，但是缩小后的多分屏显示图像清 晰度降低，导致多分屏会议中最关心的与会者图像信息模糊。</p>
    <p>发明内容</p>
    <p>本发明提供一种多分屏图像处理的方法和设备，以提高多分</p>
    <p>屏显示图像中与会者图像的清晰度。</p>
    <p>为了实现上述目的，本发明提供一种多分屏图像处理的方法，</p>
    <p>应用于与两个以上终端设备连接的图像处理设备，包括： 所述图像处理设备解码各终端设备发送的码流； 所述图像处理设备确定所述解码获得的图像中的人脸区域； 所述图像处理设备根据所述人脸区域确定所述图像的输出送</p>
    <p>显区域；</p>
    <p>所述图像处理设备将所述图像的输出送显区域拼接为多分屏</p>
    <p>显示图像，并编码发送到相应的终端设备。</p>
    <p>所述图像处理设备确定解码获得的图像中的人脸区域包括：</p>
    <p>所述图像处理设备建立人脸的图形信息数据库；</p>
    <p>所述图像处理设备将所述人脸的图形信息数据库中的图形信</p>
    <p>息与所述图像中的图形信息进行匹配；</p>
    <p>所述图像处理设备将匹配成功的图形信息所在的区域确定为</p>
    <p>人脸区域。</p>
    <p>所述图像处理设备根据所述人脸区域确定所述图像的输出送显区域包括：</p>
    <p>所述图像处理设备根据多分屏显示图像的长宽比，以所述人 脸区域为中心确定准输出送显区域；</p>
    <p>所述图像处理设备比较所述准输出送显区域的尺寸与预定输 出图像尺寸的大小；</p>
    <p>时，所述图像处理设备将所述准输出送显区域缩小为预定输出图 像尺寸，作为所述图像的输出送显区域；</p>
    <p>当所述待输出送显区域的尺寸小于所述预定输出图像尺寸 时，所述图像处理设备以所述待输出送显区域为中心确定所述图 像的输出送显区域。</p>
    <p>所述图像处理设备根据所述人脸区域确定所述图像的输出送 显区域还包括：</p>
    <p>当所述人脸区域不唯一时，或者当所述人脸区域没有互相连 接时，所述图像处理设备以所有人脸区域互相连接后的区域为中 心确定准输出送显区域。</p>
    <p>所述图像处理设备解码所述终端设备发送的码流之后，还包</p>
    <p>括：</p>
    <p>所述图像处理设备获取所述图像的运动矢量分布信息； 所述图像处理设备根据所述图像的运动矢量分布信息预先判</p>
    <p>断所述图像的人脸区域与上一时刻图像的人脸区域相比是否发生</p>
    <p>变化；</p>
    <p>当判断结果为否时，所述图像处理设备将上一时刻图像的输 出送显区域作为所述图像的输出送显区域；</p>
    <p>当判断结果为是时，所述图像处理设备确定所述解码获得的 图像中的人脸区域。</p>
    <p>所述图像处理设备确定所述图像中的人脸区域之后，还包括：</p>
    <p>所述图像处理设备判断所述图像中的人脸区域是否处于上一 时刻图像的输出送显区域内；</p>
    <p>8判断结果为是时，所述图像处理设备将所述上 一 时刻图像的</p>
    <p>输出送显区域作为所述图像的输出送显区域；</p>
    <p>判断结果为否时，所述图像处理设备根据所述人脸区域确定 所述图像的输出送显区域。</p>
    <p>所述上一时刻图像具体为上一帧图像。</p>
    <p>所述图像处理设备确定所述解码获得的图像中的人脸区域之 后，还包括：</p>
    <p>所述图像处理设备获取所述图像的运动矢量分布信息；</p>
    <p>所述图像处理设备根据所述图像的运动矢量分布信息确定发</p>
    <p>生运动的图像区域；</p>
    <p>所述图像处理设备根据所述发生运动的图像区域和所述人脸</p>
    <p>区域确定输出送显区域，该输出送显区域包括该运动图像区域和</p>
    <p>人脸区域。</p>
    <p>本发明提供一种图像处理设备，与两个以上终端设备连接，包括..</p>
    <p>图像解码单元，用于解码各终端设备发送的码流； 人脸确定单元，用于确定所述图像解码单元解码获得的图像 中的人脸区域；</p>
    <p>输出区域单元，用于根据所述人脸确定单元确定的人脸区域 确定所述图像的输出送显区域；</p>
    <p>图像发送单元，用于将所述输出区域单元确定的图像的输出 送显区域拼接为多分屏显示图像，并编码发送到相应的终端设备。</p>
    <p>所述人脸确定单元包括：</p>
    <p>图形建立子单元，用于建立人脸的图形信息数据库； 图形匹配子单元，用于将所述图形建立子单元建立的人脸的</p>
    <p>图形信息数据库中的图形信息，与所述图像中的图形信息进行匹</p>
    <p>配；</p>
    <p>区域确定子单元，用于当所述图形匹配子单元匹配成功时， 将所述匹配成功的图形信息所在的区域确定为人脸区域。</p>
    <p>9所述输出区域单元包括：</p>
    <p>准输出区域子单元，用于根据多分屏显示图像的长宽比以所 述人脸区域为中心确定准输出送显区域；</p>
    <p>区域比较子单元，用于比较所述准输出区域子单元确定的准 输出送显区域的尺寸与预定输出图像尺寸的大小；</p>
    <p>缩小子单元，用于当所述区域比较子单元的结果为所述准输 出送显区域的尺寸大于所述预定输出图像尺寸时，将所述准输出 送显区域缩小为预定输出图像尺寸，作为所述图像的输出送显区 域；</p>
    <p>中心子单元，用于当所述区域比较子单元的结果为所述准输 出送显区域的尺寸小于所述预定输出图像尺寸时，以所述准输出 送显区域为中心确定所述图像的输出送显区域。</p>
    <p>本发明提供的图像处理设备，还包括：</p>
    <p>运动信息单元，用于获取所述图像的运动矢量分布信息；</p>
    <p>第一判断单元，用于根据所述运动信息单元获取的运动矢量</p>
    <p>分布信息预先判断所述图像的人脸区域与上一时刻图像的人脸区 域相比是否发生变化；</p>
    <p>所述输出区域单元还用于，当所述第一判断单元的判断结果 为否时，将上一时刻图像的输出送显区域作为所述图像的输出送 显区域。</p>
    <p>本发明提供的图像处理设备，还包括：</p>
    <p>第二判断单元，用于当所述第一判断单元的判断结果为是时， 判断所述图像中的人脸区域是否处于所述上一时刻图像的输出送 显区i或内；</p>
    <p>所述输出区域单元还用于，当所述第二判断单元的判断结果</p>
    <p>为是时，将所述上 一 时刻图像的输出送显区域作为所述图像的输</p>
    <p>出送显区域。</p>
    <p>本发明提供的图像处理设备，还包括：</p>
    <p>运动信息单元，用于获取所述图像的运动矢量分布信息；</p>
    <p>10运动区域单元，用于根据所述运动信息单元获取的运动矢量</p>
    <p>分布信息确定发生运动的图像区域；</p>
    <p>所述输出区域单元还用于，根据所述运动区域单元确定的发 生运动的图像区域和所述人脸确定单元确定的人脸区域确定输出 送显区域，该输出送显区域包括该运动图像区域和人脸区域。 与现有技术相比，本发明至少具有以下优点： 图像处理设备获取各终端设备发送的图像后，根据图像中的 人脸区域确定图像的输出送显区域，进一步将图像的输出送显区 域拼接为完整的多分屏显示图像，从而可以在多分屏会议中获取 清楚的与会者的图像信息。</p>
    <p>附图说明</p>
    <p>图1为现有技术中多分屏会议的典型系统架构图；</p>
    <p>图2为现有技术中四分屏会议图像显示示意图；</p>
    <p>图3为现有技术中实现四分屏会议的流程示意图；</p>
    <p>图4为本发明提供的多分屏图像处理的方法的流程示意图；</p>
    <p>图5为本发明提供的多分屏图像处理的方法的流程示意图；</p>
    <p>图6为本发明一应用场景中MCU获取终端设备的图像并确定</p>
    <p>图像的输出送显区域的流程示意图；</p>
    <p>图7为本发明另一应用场景中MCU获取终端设备的图像并确</p>
    <p>定图像的输出送显区域的流程示意图；</p>
    <p>图8为本发明一应用场景中多分屏图像处理的方法的流程示</p>
    <p>意图；</p>
    <p>图9为本发明一实施例提供的图像处理设备的结构示意图； 图10为本发明另 一实施例中图像处理设备的的结构示意图； 图11为本发明另一实施例中图像处理设备的的结构示意图。</p>
    <p>具体实施方式本发明提供一种多分屏图像处理的方法，应用于与两个以上终</p>
    <p>端设备连接的图像处理设备，如图4所示，包括：</p>
    <p>步骤s401,图像处理设备解码终端设备发送的码流。</p>
    <p>步骤s402,图像处理设备确定解码获得的图像中的人脸区域。</p>
    <p>步骤s403,图像处理设备根据人脸区域确定图像的输出送显区域。</p>
    <p>步骤s404，图像处理设备将图像的输出送显区域拼接为多分屏 显示图像并编码发送到相应的终端设备。</p>
    <p>下面结合 一 具体应用场景对本发明提供的方法进行详细介 绍。本发明提供一种多分屏图像处理的方法，其中，图像处理设备 以MCU为例，如图5所示，包括以下步骤：</p>
    <p>步骤s501, MCU解码各终端设备发送的码流，获取各会场的 图像。</p>
    <p>若该图像为MCU解码的第一帧图像，则直接执行步骤s504; 否则继续。</p>
    <p>步骤s502, MCU根据图像的运动矢量分布信息预先判断图像 的人脸区域与上一帧图像的人脸区域相比是否发生变化。若发生 了变化，则执行步骤s504;否则执行步骤s503。</p>
    <p>具体的，MCU解码图像时，获取图像的运动矢量分布信息， 该运动矢量分布信息可以通过运动矢量分布图提供。运动矢量分 布图上以若干像素块，例如16*16的像素块为单位标识图像的运 动情况，记录像素块在上一帧图像与当前图像上的位置变化。MCU 存储上一次检测出的人脸区域，以及运动矢量分布图上该人脸区 域内的像素块位置信息，比较当前运动矢量分布图上该人脸区域 内的像素块位置信息的变化。例如，若上一帧图像的运动矢量分 布图上该人脸区域内的像素块有8个，当前运动矢量分布图上该 人脸区域内的像素块为6个，则可以直接判断图像的人脸区域发 生了变化；或者，整体发生了位置移动，则可以设置位置移动阈值作为判断人脸区域是否发生移动的标准，例如该阈值可以设置</p>
    <p>为6个像素点，若当前运动矢量分布图上该人脸区域内的像素块 位置整体移动了 5个像素点，则MCU判断该人脸区域没有发生变 化。</p>
    <p>对于上述人脸区域内像素块位置的整体移动，可以采用多种 方式进行判断，例如，可以将像素块向上和向右的位置变化取正 值，向下和向左的位置变化取负值，最后加和求出平均值，作为 人脸区域内像素块位置的整体移动值。</p>
    <p>步骤s503,MCU将上一帧图像的输出送显区域作为当前图像 的输出送显区域。</p>
    <p>步骤s504， MCU利用人脸检测算法确定解码获得的图像中的 人脸区域。</p>
    <p>具体的，MCU建立人脸的图形信息数据库，将人脸的图形信 息数据库中的图形信息与解码获得的图像中的图形信息进行匹 配；当匹配成功时，MCU将匹配成功的图形信息所在区域确定为 人脸区域。</p>
    <p>步骤s506, MCU根据人脸区域确定图像的准输出送显区域。 MCU根据多分屏显示图像的长宽比以上述确定的人脸区域为 中心确定准输出送显区域，即以人脸区域的长或宽为基准，根据 多分屏显示图像的长宽比确定准输出送显区域。例如，人脸区域 的纵坐标长度大于横坐标长度时，可以以人脸区域的纵坐标长度 为基准，根据多分屏显示图像的长宽比确定相应的宽度，作为准 输出送显区域的宽，并以人脸区域的纵坐标长度作为准输出送显 区域的长。</p>
    <p>当步骤s504中确定的人脸区域不唯一时，或者当多个人脸区 域彼此没有互相连接时，MCU可以以所有人脸区域互相连接后的 区域为中心确定准输出送显区域。例如，当图像中有三个人脸区 域A、 B、 C,并且A、 B、 C分别处于图像的中间位置、左上侧和 左下侧，且彼此没有连接时，MCU以人脸区域A、 B、 C连接后的区域为基础，确定准输出送显区域。</p>
    <p>步骤s507, MCU根据准输出送显区域确定输出送显区域。 MCU比较准输出送显区域的尺寸与预定尺寸的大小；当准输 出送显区域的尺寸大于预定尺寸时，MCU将准输出送显区域缩小 为预定尺寸，作为图像的输出送显区域；当待输出送显区域的尺 寸小于预定尺寸时，MCU以准输出送显区域为中心确定图像的输 出送显区域。MCU输出送显区域的预定尺寸由需要显示的多分屏 图像决定，例如MCU需要输出四分屏显示图像时，则输出送显区 域的预定尺寸为屏幕的1/4，输出送显区域的长宽比可以为1: 1。 步骤s508, MCU将图像的输出送显区域拼接为多分屏显示图 像并编码发送到相应的终端设备。</p>
    <p>MCU可以根据预置的顺序将图像的输出送显区域拼接为多分 屏显示图像，然后进行编码发送。</p>
    <p>本应用场景中，步骤s504与步骤s506之间，还可以包括： 步骤s505, MCU判断图像中的人脸区域是否处于上一帧图像 的输出送显区域内。判断结果为是时，执行步骤s503;否则执行 步骤s506。具体的，MCU可以存储上一帧图像的输出送显区域的 位置信息，例如坐标信息，根据该坐标信息判断上述步骤中确定 的人脸区域是否在该输出送显区域内。</p>
    <p>下面再结合一具体应用场景对本发明提供的多分屏图像处理 的方法进行进一步介绍。其中，以四分屏显示为例，MCU获取终 端设备的图像并确定图像的输出送显区域的流程如图6所示，包 括以下步骤：</p>
    <p>步骤s601, MCU解码终端设备发送的码流，获取第一帧的图像。</p>
    <p>步骤s602， MCU对第一帧的图像进行人脸检测算法，根据识 别出的人脸，确定人脸区域。</p>
    <p>MCU中存储的人脸图形信息库中可以存储多种图形信息，例如人眼的图形信息，并设定两个眼睛之间的距离为5mm-5cm，当 图像中存在两个人眼的图形并且两个人眼的图形之间的距离在 5mm-5cm内时，MCU可以确定以该两个眼睛图形为中心的区域为 人脸区域。例如，当MCU获取的第一帧的图像中出现两个眼睛图 形，且这两个眼睛图形之间的距离为1.5cm时，MCU可以确定以 这两个眼睛图形为中心，向上3倍于1.5cm的距离、向下5倍于 1.5cm的距离、左右各lcm的距离为人脸区域。</p>
    <p>步骤s603, MCU才艮据人脸区域确定输出送显区域。 具体的，MCU根据人脸区域确定输出送显区域可以为：MCU 根据四分屏显示图像的长宽比和尺寸提取以人脸区域为中心的图 像作为准输出送显区域，将准输出送显区域整体缩小、放大或不 改变尺寸，作为图像的输出送显区域。例如，当四分屏显示图像 为四块尺寸为10cm*10cm的图像构成时，图像的输出送显区域应 当为10cm承10cm大小。若MCU获取的人脸区域为12 cm *3.5cm 时，MCU可以首先确定以该人脸区域为核心的12cm^2cm作为 准输出送显区域，将该准输出送显区域缩小为10cm*10cm,作为 输出送显区域。然后MCU将该输出送显区域与其它终端设备发送 的图像的输出送显区域拼接为完整的四分屏显示图像，并编码传 输到相应的终端设备。</p>
    <p>步骤s604， MCU解码下一帧的图像，获取该帧图像的运动矢 量分布信息。</p>
    <p>该图像的运动矢量分布信息可以由MCU从解码时产生的运 动矢量分布图像上获取。</p>
    <p>步骤s605, MCU根据运动矢量分布信息判断人脸区域是否发 生变化；若发生变化，则执行步骤s606;若没有发生变化，执行 步骤s608。</p>
    <p>例如，第一帧图像上的人脸区域由七个像素块构成，该下一 帧图像的运动矢量分布图像上显示这七个像素块的位置整体向左 平移了  lcm,则可以据此推断人脸区域发生了变化，需要重新确</p>
    <p>15定人脸区域，提取新的图像信息。</p>
    <p>步骤s606, MCU对下一帧图像进行人脸4企测算法，获取该图 像的人脸区域。</p>
    <p>步骤s607， MCU判断该人脸区域是否在第一帧图像的输出显 示区域内；若在，则执行步骤s608;否则，执行步骤s609。</p>
    <p>步骤s608, MCU继续进行下一帧图像的解码。</p>
    <p>步骤s609, MCU根据步骤s606中获取的图像的人脸区域重 新确定输出显示区域。</p>
    <p>本应用场景中，人脸检测算法可以但不限于识别图像中的人 脸，例如还可以用来识别图像中的麦克风等具有重要意义的图像 信息。人脸区域与人脸检测算法检测的图像信息相适应，当人脸 检测算法检测的图像信息为麦克风时，人脸区域可以为麦克风所 在的图像区域。</p>
    <p>下面结合另 一 具体应用场景对本发明提供的多分屏图像处理 的方法进行介绍，其中，MCU获取终端设备的图像并确定图像的 输出送显区域的流程如图7所示，包括以下步骤：</p>
    <p>步骤s701， MCU解码终端设备发送的码流，获取图像。</p>
    <p>步骤s702， MCU获取该图像的运动矢量分布信息，获取发生 运动的图像区域。</p>
    <p>具体的，MCU根据运动矢量分布信息上像素块的变化确定发 生运动的图像区域。</p>
    <p>步骤s703, MCU对获取到的图像进行人脸检测算法，获取该 图像的人脸区域。</p>
    <p>步骤s704， MCU将包括发生运动的图像区域和人脸区域的区 域作为输出送显区域。</p>
    <p>具体的，MCU以发生运动的图像区域和人脸区域为核心确定 输出送显区域。其中，发生运动的图像区域与人脸区域可以在图 像的两个不同位置，输出送显区域包括该两个位置之间的区域。</p>
    <p>16例如，人在讲话时，如果有手势，则MCU可以通过运动矢量分布 信息获取手的图像区域，根据人脸检测算法获取人脸区域，然后 建立包括这两个区域的输出送显区域，获取该输出送显区域的图 像信息，包括人脸与手的图像信息。</p>
    <p>上述步骤s702与步骤s703之间的顺序还可以相互调换，并不 影响实现的效果。</p>
    <p>下面结合另一具体应用场景对本发明提供的多分屏图像处理 的方法进行进一步介绍。以四分屏显示为例，如图8所示，包括 以下步骤：</p>
    <p>步骤s801， MCU"I妄收四个终端设备发送的编码码流。 MCU可以通过多个接口同时接收各终端设备发送的码流，也 可以按照一定的顺序进行接收。满足每秒钟最少输出25帧图像的 前提下，MCU接收编码码流的方式可以灵活设置。</p>
    <p>步骤s802， MCU解码各终端设备发送的码流获得四副图像。 步骤s803， MCU对解码获得的图像提取重要信息，获取输出 送显区域。</p>
    <p>其中，MCU对解码获得的图像提取重要信息的方法可以为：</p>
    <p>MCU对图像进行人脸检测算法，以获取的人脸区域作为中心 获取输出送显区域；或者</p>
    <p>MCU对图像进行人脸检测算法，获取人脸区域；根据后续图 像的运动矢量分布信息确定人脸区域是否发生运动，若发生运动， 则MCU对后续图像进行人脸检测算法，确定新的人脸区域并根据 该新的人脸区域进一步确定输出送显区域；或者</p>
    <p>MCU对图像进行人脸检测算法，获取人脸区域；并且，MCU 根据运动矢量分布信息获取发生运动的图像区域；MCU建立以人 脸区域和发生运动的图像区域为中心的输出送显区域。</p>
    <p>步骤s804， MCU将获得的输出送显区域的图像拼接为完整的 四分屏显示图像。</p>
    <p>17步骤s805， MCU将四分屏显示图像进行编码，并将编码码流 发送到四个终端设备，实现四分屏显示。</p>
    <p>通过采用本发明提供的方法，MCU获取各终端设备的图像后， 根据图像中的人脸区域确定图像的输出送显区域，并根据图像的 输出送显区域提取相应的图像信息拼接为完整的多分屏显示图像 发送到终端设备，从而可以在多分屏显示会议中获取清楚的与会 者的图像信息。</p>
    <p>本发明提供一种图像处理设备，与两个以上终端设备连接，如 图9所示，包括：</p>
    <p>图像解码单元91，用于解码各终端设备发送的码流；</p>
    <p>人脸确定单元92,用于确定所述图像解码单元91解码获得的 图像中的人脸区域；</p>
    <p>可选的，该单元包括：</p>
    <p>图形建立子单元921,用于建立人脸的图形信息数据库； 图形匹配子单元922,用于将所述图形建立子单元921建立的</p>
    <p>人脸的图形信息数据库中的图形信息，与所述图像中的图形信息</p>
    <p>进4亍匹配；</p>
    <p>区域确定子单元923,用于当所述图形匹配子单元922匹配成 功时，将所述匹配成功的图形信息所在区域确定为人脸区域。</p>
    <p>输出区域单元93，用于根据所述人脸确定单元92确定的人脸 区域确定所述图像的输出送显区域；</p>
    <p>可选的，该单元包括：</p>
    <p>准输出区域子单元931，用于根据多分屏显示图像的长宽比以 所述人脸区域为中心确定准输出送显区域；</p>
    <p>区域比较子单元932，用于比较所述准输出区域子单元931确 定的准输出送显区域的尺寸与预定输出图像尺寸的大小；</p>
    <p>缩小子单元933，用于当所述区域比较子单元932的结果为所 述准输出送显区域的尺寸大于所述预定输出图像尺寸时，将所述准输出送显区域缩小为预定输出图像尺寸，作为所述图像的输出</p>
    <p>送显区域；</p>
    <p>中心子单元934,用于当所述区域比较子单元932的结果为所 述准输出送显区域的尺寸小于所述预定输出图像尺寸时，以所述 准输出送显区域为中心确定所述图像的输出送显区域。</p>
    <p>图像发送单元94,用于将所述输出区域单元93确定的图像的 输出送显区域拼接为多分屏显示图像并编码发送到相应的终端设 备。</p>
    <p>如图10所示，本发明提供的设备还包括：</p>
    <p>运动信息单元101,用于获取所述图像的运动矢量分布信息；</p>
    <p>第一判断单元102，用于根据所述运动信息单元101获取的运</p>
    <p>动矢量分布信息预先判断所述图像的人脸区域与上一时刻图像的</p>
    <p>人脸区域相比是否发生变化；</p>
    <p>所述输出区域单元93还用于，当所述第一判断单元102的判</p>
    <p>断结果为否时，将上一时刻图像的输出送显区域作为所述图像的</p>
    <p>输出送显区域。</p>
    <p>进一步，本发明提供的设备还可以包括：</p>
    <p>第二判断单元103，用于当所述第一判断单元102的判断结果</p>
    <p>为是时，判断所述图像中的人脸区域是否处于所述上一时刻图像</p>
    <p>的输出送显区域内；</p>
    <p>所述输出区域单元93还用于，当所述第二判断单元103的判</p>
    <p>断结果为是时，将所述上一时刻图像的输出送显区域作为所述图</p>
    <p>像的输出送显区域。</p>
    <p>其中，上一时刻图像具体为上一帧图像。 如图ll所示，本发明提供的设备中，还可以包括： 运动信息单元111,用于获取所述图像的运动矢量分布信息； 运动区域单元112，用于根据所述运动信息单元111获取的运</p>
    <p>动矢量分布信息确定发生运动的图像区域；</p>
    <p>所述输出区域单元93还用于，根据所述运动区域单元112确定的发生运动的图像区域和所述人脸确定单元92确定的人脸区域 确定输出送显区域，该输出送显区域包括该运动图像区域和人脸 区域。</p>
    <p>通过采用本发明提供的图像处理设备，获取各终端设备的图像 后，根据图像中的人脸区域确定图像的输出送显区域，并将图像 的输出送显区域拼接为完整的多分屏显示图像，并编码发送到终 端设备，从而可以在多分屏会议中获取清楚的与会者的图像信息。</p>
    <p>通过以上的实施方式的描述，本领域的技术人员可以清楚地 了解到本发明可以通过硬件实现，也可以借助软件加必要的通用 硬件平台的方式来实现。基于这样的理解，本发明的技术方案可 以以软件产品的形式体现出来，该软件产品可以存储在 一个非易 失性存储介质（可以是CD-ROM， U盘，移动硬盘等）中，包括 若干指令用以使得一台计算机设备（可以是个人计算机，服务器， 或者网络设备等）执行本发明各个实施例所述的方法。</p>
    <p>总之，以上所述仅为本发明的较佳实施例而已，并非用于限 定本发明的保护范围。凡在本发明的精神和原则之内，所作的任 何修改、等同替换、改进等，均应包括在本发明的保护范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102740155A?cl=zh">CN102740155A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月15日</td><td class="patent-data-table-td patent-date-value">2012年10月17日</td><td class="patent-data-table-td ">宇龙计算机通信科技(深圳)有限公司</td><td class="patent-data-table-td ">图像显示的方法及电子设备</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8866871">US8866871</a></td><td class="patent-data-table-td patent-date-value">2014年3月4日</td><td class="patent-data-table-td patent-date-value">2014年10月21日</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">Image processing method and image processing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014036741A1?cl=zh">WO2014036741A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月10日</td><td class="patent-data-table-td patent-date-value">2014年3月13日</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">图像处理方法和图像处理设备</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=JoNsBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0007180000">H04N7/18</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=JoNsBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2009年8月19日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年12月9日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年11月10日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/1c4a79a61cc37977eb65/CN101511008A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%A4%9A%E5%88%86%E5%B1%8F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C.pdf?id=JoNsBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1MDAe1TGqbi3zenenlSjgwJxWteg"},"sample_url":"https://www.google.com/patents/reader?id=JoNsBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>