<!DOCTYPE html><html><head><title>专利 CN101136015A - 一种计算图像之间相似度的方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种计算图像之间相似度的方法"><meta name="DC.contributor" content="彭宇新" scheme="inventor"><meta name="DC.contributor" content="肖建国" scheme="inventor"><meta name="DC.contributor" content="陈晓鸥" scheme="inventor"><meta name="DC.contributor" content="北大方正集团有限公司;北京大学;北京北大方正技术研究院有限公司" scheme="assignee"><meta name="DC.date" content="2006-9-1" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种图像相似度计算及检索方法。现有技术中，尽管考虑了利用图像分块的方法以提高检索的准确性，但在图像分块以后，采用的是对应块相似度度量的方法，最后图像的相似度是图像对应块相似度的平均值。本发明提出了一种基于分块最优匹配的图像检索方法。首先也对图像进行分块处理，并利用最优匹配在一对一匹配的前提下，计算两幅图像的全部分块所能达到的最大相似度。试验结果表明，与现有方法相比，本发明可以取得更高的检索准确性，从而可以充分发挥图像检索技术在信息检索中的巨大作用。"><meta name="DC.date" content="2008-3-5"><meta name="citation_patent_publication_number" content="CN:101136015:A"><meta name="citation_patent_application_number" content="CN:200610112799"><link rel="canonical" href="https://www.google.com/patents/CN101136015A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101136015A?cl=zh"/><meta name="title" content="专利 CN101136015A - 一种计算图像之间相似度的方法"/><meta name="description" content="本发明公开了一种图像相似度计算及检索方法。现有技术中，尽管考虑了利用图像分块的方法以提高检索的准确性，但在图像分块以后，采用的是对应块相似度度量的方法，最后图像的相似度是图像对应块相似度的平均值。本发明提出了一种基于分块最优匹配的图像检索方法。首先也对图像进行分块处理，并利用最优匹配在一对一匹配的前提下，计算两幅图像的全部分块所能达到的最大相似度。试验结果表明，与现有方法相比，本发明可以取得更高的检索准确性，从而可以充分发挥图像检索技术在信息检索中的巨大作用。"/><meta property="og:title" content="专利 CN101136015A - 一种计算图像之间相似度的方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101136015A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101136015A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=xpVbBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101136015A&amp;usg=AFQjCNHuRyHcov8Ad-zjFsfA4RINoarnvQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/53eab5e990b899cfe2dd/CN101136015A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/53eab5e990b899cfe2dd/CN101136015A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101136015A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101136015A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101136015A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种图像相似度计算及检索方法。现有技术中，尽管考虑了利用图像分块的方法以提高检索的准确性，但在图像分块以后，采用的是对应块相似度度量的方法，最后图像的相似度是图像对应块相似度的平均值。本发...</span><span itemprop="url">https://www.google.com/patents/CN101136015A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101136015A - 一种计算图像之间相似度的方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101136015A - 一种计算图像之间相似度的方法" title="专利 CN101136015A - 一种计算图像之间相似度的方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101136015 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200610112799</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2008年3月5日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2006年9月1日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2006年9月1日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200610112799.9, </span><span class="patent-bibdata-value">CN 101136015 A, </span><span class="patent-bibdata-value">CN 101136015A, </span><span class="patent-bibdata-value">CN 200610112799, </span><span class="patent-bibdata-value">CN-A-101136015, </span><span class="patent-bibdata-value">CN101136015 A, </span><span class="patent-bibdata-value">CN101136015A, </span><span class="patent-bibdata-value">CN200610112799, </span><span class="patent-bibdata-value">CN200610112799.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BD%AD%E5%AE%87%E6%96%B0%22">彭宇新</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%82%96%E5%BB%BA%E5%9B%BD%22">肖建国</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E6%99%93%E9%B8%A5%22">陈晓鸥</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8C%97%E5%A4%A7%E6%96%B9%E6%AD%A3%E9%9B%86%E5%9B%A2%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%3B%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%3B%E5%8C%97%E4%BA%AC%E5%8C%97%E5%A4%A7%E6%96%B9%E6%AD%A3%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E9%99%A2%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">北大方正集团有限公司;北京大学;北京北大方正技术研究院有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101136015A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101136015A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101136015A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (15),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=xpVbBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200610112799&amp;usg=AFQjCNHSlCDHpV0l-g2UUSVyZv8pa33ZYQ"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=xpVbBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101136015A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEiqXmAmJRbtgGQ1y4AFYnUwdzaBw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT70520780" lang="ZH" load-source="patent-office">一种计算图像之间相似度的方法</invention-title>
      </span><br><span class="patent-number">CN 101136015 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA38290467" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种图像相似度计算及检索方法。现有技术中，尽管考虑了利用图像分块的方法以提高检索的准确性，但在图像分块以后，采用的是对应块相似度度量的方法，最后图像的相似度是图像对应块相似度的平均值。本发明提出了一种基于分块最优匹配的图像检索方法。首先也对图像进行分块处理，并利用最优匹配在一对一匹配的前提下，计算两幅图像的全部分块所能达到的最大相似度。试验结果表明，与现有方法相比，本发明可以取得更高的检索准确性，从而可以充分发挥图像检索技术在信息检索中的巨大作用。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(11)</span></span></div><div class="patent-text"><div mxw-id="PCLM5770413" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1、一种计算图像之间相似度的方法，其特征在于，该方法包括以下步骤：    (1)将待计算的图像分别分割为一个个图像块；    (2)计算上述图像中任意两个图像块之间的相似度；    (3)基于(2)的结果，计算上述图像之间的相似度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2、 如权利要求1所述的计算图像之间相似度的方法，其特征在于，所述 步骤（3)利用最优匹配方法计算上述图像之间的相似度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3、 如权利要求2所述的计算图像之间相似度的方法，其特征在于，将每 一幅图像均匀分割为nxn个图像块，其中n为2-10之间的整数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4、 如权利要求3所述的计算图像之间相似度的方法，其特征在于，所述n 的值为5。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5、 如权利要求l、 2或4所述的计算图像之间相似度度量的方法，其特征 在于，步骤（2)中，使用如下直方图交的方法计算两个图像块的相似度：&lt;formula&gt;formula see original document page 2&lt;/formula&gt;&lt;formula&gt;formula see original document page 2&lt;/formula&gt;A^，s，v)是HSV颜色空间的直方图，本发明用H， S， V分量在5x5x5的三 维空间中统计直方图，以归一化后的125个数值作为颜色特征值， /"^see"x"^)表示两个直方图的交，用它来判断两个图像块的相似度，使用4^」归一化7"^sec^，^)到0, i之间。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6、 如权利要求5所述的计算图像之间相似度的方法，其特征在于，所述 步骤（3)的具体操作为：A:根据步骤（2)图像块的计算结果，将两幅图像的相似度计算建模为一 个带权二分图模型G&#8212;Y工^:义表示图像义有"个图像块A，巧，…,卜，r表示 图像y有"个图像块乃，乃，…，少"，边集&#163; = {&#163;"】，其中边^的权值&#12316;表示两个图像 块、与力的相似值；B:利用图论中的最优匹配方法，求出G&#8212;^，y，^的最优匹配M,把M中 每条边e"的权值&#12316;相加，求得G = ^， F，"的最大权"；C:定义两幅图像I和y的视觉相似度 "，使用"将^柳'^办(U)归一化到0， l之间，得到相似度结果。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7、 如权利要求6所述的计算图像之间相似度的方法，其特征在于，所述 最优匹配方法采用图论中的Kuhn-Munkres算法。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8、 一种图像检索方法，用于从图像库中检索出与待查询图像相似的图像， 其特征在于，包括以下步骤：(一） 将待查询图像及图像库中的每幅图像分别分割为一个个图像块；(二） 计算待查询图像中图像块和图像库每幅图像中图像块之间的相似度；(三） 利用最优匹配方法，分别计算上述待查询图像和每幅图像之间的相似度；(四） 按照相似度值从高到低排列，检索出与待查询图像相似的图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9、 如权利要求8所述的一种图像检索的方法，其特征在于，将每一幅图 像均匀分割为nxn个图像块，其中n为2-10之间的整数。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10、 如权利要求9所述的一种图像检索的方法，其特征在于，所述n取值 为5,并使用如下直方图交的方法计算两个图像块的相似度：&lt;formula&gt;formula see original document page 3&lt;/formula&gt; A(A，s，v)是HSV颜色空间的直方图，本发明用H, S,V分量在5x5x5的三 维空间中统计直方图，以归一化后的125个数值作为颜色特征值，Mersee^'，力)表示两个直方困的交，用它泉判断两个图像块的相似度，使用 4^A)归一化众^sec4，^)到0, i之间。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11、如权利要求9所述的一种图像检索的方法，其特征在于，所述步骤（三） 的具体操作为：A:根据步骤（二）图像块的计算结果，将两幅图像的相似度计算建模为 一个带权二分图模型G&#8212;m^:义表示图像义有"个图像块々七，…，卜，r表示图像r有"个图像块乃，力，…^"，边集&#163;&#8212;"，其中边^的权值^表示两个图像块A与力'的相似值；B:利用图论中的最优匹配方法，求出G-^，y，^的最优匹配M，把M中每条边S的权值&#12316;相加，求得G-^J，^的最大权"；&#27512;/&#8212;(U0 =-C: 定义两幅图像X和y的视觉相似度 "，使用"将S!'w^^d"归一化到0, l之间，得到相似度值。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES10478694" lang="ZH" load-source="patent-office" class="description">
    <p>一种计算图像之间相似度的方法技术领域本发明属于图像检索技术领域，具体涉及一种计算图像之间相似度及实现 图&#20659;趁索的方法。背景技术随着图《象内容的不断增多，如人类已有的图片、互联网上的大量图片以及 个人数码相片的不断增加，如何从海量图像库中找到需要的图像就显得至关重 要。而基于查询例子的图像检索就是满足上述需求的最重要技术之一，即用户 给定一个查询图像，计算机自动从图像库里检索到与查询图像相似的图像，并 按照相似度从高到低排序。现有的图&#20659;J险索技术， 一般是从图像中提取出颜色 等特征，然后利用这些特征进行相似度度量，根据度量结果进行检索。这种方 法因为没有考虑两幅图像中具体内容的差别，而&#37318;用整幅图像的特征进行相似 度度量，因此不能有效计算两幅图像之间的相似度。2004年在世界著名的TREC比赛中发表的文献"Confouncied Expectations: Informedia at TRECVID 2004"(作者是A. Hauptmann, M.     Y. Chen, M. Christel， W a/.)，提出了一种基于图像分块的图像检索方法。然而，该文 献尽管考虑了利用图像分块的方法以提高检索的准确性，但在图像分块以后， 采用的是对应块相似度度量的方法，最后图像的相似度是图像对应块相似度的 平均值。上述方法利用分块的思想是合理的，但基于对应块相似度的方法并不 合理，因为相似图像的分块并不一定对应相似，上述问题大大限制了图&lt;&#32160;索 的准确度。针对上述问题，本发明提出了一种基于分块最优匹配的图像相似度计算及 检索方法。</p>
    <p>发明内容针对现有技术的不足，本发明提出了一种计算图像之间相似度的方法，用 于计算不同图《象之间的相似度。为达到以上目的，本发明采用的技术方案是： 一种计算图像之间相似度的 方法，包括以下步骤：(1) 将待计算的图像分别分割为一个个图像块；(2) 计算上述图像中任意两个图像块之间的相似度；(3) 基于（2)的结果，计算上述图像之间的相似度。进一步，利用最优匹配方法计算上述图像之间的相似度。进一步，将每一幅图像均匀分割为nxn个图像块，其中n为2-IO之间的整数。进一步，n的值为5。进一步，使用如下直方图交的方法计算两个图像块的相似度，最优匹配方 法采用图论中的Kuhn-Munkres算法。4w&gt; mi4sX2&gt;,("v)，SZ2X (" v)}其中， S     V A     … JH,(A，W)是HSV颜色空间的直方图，本发明用H， S， V分量在5 x 5 x 5的三 维空间中统计直方图，以归一化后的125个数值作为颜色特征值， /"敏see^:'，力)表示两个直方图的交，用它来判断两个图像块的相似度，使用4^&#20034;)归一化l"^se"(x,，^)到0，工之间。进一步，计算两幅图^4目似度的具体步骤为：A:根据步骤（2)图像块的计算结果，将两幅图像的相似度计算建模为一 个带权二分图模型G-^J，^: X表示图像X有"个图像块々，巧，…，卜，r表示</p>
    <p>图像r有"个图像块力，力，…J",边集其中边^的权值&#12316;表示两个图像块、与力的相似值;B:利用图论中的最优匹配方法，求出"足y，^的最优匹配M，把M中每条边^的权值S相加，求得&lt;formula&gt;formula see original document page 7&lt;/formula&gt;的最大权必;C:定义两幅图像义和y的视觉相似度&lt;formula&gt;formula see original document page 7&lt;/formula&gt;使用"将&amp;&gt;&#171;//"/7'0&lt;%，;0归一化到o, i之间，得到相似度结果。上述方法的效果在于，通过度量两幅图^f象的全部分块所能达到的最大相似 度，从而获得更准确的图像之间的相似结果。另外，本发明提出一种图像险索方法，用于从图像库中检索出与待查询图 像相似的图像，包括以下步骤：(一） 将待查询图像及图像库中的每幅图像分别分割为 一个个图像块；(二） 计算待查询图像中图像块和图像库每幅图像中图像块之间的相似度；(三） 利用最优匹配方法，分别计算上述待查询图像和每幅图像之间的相似度；(四） 按照相似度值从高到低排列，检索出与待查询图像相似的图像。进一步，将每一幅图像均&#21243;分割为nxn个图像块，其中n为2-IO之间的 整数。进一步，n取值为5，并使用如下直方图交的方法计算两个图像块的相似'(A，s，v)是HSV颜色空间的直方图，本发明用H， S， V分量在5 x 5 x 5的三&lt;formula&gt;formula see original document page 7&lt;/formula&gt;争,维空间中统计直方图，以归一化后的125个数值作为颜色特征值， /"ferse""，;;」表示两个直方图的交，用它来判断两个图像块的相似度，使用4x,，:^)归一化/"^secf(x,，;g到o, i之间。进一步，计算两幅图^M目似度的具体操作为：A:根据步骤（二）图像块的计算结果，将两幅图像的相似度计算建模为 一个带权二分图模型G-P^，^: X表示图像X有"个图像块^，巧，…，x"， y表示图像y有"个图像块力，乃，…^"，边集&#163; = {"，其中边^的权值&#12316;表示两个图 像块A与"的相似值；B:利用图论中的最优匹配方法，求出G&#8212;U，勾的最优匹配M,把M中 每条边^的权值&#12316;相加，求得G&#8212;U，^的最大权《 ;C:定义两幅图像X和y的视觉相似度 ；"，使用"将S/;m'^砂(X，F)归一化到o，  l之间，得到相似度值。本发明的效果在于：与现有方法相比，本发明可以取得更高的检索准确性， 从而可以充分发挥图4&#32160;索技术的巨大作用。本发明之所以具有上述发明效果，其原因在于：本发明不仅使用了图像分 块的合理思想，而且在图像分块以后，本发明不是采用简单的对应块相似度度 量的方法，而是提出了利用最优匹配在一一匹配的前提下，计算两幅图像的全 部分块所能达到的最大相似度。附图说明图l是本发明的方法流程图。具体实施方式下面结合附图和具体实施例对本发明作进一步详细的描述。如图1所示，本发明的方法具体包括以下步骤：(1)将待查询的图像及困像库中的每幅图像分割为 一个个图像块；将上述每幅图像均匀分割为nxn个图像块，n为2-10之间的整数，在此 将每幅图像均匀分割为5 x 5 = 25个图像块作为最佳实施例。(2 )分别计算查询图像的每个图像块和图像库中图像的每个图像块之间 的相似度；使用如下直方图交的方法计算两幅图像块的相似度：A(a，s，v)是hsv颜色空间的直方图，本发明用h，s,v分量在5 x 5 x 5的 三维空间中统计直方图，以归一化后的125个数值作为颜色特征值，(3)利用最优匹配方法，分别计算上述查询图像和图像库中每幅图像之 间的相似度；根据步骤（2)中图像块的计算结果，可以把两幅图像的相似度计算建模 为一个带权二分图模型G-^J，，义表示图像尤有"个图像块巧，x2，…，^， r表像块A与力的相似值。然后利用图论中的最优匹配方法，求出G&#8212;U，"的最 优匹配M后，把M中每条边^的权值&#12316;相加，可以求得G&#8212;m^的最大权"，示图像y有"个图像块^，h，…，凡，边集="}，其中边^的权值,表示两个图定义两幅图像X和y的视觉相似度:，寸吏用"将&amp;&#187;"7w7'o&lt;y,y)归一化到o, i之间，值越大，表明两幅图像x和y越相似。</p>
    <p>最优匹配方法可以采用图论中的Kuhn-Munkres算法；此外，"=25。 (4)按相似度从高到低，检索出与查询图像相似的图像。 上述步骤（3)中，在图像分块以后，最优匹配方法可以在两幅图像的图 像块一对一匹配的条件下，计算出两幅图像所能达到的最大相似度。因为这种 方法使用的是图像块一对一匹配而不是一对多的重复匹配，所以可以客观全面 地计算出两幅图像所能得到的最大相似度。下面的实验结果表明，与现有方法相比，本发明可以取得更高的检索准确性。本实施例中建立了 3000幅图像的数据库，包括了许多类型的图像，例如 动物、建筑、汽车、瀑布、云彩、沙漠、花、草等各种类型的图像。为了全面 充分地证明本发明的有效性，我们使用了这3000幅图像中的每一幅图像作为 查询图像进行检索，最后统计了平均检索结果进行实验对比。另外，我们测试了以下2种方法作为实验对比：1、 本发明；2、 现有方法：2004年在世界著名的TREC比赛中发表的文献"Confounded Expectations: Informedia at TRECVID 2004"(作者是A. Hauptmann， M. Y. Chen， M. Christel， et al.)。上述2种方法，采用的是同样的图像分块、特征和相似度度量方法，即每 幅图像都使用了 5 x 5的分块；用H，S，V分量在5x5x5的三维空间中统计直 方图，以归一化后的125个数值作为颜色特征值；4吏用直方图的交来判断两个 图像块的相似度。因此最后的结果，能够充分证明本发明采用基于图像块最优 匹配方法的有效性。实验采用了两种在MPEG-7标准化活动中的评价指标：平均归一化调整后 的检索秩ANMRR (Average Normalized Modified Retrieval Rank)和平均查全率 AR(Average Recall)。 AR类似于传统的查全率(Recall)，而ANMRR与传统的查 准率(Precision)相比，不仅能够反映出正确的检索结果比例，而且能够反映出</p>
    <p>正确结果的排列序号。ANMRR值越小，意味着检索得到的正确图像的排名越 靠前；AR值越大，意味着在前K (K是检索结果的截断值）个检索结果中相 似图像占所有相似图像的比例越大。所以，AR越大，说明图f4金索的查全率 越好；ANMRR越小，说明图像检索的准确性越高。表1是上述2种方法对3000 幅图&lt;&#32160;索的AR和ANMRR比较。表1 本发明与现有方法的对比实验结果&lt;table&gt;table see original document page 11&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;</p>
    <p>从表l可以看出，本发明无论是AR还是ANMRR,都取得了比现有方法 更好的效果，这主要是因为：本发明在图像分块以后，不是采用现有方法中简 单的对应块相似度度量，而是提出了利用最优匹配在&#8212;&#8212;匹配的前提下，计算 两幅图像的全部分块所能达到的最大相似度。由于本试验是采用3000幅图像 中的每一幅图像作为查询图像，因此表l的试验结果，可以充分证明本发明在 图^f嫌索中的出色效果。本发明之所以具有上述发明效果，其原因在于：本发明不仅使用了图像分 块的合理思想，而且在图像分块以后，本发明不是采用简单的对应块相似度度 量的方法，而是提出了利用最优匹配在&#8212;&#8212;匹配的前提下，计算两幅图像的全 部分块所能达到的最大相似度。显然，本领域的技术人员可以对本发明进行各种改动和变型而不脱离本发 明的精神和范围。这样，倘若本发明的这些修改和变型属于本发明权利要求及 其等同技术的范围之内，则本发明也意图包含这些改动和变型在内。注：本发明的工作，由国家自然科学基金资助（项目批准号：60503062 )。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101477529B?cl=zh">CN101477529B</a></td><td class="patent-data-table-td patent-date-value">2008年12月1日</td><td class="patent-data-table-td patent-date-value">2011年7月20日</td><td class="patent-data-table-td ">清华大学</td><td class="patent-data-table-td ">一种三维对象的检索方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101980247A?cl=zh">CN101980247A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月21日</td><td class="patent-data-table-td patent-date-value">2011年2月23日</td><td class="patent-data-table-td ">西北工业大学</td><td class="patent-data-table-td ">海量遥感图像中基于纹理谱相似性的无价值图像判读方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102012939A?cl=zh">CN102012939A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月13日</td><td class="patent-data-table-td patent-date-value">2011年4月13日</td><td class="patent-data-table-td ">中国人民解放军国防科学技术大学</td><td class="patent-data-table-td ">综合颜色和局部不变特征匹配的动画场景自动标注方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102012939B?cl=zh">CN102012939B</a></td><td class="patent-data-table-td patent-date-value">2010年12月13日</td><td class="patent-data-table-td patent-date-value">2012年11月14日</td><td class="patent-data-table-td ">中国人民解放军国防科学技术大学</td><td class="patent-data-table-td ">综合颜色和局部不变特征匹配的动画场景自动标注方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102054177A?cl=zh">CN102054177A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月29日</td><td class="patent-data-table-td patent-date-value">2011年5月11日</td><td class="patent-data-table-td ">北京新媒传信科技有限公司</td><td class="patent-data-table-td ">一种图像相似度计算方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102054177B?cl=zh">CN102054177B</a></td><td class="patent-data-table-td patent-date-value">2010年12月29日</td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td ">北京新媒传信科技有限公司</td><td class="patent-data-table-td ">一种图像相似度计算方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102184186A?cl=zh">CN102184186A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年4月12日</td><td class="patent-data-table-td patent-date-value">2011年9月14日</td><td class="patent-data-table-td ">宋金龙</td><td class="patent-data-table-td ">基于多特征自适应融合的图像检索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102914549B?cl=zh">CN102914549B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月10日</td><td class="patent-data-table-td patent-date-value">2015年3月25日</td><td class="patent-data-table-td ">中国航天科技集团公司第五研究院第五一三研究所</td><td class="patent-data-table-td ">针对星载表露型pcb焊点质量的光学图像匹配检测方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102945246A?cl=zh">CN102945246A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月28日</td><td class="patent-data-table-td patent-date-value">2013年2月27日</td><td class="patent-data-table-td ">北界创想（北京）软件有限公司</td><td class="patent-data-table-td ">网络信息数据的处理方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102945246B?cl=zh">CN102945246B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月28日</td><td class="patent-data-table-td patent-date-value">2015年12月2日</td><td class="patent-data-table-td ">北界创想（北京）软件有限公司</td><td class="patent-data-table-td ">网络信息数据的处理方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103049512A?cl=zh">CN103049512A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月14日</td><td class="patent-data-table-td patent-date-value">2013年4月17日</td><td class="patent-data-table-td ">杭州淘淘搜科技有限公司</td><td class="patent-data-table-td ">一种基于商品图像显著图分块加权匹配检索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103049512B?cl=zh">CN103049512B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月14日</td><td class="patent-data-table-td patent-date-value">2015年6月17日</td><td class="patent-data-table-td ">杭州淘淘搜科技有限公司</td><td class="patent-data-table-td ">一种基于商品图像显著图分块加权匹配检索方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103295217A?cl=zh">CN103295217A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月1日</td><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">阿里巴巴集团控股有限公司</td><td class="patent-data-table-td ">图片信息处理方法以及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103295217B?cl=zh">CN103295217B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月1日</td><td class="patent-data-table-td patent-date-value">2016年3月30日</td><td class="patent-data-table-td ">阿里巴巴集团控股有限公司</td><td class="patent-data-table-td ">图片信息处理方法以及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103517150A?cl=zh">CN103517150A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年9月13日</td><td class="patent-data-table-td patent-date-value">2014年1月15日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">蓝光播放器用以表示网络视频正在加载的方法及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=xpVbBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=xpVbBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0007000000">G06T7/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2008年3月5日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2008年4月30日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/53eab5e990b899cfe2dd/CN101136015A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E6%96%B9.pdf?id=xpVbBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U20tkYzn1U6JmIYHXYMz6k_8JQs6w"},"sample_url":"https://www.google.com/patents/reader?id=xpVbBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>