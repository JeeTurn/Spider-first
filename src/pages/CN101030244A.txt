<!DOCTYPE html><html><head><title>专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于人体生理图像中排序测度特征的自动身份识别方法"><meta name="DC.contributor" content="谭铁牛" scheme="inventor"><meta name="DC.contributor" content="孙哲南" scheme="inventor"><meta name="DC.contributor" content="李子青" scheme="inventor"><meta name="DC.contributor" content="中国科学院自动化研究所" scheme="assignee"><meta name="DC.date" content="2006-3-3" scheme="dateSubmitted"><meta name="DC.description" content="一种基于人体生理图像中排序测度特征的自动身份识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像的二值化特征向量；计算两幅生理图像的特征向量之间的汉明距离；根据计算所得的Hamming距离判断上述的两幅生理图像是否来自同一人。本发明的身份认证系统具有识别精度高、计算速度快、鲁棒性强、特征模板容量小的优点。本发明可满足门禁、考勤、电子护照、电子商务、银行提款机等应用系统对身份鉴定的需求。"><meta name="DC.date" content="2007-9-5"><meta name="citation_patent_publication_number" content="CN:101030244:A"><meta name="citation_patent_application_number" content="CN:200610058774"><link rel="canonical" href="https://www.google.com/patents/CN101030244A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101030244A?cl=zh"/><meta name="title" content="专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法"/><meta name="description" content="一种基于人体生理图像中排序测度特征的自动身份识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像的二值化特征向量；计算两幅生理图像的特征向量之间的汉明距离；根据计算所得的Hamming距离判断上述的两幅生理图像是否来自同一人。本发明的身份认证系统具有识别精度高、计算速度快、鲁棒性强、特征模板容量小的优点。本发明可满足门禁、考勤、电子护照、电子商务、银行提款机等应用系统对身份鉴定的需求。"/><meta property="og:title" content="专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101030244A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101030244A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=RcaGAAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101030244A&amp;usg=AFQjCNHnKcHWON6Q7guJIZs2kr1vgQC0gA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/d4284ddf4bbb5313116f/CN101030244A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/d4284ddf4bbb5313116f/CN101030244A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101030244A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101030244A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101030244A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101030244B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101030244A?cl=zh" style="display:none"><span itemprop="description">一种基于人体生理图像中排序测度特征的自动身份识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像...</span><span itemprop="url">https://www.google.com/patents/CN101030244A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法" title="专利 CN101030244A - 基于人体生理图像中排序测度特征的自动身份识别方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101030244 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200610058774</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2007年9月5日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2006年3月3日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2006年3月3日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101030244B?hl=zh-CN&amp;cl=zh">CN101030244B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200610058774.5, </span><span class="patent-bibdata-value">CN 101030244 A, </span><span class="patent-bibdata-value">CN 101030244A, </span><span class="patent-bibdata-value">CN 200610058774, </span><span class="patent-bibdata-value">CN-A-101030244, </span><span class="patent-bibdata-value">CN101030244 A, </span><span class="patent-bibdata-value">CN101030244A, </span><span class="patent-bibdata-value">CN200610058774, </span><span class="patent-bibdata-value">CN200610058774.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B0%AD%E9%93%81%E7%89%9B%22">谭铁牛</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%99%E5%93%B2%E5%8D%97%22">孙哲南</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E5%AD%90%E9%9D%92%22">李子青</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80%22">中国科学院自动化研究所</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101030244A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101030244A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101030244A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (9),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=RcaGAAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200610058774&amp;usg=AFQjCNEKMIUoJj5D5zeUBX77CbeqAY3egA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=RcaGAAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101030244A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFubvpr491ErQFrGja0QlDdG7dNdQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT121948015" lang="ZH" load-source="patent-office">基于人体生理图像中排序测度特征的自动身份识别方法</invention-title>
      </span><br><span class="patent-number">CN 101030244 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA108181666" lang="ZH" load-source="patent-office">
    <div class="abstract">一种基于人体生理图像中排序测度特征的自动身份识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像的二值化特征向量；计算两幅生理图像的特征向量之间的汉明距离；根据计算所得的Hamming距离判断上述的两幅生理图像是否来自同一人。本发明的身份认证系统具有识别精度高、计算速度快、鲁棒性强、特征模板容量小的优点。本发明可满足门禁、考勤、电子护照、电子商务、银行提款机等应用系统对身份鉴定的需求。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(21)</span></span></div><div class="patent-text"><div mxw-id="PCLM50769206" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种基于人体生理图像中排序测度特征的自动身份识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像的二值化特征向量；计算两幅生理图像的特征向量之间的汉明距离；根据计算所得的Hamming距离判断上述的两幅生理图像是否来自同一人。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，所述的生理图像是人的虹膜、脸像、掌纹、皮肤、指纹、静脉图像等。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的方法，其特征在于，所述的生理图像采集通过采用CCD、CMOS图像传感器、扫描仪、红外主动光源或者普通可见光源。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1或3所述的方法，其特征在于，所述的生理图像采集可以是在线采集，也可以是离线采集。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的方法，其特征在于，所述的生理图像采集平台可以是固定型的或者是移动型的。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求1所述的方法，其特征在于还包括步骤：采用有线或无线的方式将采集的图像数字化并传输到计算平台。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的方法，其特征在于，所述传输图像到计算平台可以是下述传输之一：现场或者远程网络输送图像；串口通讯；USB接口方式；基于图像采集卡的线缆方式或者是基于红外适配器；蓝牙适配器；无线局域网。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求6所述的方法，其特征在于，所述的生理图像计算平台是个人电脑、笔记本电脑、服务器、图形工作站、嵌入式系统、手机、PDA。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求1所述的方法，其特征在于，所述的图像归一化是用参考坐标来得到校准的特征提取区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求1所述的方法，其特征在于，所述的排序测度特征包括对图像数据进行各种变换加工后再排序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求1所述的方法，其特征在于所述排序测度特征包括多个局部区域特征之间的排序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求1所述的方法，其特征在于，所述的多极微分滤波器f(x，y)的定义如下：f(x,y)=&amp;Sigma;i=1mfi(x+xi,y+yi)-&amp;Sigma;i=m+1m+nfi(x+xi,y+yi),]]&gt;式中fi(x+xi，y+yi)(i＝1，2，…，m+n)是低通滤波器，每个fi(x+xi，y+yi)称为一个“极”，(xi，yi)表明这个低通滤波器在空间的位置，f(x，y)的系数和为零。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的方法，其特征在于所述低通滤波器是Gaussian滤波器或盒状滤波器。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求1所述的方法，其特征在于，所述的采用多极微分滤波器提取归一化图像中的排序测度特征包括：对归一化生理图像的每个区域进行空域滤波；微分滤波器和图像滤波的结果就是正极滤波结果总和和负极滤波结果总和的差值；通过差值的正负符号就得到正极图像区域和负极图像区域之间的相对关系，最后得到的归一化生理图像中的排序测度特征。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求14所述的方法，其特征在于所述排序测度特征是多个数据量之间的排序关系、最大数据量的编号、最小数据量的编号等各种定性的顺序关系。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求14所述的方法，其特征在于所述对归一化生理图像的每个区域进行空域滤波包括步骤：将多级微分滤波器在归一化生理图像上漫游；被多极微分滤波器覆盖的图像区域的灰度值和滤波器的窗口系数进行点积后作为对应多级微分滤波器模板中心的图像像素的滤波结果。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求15所述的方法，其特征在于，所述的多极微分滤波器的滤波对象是归一化生理图像的原始灰度数值或图像的各种变换特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求16所述的方法，其特征在于所述变换特征量包括：对比度、能量特征、统计特征、小波特征和纹理特征等。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.根据权利要求1所述的方法，其特征在于，所述的对排序测度特征进行编码和构建图像的二值化特征向量包括：根据排序测度特征的两两比对的结果进行离散编码。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.根据权利要求18所述的方法，其特征在于所述编码是二进制编码。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21.根据权利要求1所述的方法，其特征在于所述特征向量是由多个不同的多极微分滤波器编码结果联合组成的特征向量或者特征矩阵。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES58822930" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">基于人体生理图像中排序测度特征的自动身份识别方法</invention-title>
    <technical-field>
      <p>技术领域</p>
      <p>本发明涉及生物特征识别，特别是一种基于人体生理图像的自动身份鉴定方法。</p>
    </technical-field>
    <background-art>
      <p>背景技术</p>
      <p>有效的身份鉴别系统或者机制对于维护一个社会的公平、安全和稳定起着重要的作用。在数字化时代，个人身份的自动化识别为个性化服务的便捷提供保驾护航，如电子商务、电子银行、电子钱包、电子通关、电子教育、电子票务、电子办公室等；同时身份认证能够有效防止个人身份的盗用，如信用卡诈骗、网络黑客、访问控制(包括物理门禁和逻辑门禁)等；更重要的是身份识别在国防安全和公共安全中也扮演着重要角色，如海关出入境身份检查、刑事案件的侦破、流动人口管理、数字化居民身份证的应用等。传统的身份识别方法一般分为基于知识的方法(密码、特殊问题的答案)、基于标识物品的方法(钥匙、胸卡)或者二者的结合(如银行卡)。知识容易遗忘、易破解，而标识物品易丢失、易损坏、易复制。所以传统的身份识别方法既不安全，也不方便。而生物特征认证和其它传统方法相比具有许多独特的优势，比如说可靠性高、防伪性好、使用方便等。所谓生物特征识别(BIOMETRICS)技术是指通过计算机利用人体所固有的生理特征或行为特征来进行个人身份鉴定。生理特征与生俱来，多为先天性的，如人的指纹、虹膜、脸像、掌纹、皮肤；行为特征则是习惯使然，多为后天性的，如声音、笔迹、步态。生理和行为特征统称为生物特征。生理特征比行为特征更加稳定，不易伪造，可靠性更高。可用于身份认证的人体生理特征一般可以用图像的方式进行表达，用计算机自动提取生理图像中的可区分信息，就可以快速识别不同人的身份。所以基于人体生理图像的识别技术是一项很有前途的技术，拥有广泛的应用领域。</p>
      <p>现有的生物特征识别方法一般都是针对不同生理图像的特点进行设计，并且基本上都是基于比较复杂的数字图像处理、计算机视觉和模式识别算法，计算量和存储量都比较大，识别精度也无法得到保证，还容易受到光线变化、图像噪声和形变的影响，鲁棒性和稳定性都不是很好。近年来移动电子设备(如带数码相机的手机、PDA)已经开始走入千家万户，再加上无线通讯的发展，人们已经开始用这些移动设备接收电子邮件、开展电子商务、参与股市买卖、存储私人机密。这些场合都需要进行身份认证，采用生理图像识别将是一个安全可靠的选择。由于受体积和能量的限制，这些设备的计算资源、存储资源都是有限的，并且采集到的生理图像的质量也不能得到保证。</p>
    </background-art>
    <disclosure>
      <p>发明内容</p>
      <p>本发明的目的是提出一种基于生理图像排序测度特征的身份认证方法，利用虹膜、人脸、掌纹、皮肤、指纹、静脉图像中定性的顺序比对结果来确定人身份的方法。</p>
      <p>为实现上述目的，一种基于排序测度特征的人体生理图像识别方法，包括步骤：采集人的生理图像；对采集的生理图像进行预处理和归一化；采用多极微分滤波器提取归一化图像中的排序测度特征；对排序测度特征进行编码，构建图像的二值化特征向量；计算两幅生理图像的特征向量之间的汉明距离；根据计算所得的Hamming距离判断上述的两幅生理图像是否来自同一人。</p>
      <p>本发明使用简单明了的图像特征表达方法来刻画人体生理图像中的可区分信息，本发明的生理图像识别方法从生物视觉认知机理提出了用数字图像中相邻区域之间的灰度对比信息来表达图像中稳定的可区分特征，能够刻画生理图像中灰度变化模式的随机性信息；使用同一种方法解决了各种不同的生理图像(如虹膜、人脸、掌纹、皮肤、指纹、静脉的数字化图像)的特征提取和特征匹配问题；图像中的排序测度特征间接反映了成像对象物理表面不同位置反光率之间的定性关系，是独立于光照、对比度等外界因素的生物特征图像的个体本质特征；图像排序测度特征只需要简单的二值编码，效率高，只需要占用很小的硬盘或者内存空间，非常适合于计算机存储和读取；本发明的身份识别方法计算速度快、识别精度高、稳定性和鲁棒性都很好。本发明的算法对于硬件的性能要求低，而且计算十分简单，易于编写成软件或用硬件实现。所以本发明尤其适用于PDA、手机和嵌入式系统等计算存储资源较紧缺的平台进行身份认证。</p>
    </disclosure>
    <description-of-drawings>
      <p>附图说明</p>
      <p>图1为基于生理图像识别的身份认证方法流程框图，其中：S1：采集生理图像，S2：预处理，S3：归一化，S4：采用多极微分滤波器对归一化图像数据进行滤波，S5：特征编码，S6：特征匹配，S7：认证决策；图2为生理图像预处理和归一化示意图，其中：(a)是虹膜图像的定位结果和归一化结果，(b)是人脸图像的定位结果和归一化结果，(c)是掌纹图像的定位结果和归一化结果，(d)是皮肤图像的定位结果和归一化结果，(e)是指纹图像的定位结果和归一化结果；图3为各种多极微分滤波器；图4为多极微分滤波器和生物特征图像进行滤波处理的示意图；图5是使用图3中的多极微分滤波器提取排序测度特征，编码得到的生理图像的特征模板，其中，(a)是虹膜图像的特征编码；(b)是人脸图像的特征编码；</p>
      <p>(c)是掌纹图像的特征编码；(d)是皮肤图像的特征编码。</p>
      <p>(e)是指纹图像的特征编码。</p>
      <p>图6是图像中的排序测度特征示例；图7是生理图像采集流程示意图。</p>
    </description-of-drawings>
    <mode-for-invention>
      <p>具体实施方式</p>
      <p>本发明提出一种新颖的基于生理图像中排序测度特征的身份识别方法。生理图像识别系统一般工作在两种状态下：注册模式和识别模式。在注册模式，合法用户向系统提交自己的生理特征模板；在识别模式，系统通过对比存储的模板和用户临时采集的生理图像的特征来确定这个用户身份是否合法。不论是注册模式还是识别模式，生理特征识别方法都要进行图像预处理和特征提取，在识别模式下还要进行特征匹配。</p>
      <p>下面对排序测度特征进行较为深入的阐述：在上世纪末期，一些神经生理科学家发现：高等动物的大脑皮层的大部分神经细胞对于视觉对比度刺激的响应具有快速饱和特性。也就是说，当视觉对象的对比度极性(contrast&#160;polarity)和这些细胞的感受性质吻合时，只要对比度的强度(绝对值)超过一个较小的阈值，这些细胞的输出响应就接近了峰值；此后再增加外界视觉刺激的强度也不会对神经信息的生成有显著贡献。所以可以推理出对生物体视觉认知起决定作用的是对比度的方向信息，而不是绝对强度大小；如果把输入-输出关系理想化和简单化，就可以用阶跃函数近似拟合这些响应曲线，即神经细胞的响应结果是两态的(ON/OFF)，根据输入对比度的极性而定。通过模拟这些生物体神经细胞对外界视觉刺激的信息编码规则，计算机视觉领域的科学家提出了用于表达图像信息的排序测度特征。图6给出了一个排序测度特征示例，符号“p”和“f”表明了两个图像区域平均灰度值之间的不等式关系，即描述了这两个区域对比度的方向信息。对于这种定性的图像邻域之间的顺序度量关系，只需要一位比特码就可以表达，例如可以用“1”表示“Ap&#160;B”，而用“0”表示“Af&#160;B”，至于两个区域平均灰度值完全相等的情况对于8位的数字图像而言是一个小概率事件，可以任意划到“1”或者“0”。</p>
      <p>由于排序测度特征摒弃了精确的绝对信息，使它特别适合于计算机视觉领域的图像特征表达，因为在不同的光线条件下同一物体的灰度值会发生明显的变化，而图像区域之间的排序测度特征却大多稳定不变，更加能够反映视觉对象的本质特征。</p>
      <p>除了视觉领域的应用，其实排序测度特征也是我们日常生活中常用的定性度量工具，例如我们可以很容易判断两个人的身高和体重的相对大小，但是我们很难主观给出他们的绝对差值。例如人们往往记住的是奥运获胜选手的“金”、“银”、“铜”排名，而不是具体的量化成绩。由于排序测度特征可看成是一种非参数的统计量，在统计学领域得到了广泛的应用，如通过排序得到的中位数就是一个比较鲁棒的点估计结果；基于排序相关系数的方法(Rank&#160;Correlation&#160;Method)更是广泛被各行各业用来对定性化的变量进行分析。</p>
      <p>虽然排序测度特征的鲁棒性很强，但是它的分类能力十分有限，例如一个排序测度特征编码最多只能区分两种情况：正向或者反向。而且排序测度特征的现有成功应用中的类别数也极其有限，例如人脸检测只涉及人脸/非人脸两类问题，图像库检索只涉及沙滩、瀑布、陆地等一些简单的类别。所以排序测度特征一直没有用于大规模类别的视觉对象识别。本发明是第一次将排序测度特征用于高精度、大规模的生物特征识别问题。</p>
      <p>虽然排序测度特征很简单，但是我们认为它对于人体生理特征图像这种复杂模式的特征表达却有独特的优势，而且是人体生理特征图像本质特征的最佳描述。追根刨底，一幅二维人体生理特征图像的亮度分布I(x，y)主要由两个因素决定：人体生理特征表面接收到的光源强度M(x，y)和人体生理特征表面的反射率R(x，y)，并且和它们的乘积成正比：I(x，y)＝M(x，y)R(x，y)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(1)其中M(x，y)又取决于光源强度、光源和人体生理特征表面的距离、光源在空中衰减的特性等因素，是一个和身份无关的量。由于人体生理特征一般和光源距离较远，可认为人体生理特征邻域各点接收的光源强度近似相等，所以人体生理特征图像不同区域的灰度差异主要是由R(x，y)决定。因为人体生理特征不同区域对于光线有参差不齐的吸收和反射性能，所以人体生理特征图像中与身份信息紧密关联的物理量就是人体生理特征表面的光学属性R(x，y)。正由于人体生理特征的R(x，y)是随机的、无规律的，才赋予人体生理特征图像极高的唯一性。</p>
      <p>综上所述，很容易想到我们只要恢复出每幅人体生理特征图像的R(x，y)，不就抓住了人体生理特征中的本质特征吗？但在实际应用中很难计算R(x，y)，因为M(x，y)在每一幅人体生理特征图像中随着用户的姿态变化、环境变化、距离变化等都会相应发生复杂的变化，很难去准确估计。</p>
      <p>既然我们不能从图像直接计算出R(x，y)的绝对值，寻求R(x，y)的相对值也就成了我们唯一的选择。幸运的是，这个间接的方法是可行的。</p>
      <p>假设我们要比较人体生理特征表面点A(x，y)和邻近点B(x+Δx，y+Δy)之间的光学反射率的大小，即判断            <span class="patent-image-not-available"> </span>是否大于1，我们就可以通过比较I(x，y)和I(x+Δx，y+Δy)来近似给出答案。因为当Δx和Δy较小时，M(x，y)≈M(x+Δx，y+Δy)，R(x,y)R(x+&amp;Delta;x,y+&amp;Delta;y)=I(x,y)/M(x,y)I(x+&amp;Delta;x,y+&amp;Delta;y)/M(x+&amp;Delta;x,y+&amp;Delta;y)&amp;ap;I(x,y)I(x+&amp;Delta;x,y+&amp;Delta;y)---(2)]]&gt;所以通过直接计算图像灰度值的排序测度特征就可以估计出人体生理特征本质特征R(x，y)随空间变化的升降关系，这是和外界因素无关但是和身份特征紧密相连的特征量。</p>
      <p>根据上述分析，我们可以总结出排序测度特征非常适合于人体生理特征图像的本质属性表达。</p>
      <p>根据公式(2)，我们可以从图像数据中推导出无穷多种人体生理特征表面本质属性中存在着的不变量，这些不变量都是与光照无关的本质特征，例如I(x，y)＞I(x+Δx，y+Δy)�R(x，y)＞R(x+Δx，y+Δy)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(3)f(I(x，y))＞f(I(x+Δx，y+Δy))�f(R(x，y))＞f(R(x+Δx，y+Δy))&#160;&#160;&#160;&#160;(4)w1I(a，b)+w2I(c，d)＞w3I(e，f)+w4I(g，h)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(5)�w1R(a，b)+w2R(c，d)＞w3R(e，f)+w4R(g，h)……其中f(x)为任意增函数，wi(i＝1，2，3，4)为任意实数。</p>
      <p>所以在提取排序测度特征时，我们并不局限于原始的灰度值，可以对图像数据进行各种变换加工后再排序；我们也不局限于两两之间的顺序关系，可以是多个局部区域特征之间的顺序关系。但是我们设计各种排序测度特征的最终目的是为了实现高性能的生物识别系统，主要要解决缩小类内差异和扩大类间差异之间的矛盾问题和计算量的问题。所以在设计人体生理特征图像特征表达模型时首先要想好选用什么样的排序特征量，然后具体排序的过程就很简单了，减法和除法都可以使用。如果我们用区域的加权灰度平均值作为排序特征量，就可以用一个微分滤波器的滤波结果正负号就可以得到所要的排序测度特征。根据不同的排序特征表达策略，输出可能是不等式的方向、多个特征量的顺序、最大值、最小值等等。在鲁棒编码过程中，我们需要将这些结果编成计算机能够存储和读取的特征码，另外还要便于匹配、保证特征的鲁棒性，因为排序总是以两两比对为基础，所以很方便用二值编码。在特征匹配时，特征之间的距离一般用Hamming距离来衡量。类内匹配的Hamming距离一般小于类间匹配的Hamming距离，所以可以根据错误接收率的不同要求设定识别系统的阈值，只要特征和模板的距离小于这个阈值就认为识别成功。</p>
      <p>本发明的流程框图如图1所示。本发明提出的基于生理图像识别的身份认证方法包含七个主要步骤(见图1)：1.采集生理图像S1。人体的生理模式，如虹膜、人脸、掌纹、皮肤、指纹、静脉等在光线下会呈现出独特的图像结构，可通过各种光学镜头和图像传感器成像。采集生理图像的原理类似于我们用数码相机对准生物特征拍照。一般的生理图像采集模型如图7所示。</p>
      <p>在光源的照射下，生理特征表面会将部分光反射回成像装置，通过光学镜头组将反射光汇聚到图像传感器上，然后用图像采集卡将图像数据传到计算机。常见的图像传感器包括CCD、CMOS或者扫描仪，成像光源包括红外主动光源、普通可见光源、微波、超声波等。上述的“生理图像采集”可以是在线采集，也可以是离线采集。生理图像采集装置可以是固定型的或者是移动型的。移动型的生理图像采集系统采用移动终端设备采集，例如手机和PDA上的摄像头。图像传输到计算机可以是有线或者无线的方式、可以是现场或者远程网络输送图像、可以是串口通讯、USB接口方式、基于图像采集卡的线缆方式或者是基于红外适配器(IRDA标准)、蓝牙适配器(Bluetooth协议)、无线局域网(IEEE的802.11标准)等无线数据连接的传输方式。图像信号的接收平台可以是个人电脑、笔记本电脑、服务器、图形工作站、嵌入式系统、手机、PDA等一切具有计算功能的系统。例如我们可以使用网络摄像头采集人脸、掌纹和皮肤图像，用户将人脸、掌纹和皮肤正对着摄像头，然后通过USB接口将连续的图像桢传输到电脑。可以利用指纹脊和谷对光线反射性能的差异使用光学传感器成像，也可以通过测量凹凸纹路造成的电容差异获取指纹图像信息。虹膜成像需要使用红外光源，使用凸透镜将直径为11毫米的虹膜放大到200个像素左右的分辨率。</p>
      <p>2.预处理S2。原始的生理图像并不是所有的区域都存在着个体区分能力。如虹膜图像中的瞳孔和巩膜区域、人脸图像中的头发和背景区域、掌纹图像中手指和腕部并不能对身份识别贡献分类信息。在不同时刻、不同距离、不同姿态下采集的人的生理图像存在着位置、尺度和旋转的变化，这就为同一个体图像间的成功匹配带来了困难。有时光照和噪声也会影响匹配精度。为了获取生理图像中的感兴趣区域(对于区分不同个体的有效区域)、准确对齐参与比对的两幅图像和克服光照、噪声的干扰，必须对原始图像进行预处理。一般的生理图像预处理的策略就是首先定位参考点或者参考线来建立参考坐标。如虹膜图像中瞳孔和巩膜的圆形边界(图2a)、人脸图像中的眼睛、鼻子和嘴巴(图2b)、掌纹图像中手指之间的角点(图2c)、手背皮肤图像中手的轮廓边界(图2d)、指纹图像中的奇异点和方向场(图2e)就为统一坐标系的建立提供了参考信息。例如对于虹膜定位，可以用边缘检测算法(如Sobel算子)来得到瞳孔和虹膜的边缘点，然后用Hough变换来估计瞳孔的中心坐标和半径。对于人脸定位，可以用Harr小波或者Gabor变换的方法来定位人脸图像中的眼睛和嘴巴，这在计算机视觉领域已经有比较的成熟的算法。对于掌纹定位，首先通过二值化的方法获得前景区域，然后用边界跟踪的方法根据曲率变化的剧烈程度定位手指之间的角点。对于指纹定位，可以用方向场和脊线信息确定奇异点和旋转角度。</p>
      <p>3.归一化S3。在统一坐标系中的固定位置截取固定大小的图像区域用于特征提取，这个图像区域称为归一化的生理图像(见图2)。对于来自同一人在不同时刻采集的生理图像，不论原始图像是否有平移、旋转和尺度的变化，通过步骤1和2得到的归一化生理图像应该都是对应于人体生理部位信息丰富的同一区域。对于虹膜图像，可以将笛卡儿坐标下的原始图像通过线性采样转换到极坐标(见图2a)；对于人脸图像，可以根据双眼之间的距离将图像缩放到固定大小的矩形(见图2b)；对于掌纹图像，可以根据两个角点建立统一的坐标系，然后在坐标系固定位置截取固定大小的特征提取区域(见图2c)。</p>
      <p>4.使用多极微分滤波器提取排序测度特征S4。所述的多极微分滤波器f(x，y)的定义如下：f(x,y)=&amp;Sigma;i=1mfi(x+xi,y+yi)-&amp;Sigma;i=m+1m+nfi(x+xi,y+yi),]]&gt;式中fi(x+xi，y+yi)(i＝1，2，…，m+n)都是低通滤波器，例如Guassian滤波器、盒状滤波器等，每个fi(x+xi，y+yi)称为一个“极”，(xi，yi)表明这个低通滤波器在空间的位置。f(x，y)的系数和为零。例如基于Gaussian函数的多极微分滤波器的定义如下：filter=&amp;Sigma;i=1N+C+i2&amp;pi;&amp;delta;i+exp[-(X-&amp;mu;i+)22&amp;delta;i+2]-&amp;Sigma;j=1N-C-j2&amp;pi;&amp;delta;j-exp[-(X-&amp;mu;j-)22&amp;delta;j-2]---(6)]]&gt;式中μi+和δi+分别表示正峰Gaussian滤波器的中值和标准差，N+代表正峰个数，μj-和δj-分别表示负峰Gaussian滤波器的中值和标准差，N-代表负峰个数，C+i和C-j分别代表滤波器中正峰和负峰的个数。为了让每个排序测度特征的信息熵极大化，需要满足&amp;Sigma;i=1N+C+i=&amp;Sigma;j=1N-C-j---(7)]]&gt;调节多极微分滤波器的各个参数，例如Gaussian滤波器的中值和标准差、Gaussian滤波器的个数等可以得到灵活多变的多极微分滤波器(见附图3)。即所述的“多极微分滤波器”是由多个正负不一、位置不一的低通滤波器组成的系数和为0的微分滤波器。每个低通滤波器称为一个“极”。微分滤波器和图像滤波的结果就是正极滤波结果总和和负极滤波结果总和的差值，通过差值的正负符号就得到正极图像区域和负极图像区域之间的相对关系，最后得到的归一化生理图像中的排序测度特征可以是多个数据量之间的排序关系、最大数据量的编号、最小数据量的编号等各种定性的顺序关系。</p>
      <p>所述的“采用多极微分滤波器提取归一化图像中的排序测度特征”是对归一化生理图像的每个区域进行空域滤波：将多极微分滤波器在归一化生理图像上漫游，被多极微分滤波器覆盖的图像区域的灰度值和滤波器的窗口系数进行点积后作为对应多极微分滤波器模板中心的图像像素的滤波结果。</p>
      <p>应用多极微分滤波器对生物特征图像滤波的过程与方法见图4。假设图像数据为I(x，y)，多极微分滤波器的尺寸为(2n+1)×(2n+1)，滤波器的系数是w(s，t)(s，t∈[-n，n])，要对以坐标(x，y)为中心的图像区域滤波，滤波结果就是&amp;Sigma;s=-nn&amp;Sigma;i=-nnI(x+s,y+sw(s,t)---(8)]]&gt;多极微分滤波器的滤波对象不仅可以是归一化生理图像的原始灰度数值，也可以是图像的各种变换特征量，如对比度、能量特征、统计特征、小波特征和纹理特征等。</p>
      <p>5.特征编码S5。根据上一步的滤波结果的正负符号对被滤波图像区域进行二值编码，例如：如果滤波结果大于0则区域中心像素(x，y&#160;)的特征编码为1；如果滤波结果小于等于0则区域中心像素(x，y)的特征编码为0。最后将所有的特征码联合起来组成特征向量。可以根据实际情况对特征向量降采样以降低特征向量的长度，节省存储空间和匹配时间。如果是注册过程，将特征向量保存在模板数据库里；如果是识别过程则将特征向量作为匹配引擎的输入。图5就是用多级微分滤波器对图2进行滤波和特征编码后的二值特征模板。描述一幅生理图像的特征向量或者特征矩阵可以是由多个不同的多极微分滤波器(不同尺度、不同滤波特征、不同个数的低通正负极)编码结果联合组成的特征向量或者特征矩阵。</p>
      <p>6.特征匹配S6。当生物鉴别系统运行在认证模式下，用户要声明自己的身份，系统根据他的声明从数据库中找出这个人的模板特征向量和输入特征向量进行匹配，即证明他的确是他所说的那个人。当生物鉴别系统运行在识别模式下时，用户不用告诉系统“我是谁”，系统根据他的输入特征和数据库中所有的特征模板一一匹配。所有的身份鉴别模式都是以两两匹配为基础的。计算两幅生理图像(一般而言，其中的一幅生理图像是注册时预先采集，另一幅是认证过程中临时采集)的特征编码的Hamming距离，它的值是从0到1之间的浮点数。Hamming距离值越小，两幅图像的相似性越高，来自同一人的可能性越大。</p>
      <p>7.识别决策S7。根据生理图像识别系统不同的应用场合设置不同的阈值，对应着不同的错误接受率(FAR，False&#160;Accept&#160;Rate)和错误拒绝率(FRR，False&#160;Reject&#160;Rate)。当Hamming距离小于预先定义的阈值时，判断用户通过身份认证，否则给出未通过认证的信息。</p>
      <p>实施例1：生理图像识别系统在自动化出入境管理中的应用2003年6月，联合国国际民用航空组织公布了生物技术的应用规划，规划提出，将在个人护照中加入生物特征(指纹识别、虹膜识别、面相识别)并在进入各个国家的边境时进行个人身份的确认。由于现在没有成熟和通用的虹膜和人脸特征表达模式和特征模板，为了保证不同国家之间的生物护照系统的互操作性，每个国家不得不在护照中存储持照人的虹膜和人脸图像，占用了上百K字节的存储空间。当中国人张三拿着护照进入美国国境时，美国的生物认证系统中的无线读卡器花了5秒钟才读出张三护照中的人脸图像，然后花了1秒钟对护照图像进行预处理和提取特征，然后将护照生物特征和临时采集人脸图像的生物特征进行比对，如果相似性足够高，确认张三身份正确。而采用了本发明的生理图像识别系统后，所有国家的生物护照中只保留每个人几百个字节的排序测度特征，张三过境时只需要0.005秒读出护照中的排序测度特征，直接和现场图像的排序测度特征进行比对。整个认证过程节约了5.995秒的时间，生物护照芯片也节省了上百K字节的存储空间，也不需要非常快速的读卡器，降低了整个系统的成本，保证了全世界生物认证系统模板的统一性。而且，张三再也不敢和他的孪生弟弟共用一本护照去出入境，因为以前的人脸识别系统无法区分他和他弟弟的人脸图像。</p>
      <p>实施例2：便携式生理图像识别系统警察李四在街上巡逻，发现王五鬼鬼祟祟、形迹可疑。于是警察叫住王五，拿出只有手机大小的便携式生理图像识别系统，将摄像头对准王五的虹膜、人脸、掌纹和手背皮肤任一处快速拍照，系统在1秒钟得到了王五的排序测度特征，然后和本机中定时更新的100万名网上逃犯人员的排序测度特征(只占用了100M的硬盘容量)进行对比。系统在3秒钟后给出识别结果，表明王五和某地的一起重大案件的作案逃犯的生理特征很吻合。于是李四将王五带回警局，会同案发当地刑侦人员深入审问，发现王五确是案犯。就这样，在便携式生理图像识别系统的帮助下，一个在逃犯在短短的10秒钟之内成功被抓。</p>
      <p>本发明提出了一种基于生理图像识别的身份认证方法。本方法的优点在于以下几个方面：1.识别精度高。由于排序测度特征信息能很好地刻画生理图像中存在的个体差异，所以本发明得到的特征向量有很强的区分性能。因为对于一个随机的图像模式，相对应的每个区域的二进制编码具有相等的概率等于1或者0，所以每个比特特征位的信息熵得到了极大化。对于不同类的特征模板间的Hamming距离，被证明是以0.5为中心的二项分步，一般不同类的Hamming距离能够小于0.35只有百万分之一的概率。所以只要同类图像间由于噪声、误配准、遮挡等误差引起的编码错误不超过35％，我们都可以有非常高的信心判定两幅图像来自于同一人。</p>
      <p>2.编码效率高，存储量小。由于采用二值编码，8次滤波的结果只要1个字节就能保存，整幅生理图像只需要几百个字节的容量存储，完全能保存在绝大多数的IC卡(包括第二代身份证)和各种移动设备里。</p>
      <p>3.计算速度快。整个算法的主要计算量消耗在多极微分滤波上。如果将其分解为多个低通滤波和差值对比，并将整个滤波过程用快速算法近似的话，整个特征提取和匹配过程只涉及加法和减法，没有耗时较长的乘法和除法操作，并且过程简单明了、计算量小，算法易于软件编程和硬件实现，在普通台式计算机上测试的特征提取时间在20-30毫秒左右，远低于其它经典的生理图像识别方法(一般在100毫秒左右)。</p>
      <p>4.鲁棒性强。对多个非近邻图像区域的低通滤波结果进行定性对比和二值编码都使整个算法的鲁棒性大大增强，受噪声、光照对比度变化的影响小。</p>
      <p>5.本发明提出的嵌入式计算平台和无线通讯方式能够推广生理图像识别系统的应用范围。因为本发明提出的特征模板容量小，易于移动终端存储和无线传输；本发明提出的特征提取和匹配算法简单、易于嵌入式系统实现。</p>
      <p>6.能够区分孪生子的人脸图像。现有的其他人脸识别方法利用的是人脸的粗尺度特征，无法对双胞胎人群进行有效辨别，而本发明利用各种尺度的排序测度特征，深入刻画人脸表皮的细微结构，即使是表面上长得很像的双胞胎在这些细化到毛孔级的表现层也具有较大差异。</p>
      <p>7.本发明提出了一个通用的生物特征编码方案，便于规范和统一不同国家、不同应用、不同传感器生产厂商之间的生物特征数据交换格式，可以进一步提升为国际标准和行业标准。</p>
      <p>8.本发明除了应用于生物特征图像的特征提取和识别，也可应用于生物特征图像增强和特征点检测，如指纹图像脊线增强和细节点提取。</p>
      <p>9.本发明是一种通用的视觉对象表达方法，不仅可以用于生物特征识别，还可应用于其他视觉对象的检测和识别，如人脸检测、行人检测、车辆检测、纹理分析、建筑物识别、图像库的检索等。</p>
      <p>综上所述，本发明可以有效地完成生理图像识别，从而可靠地进行身份认证。同时本发明具有计算速度快、识别精度高、鲁棒性强、存储量小等优点。本发明具有很广的应用范围，它可用于电子商务、电子政务、电子军务和电子警务，以及其他需要进行身份鉴别的领域。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101739742B?cl=zh">CN101739742B</a></td><td class="patent-data-table-td patent-date-value">2009年12月22日</td><td class="patent-data-table-td patent-date-value">2012年3月21日</td><td class="patent-data-table-td ">中国科学院长春光学精密机械与物理研究所</td><td class="patent-data-table-td ">联网式多通道门禁考勤系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102063740A?cl=zh">CN102063740A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年11月15日</td><td class="patent-data-table-td patent-date-value">2011年5月18日</td><td class="patent-data-table-td ">北京交通大学</td><td class="patent-data-table-td ">基于手掌静脉网络特征认证的实名制火车票检票系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102096950A?cl=zh">CN102096950A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月10日</td><td class="patent-data-table-td patent-date-value">2011年6月15日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">用于售票系统的人脸识别装置和识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102147868A?cl=zh">CN102147868A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年12月22日</td><td class="patent-data-table-td patent-date-value">2011年8月10日</td><td class="patent-data-table-td ">索尼公司</td><td class="patent-data-table-td ">学习装置、学习方法、识别装置、识别方法和程序</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102385766A?cl=zh">CN102385766A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月23日</td><td class="patent-data-table-td patent-date-value">2012年3月21日</td><td class="patent-data-table-td ">哈尔滨工业大学深圳研究生院</td><td class="patent-data-table-td ">基于掌纹的认证开锁方法、终端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102542286A?cl=zh">CN102542286A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月30日</td><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">索尼公司</td><td class="patent-data-table-td ">学习装置、学习方法、识别装置、识别方法和程序</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103207990A?cl=zh">CN103207990A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年3月26日</td><td class="patent-data-table-td patent-date-value">2013年7月17日</td><td class="patent-data-table-td ">苏州福丰科技有限公司</td><td class="patent-data-table-td ">基于移动终端的警用人员识别系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7930556">US7930556</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value">2011年4月19日</td><td class="patent-data-table-td ">Chi Mei Communication Systems, Inc.</td><td class="patent-data-table-td ">Fingerprint system and method for access control</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9350946">US9350946</a></td><td class="patent-data-table-td patent-date-value">2015年6月18日</td><td class="patent-data-table-td patent-date-value">2016年5月24日</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">Information processing method and apparatus for video communication</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=RcaGAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2007年9月5日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年5月6日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年8月18日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/d4284ddf4bbb5313116f/CN101030244A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E4%BD%93%E7%94%9F%E7%90%86%E5%9B%BE%E5%83%8F%E4%B8%AD%E6%8E%92%E5%BA%8F%E6%B5%8B%E5%BA%A6.pdf?id=RcaGAAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2397DsGKK6g7Mv9PwHKRuLL9B8wg"},"sample_url":"https://www.google.com/patents/reader?id=RcaGAAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>