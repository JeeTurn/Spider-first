<!DOCTYPE html><html><head><title>专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法"><meta name="DC.contributor" content="张家树" scheme="inventor"><meta name="DC.contributor" content="张祖涛" scheme="inventor"><meta name="DC.contributor" content="李德芳" scheme="inventor"><meta name="DC.contributor" content="李恒建" scheme="inventor"><meta name="DC.contributor" content="西南交通大学" scheme="assignee"><meta name="DC.date" content="2012-2-2" scheme="dateSubmitted"><meta name="DC.description" content="一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法。它采用两个垂直正交同频率的摄像头采集驾驶员面部图像，在正常光照下用Harr算法定位出眼部；在无法定位眼部和低光照度条件下启动红外光源，获得脸部红外图像，用降维空间随机投影方法提取眼部特征，再用特征匹配方法定位眼部。采用复小波相位算法得出眼部图像各像素的配对关系，以双眼的瞳孔中心为坐标中心，进行三维点云人眼信息拟合，重构眼部3D图像。建立眼动自适应非线性对数模型，采用自适应模糊强跟踪有限差分扩展卡尔曼滤波进行眼部3D跟踪。该法不受光照、墨镜、驾驶员姿态变化和操作的影响；重构出的眼部3D图像，能对驾驶员疲劳状态的分析与监测提供更全面的信息。"><meta name="DC.date" content="2012-7-25"><meta name="DC.relation" content="CN:101398886:A" scheme="references"><meta name="DC.relation" content="CN:101833770:A" scheme="references"><meta name="DC.relation" content="US:8077914" scheme="references"><meta name="citation_reference" content="张祖涛: &quot;基于采样强跟踪非线性滤波理论的驾驶员眼动跟踪技术研究&quot;, 《中国博士学位论文全文数据库》, 13 August 2010 (2010-08-13)"><meta name="citation_patent_publication_number" content="CN:102609984:A"><meta name="citation_patent_application_number" content="CN:201210022974"><link rel="canonical" href="https://www.google.com/patents/CN102609984A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102609984A?cl=zh"/><meta name="title" content="专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法"/><meta name="description" content="一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法。它采用两个垂直正交同频率的摄像头采集驾驶员面部图像，在正常光照下用Harr算法定位出眼部；在无法定位眼部和低光照度条件下启动红外光源，获得脸部红外图像，用降维空间随机投影方法提取眼部特征，再用特征匹配方法定位眼部。采用复小波相位算法得出眼部图像各像素的配对关系，以双眼的瞳孔中心为坐标中心，进行三维点云人眼信息拟合，重构眼部3D图像。建立眼动自适应非线性对数模型，采用自适应模糊强跟踪有限差分扩展卡尔曼滤波进行眼部3D跟踪。该法不受光照、墨镜、驾驶员姿态变化和操作的影响；重构出的眼部3D图像，能对驾驶员疲劳状态的分析与监测提供更全面的信息。"/><meta property="og:title" content="专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102609984A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102609984A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102609984A&amp;usg=AFQjCNHOE8sP74erO1ZnNJbLEUEHrVEkLA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/7741a10ab5998270223f/CN102609984A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/7741a10ab5998270223f/CN102609984A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102609984A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102609984A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102609984A?cl=zh" style="display:none"><span itemprop="description">一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法。它采用两个垂直正交同频率的摄像头采集驾驶员面部图像，在正常光照下用Harr算法定位出眼部；在无法定位眼部和低光照度条件下启动红外光源，获得脸部红外图像，...</span><span itemprop="url">https://www.google.com/patents/CN102609984A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法" title="专利 CN102609984A - 基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102609984 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210022974</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年7月25日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年2月2日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年2月2日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210022974.0, </span><span class="patent-bibdata-value">CN 102609984 A, </span><span class="patent-bibdata-value">CN 102609984A, </span><span class="patent-bibdata-value">CN 201210022974, </span><span class="patent-bibdata-value">CN-A-102609984, </span><span class="patent-bibdata-value">CN102609984 A, </span><span class="patent-bibdata-value">CN102609984A, </span><span class="patent-bibdata-value">CN201210022974, </span><span class="patent-bibdata-value">CN201210022974.0</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BC%A0%E5%AE%B6%E6%A0%91%22">张家树</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BC%A0%E7%A5%96%E6%B6%9B%22">张祖涛</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E5%BE%B7%E8%8A%B3%22">李德芳</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E6%81%92%E5%BB%BA%22">李恒建</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%22">西南交通大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102609984A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102609984A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102609984A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (4),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210022974&amp;usg=AFQjCNFjuQ4y0x_LhpVl0LK-sPoewDgS_Q"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102609984A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHjNUGpziEN1wQRZPvXCXMx_KYZEg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114436113" lang="ZH" load-source="patent-office">基于正交双目降维空间的驾驶员眼部3d重构与跟踪方法</invention-title>
      </span><br><span class="patent-number">CN 102609984 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA99197250" lang="ZH" load-source="patent-office">
    <div class="abstract">一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法。它采用两个垂直正交同频率的摄像头采集驾驶员面部图像，在正常光照下用Harr算法定位出眼部；在无法定位眼部和低光照度条件下启动红外光源，获得脸部红外图像，用降维空间随机投影方法提取眼部特征，再用特征匹配方法定位眼部。采用复小波相位算法得出眼部图像各像素的配对关系，以双眼的瞳孔中心为坐标中心，进行三维点云人眼信息拟合，重构眼部3D图像。建立眼动自适应非线性对数模型，采用自适应模糊强跟踪有限差分扩展卡尔曼滤波进行眼部3D跟踪。该法不受光照、墨镜、驾驶员姿态变化和操作的影响；重构出的眼部3D图像，能对驾驶员疲劳状态的分析与监测提供更全面的信息。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(1)</span></span></div><div class="patent-text"><div mxw-id="PCLM44626476" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法，包括以下步骤：A、图像获取Al、采用两个垂直正交的相同采样频率的摄像头对准驾驶员采集面部图像；同时利用光线感应器检测驾驶室的光照度，当检测出的光照度&lt;4 Lux(勒克斯）且保持I分钟以上时，则进行以下A2的操作，A2、启动对准驾驶员面部的红外光源，此时摄像头采集到的面部图像为红外图像；B、眼部特征提取及定位：对两个摄像头采集到的第一帧面部图像分别采用Harr算法定位出驾驶员眼部；若定位不出驾驶员眼部，则进行以上A2步的操作；若采集到的两个第一帧面部图像为红外图像，则分别用降维空间随机投影方法提取红外面部图像眼部特征，然后用特征匹配方法定位驾驶员眼部；C、3D人眼重构：将B步已定位眼部的两个第一帧图像，利用复小波相位算法得出两个第一帧图像眼部各像素的配对关系，再以双眼的瞳孔中心为坐标中心，分别进行三维点云人眼信息拟合，重构出驾驶员双眼的第一帧3D眼部图像；D、眼动3D跟踪：根据C步重构出的第一帧3D眼部图像，建立驾驶员眼动自适应非线性对数模型，采用自适应模糊强跟踪有限差分扩展卡尔曼滤波（EKF)算法进行眼部3D跟踪：即通过模糊逻辑控制动态调整强跟踪扩展卡尔曼滤波算法的弱化因子，然后将有限差分替代强跟踪EKF滤波算法中的非线性函数的偏导数，估计出下一帧的3D眼部图像；根据驾驶员眼动自适应非线性对数模型，重复以上操作，估计出一系列连续帧3D图像的驾驶员眼部，实现驾驶员的眼动3D跟踪。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES50779203" lang="ZH" load-source="patent-office" class="description">
    <p>基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及图像检测与跟踪方法，尤其涉及一种驾驶员眼部3D重构与跟踪方法。 技术背景</p>
    <p>[0002]	汽车诞生100多年来，给人类生活带来巨大的改变，惠及整个世界。但是，由此引发的道路交通事故也给社会带来深重的灾难。据欧美各国的交通事故统计分析表明，在众多的交通事故中，有80&#12316;90%是驾驶员的因素，而过度疲劳驾驶又是其中最容易造成重大交通事故的“第一杀手”。据法国国家警察局（NPAF)统计，在车祸的死亡事故中，20. 6%是因司机疲劳驾驶引起的；车祸受伤事故中，14. 9%与驾驶员疲劳驾驶有关。根据美国国家公路交通安全署的统计，在美国的公路上，每年由于驾驶员疲劳驾驶而导致的交通事故大约有10万起。其中约有1500起直接导致死亡，7. I万起事故导致人身伤害；在欧洲的情况也大致相同。而在中国，因驾驶员疲劳驾驶而造成的车祸，在事故数量、发生率和造成的后果损失上，都远远高于国外。理论研究表明，人类感知客观世界有90%以上的信息是通过眼睛获取的，而驾驶员的眼动过程直接反映了驾驶员的注意力状态以及是否疲劳驾驶。</p>
    <p>[0003]目前，研究人员已经对驾驶员人眼定位及眼动跟踪进行了一些研究，并取得了一定的研究成果。但是在实际应用中暴露了以下一些亟待解决的问题：1、夜晚、戴墨镜以及各种光照条件下眼动跟踪容易失败；2、可变姿态下人眼跟踪的精度和鲁棒性有待提高；3、均是对二维图像的眼部定位与跟踪，很难全面分析驾驶员的疲劳状态。</p>
    <p>发明内容</p>
    <p>[0004]	本发明的目的在于提供一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法，该方法不受光照和墨镜影响；不受驾驶员各种姿态变化和操作影响；重构与跟踪的眼部图像为3D图像，能对驾驶员疲劳状态的分析与监测提供更加全面的信息。</p>
    <p>[0005]	本发明的目的是这样实现的，一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法，包括以下步骤：</p>
    <p>[0006]	A、图像获取</p>
    <p>[0007]	Al、采用两个垂直正交的相同采样频率的摄像头对准驾驶员采集面部图像；同时利用光线感应器检测驾驶室的光照度，当检测出的光照度&lt; 4Lux(勒克斯）且保持I分钟以上时，则进行以下A2的操作，</p>
    <p>[0008]	A2、启动对准驾驶员面部的红外光源，此时摄像头采集到的面部图像为红外图</p>
    <p>[0009]	B、眼部特征提取及定位：</p>
    <p>[0010]	对两个摄像头采集到的第一帧面部图像分别采用Harr算法定位出驾驶员眼部； 若定位不出驾驶员眼部，则进行以上A2步的操作；若采集到的两个第一帧面部图像为红外图像，则分别用降维空间随机投影方法提取红外面部图像眼部特征，然后用特征匹配方法定位驾驶员眼部；[0011]	C、3D人眼重构：</p>
    <p>[0012]	将B步已定位眼部的两个第一帧图像，利用复小波相位算法得出两个第一帧图像眼部各像素的配对关系，再以双眼的瞳孔中心为坐标中心，分别进行三维点云人眼信息拟合，重构出驾驶员双眼的第一帧3D眼部图像；</p>
    <p>[0013]	D、眼动3D跟踪:</p>
    <p>[0014]	根据C步重构出的第一帧3D眼部图像，建立驾驶员眼动自适应非线性对数模型， 采用自适应模糊强跟踪有限差分扩展卡尔曼滤波（EKF)算法进行眼部3D跟踪：即通过模糊逻辑控制动态调整强跟踪扩展卡尔曼滤波算法的弱化因子，然后将有限差分替代强跟踪 EKF滤波算法中的非线性函数的偏导数，估计出下一帧的3D眼部图像；根据驾驶员眼动自适应非线性对数模型，重复以上操作，估计出一系列连续帧3D图像的驾驶员眼部，实现驾驶员的眼动3D跟踪。</p>
    <p>[0015]	与现有技术相比，本发明的收益效果是：</p>
    <p>[0016]	一、能够有效地实现夜晚驾驶环境下以及戴墨镜状态下的驾驶员眼部定位：</p>
    <p>[0017]	当光线感应器检测驾驶室的光照度&lt; 4Lux(勒克斯）且保持I分钟以上时，本发明启动红外光源，使得摄像头能够在夜晚等光照条件差的环境下采集到驾驶员脸部的红外图像；同时驾驶员戴墨镜等情况使得摄像头采集到的图像无法定位出驾驶员眼部时，本发明也启动红外光源，完成驾驶员眼部定位，从而本发明在驾驶员戴墨镜及夜晚等光照条件差的情况下均能实现眼部3D的重构与跟踪，其可靠性强。</p>
    <p>[0018]	二、采用降维空间随机投影技术，算法复杂度降低，人眼定位实时性提高</p>
    <p>[0019]	当光照度&gt; 4LUX(勒克斯），本发明采用Harr眼部定位方法能够更加快速有效地定位驾驶员眼部；对于低光照条件下获取到的红外图像，则利用降维空间随机投影技术快速、精确进行驾驶员红外面部图像的眼部定位。其算法复杂度低，实时性好，正确率高。</p>
    <p>[0020]	三、能够有效地实现各种姿态和驾驶状态下的人眼跟踪：</p>
    <p>[0021]	本发明采用两个垂直正交摄像头对准驾驶员面部，有效地避免了驾驶员因为视频采集盲区而导致跟踪精度降低，解决了因姿态和头部旋转问题导致单个摄像头无法检测驾驶员眼动特征问题，提高了 3D眼部图像重构的正确率和鲁棒性。</p>
    <p>[0022]	四、能够有效的实现驾驶员眼部3D重构，重构匹配正确率高、鲁棒性强：</p>
    <p>[0023]	利用复小波相位算法得出眼部各像素的配对关系，以双眼的瞳孔中心为坐标中心，分别进行三维点云人眼信息拟合，重构出驾驶员双眼的第一帧3D眼部图像。其重构算法正确率高、鲁棒性好。</p>
    <p>[0024]	五、在驾驶员眼部3D跟踪阶段，跟踪率高、鲁棒性强：</p>
    <p>[0025]	建立驾驶员眼动自适应非线性对数模型，采用自适应模糊强跟踪有限差分扩展卡尔曼滤波（EKF)算法进行眼部3D跟踪，跟踪率高，鲁棒性强。</p>
    <p>[0026]	下面结合附图和具体的实施方式对本发明作进一步详细的说明。</p>
    <p>附图说明</p>
    <p>[0027]	图I是本发明实例中红外图像眼部3D重构与跟踪示意图。</p>
    <p>具体实施方式[0028]	实施例</p>
    <p>[0029]	如图I所示，本发明的一种具体实施方式是：一种基于正交双目降维空间的驾驶员眼部3D重构与跟踪方法，包括以下步骤：</p>
    <p>[0030]	A、图像获取</p>
    <p>[0031]	Al、采用两个垂直正交的相同采样频率的摄像头对准驾驶员采集面部图像；同时利用光线感应器检测驾驶室的光照度，当检测出的光照度&lt; 4Lux(勒克斯）且保持I分钟以上时，则进行以下A2的操作，</p>
    <p>[0032]	A2、启动对准驾驶员面部的红外光源，此时摄像头采集到的面部图像为红外图</p>
    <p>[0033]	B、眼部特征提取及定位：</p>
    <p>[0034]	对两个摄像头采集到的第一帧面部图像分别采用Harr算法定位出驾驶员眼部； 若定位不出驾驶员眼部，则进行以上A2步的操作；若采集到的两个第一帧面部图像为红外图像，则分别用降维空间随机投影方法提取红外面部图像眼部特征，然后用特征匹配方法定位驾驶员眼部；</p>
    <p>[0035]	C、3D人眼重构：</p>
    <p>[0036]	将B步已定位眼部的两个第一帧图像，利用复小波相位算法得出两个第一帧图像眼部各像素的配对关系，再以双眼的瞳孔中心为坐标中心，分别进行三维点云人眼信息拟合，重构出驾驶员双眼的第一帧3D眼部图像；</p>
    <p>[0037]	D、眼动3D跟踪：</p>
    <p>[0038]	根据C步重构出的第一帧3D眼部图像，建立驾驶员眼动自适应非线性对数模型， 采用自适应模糊强跟踪有限差分扩展卡尔曼滤波（EKF)算法进行眼部3D跟踪：即通过模糊逻辑控制动态调整强跟踪扩展卡尔曼滤波算法的弱化因子，然后将有限差分替代强跟踪 EKF滤波算法中的非线性函数的偏导数，估计出下一帧的3D眼部图像；根据驾驶员眼动自适应非线性对数模型，重复以上操作，估计出一系列连续帧3D图像的驾驶员眼部，实现驾驶员的眼动3D跟踪。</p>
    <p>[0039]	本实施例方法的计算机仿真实验如下：</p>
    <p>[0040]	一、实时性能</p>
    <p>[0041]	仿真实验结果表明，本发明对红外图像循环一次（即完成眼部定位过程到重构) 仅需要O. 012秒，远远低于EKF滤波算法的O. 050秒和强跟踪滤波算法（STF)的O. 058秒， 说明对红外图像采用本发明的降维空间随机投影技术进后，算法复杂度降低，具有较高的实时性能。</p>
    <p>[0042]	二、定位性能</p>
    <p>[0043]	表I本发明方法与基于Harr特征的眼部定位结果比较</p>
    <p>5[0044]</p>
    <p>方法	检测正确率  (%)	测试条件本发明方法	99. 95	夜晚驾驶条		件下本发明方法	99. 90	戴墨镜驾驶基于Harr特征	95. 21	件下的方法		夜晚驾驶条		件下</p>
    <p>正确检测到驾驶员眼部位置的视频图像数</p>
    <p>_] $巾’ JBhiEmm- 断检&#32177;驶碰&#39023;像总数</p>
    <p>[0046]	表I表明，在驾驶员眼部定位阶段，本发明的方法在夜晚驾驶环境下和戴墨镜状态下的眼部定位正确率分别达到99. 95%和99. 90%，其平均正确率可达到99. 93% ;而单一的Harr特征方法，在夜晚眼部定位正确率仅为95. 21 %，不能满足应用需要。</p>
    <p>[0047]	三、鲁棒性</p>
    <p>[0048]	表2不同跟踪算法的均方根差（RMSE)和均方差（MSE)比较</p>
    <p>[0049]</p>
    <p>[0050]</p>
    <p>方法	RMSE	MSE标准EKF算法	0. 10	0. 13120	161	强跟踪滤波算法(STF)	0. 09	0. 12361	987	本发明方法	0. 09	0. 10260	941	</p>
    <p>[0051]	表2表明，本发明的RMSE(0. 09941)和MSE(0. 10260)，远远小于标准EKF算法的 RMSE (0. 10161)和 MSE (0. 13120)，小于强跟踪滤波算法(STF)的 RMSE (0. 09987)和 MSE (0. 12361)，说明本发明具有更好的鲁棒性。</p>
    <p>[0052]	四、眼部3D重构正确率</p>
    <p>[0053]	仿真实验表明，本发明的驾驶员眼动3D重构匹配正确率为95. 12%，具有较高的匹配正确率，能够解决因姿态变化而导致跟踪失败的问题，能够满足3D重构应用要求。</p>
    <p>[0054]	五、3D眼部跟踪率[0055] 表3不同方法的3D眼部跟踪率比较（全天候：包括白天和夜晚等不同光照条件下）</p>
    <p>[0056]</p>
    <p>[0057]</p>
    <p>[0058]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609984A/CN102609984AD00071.png"> <img id="idf0001" file="CN102609984AD00071.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609984A/CN102609984AD00071.png" class="patent-full-image" alt="Figure CN102609984AD00071"> </a> </div>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102609984A/CN102609984AD00072.png"> <img id="idf0002" file="CN102609984AD00072.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102609984A/CN102609984AD00072.png" class="patent-full-image" alt="Figure CN102609984AD00072"> </a> </div>
    <p> 以上表3表明，本发明方法在各种光照条件下的驾驶员眼部3D跟踪率为99. 3%, 高于Kalman滤波算法、标准EKF滤波算法和强跟踪滤波算法（STF)，可见本例方法的跟踪率更高。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101398886A?cl=zh">CN101398886A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年3月17日</td><td class="patent-data-table-td patent-date-value">2009年4月1日</td><td class="patent-data-table-td ">杭州大清智能技术开发有限公司</td><td class="patent-data-table-td ">一种基于双目被动立体视觉的快速三维人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101833770A?cl=zh">CN101833770A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年5月17日</td><td class="patent-data-table-td patent-date-value">2010年9月15日</td><td class="patent-data-table-td ">西南交通大学</td><td class="patent-data-table-td ">基于光线感应的驾驶员眼动特征切换检测与跟踪方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8077914">US8077914</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年8月7日</td><td class="patent-data-table-td patent-date-value">2011年12月13日</td><td class="patent-data-table-td ">Arkady Kaplan</td><td class="patent-data-table-td ">Optical tracking apparatus using six degrees of freedom</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">张祖涛: "<a href='http://scholar.google.com/scholar?q="%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E5%BC%BA%E8%B7%9F%E8%B8%AA%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BB%A4%E6%B3%A2%E7%90%86%E8%AE%BA%E7%9A%84%E9%A9%BE%E9%A9%B6%E5%91%98%E7%9C%BC%E5%8A%A8%E8%B7%9F%E8%B8%AA%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6"'>基于采样强跟踪非线性滤波理论的驾驶员眼动跟踪技术研究</a>", 《中国博士学位论文全文数据库》, 13 August 2010 (2010-08-13)</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102957931A?cl=zh">CN102957931A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月2日</td><td class="patent-data-table-td patent-date-value">2013年3月6日</td><td class="patent-data-table-td ">京东方科技集团股份有限公司</td><td class="patent-data-table-td ">一种3d显示的控制方法和装置、及视频眼镜</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104325930A?cl=zh">CN104325930A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年11月5日</td><td class="patent-data-table-td patent-date-value">2015年2月4日</td><td class="patent-data-table-td ">无锡悟莘科技有限公司</td><td class="patent-data-table-td ">一种防止疲劳驾驶的汽车控制系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009460000">G06K9/46</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0007200000">G06T7/20</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009200000">G06K9/20</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=ODGPBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06T0017000000">G06T17/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年7月25日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年9月26日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年4月15日</td><td class="patent-data-table-td ">C12</td><td class="patent-data-table-td ">Rejection of a patent application after its publication</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/7741a10ab5998270223f/CN102609984A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E6%AD%A3%E4%BA%A4%E5%8F%8C%E7%9B%AE%E9%99%8D%E7%BB%B4%E7%A9%BA%E9%97%B4%E7%9A%84%E9%A9%BE%E9%A9%B6.pdf?id=ODGPBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2kFI3fVS6nVu1C8NZJiaqxqpAERg"},"sample_url":"https://www.google.com/patents/reader?id=ODGPBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>