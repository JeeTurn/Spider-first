<!DOCTYPE html><html><head><title>专利 CN101373514A - 人脸识别方法和系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5115ea495017d9115e613207d3810e5a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5115ea495017d9115e613207d3810e5a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="人脸识别方法和系统"><meta name="DC.contributor" content="李树德" scheme="inventor"><meta name="DC.contributor" content="李树德" scheme="assignee"><meta name="DC.date" content="2007-8-24" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种人脸识别方法和系统。所述人脸识别方法包括：检测所捕捉到的图像中的人脸；从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量；根据获得的多个人脸标志特征向量生成动态链接属性图；比较生成的属性图与人脸数据库中的属性图以确定是否匹配。所述人脸识别系统包括服务器子系统和一个或多个客户端子系统。本发明的人脸识别系统是一种全自动和智能的人脸检测和验证系统。本发明使用人脸轮廓图的动态链接模型实现人脸图像的高效存储和识别，可以获得很高的正确识别率。"><meta name="DC.date" content="2009-2-25"><meta name="citation_patent_publication_number" content="CN:101373514:A"><meta name="citation_patent_application_number" content="CN:200710148229"><link rel="canonical" href="https://www.google.com/patents/CN101373514A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101373514A?cl=zh"/><meta name="title" content="专利 CN101373514A - 人脸识别方法和系统"/><meta name="description" content="本发明涉及一种人脸识别方法和系统。所述人脸识别方法包括：检测所捕捉到的图像中的人脸；从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量；根据获得的多个人脸标志特征向量生成动态链接属性图；比较生成的属性图与人脸数据库中的属性图以确定是否匹配。所述人脸识别系统包括服务器子系统和一个或多个客户端子系统。本发明的人脸识别系统是一种全自动和智能的人脸检测和验证系统。本发明使用人脸轮廓图的动态链接模型实现人脸图像的高效存储和识别，可以获得很高的正确识别率。"/><meta property="og:title" content="专利 CN101373514A - 人脸识别方法和系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101373514A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101373514A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101373514A&amp;usg=AFQjCNHGHeevB0YycDyDaCLRNG0CwHAH1Q" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/21b2dee42d1996f71987/CN101373514A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/21b2dee42d1996f71987/CN101373514A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101373514A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101373514A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101373514A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种人脸识别方法和系统。所述人脸识别方法包括：检测所捕捉到的图像中的人脸；从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量；根据获得的多个人脸标志特征向量生成动态链接属性图；比较生成...</span><span itemprop="url">https://www.google.com/patents/CN101373514A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101373514A - 人脸识别方法和系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101373514A - 人脸识别方法和系统" title="专利 CN101373514A - 人脸识别方法和系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101373514 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200710148229</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2009年2月25日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2007年8月24日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年8月24日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200710148229.X, </span><span class="patent-bibdata-value">CN 101373514 A, </span><span class="patent-bibdata-value">CN 101373514A, </span><span class="patent-bibdata-value">CN 200710148229, </span><span class="patent-bibdata-value">CN-A-101373514, </span><span class="patent-bibdata-value">CN101373514 A, </span><span class="patent-bibdata-value">CN101373514A, </span><span class="patent-bibdata-value">CN200710148229, </span><span class="patent-bibdata-value">CN200710148229.X</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E6%A0%91%E5%BE%B7%22">李树德</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%9D%8E%E6%A0%91%E5%BE%B7%22">李树德</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101373514A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101373514A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101373514A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (10),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200710148229&amp;usg=AFQjCNEY3FkBatFP7K6mVCKEirUx4Ry8pg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101373514A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH1pOBj4QfHsMWTbRxWirIpcwKVNg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT84954119" lang="ZH" load-source="patent-office">人脸识别方法和系统</invention-title>
    </span><br><span class="patent-number">CN 101373514 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA61188822" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种人脸识别方法和系统。所述人脸识别方法包括：检测所捕捉到的图像中的人脸；从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量；根据获得的多个人脸标志特征向量生成动态链接属性图；比较生成的属性图与人脸数据库中的属性图以确定是否匹配。所述人脸识别系统包括服务器子系统和一个或多个客户端子系统。本发明的人脸识别系统是一种全自动和智能的人脸检测和验证系统。本发明使用人脸轮廓图的动态链接模型实现人脸图像的高效存储和识别，可以获得很高的正确识别率。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(9)</span></span></div><div class="patent-text"><div mxw-id="PCLM13335428" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种人脸识别方法，其特征在于，所述方法包括如下步骤：(a)检测所捕捉到的图像中的人脸；(b)从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量；(c)根据获得的多个人脸标志特征向量生成动态链接属性图；(d)比较生成的属性图与人脸数据库中的属性图以确定是否匹配。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2、 根据权利要求1所述的人脸识别方法，其特征在于，所述步骤（a)进 一步包括：使用人脸模板比较所捕捉到的图像，将匹配人脸模板的图像部分分 割出来。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3、 根据权利要求1所述的人脸识别方法，其特征在于，所述步骤（b)进 一步包括：(bl)使用活动轮廓模型提取出人脸轮廓；(b2 )使用Gabor特征提取器从所述人脸轮廓中多个标志部分提取出多个 特征向量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4、 根据权利要求1所述的人脸识别方法，其特征在于，所述步骤（c)进 一步包括：使用弹性图动态链接模型建立所述多个特征向量的属性图。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5、 根据权利要求1所述的人脸识别方法，其特征在于，所述步骤（d)进 一步包括：判断所生成的属性图与人脸数据库中的属性图之间的偏差是否在允许偏差范围内，若是，则匹配。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6、 一种人脸识别系统，其特征在于，所述系统包括： 一个或多个客户端子系统，所述客户端子系统包括：用于检测所捕捉到的图像中的人脸的人脸检测模块；用于从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量的特征提取模块；通过网络与所述一个或多个客户端子系统连接的服务器子系统，所述服务 器子系统包括：用于根据获得的多个人脸标志特征向量生成动态链接属性图的动态链接初始化模块；用于比较生成的属性图与人脸数据库中的属性图以确定是否匹配的 弹性图匹配模块；存储人脸模型的人脸数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7、 根据权利要求6所述的人脸识别系统，其特征在于，所述特征提取模 块进一步包括：用于提取出人脸轮廓的活动轮廓模型模块；从所述人脸轮廓中多个标志部分提取出多个特征向量的Gabor特征提取器o</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8、 根据权利要求6所述的人脸识别系统，其特征在于，所述客户端子系 统还包括有用于将所提取到的人脸标志特征向量发送给服务器子系统并接收 匹配结果的客户端通信模块，所述服务器端子系统还包括有接收客户端子系统 发送的人脸标志特征向量并返回匹配结果的服务器端通信模块。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9、 根据权利要求7所述的人脸识别系统，其特征在于，所述客户端通信 模块和服务器端通信模块通过有线或无线网络通信。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES18722453" lang="ZH" load-source="patent-office" class="description">
    <p>人脸识别方法和系统</p>
    <p>技术领域</p>
    <p>本发明涉及生物特征识别技术，更具体地说，涉及一种智能的人脸识别方 法和系统。</p>
    <p>背景技术</p>
    <p>传统的验证方案采用通过安全传输层例如SSL协议由用户使用用户名和 密码登录的机制。尽管这一机制能够提供安全的用户验证方案，但是这种机制 需要用户先登入用户系统才能获得访问权，这一过程降低了系统的可用性，特 别是在客户忘记用户名和密码的情况下，明显降低线上购物站点的用户友好 性。使用数字签名的验证机制看起来似乎提供了可行的方案，但是这种技术存 在潜在的缺点。首先，数字证书需要存储在用户的PC或笔记本电脑内，这便 影响了移动性。尽管新近研发出来的智能卡可以将数字证书嵌入其中，但是如 果不能在大部分公共场合例如网吧、酒店等提供这种智能卡读卡器，便仍不能 解决移动性的问题。使用生物特征例如指纹、手掌和虹膜识别的其它自动验证 机制虽然提供了可行的解决方案，但是都存在上述的各种问题。</p>
    <p>从移动性的角度考虑，人脸识别不会存在这一问题。与其它生物特征识别 技术例如指纹、虹膜扫描、签名不同的是，人脸识别更加友好和方便，不需要 与采集装置有任何物理接触。而且，人脸识别是唯一能够与视频监视系统结合 使用的生物特征识别技术。人脸识别技术尤其在法律领域具有很重要的作用， 特别在照片是可用于识别某个目标的唯一证据的情况下。从照片中读取和检测 罪犯的指纹或虹膜是不可能的，但是通过人脸识别技术，便可以仅仅从一张照 片中找出目标。</p>
    <p>而且，由于桌面视频会话的广泛流行，数字视频摄像头已经成为桌面型和 笔记本电脑的标准外设。换言之，使用人脸识别技术的用户验证不需要担心是</p>
    <p>否有人脸图像采集设备的问题。此外，这种验证方案能够提供真正的自动验证， 用户不需要提供任何身份信息或数据，更重要的是，用户不需要提供任何私秘 的个人数据例如指纹和虹膜模本。</p>
    <p>因此，人脸识别技术已经成为近二十年来最受关注的研究课题，人脸识别 是用于用户验证和访问控制的最有用技术之一。鉴于人脸识别很容易在各种条 件下执行，大量的研究都把重点放在开发自动人脸识别系统，在保证相同性能 的情况下提供更快的速度和更高的准确性。</p>
    <p>目前已经研究出了多种人脸识别技术,这些技术在某种程度上都允许在受 控环境下采集的存储在数据库中的人脸图像与在非受控环境中采集的输入人 脸图像之间存在差别。这些技术在识别从相近角度采集的、在大小比例、方向 上都存在小的偏差的人脸图像方面都已经取得了一些进步。但是这一进步不仅 很有限，而且计算复杂、昂贵且速度很慢。</p>
    <p>发明内容</p>
    <p>本发明要解决的技术问题在于，针对现有技术的上述不足，提供一种识别 率高且高效智能的人脸识别方法和系统。</p>
    <p>本发明解决其技术问题所采用的技术方案是：提出一种人脸识别方法，包 括如下步骤-</p>
    <p>(a) 检测所捕捉到的图像中的人脸；</p>
    <p>(b) 从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向量； (C )根据获得的多个人脸标志特征向量生成动态链接属性图；</p>
    <p>(d)比较生成的属性图与人脸数据库中的属性图以确定是否匹配。 上述人脸识别方法中，所述步骤（a)进一步包括：使用人脸模板比较所 捕捉到的图像，将匹配人脸模板的图像部分分割出来。 上述人脸识别方法中，所述步骤（b)进一步包括：</p>
    <p>(bl)使用活动轮廓模型（Active Contour Model,简称为ACM)提取出 人脸轮廓；</p>
    <p>(b2)使用Gabor特征提取器从所述人脸轮廓中多个标志部分提取出多个</p>
    <p>特征向量。</p>
    <p>上述人脸识别方法中，所述步骤（C)进一步包括：使用弹性图动态链接</p>
    <p>模型（Elastic Graph Dynamic Link Model,简称为EGDLM)建立所述多个特 征向量的属性图。</p>
    <p>上述人脸识别方法中，所述步骤（d)进一步包括：判断所生成的属性图 与人脸数据库中的属性图之间的偏差是否在允许偏差范围内，若是，则匹配。 本发明为解决其技术问题还提出一种人脸识别系统，所述系统包括： 一个或多个客户端子系统，所述客户端子系统进一步包括： 用于检测所捕捉到的图像中的人脸的人脸检测模块； 用于从所检测到的人脸中提取人脸轮廓并获得多个人脸标志特征向 量的特征提取模块；</p>
    <p>通过网络与所述一个或多个客户端子系统连接的服务器子系统，所述服务 器子系统进一步包括：</p>
    <p>用于根据获得的多个人脸标志特征向量生成动态链接属性图的动态 链接初始化模块；</p>
    <p>用于比较生成的属性图与人脸数据库中的属性图以确定是否匹配的 弹性图匹配模块；</p>
    <p>存储人脸模型的人脸数据库。</p>
    <p>上述人脸识别系统中，所述特征提取模块进一步包括：用于提取出人脸轮 廓的活动轮廓模型模块，和从所述人脸轮廓中多个标志部分提取出多个特征向 量的Gabor特征提取器。</p>
    <p>上述人脸识别系统中，所述客户端子系统还包括有用于将所提取到的人脸 标志特征向量发送给服务器子系统并接收匹配结果的客户端通信模块，所述服 务器端子系统还包括有接收客户端子系统发送的人脸标志特征向量并返回匹 配结果的服务器端通信模块。</p>
    <p>上述人脸识别系统中，所述客户端通信模块和服务器端通信模块通过有线 或无线网络通信。</p>
    <p>实施本发明的人脸识别方法和系统，具有以下有益效果：本发明的人脸识别系</p>
    <p>统是一种全自动和智能的人脸检测和验证系统。本发明不仅提供了一种便携、 鲁棒、多样的验证系统，还提供了一种有效且高效的人脸识别方案。本发明的 另一个显著特征是，使用人脸轮廓图的动态链接模型实现人脸图像的高效存储</p>
    <p>和识别，这一点对于web站点例如线上购物中心等的人脸数据库管理来说是</p>
    <p>非常重要的，因为他们每小时要验证数以千计的顾客。本发明的人脸识别系统 已经从以下四个方面经过了评估，结果显示其可以获得很高的正确识别率。</p>
    <p>试验中使用包含100个人脸图像的肖像集来对系统进行训练。训练中使用 了一组1020个测试样本，产生自具有不同的脸部表情、视角和大小的人脸。 该组测试用人脸样本使用提供标准视频信号的CCD摄像头捕捉到，为512x384 像素，并具有8比特的分辨率。用于执行测试并测量该系统性能的计算机系统 为SUN-Sparc20工作站。 1、人脸图像亮度测试</p>
    <p>在亮度测试中，使用具有不同亮度的ioo个测试样本进行识别，其亮度变</p>
    <p>化范围为正常亮度的+30%到-30%，实验结果如下表1。</p>
    <p>表1.亮度测试结果</p>
    <p>&lt;table&gt;table see original document page 7&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;由表l可以看出，本发明的系统基本不受图像亮度级的影响，主要是因为活动</p>
    <p>轮廓模型的"亮度不变性"特性，平均可以达到85%的正确识别率。 2、观察视角测试</p>
    <p>在这一测试中，所使用的100个人脸样本的视角在-30°到+30°的范围内变 化（基于横轴和纵轴），识别结果如下表2。</p>
    <p>表2.视角测试结果</p>
    <p>&lt;table&gt;table see original document page 7&lt;/column&gt;&lt;/row&gt;
&lt;table&gt; &lt;table&gt;table see original document page 8&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;</p>
    <p>根据动态链接模型的"旋转不变性"，因此在弹性图匹配过程中，弹性图动态链</p>
    <p>接模型具有相同的特性，由表2可以看出，可以达到超过86%的正确识别率。 3、人脸图像扩张/收&#32302;测试</p>
    <p>这一测试使用了 300个测试样本，局部收&#32302;比例在-30% (样本收&#32302;）到 +30% (样本扩张）之间，获得的识别结果如表3所示。</p>
    <p>&lt;table&gt;table see original document page 8&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;源于弹性图动态链接模型的"弹性图匹配"特性，本发明的系统具有"扩张/收&#32302;</p>
    <p>不变性"，整体的正确识别率可以达到85%。 4、人脸图像遮挡和扭曲测试</p>
    <p>该测试将120个测试样本分为三个类别：第一类，带眼镜或其它装饰品； 第二类，脸部部分被其它物体例如杯子、书等遮挡；第三类，脸部具有各种不 同的表情，例如笑脸、生气的脸、欺骗的脸等。所获得的测试结果如下表4 所示。</p>
    <p>&lt;table&gt;table see original document page 8&lt;/column&gt;&lt;/row&gt;
&lt;table&gt;比较上述的三类人脸，"带眼镜"对识别的影响最小，因为人脸的主要轮廓仍然 呈现出来了。第二类的情况下，对识别率的影响主要取决于遮挡的比例以及被</p>
    <p>遮挡的部位。尽管如此，还是可以达到73%以上的平均正确识别率。带面部 表情的人脸的识别结果最显著，这是因为采用了弹性图动态链接模型，该识别</p>
    <p>系统具有"扭曲不变性"特性，总体的正确识别率可以到达83%。 附图说明</p>
    <p>图1是本发明人脸识别系统的一个实施例的结构示意图；</p>
    <p>图2是本发明人脸识别方法的一个实施例的流程图；</p>
    <p>图3是根据本发明一个实施例检测图像中的人脸的示意图；</p>
    <p>图4是根据本发明一个实施例使用活动轮廓模型提取人脸轮廓的示意图；</p>
    <p>图5是根据本发明一个实施例提取人脸标志特征的示意图。</p>
    <p>具体实施方式</p>
    <p>下面将结合附图及实施例对本发明作进一步说明：</p>
    <p>如图1所示，本发明的人脸识别系统主要包括两个子系统， 一个是位于客 户端（例如客户的桌面电脑、安全接入点等）的客户端子系统IOO，另一个是 位于服务器端（例如线上购物中心、安全控制中心等）的服务器端子系统300。 客户端子系统100与服务器端子系统300之间通过有线或无线网络连接，例如， 两者之间通过互联网200进行通信和信息传递。</p>
    <p>在本发明的人脸识别系统中运行有两种类型的智能代理。客户端子系统 IOO进一步包括人脸检测模块104、活动轮廓模型模块106、 Gabor特征提取器 108以及客户端通信模块110。其中，人脸检测模块104是固定代理，自动检 测从客户端的数字摄像头102捕捉到的图像并将检测到的人脸分割出来。ACM 模块106是固定代理，从人脸检测模块104检测到的人脸中提取人脸轮廓。 Gabor特征提取器108是固定代理，用于从人脸轮廓中提取出人脸标志部分 (Landmark)的多个特征向量。客户端通信模块110是用于传送信息的移动代 理， 一方面将提取出的人脸特征向量发送给服务器子系统300，另一方面将服 务器子系统的匹配结果以及最新的状态信息返回给客户端设备。</p>
    <p>服务器子系统300进一步包括服务器端通信模块302、动态链接初始化模 块304、弹性图匹配模块306。其中，服务器端通信模块302是用于传送信息 的移动代理，用于接收客户端子系统100传送过来的人脸特征向量，并将匹配</p>
    <p>结果返回给客户端子系统100。动态链接初始化模块304是位于服务器（例如 线上购物中心、安全控制中心等）内的固定代理，主要任务是使用弹性图动态 链接模型建立多个特征向量的属性图。弹性图匹配模块306是固定代理，用于 将检测到的人脸的属性图与人脸数据库内的人脸模本进行比较。此外，服务器 子系统300还包括存储人脸模本的人脸数据块，该人脸数据库也可以位于并非 服务器本地的远端。</p>
    <p>本发明的人脸识别系统所执行的识别过程如图2所示。当需要识别某用户 时，本发明从步骤400开始，然后该系统所执行的主要流程如下：</p>
    <p>步骤402:客户端的摄像头捕捉用户所在的场景图像。</p>
    <p>步骤404:人脸检测模块检测捕捉到的场景图像中出现的人脸，并对人脸 进行包络和分割。</p>
    <p>步骤406: ACM模块从人脸图像中提取出人脸轮廓。</p>
    <p>步骤408: Gabor特征提取器从人脸轮廓中提取出人脸标志部位的多个特 征向量。</p>
    <p>步骤410:使用弹性图动态链接模型建立所述多个特征向量的属性图。 步骤412:通过弹性图匹配模块比较生成的属性图与人脸数据库中人脸模</p>
    <p>本的属性图。</p>
    <p>步骤414:判断所生成的属性图与人脸数据库中人脸模本的属性图是否在</p>
    <p>存在匹配。系统设置了一定的允许偏差，若二者之间存在的匹配偏差在系统允</p>
    <p>许的范围内，则视为二者匹配，在步骤416中，该户成功通过识别，可以继续</p>
    <p>后续操作。</p>
    <p>若步骤414中判断出生成的属性图与人脸数据库中的模本不相匹配，则返 回步骤402。</p>
    <p>以下将具体介绍本发明人脸识别方法中的特征提取和匹配过程。首先，在 客户端进行人脸特征提取。</p>
    <p>步骤404中，在收到客户端的摄像头102 (网络摄像头、数字摄像机、监 视摄像头等）捕捉到的场景图像后，如图3所示，人脸检测模块104自动检测 捕捉到的场景内的任何可能出现有人脸的区域。这时，人脸检测模块104可以</p>
    <p>利用经过预处理的人脸模板（例如，从FRET和Yale人脸数据库获得）对捕 捉到的场景图象进行匹配。所有的人脸模板可以通过haar小波变换提取出来， 并以XML的格式存储在判定树（decisiontree)内。基于人脸模版检测到场景 中出现人脸后，人脸检测模块104对该区域进行包络，将人脸502分割出来以 用于特征提取。实际上，人脸检测模块104除了可以检测单个用户的人脸以用 于一般的用户验证之外，还可以检测捕捉到的场景中的多个人脸，如图3所示。 步骤406中，活动轮廓模型模块106使用蛇形（snake)曲线600提取人 脸轮廓，如图4所示。Snake曲线600为构成人脸初始状态（即人脸模板）的 连续曲线，在人脸图像上动态地变形（504)。 Snake曲线的形状由曲线本身的 内力和图像数据的外力所控制。内力起平滑约束作用，保持人脸模板形状的平 滑，而外力则引导snake曲线向人脸图像特征移动，最终使snake曲线达到一个 新的平衡（506)。通过表示snake曲线拉伸的隔膜能（membrane energy)与表 示snake曲线弯曲的薄板能（thin-plate energy)之和，可以得出以下snake能</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt; (1)</p>
    <p>其中，i/&#12316;=(V4x^)即为snake曲线，s表示该曲线的弧长。弹性参数a和" 控制snake曲线的平滑度。</p>
    <p>snake曲线的变形受外力的控制。这些外力与势能P(x,y)有关，势能P(x，y) 一般依据经高斯函数&#24059;积积分的图像的梯度来定义：</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt; (2)</p>
    <p>或者作为边缘点（edge point)的距离图（distance map):</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt; (3) 其中，《^rj表示像素(x，y)与其最近边缘点之间的距离。Snake曲线在势位场的 作用下移动进而凹陷，就好像受到地心引力的作用。</p>
    <p>Snake曲线的总能量由以下能量函数之和来表示：</p>
    <p>&lt;formula&gt;formula see original document page 11&lt;/formula&gt; (4)Snake曲线能量的最小值满足欧拉-拉格朗日（Euler-Lagrange)方程及边 界条件：</p>
    <p>&lt;formula&gt;formula see original document page 12&lt;/formula&gt;</p>
    <p>步骤408中，Babor特征提取器108依据人脸模板内定义的50个人脸标 志（例如，鼻子、眼睛、眉毛、嘴、脸型轮廓等），使用具有15个不同频带（小) 和8个不同方向（e)的Gabor滤波器，可以自动从这些标志部位提取出总共 120个具有不同属性的特征向量，如图5所示。Gabor滤波器的函数如下：</p>
    <p>&lt;formula&gt;formula see original document page 12&lt;/formula&gt; （6)</p>
    <p>步骤410中，服务器端的动态链接初始化模块304在从服务器端通信模块 302接收到客户端传来的人脸特征向量信息后，建立属性图（即弹性图）。在 动态链接初始化过程中，生成的人脸属性图与人脸数据库中的属性图目标之间 的动态链接(zij,k,)根据以下规则进行初始化：</p>
    <p>&lt;formula&gt;formula see original document page 12&lt;/formula&gt;</p>
    <p>其中，A是从人脸标志中提取出来的特征向量，s是O到l之间的参数值，A 和B分别表示捕捉到的人脸的弹性图和人脸数据库内的弹性图。</p>
    <p>然后步骤412中，在弹性图匹配模块内，通过最小化能量函数H(z)来将 捕捉到的人脸图像的属性图与人脸数据库内每个存储的人脸模本的属性图进 行匹配，其允许的匹配偏差为^</p>
    <p>&lt;formula&gt;formula see original document page 12&lt;/formula&gt; (8)</p>
    <p>H(z)可使用梯度下降来最小化：</p>
    <p>&lt;formula&gt;formula see original document page 12&lt;/formula&gt;</p>
    <p>其中，[...r表示被限制在[O,w]的范围内的A的值。达到平衡时（位于选定的 允许偏差li的范围内），H(z)被最小化，即找到匹配的人脸模本。若找到位于允许偏差范围内的人脸模本，则该用户通过识别。</p>
    <p>本发明的人脸识别方法和系统可以应用于各个方面。例如，本发明可以替 代配备有摄像头的桌面电脑、笔记本电脑等设备现有的由密码保护的屏保，提 供一种基于人脸识别的屏幕保护。类似于设置密码，用户可以事先建立授权用</p>
    <p>户人脸数据库。除了屏保登录之外，本发明的系统还可以与Windows、 Mac OSX、 Linux等系统结合，以提供基于人脸识别的登录系统。此外，本发明还 可用来进行文件加密和保护。本发明的自动人脸检测特征还可以用于照相机自 动图像聚焦系统，本发明只需要花0.1秒的时间便可以捕捉并检测出一张 640x320像素的图像中出现的所有人脸，因此可以为照相机等类似设备提供高 效的图像聚焦和光学控制。此外，本发明的人脸识别方法和系统还可以应用于 访问控制领域，例如门禁系统。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102201061A?cl=zh">CN102201061A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2011年9月28日</td><td class="patent-data-table-td ">常州锐驰电子科技有限公司</td><td class="patent-data-table-td ">基于多阶层过滤人脸识别的智能安全监控系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102201061B?cl=zh">CN102201061B</a></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2012年10月31日</td><td class="patent-data-table-td ">常州锐驰电子科技有限公司</td><td class="patent-data-table-td ">基于多阶层过滤人脸识别的智能安全监控系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102262729A?cl=zh">CN102262729A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年8月3日</td><td class="patent-data-table-td patent-date-value">2011年11月30日</td><td class="patent-data-table-td ">山东志华信息科技股份有限公司</td><td class="patent-data-table-td ">基于集成学习的混合融合人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102262729B?cl=zh">CN102262729B</a></td><td class="patent-data-table-td patent-date-value">2011年8月3日</td><td class="patent-data-table-td patent-date-value">2013年1月2日</td><td class="patent-data-table-td ">山东志华信息科技股份有限公司</td><td class="patent-data-table-td ">基于集成学习的混合融合人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102346846A?cl=zh">CN102346846A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月16日</td><td class="patent-data-table-td patent-date-value">2012年2月8日</td><td class="patent-data-table-td ">由田信息技术(上海)有限公司</td><td class="patent-data-table-td ">人脸抓拍及轮廓分析系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102496025A?cl=zh">CN102496025A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月7日</td><td class="patent-data-table-td patent-date-value">2012年6月13日</td><td class="patent-data-table-td ">方正国际软件有限公司</td><td class="patent-data-table-td ">一种文档中含有人物肖像的图像检测方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102496025B?cl=zh">CN102496025B</a></td><td class="patent-data-table-td patent-date-value">2011年12月7日</td><td class="patent-data-table-td patent-date-value">2014年4月30日</td><td class="patent-data-table-td ">方正国际软件有限公司</td><td class="patent-data-table-td ">一种文档中含有人物肖像的图像检测方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104143104A?cl=zh">CN104143104A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月10日</td><td class="patent-data-table-td patent-date-value">2014年11月12日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">一种图像识别方法、装置、终端设备及服务器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9195896">US9195896</a></td><td class="patent-data-table-td patent-date-value">2014年5月15日</td><td class="patent-data-table-td patent-date-value">2015年11月24日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">Methods and systems for image recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013091370A1?cl=zh">WO2013091370A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月29日</td><td class="patent-data-table-td patent-date-value">2013年6月27日</td><td class="patent-data-table-td ">Institute Of Automation, Chinese Academy Of Sciences</td><td class="patent-data-table-td ">基于三维深度图像信息的并行统计学习人体部位检测方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0029060000">H04L29/06</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=9MpnBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0009320000">H04L9/32</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2009年2月25日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年4月22日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年7月7日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年7月7日</td><td class="patent-data-table-td ">COR</td><td class="patent-data-table-td ">Bibliographic change or correction in the description</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECT: ADDRESS; FROM: ROOM 1515, XINGGUANGHANG, NO.3, SALISBURY ROAD, TSIM SHA TSUI, HONGKONG, CHINA TO: ROOM 1515, XINGGUANGHANG, NO.3, SALISBURY ROAD, TSIM SHA TSUI, KOWLOON, HONGKONG</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年7月7日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">IATOPIA.COM LTD</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: LI SHUDE</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100527</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年11月7日</td><td class="patent-data-table-td ">C12</td><td class="patent-data-table-td ">Rejection of an application for a patent</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/21b2dee42d1996f71987/CN101373514A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5115ea495017d9115e613207d3810e5a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E7%B3%BB%E7%BB%9F.pdf?id=9MpnBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U02PzrxJGNiwhG4IU3OAno1fBog7Q"},"sample_url":"https://www.google.com/patents/reader?id=9MpnBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>