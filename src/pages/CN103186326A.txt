<!DOCTYPE html><html><head><title>专利 CN103186326A - 一种应用对象操作方法及电子设备 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种应用对象操作方法及电子设备"><meta name="DC.contributor" content="李琦" scheme="inventor"><meta name="DC.contributor" content="阳光" scheme="inventor"><meta name="DC.contributor" content="联想(北京)有限公司" scheme="assignee"><meta name="DC.date" content="2011-12-27" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种应用对象操作方法及电子设备。所述方法包括：在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；确定所采集的面部信息和/或语音信息对应的参数值；判断预定时间段内所述参数值是否满足预设条件，当满足所述预设条件时，在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。本发明所提供的方案，可以根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。"><meta name="DC.date" content="2013-7-3"><meta name="DC.relation" content="CN:101370195:A" scheme="references"><meta name="DC.relation" content="CN:102103617:A" scheme="references"><meta name="DC.relation" content="CN:1896918:A" scheme="references"><meta name="DC.relation" content="EP:1791053:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103186326:A"><meta name="citation_patent_application_number" content="CN:201110445098"><link rel="canonical" href="https://www.google.com/patents/CN103186326A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103186326A?cl=zh"/><meta name="title" content="专利 CN103186326A - 一种应用对象操作方法及电子设备"/><meta name="description" content="本发明公开了一种应用对象操作方法及电子设备。所述方法包括：在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；确定所采集的面部信息和/或语音信息对应的参数值；判断预定时间段内所述参数值是否满足预设条件，当满足所述预设条件时，在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。本发明所提供的方案，可以根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。"/><meta property="og:title" content="专利 CN103186326A - 一种应用对象操作方法及电子设备"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103186326A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103186326A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=p6XDCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103186326A&amp;usg=AFQjCNESISpQYU0VGrt9YmwampA3Zr8FYQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/cc78dc686be95e898905/CN103186326A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/cc78dc686be95e898905/CN103186326A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103186326A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103186326A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103186326A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种应用对象操作方法及电子设备。所述方法包括：在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；确定所采集的面部信息和/或语音信息对应的参数值；判断预定时间段内所述参数值是 ...</span><span itemprop="url">https://www.google.com/patents/CN103186326A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103186326A - 一种应用对象操作方法及电子设备</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103186326A - 一种应用对象操作方法及电子设备" title="专利 CN103186326A - 一种应用对象操作方法及电子设备"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103186326 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110445098</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年7月3日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年12月27日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年12月27日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110445098.8, </span><span class="patent-bibdata-value">CN 103186326 A, </span><span class="patent-bibdata-value">CN 103186326A, </span><span class="patent-bibdata-value">CN 201110445098, </span><span class="patent-bibdata-value">CN-A-103186326, </span><span class="patent-bibdata-value">CN103186326 A, </span><span class="patent-bibdata-value">CN103186326A, </span><span class="patent-bibdata-value">CN201110445098, </span><span class="patent-bibdata-value">CN201110445098.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%8E%E7%90%A6%22">李琦</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%98%B3%E5%85%89%22">阳光</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%81%94%E6%83%B3(%E5%8C%97%E4%BA%AC)%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">联想(北京)有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103186326A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103186326A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103186326A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=p6XDCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110445098&amp;usg=AFQjCNH1ZRr1aTsluf4LVnb5C6eW6x9G4w"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=p6XDCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103186326A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFGgrKoDDfIMLAVvE1L_poc1aYPwg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT125793040" lang="ZH" load-source="patent-office">一种应用对象操作方法及电子设备</invention-title>
      </span><br><span class="patent-number">CN 103186326 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA117198036" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种应用对象操作方法及电子设备。所述方法包括：在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；确定所采集的面部信息和/或语音信息对应的参数值；判断预定时间段内所述参数值是否满足预设条件，当满足所述预设条件时，在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。本发明所提供的方案，可以根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM53495071" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种应用对象操作方法，其特征在于，所述方法包括:  在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；  确定所采集的面部信息和/或语音信息对应的参数值；  判断预定时间段内所述参数值是否满足预设条件，当满足所述预设条件时，在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的方法，其特征在于，所述第一模式为:  用于提示用户进行微笑动作的微笑触发模式。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的方法，其特征在于，所述方法还包括:在开启所述微笑触发模式后，限定所述用户操作所述当前应用对象并提示所述用户进行符合所示微笑要求的微笑动作；  当所述用户的微笑动作满足所述微笑要求时，允许所述用户继续操作所述当前应用对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3所 述的方法，其特征在于，所述用户的微笑动作满足所述微笑要求，具体为:  所述用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求2或3所述的方法，其特征在于，当采集用户的面部信息时，确定所采集的面部信息对应的参数值，具体为:  根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；  相应的，所述预设条件为:  预定时间段内用户面部信息对应的嘴角上扬角度均小于预设的角度阈值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求2或3所述的方法，其特征在于，当采集用户的语音信息时，确定所采集的语音信息对应的参数值，具体为:  根据语音识别算法，获取所采集的用户语音信息对应的频率；  相应的，所述预设条件为:  预定时间段内用户语音信息对应频率均小于预设的频率阈值。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求2或3所述的方法，其特征在于，当采集用户的面部信息和语音信息时，确定所采集的面部信息和语音信息对应的参数值，具体为:  根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；  根据语音识别算法，获取所采集的用户语音信息对应的频率；  分别为所获取的嘴角上扬角度和频率设置相应的权值；  利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；  相应的，所述预设条件为:  预定时间段内用户的微笑权值均小于预设的微笑阈值。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.&#8212;种电子设备,其特征在于,包括:  信息获取模块，用于在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语首&#943;目息；  参数值确定模块，用于确定所采集的面部信息和/或语音信息对应的参数值；  判断模块，用于判断预定时间段内所述参数值是否满足预设条件，并当满足所述预设条件时，触发模式开启模块；模式开启模块，用于在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的电子设备，其特征在于，所述模式开启模块，具体用于:  开启用于提示用户进行微笑动作的微笑触发模式。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的电子设备，其特征在于，还包括:  微笑处理模块，用于在开启所述微笑触发模式后，限定所述用户操作所述当前应用对象并提示所述用户进行符合所示微笑要求的微笑动作；  当所述用户的微笑动作满足所述微笑要求时，允许所述用户继续操作所述当前应用对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求10所述电子设备，其特征在于，所述微笑处理模块中微笑动作满足所述微笑要求的标准为:  所述用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求9或10所述的电子设备，其特征在于，  所述信息获取模块，包括:  面部信息采集单元，用于采集所述用户的面部信息；  所述参数值确定模块，包括:  上扬角度确定单元，用于根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；   所述判断模块，包括:  角度判断单元，用于判断预定时间段内用户面部信息对应的嘴角上扬角度是否均小于预设的角度阈值，并在是的情况下，触发模式开启模块。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求9或10所述的电子设备，其特征在于，  所述信息获取模块，包括:  语音采集单元，用于采集所述用户的语音信息；  所述参数值确定模块，包括:  频率信息确定单元，用于根据语音识别算法，获取所采集的用户语音信息对应的频率;  所述判断模块，包括:  频率判断单元，用于判断预定时间段内用户语音信息对应频率是否均小于预设的频率阈值，并在是的情况下，触发模式开启模块。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求9或10所述的电子设备，其特征在于，  信息获取模块，包括:  面部和语音信息采集单元，用于采集所述用户的面部信息和语音信息；  参数值确定模块，包括:  微笑权值确定单元，用于根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；  根据语音识别算法，获取所采集的用户语音信息对应的频率；  分别为所获取的嘴角上扬角度和频率设置相应的权值；  利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；判断模块，包括:  微笑权 值判断单元，用于判断预定时间段内用户的微笑权值是否均小于预设的微笑阈值，并在是的情况下，触发模式开启模块。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES60534489" lang="ZH" load-source="patent-office" class="description">
    <p>一种应用对象操作方法及电子设备</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及应用对象处理技术领域，特别是涉及一种应用对象操作方法及电子设备。</p>
    <p>背景技术</p>
    <p>[0002]	近年来，心理问题越来越成为社会关注的热点，尤其是现在生活的节奏快，人们面临的各种压力越来越多，着实给人们的心理增加了一层层的负担。如何缓解压力，成为心里健康的人群一个需要解决的问题。而心理学家认为，微笑是缓解压力的一种非常有效的办法。微笑不仅是脸部肌肉动作，更是内在情绪的表露和两个心灵亲密融合的最直观表现。研究证明，当人们微笑时，内脑接收的讯息通常是积极的，并且能使身体处于放松和满足状态。</p>
    <p>[0003]	在每天忙碌的生活中，如果不刻意的心理暗示要微笑，可能一整天的工作下来，好多人都是眉头紧锁，神情紧张。</p>
    <p>[0004]	而面部信息和/或语音信息可以表征人们的情绪，因此，如何利用人们的面部信息和/或语音信息触发特定的模式，以提示用户进行相应的动作，例如:触发用于提示用户进行微笑动作的微笑触发模式，是一个值得关注的问题。</p>
    <p>发明内容</p>
    <p>[0005]	为解决上述技术问题，本发明实施例提供了一种应用对象操作方法及电子设备，以根据用户的面部信息和/或语音信息触发相应模式，进而提示用户进行相应动作，技术方案如下:</p>
    <p>[0006]	一种应用对象操作方法，包括:</p>
    <p>[0007]	在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语音信息；</p>
    <p>[0008]	确定所采集的面部信息和/或语音信息对应的参数值；</p>
    <p>[0009]	判断预定时间段内所述参数值是否满足预设条件，当满足所述预设条件时，在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。</p>
    <p>[0010]	其中，所述第一模式为:</p>
    <p>[0011]	用于提示用户进行微笑动作的微笑触发模式。</p>
    <p>[0012]	其中，所述方法还包括:在开启所述微笑触发模式后，限定所述用户操作所述当前应用对象并提示所述用户进行符合所示微笑要求的微笑动作；</p>
    <p>[0013]	当所述用户的微笑动作满足所述微笑要求时，允许所述用户继续操作所述当前应用对象。</p>
    <p>[0014]	其中，所述用户的微笑动作满足所述微笑要求，具体为:</p>
    <p>[0015]	所述用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</p>
    <p>[0016]	其中，当采集用户的面部信息时，确定所采集的面部信息对应的参数值，具体为:</p>
    <p>[0017]	根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；[0018]	相应的，所述预设条件为:</p>
    <p>[0019]	预定时间段内用户面部信息对应的嘴角上扬角度均小于预设的角度阈值。</p>
    <p>[0020]	其中，当采集用户的语音信息时，确定所采集的语音信息对应的参数值，具体为:</p>
    <p>[0021]	根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0022]	相应的，所述预设条件为:</p>
    <p>[0023]	预定时间段内用户语音信息对应频率均小于预设的频率阈值。</p>
    <p>[0024]	其中，当采集用户的面部信息和语音信息时，确定所采集的面部信息和语音信息对应的参数值，具体为:</p>
    <p>[0025]	根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；</p>
    <p>[0026]	根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0027]	分别为所获取的嘴角上扬角度和频率设置相应的权值；</p>
    <p>[0028]	利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；</p>
    <p>[0029]	相应的，所述预设条件为:</p>
    <p>[0030]	预定时间段内用户的微笑权值均小于预设的微笑阈值。</p>
    <p>[0031]	相应的，本发明实施例还提供一种电子设备，包括:</p>
    <p>[0032]	信息获取模块，用于在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语首/[目息；</p>
    <p>[0033]	参数值确定模块，用于确定所采集的面部信息和/或语音信息对应的参数值；</p>
    <p>[0034]	判断模块，用于判断预定时间段内所述参数值是否满足预设条件，并当满足所述预设条件时，触发模式开启模块；</p>
    <p>[0035]	模式开启模块，用于在用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。</p>
    <p>[0036]	其中，所述模式开启模块，具体用于:</p>
    <p>[0037]	开启用于提示用户进行微笑动作的微笑触发模式。</p>
    <p>[0038]	其中，所述电子设备还包括:</p>
    <p>[0039]	微笑处理模块，用于在开启所述微笑触发模式后，限定所述用户操作所述当前应用对象并提示所述用户进行符合所示微笑要求的微笑动作；</p>
    <p>[0040]	当所述用户的微笑动作满足所述微笑要求时，允许所述用户继续操作所述当前应用对象。</p>
    <p>[0041]	其中，所述微笑处理模块中微笑动作满足所述微笑要求的标准为:</p>
    <p>[0042]	所述用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</p>
    <p>[0043]	其中，所述信息获取模块，包括:</p>
    <p>[0044]	面部信息采集单元，用于采集所述用户的面部信息；</p>
    <p>[0045]	所述参数值确定模块，包括:</p>
    <p>[0046]	上扬角度确定单元，用于根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；</p>
    <p>[0047]	所述判断模块，包括:</p>
    <p>[0048]	角度判断单元，用于判断预定时间段内用户面部信息对应的嘴角上扬角度是否均小于预设的角度阈值，并在是的情况下，触发模式开启模块。[0049]	其中，所述信息获取模块，包括:</p>
    <p>[0050]	语音采集单元，用于采集所述用户的语音信息；</p>
    <p>[0051]	所述参数值确定模块,包括:</p>
    <p>[0052]	频率信息确定单元，用于根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0053]	所述判断模块，包括:</p>
    <p>[0054]	频率判断单元，用于判断预定时间段内用户语音信息对应频率是否均小于预设的频率阈值，并在是的情况下，触发模式开启模块。</p>
    <p>[0055]	其中，信息获取模块，包括:</p>
    <p>[0056]	面部和语音信息采集单元，用于采集所述用户的面部信息和语音信息；</p>
    <p>[0057]	参数值确定模块，包括:</p>
    <p>[0058]	微笑权值确定单元，用于根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；</p>
    <p>[0059]	根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0060]	分别为所获取的嘴角上扬角度和频率设置相应的权值；</p>
    <p>[0061]	利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；</p>
    <p>[0062]	判断模块，包括:</p>
    <p>[0063]	微笑权值判断单元，用于判断预定时间段内用户的微笑权值是否均小于预设的微笑阈值，并在是的情况下，触发模式开启模块。</p>
    <p>[0064]	本发明实施例所提供的技术方案，在用户操作电子设备过程中，采集用户的面部信息和/或语音信息，并根据所采集的信息确定相应的参数值，并在预定时间段内所采集的参数值满足预设条件时，开启该预设条件对应的第一模式，以此实现了根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。</p>
    <p>附图说明</p>
    <p>[0065]	为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作简单的介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动性的前提下，还可以根据这些附图获得其他的附图。</p>
    <p>[0066]	图1为本发明实施例所提供的一种应用对象操作方法的第一种流程图；</p>
    <p>[0067]	图2为本发明实施例所提供的一种应用对象操作方法的第二种流程图；</p>
    <p>[0068]	图3为本发明实施例所提供的一种应用对象操作方法的第三种流程图；</p>
    <p>[0069]	图4为本发明实施例所提供的一种应用对象操作方法的第四种流程图；</p>
    <p>[0070]	图5为本发明实施例所提供的一种应用对象操作方法的第五种流程图；</p>
    <p>[0071]	图6为本发明实施例所提供的一种电子设备的第一种结构图；</p>
    <p>[0072]	图7为本发明实施例所提供的一种电子设备的第二种结构图。</p>
    <p>具体实施方式</p>
    <p>[0073]	下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。</p>
    <p>[0074]	为了根据用户的面部信息和/或语音信息触发相应的模式，进而提示用户进行相应动作，本发明实施例提供一种应用对象操作方法及电子设备。</p>
    <p>[0075]	下面首先对本发明实施例所提供的一种应用对象操作方法进行介绍。</p>
    <p>[0076]	需要说明的是，本发明方案所适用的电子设备为具有面部信息和/或语音信息采集功能的设备，例如:该电子设备可以为具有面部信息和/或语音信息采集功能的笔记本、手机、IPAD等。可以理解的是，面部信息采集可以通过位于电子设备内部或与电子设备相连的摄像装置实现，而语音信息的采集可以通过位于电子设备内部或与电子设备相连的录音装置实现，当然并不局限于此。</p>
    <p>[0077]	&#8212;种应用对象操作方法，如图1所示，可以包括:</p>
    <p>[0078]	S101，在用户操作一电子设备的过程中，采集该用户的面部信息和/或语音信息；</p>
    <p>[0079]	当需要根据用户的面部信息和/或语音信息触发相应的模式，进而提示用户进行相应动作时，则需要在用户操作一电子设备时，采集该用户的面部信息和/或语音信息，以根据所采集的用户信息进行后续的处理步骤。当然，可以通过实时或定时采集的方式进行用户信息的采集。可以理解的是，在实际应用中，可以根据实际应用场景，仅仅采集该用户的面部信息，或者，仅仅采集该用户的语音信息，或者，同时采集该用户的面部信息和语音信息，这些都是合理的。</p>
    <p>[0080]	S102，确定所采集的面部信息和/或语音信息对应的参数值；</p>
    <p>[0081]	其中，当采集到该用户的面部信息和/或语音信息后，则对所采集的该用户信息进行特定的处理，以获得可以进行比较分析的参数值，以进行后续的处理。例如:对面部信息的特定处理可以为:根据人员脸部分析算法，确定出面部信息对应的嘴角上扬角度；而对语音信息的特定处理可以为:根据语音识别算法，确定出所采集的语音信息对应的声音频率等，这都是合理的。</p>
    <p>[0082]	可以理解的是，确定所采集的面部信息和/或语音信息对应的参数值，可以通过实时分析的方式，也可以对一段时间内所采集的用户信息进行统一分析，以获得用户信息对应的参数值。</p>
    <p>[0083]	S103，判断预定时间段内的参数值是否满足预设条件，如果是，则执行步骤S104，否则，不作处理；</p>
    <p>[0084]	当确定出所采集的面部信息和/或语音信息对应的参数值后，则可以判断预定时间段内的参数值是否满足预设的条件，并在满足预设条件的情况下，执行步骤S104，进行后续的相应预设条件的第一模式的开启。</p>
    <p>[0085]	可以理解的是，该预定时间可以根据实际应用场景进行设定，例如:其可以为60min或90min。同时，预设条件为根据所采集的用户信息进行设定的，也就是，当采集面部信息时，该条件与面部信息对应的参数相关；当采集语音信息时，该条件与语音信息对应的参数相关；而当同时采集面部信息和语音信息时，则该条件与面部信息和语音信息都相关。</p>
    <p>[0086]	S104，在该用户操作当前应用对象的过程中，开启该预设条件对应的第一模式。</p>
    <p>[0087]	当预定时间段内的参数值满足预设的条件时，则需要在用户操作当前应用对象的过程中，开启与该预设条件对应的第一模式，以指示用户进行相应的动作处理。当然，该第一模式可以根据实际应用需求进行设定，例如:当需要提示用户进行微笑动作时，该第一模式则为微笑触发模式，通过开启该微笑触发模式，可以提示用户进行相应的微笑动作，达到有益身心的目的；或者，当需要提示用户进行休息时，该第一模式则为休息提示模式，通过开启该模式，可以提示用户进行休息。</p>
    <p>[0088]	本实施例中，在用户操作一电子设备的过程中，采集用户的面部信息和/或语音信息，并根据所采集的信息确定相应的参数值，并在预定时间段内所采集的参数值满足预设条件时，开启该预设条件对应的第一模式，以此实现了根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。</p>
    <p>[0089]	下面以通过采集用户的面部信息实现对用户的微笑提示为例对本发明所提供的应用对象操作方法进行说明。</p>
    <p>[0090]	需要说明的是，本发明方案所适用的电子设备为具有面部信息采集功能的设备，例如:该电子设备可以为具有面部信息采集功能的笔记本、手机、IPAD等。可以理解的是，面部信息的采集可以通过位于电子设备内部的或与电子设备相连的摄像装置实现，当然并不局限于此。</p>
    <p>[0091]	一种应用对象操作方法，如图2所示，可以包括:</p>
    <p>[0092]	S201，在用户操作一电子设备的过程中，采集该用户的面部信息；</p>
    <p>[0093]	由于用户嘴角上扬角度通常作为是否微笑动作的判断标准，也就是，当用户的嘴角上扬角度达到一定角度值时，则可以认为该用户正在进行微笑动作；而当该用户嘴角上扬角度小于一定角度值时，则可以认为用户未进行微笑动作，此时，需要进行微笑提示。</p>
    <p>[0094]	因此，可以采集该用户的面部信息，以根据所采集的面部信息进行是否进行微笑提示的判断，并根据判断结果进行相应的处理。</p>
    <p>[0095]	S202，根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；</p>
    <p>[0096]当采集到该用户的面部信息后，则利用人员脸部分析算法，确定出所采集的面部信息对应的嘴角上扬角度，以进行后续的微笑判断。</p>
    <p>[0097]	可以理解的是，确定所采集用户面部信息对应嘴角上扬角度，可以通过实时分析方式，也可以对一段时间内采集的面部信息进行统一分析，以确定出面部信息对应的嘴角上扬角度。</p>
    <p>[0098]	S203，判断预定时间段内用户面部信息对应的嘴角上扬角度是否均小于预设的角度阈值，如果是，则执行步骤S204 ;否则，不作处理；</p>
    <p>[0099]	其中，预先根据当前用户的面部微笑特征确定出一角度阈值。当用户的嘴角上扬角度不小于该角度阈值时，表明该用户正在进行微笑；相反的，当用户的嘴角上扬角度小于该角度阈值时，表明用户并未微笑。</p>
    <p>[0100]	因此，当预定时间段内用户面部信息对应的嘴角上扬角度都小于该角度阈值时，此时，表明用户在该时间段内未进行过微笑动作，此时，需要进行后续的微笑提示。</p>
    <p>[0101]	可以理解的是，预定时间段可以根据实际应用情况进行设定，同样的，角度阈值可以根据用户的面部微笑特征进行设定，这些都是合理的。</p>
    <p>[0102]	S204，在该用户操作当前应用对象的过程中，开启用于提示该用户进行微笑动作的微笑触发模式。</p>
    <p>[0103]	当判断出用户在预定时间段内嘴角上扬角度都小于预设的角度阈值时，则需要在用户操作当前应用对象的过程中，开启一用于提示用户进行微笑动作的微笑触发模式，以提示用户已经长时间未进行微笑动作。</p>
    <p>[0104]	本实施例中，采集该用户的面部信息，并根据面部信息中嘴角上扬角度确定是否需要开启微笑触发模式，当在特定时间段用户的嘴角上扬角度都小于角度阈值时，则开启微笑触发模式，以提示用户进行微笑动作，以此实现了根据用户的面部信息开启微笑触发模式，进而提示用户进行微笑动作的目的。</p>
    <p>[0105]	更进一步的，为了保证用户根据微笑触发模式的指示进行相应的微笑，本发明实施例还提供一种应用对象操作方法。</p>
    <p>[0106]	需要说明的是，本发明方案所适用的电子设备为具有面部信息采集功能的设备，例如:该电子设备可以为具有面部信息采集功能的笔记本、手机、IPAD等。可以理解的是，面部信息的采集可以通过位于电子设备内部或与电子设备相连的摄像装置实现，当然并不局限于此。</p>
    <p>[0107]	一种应用对象操作方法，如图3所示，可以包括:</p>
    <p>[0108]	S301，在用户操作一电子设备的过程中，采集该用户的面部信息；</p>
    <p>[0109]	S302，根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；</p>
    <p>[0110]	S303，判断预定时间段内用户面部信息对应的嘴角上扬角度是否均小于预设的角度阈值，如果是，则执行步骤S304 ;否则，不作处理；</p>
    <p>[0111]	S304，在该用户操作当前应用对象的过程中，开启用于提示该用户进行微笑动作的微笑触发模式；</p>
    <p>[0112]	本实施例中，步骤S301&#12316;步骤S304与上述实施例步骤S201&#12316;步骤S204相似，在此不再赘述。</p>
    <p>[0113]	S305，在开启该微笑触发模式后，限定该用户操作当前应用对象并提示该用户进行符合所示微笑要求的微笑动作；</p>
    <p>[0114]	本实施例中，在开启该微笑触发模式后，为了保证用户按照微笑触发模式提示进行微笑动作，则可以限定该用户操作当前的应用对象，并向该用户发出特定微笑要求，以指示用户进行相应的微笑动作。</p>
    <p>[0115]	S306，判断该用户的微笑动作是否满足该微笑要求，如果是，执行步骤S307 ;否贝IJ，不作处理；</p>
    <p>[0116]	其中，用户的微笑动作满足该微笑要求，具体可以为:</p>
    <p>[0117]	该用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</p>
    <p>[0118]	S307，允许该用户继续操作当前应用对象。</p>
    <p>[0119]	当向该用户进行微笑要求时，可以通过采集用户的面部信息，利用人员脸部分析算法，确定出该用户的嘴角上扬角度，并在所采集的面部信息中嘴角上扬角度达到所示微笑要求中的嘴角上扬角度时，允许该用户继续操作当前应用对象。</p>
    <p>[0120]	本实施例中，采集该用户的面部信息，并根据面部信息中嘴角上扬角度确定是否需要开启微笑触发模式，当在特定时间段用户的嘴角上扬角度都小于角度阈值时，则开启微笑触发模式，并限定用户操作当前应用对象，同时向用户发出特定的微笑要求，并在用户进行相应微笑要求的微笑动作后，允许该用户继续操作当前应用对象，以此实现了根据用户的面部信息开启微笑触发模式，进而提示用户进行微笑动作，并保证了用户进行相应的微笑动作的目的。</p>
    <p>[0121]	下面以通过采集用户的语音信息实现对用户的微笑提示为例对本发明所提供的应用对象操作方法进行说明。</p>
    <p>[0122]	需要说明的是，本发明方案所适用的电子设备为具有语音信息采集功能的设备，例如:该电子设备可以为具有语音信息采集功能的笔记本、手机、IPAD等。可以理解的是，语音信息的采集可以通过位于电子设备内部或与电子设备相连的录音装置实现，当然并不局限于此。</p>
    <p>[0123]	一种应用对象操作方法，如图4所示，可以包括:</p>
    <p>[0124]	S401，在用户操作一电子设备的过程中，采集该用户的语音信息；</p>
    <p>[0125]	由于在用户心情较好时，其说话的语调较为欢快，也就是，其语音频率较高，因此，可以通过用户的语音信息表征用户的心情。而当用户心情较好时，其微笑的频率将会大大提高，此时，则无需进行微笑提示；当用户心情较差时，其微笑频率将会大大降低，此时，则有必要进行微笑提示，以提示用户进行微笑动作。</p>
    <p>[0126]	因此，当需要为用户提供微笑提示的功能时，可以采集该用户的语音信息，以根据用户的语音信息进行是否需要微笑提示的判断，并根据判断结果进行相应的处理。</p>
    <p>[0127]	S402，根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0128]	当采集到该用户的语音信息后，则利用语音识别算法，确定出所采集的语音信息对应的频率，以进行后续的微笑判断。</p>
    <p>[0129]	可以理解的是，确定所采集用户语音信息对应频率，可以通过实时分析方式，也可以对一段时间内采集的语音信息进行统一分析，以确定出语音信息对应的频率值。</p>
    <p>[0130]	S403，判断预定时间段内该用户语音信息对应频率是否均小于预设的频率阈值，如果是，则执行步骤S404 ;否则，不作处理；</p>
    <p>[0131]	其中，预先根据当前用户的语音特征确定出一频率阈值。当该用户语音信息对应的频率值不小于该频率阈值时，表明用户语调较为欢快，进一步表示用户心情较好，此时，微笑频率将会较高；相反的，当该用户语音信息对应的频率值小于该频率阈值时，微笑频率将会较低。</p>
    <p>[0132]	因此，当预定时间段内该用户语音信息对应的频率都小于该频率阈值时，此时，表明用户在该时间段内的微笑频率较低，此时，需要进行后续的微笑提示。</p>
    <p>[0133]	可以理解的是，预定时间段可以根据实际应用情况进行设定，同样的，频率阈值可以根据用户的语音特征进行设定，这些都是合理的。</p>
    <p>[0134]	S404，在该用户操作当前应用对象的过程中，开启用于提示该用户进行微笑动作的微笑触发模式。</p>
    <p>[0135]	当判断出该用户在预定时间段内语音频率都小于预设的频率阈值时，则需要在用户操作当前应用对象的过程中，开启一用于提示用户进行微笑动作的微笑触发模式，以提示用户已经长时间未进行微笑动作。</p>
    <p>[0136]	本实施例中，采集用户的语音信息，并根据语音信息中频率信息确定是否需要开启微笑触发模式，当在特定时间段语音信息频率值都小于频率阈值时，则开启微笑触发模式，以提示用户进行微笑动作，以此实现了根据用户的语音信息开启微笑触发模式，进而提示用户进行微笑动作的目的。</p>
    <p>[0137]	更进一步的，在根据用户的语音信息开启微笑触发模式后，为了保证用户根据微笑触发模式的指示进行相应的微笑，则可以限定该用户操作当前应用对象，并向该用户发出特定微笑要求，以指示用户进行相应的微笑动作。当向该用户进行微笑要求时，可以通过采集用户的面部信息，利用人员脸部分析算法，确定出该用户的嘴角上扬角度，并在所采集的面部信息中嘴角上扬角度达到所示微笑要求中的嘴角上扬角度时，允许该用户继续操作当前应用对象，以此实现了根据用户的语音信息开启微笑触发模式，并保证了用户进行相应微笑动作的目的。</p>
    <p>[0138]	下面以通过采集用户的面部信息和语音信息实现对用户的微笑提示为例对本发明所提供的应用对象操作方法进行说明。</p>
    <p>[0139]	需要说明的是，本发明方案所适用的电子设备为具有面部信息和语音信息采集功能的设备，例如:该电子设备可以为具有面部信息和语音信息采集功能的笔记本、手机、IPAD等。可以理解的是，面部信息采集可以通过位于电子设备内部或与电子设备相连的摄像头实现，而语音信息的采集可以通过位于电子设备内部或与电子设备相连的录音装置实现，当然并不局限于此。</p>
    <p>[0140]	一种应用对象操作方法，如图5所示，可以包括:</p>
    <p>[0141]	S501，在用户操作一电子设备的过程中，采集用户的面部信息和语音信息；</p>
    <p>[0142]	由于通过用户的面部信息和语音信息均可以判断出用户是否进行微笑动作，所以，为了提高微笑动作判断的准确性，可以同时采集该用户的面部信息和语音信息，以进行后续的微笑判断。</p>
    <p>[0143]	S502，根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；</p>
    <p>[0144]	S503，根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0145]	可以理解的是，步骤S502和步骤S503并不局限于本实施例所述的顺序，在实际应用中，也可以先执行步骤S503后执行步骤S502，或者同时执行步骤S502和步骤S503，这都是合理的。</p>
    <p>[0146]	S504，分别为所获取的嘴角上扬角度和频率设置相应的权值；</p>
    <p>[0147]	S505，利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；</p>
    <p>[0148]	为了对面部信息对应的嘴角上扬角度和语音信息对应的频率进行运算操作，因此需要为该频率和嘴角上扬角度设置相应的权值，并对频率权值和嘴角上扬角度权值进行特定运算，以确定该用户的微笑权值。</p>
    <p>[0149]	在实际应用中，对于不同的应用场景,可以为频率和嘴角上扬角度设置不同的权值；同样，可以通过不同的运算方式，确定出用户的微笑权值。</p>
    <p>[0150]	S506，判断预定时间段内用户的微笑权值是否均小于预设的微笑阈值，如果是，则执行步骤S507 ;否则，不作处理；</p>
    <p>[0151]	其中，预先设置了一微笑阈值。当用户的微笑权值不小于该微笑阈值时，则表明该用户正在微笑；相反的，当用户的微笑权值小于该微笑阈值时，表明用户并未微笑。</p>
    <p>[0152]	因此，当预定时间段内用户对应的微笑权值都小于该微笑阈值时，此时，表明用户在该时间段内未进行过微笑动作，此时，需要进行后续的微笑提示。</p>
    <p>[0153]	可以理解的是，预定时间段可以根据实际应用情况进行设定，同样的，微笑阈值可以根据用户的面部和语音特征进行设定，这些都是合理的。</p>
    <p>[0154]	S507，在该用户操作当前应用对象的过程中，开启用于提示用户进行微笑动作的微笑触发模式。</p>
    <p>[0155]	当判断出用户在预定时间段内微笑权值都小于该微笑阈值时，则需要在用户操作当前应用对象的过程中，开启一用于提示用户进行微笑动作的微笑触发模式，以提示用户已经长时间未进行微笑动作。</p>
    <p>[0156]	本实施例中，采集该用户的面部信息和语音信息，并根据面部信息和语音信息对应的微笑权值确定是否需要开启微笑触发模式，当在特定时间段用户的微笑权值都小于微笑阈值时，则开启微笑触发模式，以提示用户进行微笑动作，以此实现了根据用户的面部信息和语音信息开启微笑触发模式，进而提示用户进行微笑动作的目的。</p>
    <p>[0157]	同样的，更进一步的，在根据用户的面部信息和语音信息开启微笑触发模式后，为了保证用户根据微笑触发模式的指示进行相应的微笑，则可以限定该用户操作当前应用对象，并向该用户发出特定微笑要求，以指示该用户进行相应的微笑动作。当向该用户提出微笑要求时，可以通过采集用户的面部信息，利用人员脸部分析算法，确定出该用户的嘴角上扬角度，并在所采集的面部信息中嘴角上扬角度达到所示微笑要求中的嘴角上扬角度时，允许该用户继续操作当前应用对象，以此实现了根据用户的面部信息和语音信息开启微笑触发模式，并保证了用户进行相应的微笑动作的目的。</p>
    <p>[0158]	通过以上的方法实施例的描述，所属领域的技术人员可以清楚地了解到本发明可借助软件加必需的通用硬件平台的方式来实现，当然也可以通过硬件，但很多情况下前者是更佳的实施方式。基于这样的理解，本发明的技术方案本质上或者说对现有技术做出贡献的部分可以以软件产品的形式体现出来，该计算机软件产品存储在一个存储介质中，包括若干指令用以使得一台计算机 设备(可以是个人计算机，服务器，或者网络设备等)执行本发明各个实施例所述方法的全部或部分步骤。而前述的存储介质包括:只读存储器(ROM)、随机存取存储器(RAM)、磁碟或者光盘等各种可以存储程序代码的介质。</p>
    <p>[0159]	相应于上面的方法实施例，本发明实施例还提供一种电子设备，如图6所示，可以包括:</p>
    <p>[0160]	信息获取模块110，用于在用户操作一电子设备的过程中，采集所述用户的面部信息和/或语首&#943;目息；</p>
    <p>[0161]	参数值确定模块120，用于确定所采集的面部信息和/或语音信息对应的参数值；</p>
    <p>[0162]	判断模块130，用于判断预定时间段内所述参数值是否满足预设条件，并当满足所述预设条件时，触发模式开启模块；</p>
    <p>[0163]	模式开启模块140，用于在所述用户操作当前应用对象的过程中，开启所述预设条件对应的第一模式。</p>
    <p>[0164]	本发明实施例所提供的电子设备，采集用户的面部信息和/或语音信息，并根据所采集的信息确定相应的参数值，并在预定时间段内所采集的参数值满足预设条件时，开启该预设条件对应的第一模式，以此实现了根据用户的面部信息和/或语音信息触发相应模式，进而指示用户进行相应动作的目的。[0165]	其中，模式开启模块140，具体用于:</p>
    <p>[0166]	开启用于提示用户进行微笑动作的微笑触发模式。</p>
    <p>[0167]	更进一步的，如图7所示，所述电子设备还可以包括:</p>
    <p>[0168]	微笑处理模块150，用于在开启所述微笑触发模式后，限定所述用户操作所述当前应用对象并提示所述用户进行符合所示微笑要求的微笑动作；</p>
    <p>[0169]	当所述用户的微笑动作满足所述微笑要求时，允许所述用户继续操作所述当前应用对象。</p>
    <p>[0170]	其中，所述微笑处理模块中微笑动作满足所述微笑要求的标准为:</p>
    <p>[0171]	所述用户的面部信息中嘴角上扬角度达到所示微笑要求中嘴角上扬角度。</p>
    <p>[0172]	其中，信息获取模块110，可以包括:</p>
    <p>[0173]	面部信息采集单元，用于采集所述用户的面部信息；</p>
    <p>[0174]	参数值确定模块120，可以包括:</p>
    <p>[0175]	上扬角度确定单元，用于根据人员脸部分析算法，获取所采集的用户面部信息对应的嘴角上扬角度；</p>
    <p>[0176]	判断模块130，可以包括:</p>
    <p>[0177]	角度判断单元，用于判断预定时间段内用户面部信息对应的嘴角上扬角度是否均小于预设的角度阈值，并在是的情况下，触发模式开启模块。</p>
    <p>[0178]	其中，信息获取模块110，可以包括:</p>
    <p>[0179]	语音采集单元，用于采集所述用户的语音信息；</p>
    <p>[0180]	参数值确定模块120，可以包括:</p>
    <p>[0181]	频率信息确定单元，用于根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0182]	判断模块130，可以包括:</p>
    <p>[0183]	频率判断单元，用于判断预定时间段内用户语音信息对应频率是否均小于预设的频率阈值，并在是的情况下，触发模式开启模块。</p>
    <p>[0184]	其中，信息获取模块110，可以包括:</p>
    <p>[0185]	面部和语音信息采集单元，用于采集所述用户的面部信息和语音信息；</p>
    <p>[0186]	参数值确定模块120，可以包括:</p>
    <p>[0187]	微笑权值确定单元，用于根据人员脸部分析算法，获取所采集的面部信息对应的嘴角上扬角度；</p>
    <p>[0188]	根据语音识别算法，获取所采集的用户语音信息对应的频率；</p>
    <p>[0189]	分别为所获取的嘴角上扬角度和频率设置相应的权值；</p>
    <p>[0190]	利用嘴角上扬角度权值和频率权值，确定用户的微笑权值；</p>
    <p>[0191]	判断模块130，可以包括:</p>
    <p>[0192]	微笑权值判断单元，用于判断预定时间段内用户的微笑权值是否均小于预设的微笑阈值，并在是的情况下，触发模式开启模块。</p>
    <p>[0193]	对于装置或系统实施例而言，由于其基本相应于方法实施例，所以相关之处参见方法实施例的部分说明即可。以上所描述的装置或系统实施例仅仅是示意性的，其中所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部模块来实现本实施例方案的目的。本领域普通技术人员在不付出创造性劳动的情况下，即可以理解并实施。</p>
    <p>[0194]	在本发明所提供的几个实施例中，应该理解到，所揭露的系统，装置和方法，在没有超过本申请的精神和范围内，可以通过其他的方式实现。当前的实施例只是一种示范性的例子，不应该作为限制，所给出的具体内容不应该限制本申请的目的。例如，所述单元或子单元的划分，仅仅为一种逻辑功能划分，实际实现时可以有另外的划分方式，例如多个单元或多个子单元结合一起。另外，多个单元可以或组件可以结合或者可以集成到另一个系统，或一些特征可以忽略，或不执行。</p>
    <p>[0195]	另外，所描述系统，装置和方法以及不同实施例的示意图，在不超出本申请的范围内，可以与其它系统，模块，技术或方法结合或集成。另一点，所显示或讨论的相互之间的耦合或直接耦合或通信连接可以是通过一些接口，装置或单元的间接耦合或通信连接，可以是电性，机械或其它的形式。</p>
    <p>[0196]	以上所述仅是本发明的具体实施方式，应当指出，对于本技术领域的普通技术人员来说，在不脱离本发明原理的前提下，还可以做出若干改进和润饰，这些改进和润饰也应视为本发明的保护范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1896918A?cl=zh">CN1896918A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年7月15日</td><td class="patent-data-table-td patent-date-value">2007年1月17日</td><td class="patent-data-table-td ">英华达(上海)电子有限公司</td><td class="patent-data-table-td ">手持设备上使用面部表情控制输入的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101370195A?cl=zh">CN101370195A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年8月16日</td><td class="patent-data-table-td patent-date-value">2009年2月18日</td><td class="patent-data-table-td ">英华达(上海)电子有限公司</td><td class="patent-data-table-td ">移动终端中实现情绪调节的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102103617A?cl=zh">CN102103617A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年12月22日</td><td class="patent-data-table-td patent-date-value">2011年6月22日</td><td class="patent-data-table-td ">华为终端有限公司</td><td class="patent-data-table-td ">获取表情含义的方法和装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1791053A1?cl=zh">EP1791053A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年11月7日</td><td class="patent-data-table-td patent-date-value">2007年5月30日</td><td class="patent-data-table-td ">Sap Ag</td><td class="patent-data-table-td ">Systems and methods of processing annotations and multimodal user inputs</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015100923A1?cl=zh">WO2015100923A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年5月22日</td><td class="patent-data-table-td patent-date-value">2015年7月9日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">用户信息获取方法及移动终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=p6XDCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003048700">G06F3/0487</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年7月3日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年7月31日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/cc78dc686be95e898905/CN103186326A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%BA%94%E7%94%A8%E5%AF%B9%E8%B1%A1%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95%E5%8F%8A%E7%94%B5%E5%AD%90.pdf?id=p6XDCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3-ZiF63m8GqnmJQcWfRmvVpWHd6Q"},"sample_url":"https://www.google.com/patents/reader?id=p6XDCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>