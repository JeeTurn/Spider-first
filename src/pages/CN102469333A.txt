<!DOCTYPE html><html><head><title>专利 CN102469333A - 信息处理设备、立体显示方法和程序 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="信息处理设备、立体显示方法和程序"><meta name="DC.contributor" content="奥村泰史" scheme="inventor"><meta name="DC.contributor" content="野田卓郎" scheme="inventor"><meta name="DC.contributor" content="索尼公司" scheme="assignee"><meta name="DC.date" content="2011-11-4" scheme="dateSubmitted"><meta name="DC.description" content="本公开提供了信息处理设备、立体显示方法和程序。一种设备和方法提供了用于处理信息的逻辑。在一个实现中，设备可以包括确定单元，该确定单元被配置为确定被布置于该确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置。该第一空间位置可以是在深度方向上相对于确定单元表面而确定的。该设备还可以包括控制单元，该控制单元被配置为至少基于第一空间位置来限定立体图像的第一立体图像尺寸，并生成信号来以第一立体图像尺寸显示该立体图像。"><meta name="DC.date" content="2012-5-23"><meta name="DC.relation" content="CN:101042624:A" scheme="references"><meta name="DC.relation" content="CN:101640762:A" scheme="references"><meta name="DC.relation" content="CN:1774937:A" scheme="references"><meta name="DC.relation" content="CN:1838778:A" scheme="references"><meta name="DC.relation" content="US:20100095206:A1" scheme="references"><meta name="DC.relation" content="US:5574836" scheme="references"><meta name="DC.relation" content="US:6175379" scheme="references"><meta name="DC.relation" content="WO:2010103195:A2" scheme="references"><meta name="citation_patent_publication_number" content="CN:102469333:A"><meta name="citation_patent_application_number" content="CN:201110350964"><link rel="canonical" href="https://www.google.com/patents/CN102469333A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102469333A?cl=zh"/><meta name="title" content="专利 CN102469333A - 信息处理设备、立体显示方法和程序"/><meta name="description" content="本公开提供了信息处理设备、立体显示方法和程序。一种设备和方法提供了用于处理信息的逻辑。在一个实现中，设备可以包括确定单元，该确定单元被配置为确定被布置于该确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置。该第一空间位置可以是在深度方向上相对于确定单元表面而确定的。该设备还可以包括控制单元，该控制单元被配置为至少基于第一空间位置来限定立体图像的第一立体图像尺寸，并生成信号来以第一立体图像尺寸显示该立体图像。"/><meta property="og:title" content="专利 CN102469333A - 信息处理设备、立体显示方法和程序"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102469333A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102469333A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102469333A&amp;usg=AFQjCNHg6UBiMg2JbvBCrCfP15AlpZTIMw" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/e719729d751cba6c755a/CN102469333A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/e719729d751cba6c755a/CN102469333A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102469333A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102469333A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102469333A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102469333B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102469333A?cl=zh" style="display:none"><span itemprop="description">本公开提供了信息处理设备、立体显示方法和程序。一种设备和方法提供了用于处理信息的逻辑。在一个实现中，设备可以包括确定单元，该确定单元被配置为确定被布置于该确定单元表面的阈值距离之内的操作工具的一部分的...</span><span itemprop="url">https://www.google.com/patents/CN102469333A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102469333A - 信息处理设备、立体显示方法和程序</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102469333A - 信息处理设备、立体显示方法和程序" title="专利 CN102469333A - 信息处理设备、立体显示方法和程序"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102469333 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110350964</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年5月23日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年11月4日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年11月11日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2755689A1?hl=zh-CN&amp;cl=zh">CA2755689A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102469333B?hl=zh-CN&amp;cl=zh">CN102469333B</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2453660A1?hl=zh-CN&amp;cl=zh">EP2453660A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2453660B1?hl=zh-CN&amp;cl=zh">EP2453660B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8988500?hl=zh-CN&amp;cl=zh">US8988500</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120120064?hl=zh-CN&amp;cl=zh">US20120120064</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110350964.5, </span><span class="patent-bibdata-value">CN 102469333 A, </span><span class="patent-bibdata-value">CN 102469333A, </span><span class="patent-bibdata-value">CN 201110350964, </span><span class="patent-bibdata-value">CN-A-102469333, </span><span class="patent-bibdata-value">CN102469333 A, </span><span class="patent-bibdata-value">CN102469333A, </span><span class="patent-bibdata-value">CN201110350964, </span><span class="patent-bibdata-value">CN201110350964.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%A5%A5%E6%9D%91%E6%B3%B0%E5%8F%B2%22">奥村泰史</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%87%8E%E7%94%B0%E5%8D%93%E9%83%8E%22">野田卓郎</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E7%B4%A2%E5%B0%BC%E5%85%AC%E5%8F%B8%22">索尼公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102469333A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102469333A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102469333A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (8),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (9),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110350964&amp;usg=AFQjCNFP-11DORg90Jj6qHSNsTKhsh1h8g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102469333A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGd3KWD8Q9y0-efZnyW7uqnowCZyw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT112954079" lang="ZH" load-source="patent-office">信息处理设备、立体显示方法和程序</invention-title>
      </span><br><span class="patent-number">CN 102469333 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA96631471" lang="ZH" load-source="patent-office">
    <div class="abstract">本公开提供了信息处理设备、立体显示方法和程序。一种设备和方法提供了用于处理信息的逻辑。在一个实现中，设备可以包括确定单元，该确定单元被配置为确定被布置于该确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置。该第一空间位置可以是在深度方向上相对于确定单元表面而确定的。该设备还可以包括控制单元，该控制单元被配置为至少基于第一空间位置来限定立体图像的第一立体图像尺寸，并生成信号来以第一立体图像尺寸显示该立体图像。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(29)</span></span></div><div class="patent-text"><div mxw-id="PCLM42317624" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种信息处理设备，包括：确定单元，被配置为确定被布置于确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的； 以及控制单元，被配置为：至少基于所述第一空间位置来限定立体图像的第一立体图像尺寸；以及生成信号来以所述第一立体图像尺寸显示所述立体图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的信息处理设备，其中，所述控制单元还被配置为确定所述操作工具的该部分的所述第一空间位置与所述确定单元表面之间在深度方向上的位移。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的信息处理设备，其中，所述控制单元还被配置为至少基于所确定的位移来限定所述第一立体图像尺寸。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的信息处理设备，其中，所述第一立体图像尺寸对应于与所述第一空间位置相关联的预定尺寸。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的信息处理设备，其中，所述确定单元还被配置为确定被布置于所述阈值距离之内的所述操作工具的该部分的第二空间位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的信息处理设备，其中，响应于所述操作工具在深度方向上的运动来确定所述第二空间位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求5所述的信息处理设备，其中，所述控制单元还被配置为确定所述第二空间位置与所述确定单元表面之间在深度方向上的位移。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的信息处理设备，其中，所述控制单元还被配置为至少基于所确定的位移来限定立体图像的第二立体图像尺寸。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的信息处理设备，其中，所述控制单元还被配置为生成信号来以所述第二立体图像尺寸显示所述立体图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的信息处理设备，其中，所述确定单元还被配置为：确定所述操作工具的该部分的第三空间位置；以及确定所述第三空间位置是否落入所述确定单元表面的所述阈值距离之内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求10所述的信息处理设备，其中，所述控制单元被配置为当所述第三空间位置未落入所述确定单元表面的所述阈值距离之内时，生成信号来以所述第一立体图像尺寸显示所述立体图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求1所述的信息处理设备，其中，所述控制单元还被配置为生成信号来在第一显示位置显示所述立体图像，所述第一显示位置处于所述第一空间位置的预定距离之内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的信息处理设备，其中：所述确定单元还被配置为确定被布置于所述阈值距离内的所述操作工具的该部分的第二空间位置；以及所述控制单元还被配置为：至少基于所述第一显示位置和所述第二空间位置来确定所述立体图像的第二显示位置；以及生成连续信号来在所述第二显示位置显示所述立体图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求1所述的信息处理设备，其中，所述控制单元还被配置为： 基于所述第一空间位置来识别与所述立体图像相关联的可执行功能；以及生成信号来执行所述可执行功能。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求1所述的信息处理设备，其中，所述确定单元还被配置为检测用户的手势。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求15所述的信息处理设备，其中，所述控制单元还被配置为： 至少基于检测到的手势来识别与所述立体图像相关联的可执行功能；以及生成信号来执行所述可执行功能。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求1所述的信息处理设备，还包括显示单元，所述显示单元被配置为响应于所述信号来以所述第一立体图像尺寸显示所述立体图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求17所述的信息处理设备，其中： 所述显示单元包括显示表面；以及所述显示单元显示表面的至少一部分与所述确定单元表面相一致。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.根据权利要求1所述的信息处理设备，还包括： 立体显示单元，被配置为立体显示多个立体图像；以及其中，被所述控制单元确定所述第一立体图像尺寸的所述立体图像是所述多个立体图像当中显示于所述操作工具的该部分的所述第一空间位置的深度方向上的立体图像，以及其中，所述控制单元还被配置为进行控制，使得所述立体图像的位置靠近于所述操作工具的该部分的所述第一空间位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.根据权利要求19所述的信息处理设备，其中，所述控制单元进行控制，使得作为控制目标的所述立体图像在深度方向上的位置靠近于所述操作工具的该部分的所述第一空间位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21.根据权利要求20所述的信息处理设备，其中，所述控制单元进行控制，使得随着所述确定单元表面与所述操作工具的该部分的所述第一空间位置之间的距离变短，作为控制目标的所述立体图像在深度方向上的位置更靠近于所述确定单元表面。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22.根据权利要求1所述的信息处理设备，其中：所述确定单元还被配置为确定所述确定单元表面上的、与所述操作工具的第二部分和所述确定单元表面之间的接触相对应的位置；以及所述信息处理设备还包括：限定单元，被配置为限定第一立体图像的第一显示位置； 生成单元，被配置为响应于所述接触而生成第二立体图像；以及其中，所述控制单元还被配置为，生成信号来在所述第一显示位置显示所述第一立体图像并在第二显示位置显示所述第二立体图像，所述第一显示位置和所述第二显示位置在接触位置的预定距离内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23.根据权利要求22所述的信息处理设备，其中，所述预定距离是相对于与深度方向垂直的至少一个方向来限定的。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24.根据权利要求22所述的信息处理设备，其中，所述生成单元进一步被配置为基于所述操作工具的该第二部分和所述确定单元表面之间的所述接触来生成电子内容。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25.根据权利要求23所述的信息处理设备，其中，所述电子内容包括从所述操作工具的用户接收的书写或绘制中的至少一个。</div>
    </div>
    </div> <div class="claim"> <div num="26" class="claim">
      <div class="claim-text">26.	一种计算机实现的方法，包括：利用处理器，确定被布置于确定单元的表面的阈值距离内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于确定单元表面而确定的；利用该处理器，至少基于所述第一空间位置来限定立体图像的第一立体图像尺寸；以及利用该处理器，生成信号来以所述第一立体图像尺寸显示所述立体图像。</div>
    </div>
    </div> <div class="claim"> <div num="27" class="claim">
      <div class="claim-text">27.	&#8212;种立体显示方法，包括： 立体显示多个立体图像；确定被布置于确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的；至少基于所述第一空间位置来限定目标立体图像的第一立体图像尺寸； 生成信号来以所述第一立体图像尺寸显示所述目标立体图像；以及其中，将所述多个立体图像当中显示于所述操作工具的该部分的所述第一空间位置的深度方向上的立体图像作为所述目标立体图像，并且进行控制，使得所述目标立体图像的位置靠近于所述操作工具的该部分的所述第一空间位置。</div>
    </div>
    </div> <div class="claim"> <div num="28" class="claim">
      <div class="claim-text">28.	一种用于显示图像的计算机实现的方法，包括：利用处理器，确定确定单元表面上的、与操作工具的一部分和所述确定单元表面之间的接触相对应的位置；利用该处理器，限定第一立体图像的第一显示位置； 利用该处理器，响应于所述接触而生成第二立体图像；以及利用该处理器，生成信号来在所述第一显示位置显示所述第一立体图像并在第二显示位置显示所述第二立体图像，所述第一显示位置和所述第二显示位置在接触位置的预定距离内。</div>
    </div>
    </div> <div class="claim"> <div num="29" class="claim">
      <div class="claim-text">29.	一种用于存储指令的有形、非瞬时计算机可读介质，所述指令在被处理器执行时使得该处理器执行一种方法，所述方法包括：确定被布置于确定单元的表面的阈值距离内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于确定单元表面来确定的；至少基于所述第一空间位置来限定立体图像的第一立体图像尺寸；以及生成信号来以所述第一立体图像尺寸显示所述立体图像。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES47145207" lang="ZH" load-source="patent-office" class="description">
    <p>信息处理设备、立体显示方法和程序</p>
    <p>[0001]	相关申请的交叉引用</p>
    <p>[0002]	本申请基于2010年11月11日提交的日本专利申请JP 2010-253151并且要求享受该申请的优先权权益，该申请的全部内容通过引用合并于此。</p>
    <p>技术领域</p>
    <p>[0003]	公开的示例性实施例涉及一种信息处理设备、立体显示方法以及计算机可读介质。</p>
    <p>背景技术</p>
    <p>[0004]	近年来，能够对诸如图像内容（例如立体照片)的显示对象以及操作对象进行立体显示的立体显示装置正投入实际应用，并且变得普遍。例如，一些用于电视机、便携式游戏机和个人计算机（下文中的PC)的、能够进行立体显示的显示装置已经投入市场。关于这种立体显示装置，例如日本专利申请JP 2010-045584A公开了一种用于对立体图像进行校正的方法，该立体图像能够精确表示显示对象的创造者想要的突出量或拉回量（下文中的深度量）等。</p>
    <p>发明内容</p>
    <p>[0005]	然而，当在虚拟三维空间中立体显示图像时，出现了二维显示图像时所不会出现的问题。具体地，当真实空间中的对象与立体显示在虚拟三维空间中的对象重叠时，在真正具有三维形状的对象与通过虚拟实现视差而立体示出的显示对象之间出现关于距离感的失配，从而给观看的用户带来奇怪感。例如，有时会引起真实空间中不会出现的视觉失配， 诸如本应处于前景中的部分被背景中的东西所隐藏的失配，给用户带来不愉快感。</p>
    <p>[0006]	鉴于上述情形，期望提供一种新颖且改进的信息处理设备、立体显示方法和程序， 该信息处理设备、立体显示方法和程序能够减少当真实空间的对象接近上面立体显示有显示对象的显示表面时用户所经历的奇怪感或不愉快感。</p>
    <p>[0007]	与示例性实施例相一致，一种信息处理设备包括确定单元，该确定单元被配置为确定被布置于该确定单元的表面的阈值距离之内的操作工具的一部分的第一空间位置。该第一空间位置是在深度方向上相对于确定单元表面而确定的。信息处理设备包括控制单元，该控制单元被配置为至少基于第一空间位置来限定立体图像的第一立体图像尺寸，以及生成信号来以第一立体图像尺寸显示该立体图像。</p>
    <p>[0008]	与另外的示例性实施例相一致，一种计算机实现的方法包括：确定布置于确定单元的表面的阈值距离内的操作工具的一部分的第一空间位置。该第一空间位置是在深度方向上相对于确定单元表面而确定的。该方法包括：至少基于第一空间位置来限定立体图像的第一立体图像尺寸，以及生成信号来以第一立体图像尺寸显示该立体图像。</p>
    <p>[0009]	与另一个示例性实施例相一致，一种用于存储指令的有形、非瞬时计算机可读介质，这些指令在被处理器执行时使得该处理器执行一种方法，该方法包括：确定被布置于确定单元的表面的阈值距离内的操作工具的一部分的第一空间位置。该第一空间位置是在深度方向上相对于确定单元表面而确定的。该方法包括：至少基于第一空间位置来限定立体图像的第一立体图像尺寸，以及生成信号来以第一立体图像尺寸显示该立体图像。</p>
    <p>[0010]	根据本公开实施例，提供了一种立体显示方法，包括：立体显示多个立体图像；确定被布置于确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的；至少基于所述第一空间位置来限定目标立体图像的第一立体图像尺寸；生成信号来以所述第一立体图像尺寸显示所述目标立体图像；以及，其中，将所述多个立体图像当中显示于所述操作工具的该部分的所述第一空间位置的深度方向上的立体图像作为所述目标立体图像，并且进行控制，使得所述目标立体图像的位置靠近于所述操作工具的该部分的所述第一空间位置。</p>
    <p>[0011]	根据本公开实施例，提供了一种用于显示图像的计算机实现的方法，包括：利用处理器，确定确定单元表面上的、与操作工具的一部分和所述确定单元表面之间的接触相对应的位置；利用该处理器，限定第一立体图像的第一显示位置；利用该处理器，响应于所述接触而生成第二立体图像；以及利用该处理器，生成信号来在所述第一显示位置显示所述第一立体图像并在第二显示位置显示所述第二立体图像，所述第一显示位置和所述第二显示位置在接触位置的预定距离内。</p>
    <p>[0012]	根据公开的示例性实施例，可以减少当真实空间中的对象接近上面立体显示有显示对象的显示表面时用户所经历的奇怪感或不愉快感。</p>
    <p>附图说明</p>
    <p>[0013]	图1是根据示例性公开实施例的信息处理设备的硬件配置图；</p>
    <p>[0014]	图2是根据第一示例性实施例的信息处理设备的功能配置图；</p>
    <p>[0015]	图3是用于说明立体显示的原理的图；</p>
    <p>[0016]	图4是用于说明根据第一示例性实施例的立体显示装置的深度控制的图；</p>
    <p>[0017]	图5是用于说明根据第一示例性实施例的立体显示装置的深度控制的图；</p>
    <p>[0018]	图6是示出根据第一示例性实施例的立体显示装置的深度控制处理的流程图；</p>
    <p>[0019]	图7是用于说明根据第一示例性实施例的立体显示装置的XY坐标控制的图；</p>
    <p>[0020]	图8是根据第二和第三示例性实施例的信息处理设备的功能配置图；</p>
    <p>[0021]	图9是用于说明根据第二示例性实施例的立体显示装置的深度/编辑控制的图；</p>
    <p>[0022]	图10是用于说明根据第二示例性实施例的立体显示装置的深度/编辑控制的图；</p>
    <p>[0023]	图11是示出根据第二示例性实施例的立体显示装置的深度/编辑控制处理的流程图；</p>
    <p>[0024]	图12是用于说明图11的深度/编辑控制处理的图；</p>
    <p>[0025]	图13是示出作为根据第二示例性实施例的立体显示装置的深度/编辑控制的结果的显示屏幕的图；</p>
    <p>[0026]	图14是示出根据第二示例性实施例的修改示例1的立体显示装置的深度/编辑控制处理的流程图；</p>
    <p>[0027]	图15是用于说明图14的深度/编辑控制处理的图；[0028]	图16是示出根据第二示例性实施例的修改示例2的立体显示装置的深度/编辑控制处理的流程图；</p>
    <p>[0029]	图17是用于说明图16的深度/编辑控制处理的图；</p>
    <p>[0030]	图18是示出根据第三示例性实施例的立体显示装置的深度/编辑控制处理的流程图；</p>
    <p>[0031]	图19是用于说明根据第三示例性实施例的立体显示装置的深度/编辑控制处理的图；</p>
    <p>[0032]	图20是示出作为根据第三示例性实施例的立体显示装置的深度/编辑控制的结果的显示屏幕的图；</p>
    <p>[0033]	图21是用于说明根据另外的示例性实施例的深度/编辑控制处理的示例的图；</p>
    <p>[0034]	图22是用于说明根据另外的示例性实施例的深度/编辑控制处理的示例的图；</p>
    <p>[0035]	图23是用于说明屏幕转换的图；</p>
    <p>[0036]	图M是用于说明深度调节的图。</p>
    <p>具体实施方式</p>
    <p>[0037]	在下文中，将参考附图来详细描述示例性实施例。注意，在本说明书和附图中，用相同的附图标记来表示具有基本上相同的功能和配置的结构元件，并且省略了对这些结构元件的重复说明。</p>
    <p>[0038]	根据本公开实施例，提供了一种信息处理设备，包括：确定单元，被配置为确定被布置于所述确定单元的表面的阈值距离之内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的；以及控制单元，被配置为至少基于所述第一空间位置来限定立体图像的第一立体图像尺寸，以及生成信号来以所述第一立体图像尺寸显示所述立体图像。</p>
    <p>[0039]	根据本公开实施例，提供了一种计算机实现的方法，包括：利用处理器，确定被布置于确定单元的表面的阈值距离内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的；利用该处理器，至少基于所述第一空间位置来限定立体图像的第一立体图像尺寸；以及利用该处理器，生成信号来以所述第一立体图像尺寸显示所述立体图像。</p>
    <p>[0040]	根据本公开实施例，提供了一种立体显示方法，包括：立体显示多个立体图像；确定被布置于确定单元表面的阈值距离之内的操作工具的一部分的第一空间位置，所述第一空间位置是在深度方向上相对于所述确定单元表面而确定的；至少基于所述第一空间位置来限定目标立体图像的第一立体图像尺寸；生成信号来以所述第一立体图像尺寸显示所述目标立体图像；以及，其中，将所述多个立体图像当中显示于所述操作工具的该部分的所述第一空间位置的深度方向上的立体图像作为所述目标立体图像，并且进行控制，使得所述目标立体图像的位置靠近于所述操作工具的该部分的所述第一空间位置。</p>
    <p>[0041]	根据本公开实施例，提供了一种用于显示图像的计算机实现的方法，包括：利用处理器，确定确定单元表面上的、与操作工具的一部分和所述确定单元表面之间的接触相对应的位置；利用该处理器，限定第一立体图像的第一显示位置；利用该处理器，响应于所述接触而生成第二立体图像；以及利用该处理器，生成信号来在所述第一显示位置显示所述</p>
    <p>7第一立体图像并在第二显示位置显示所述第二立体图像，所述第一显示位置和所述第二显示位置在接触位置的预定距离内。</p>
    <p>[0042]	此外，将按照以下顺序给出说明。</p>
    <p>[0043]	1.立体显示装置的硬件配置</p>
    <p>[0044]	2.立体显示装置的功能配置（第一示例性实施例)</p>
    <p>[0045]	3.立体显示装置的深度控制（第一示例性实施例)</p>
    <p>[0046]	4.深度控制处理（第一示例性实施例）</p>
    <p>[0047]	5. XY坐标的控制（第一示例性实施例）</p>
    <p>[0048]	6.立体显示装置的功能配置（第二示例性实施例)</p>
    <p>[0049]	7.立体显示装置的深度/编辑控制（第二示例性实施例）</p>
    <p>[0050]	8.立体显示装置的深度/编辑控制（第二示例性实施例）</p>
    <p>[0051]	9.示例性深度/编辑控制处理（第二示例性实施例)</p>
    <p>[0052]	10.另外的示例性深度/编辑控制处理（第二示例性实施例)</p>
    <p>[0053]	11.立体显示装置的缩小/放大控制（第三示例性实施例)</p>
    <p>[0054]	12.另外的示例性实施例的组合</p>
    <p>[0055]	信息处理设备通常包括触摸屏。信息处理设备可以是个人计算机（PC)、智能手机、 个人数字助理、音乐播放器、游戏终端、数字家用电器等。信息处理设备还可以是要与上述装置相连接的外围装置。此外，根据各示例性实施例的信息处理设备是立体显示装置，能够对立体显示（三维显示）在可立体观看的显示器上的对象进行显示。在下文中，将以立体照片作为包括于立体显示的图像内容中的一个或多个显示对象的示例来给出说明。</p>
    <p>[0056]	在下文中，将以立体显示装置10为例来描述根据第一至第三示例性实施例的信息处理设备。本实施例提出一种立体显示方法，该方法能够减少当真实空间中的对象接近立体显示装置10上立体显示的显示对象时用户所经历的奇怪感或不愉快感。</p>
    <p>[0057]	1.立体显示装置的硬件配置</p>
    <p>[0058]	图1是示出根据示例性公开实施例的立体显示装置10的硬件配置示例的框图。参考图1，立体显示装置10包括触摸面板20、总线30、CPU(中央处理单元）32、R0M(只读存储器）；34和RAM(随机存取存储器）36。</p>
    <p>[0059]	触摸面板20包括例如为检测表面22的确定表面和显示表面（触摸表面）24。检测表面22检测操作工具（用户手指或笔）与触摸面板20的接近或接触，并生成指示接近位置或接触位置的电信号。触摸面板20是用于输入信息的输入装置的示例。例如可以根据诸如压敏方法、电容式方法或红外线方法的任意触摸检测方法来形成检测表面22。触摸面板20可以是只能够检测到与显示表面M的接触的触摸面板，但是，优选地，触摸面板20 能够检测接近以及接触。</p>
    <p>[0060]	显示表面M对来自立体显示装置10的输出图像进行显示。例如可以通过使用液晶、有机发光二极管（例如，有机EL:0LED)或阴极射线管（CRT)来实现显示表面Μ。使用眼镜的方法或者使用视差屏障（parallax barrier)或柱状透镜（lenticular lens)的自动立体方法等可以用于允许立体观看的显示器。</p>
    <p>[0061]	总线30将检测表面22、显示表面M、CPU 32,ROM ；34和RAM 36互相连接。CPU 32 控制立体显示装置10的全部操作。ROM 34存储用于构成要由CUP 32执行的软件的数据和程序。RAM 36临时存储CPU 32执行处理时的数据和程序。此外，立体显示装置10还可以包括除了图1中所示的结构元件之外的结构元件。</p>
    <p>[0062]	2.立体显示装置的功能配置（第一示例性实施例）</p>
    <p>[0063]	接下来，将参考图2描述根据第一示例性实施例的立体显示装置10的功能配置。 根据本示例性实施例的立体显示装置10包括立体显示单元40、例如为接近检测单元42的确定单元、显示控制单元44和存储单元60。</p>
    <p>[0064]	触摸面板20设置于立体显示单元40的显示表面上。立体显示单元40立体地显示图像内容。图像内容是诸如立体视频等的具有视差信息的视频或静止图像。这里，将以包括立体照片的图像内容作为各自具有各自的视差信息的一个或多个显示对象的示例来给出说明。</p>
    <p>[0065]	接近检测单元42检测操作工具对立体显示单元40的触摸表面的接近。这里，将以用户手指作为操作工具的示例来给出说明。在检测到操作工具接近的情况下，显示控制单元44将在图像内容中包括的一个或多个立体照片当中、显示在操作工具的接近位置的深度方向上的那个立体照片作为控制目标，并控制该立体照片的位置使其更靠近操作工具的接近位置。存储单元60存储图像内容以及图像内容中包括的立体照片的深度量等。</p>
    <p>[0066]	显示控制单元44读取存储于存储单元60中的图像数据，并使立体显示单元40显示已读取的图像数据。显示控制单元44还使立体显示单元40显示视频内容和图形用户界面（⑶I)等。此时，显示控制单元44执行用于对诸如图像数据、视频内容或⑶I等的显示对象进行立体显示的计算。例如，显示控制单元44执行对深度量的计算，该深度量用于使显示对象从立体显示单元40的显示表面突出或者被拉回到显示表面之后。</p>
    <p>[0067]	在使立体图像显示于虚拟三维空间的情况下，除虚拟三维空间本身持有的深度信息之外，立体照片本身也持有视差信息。图3中示出了三维空间中存在立体照片的情况的示意图。在这种情况下，由于用于右眼的照片和用于左眼的照片位于显示表面M上，因此在显示表面M上看到了这些照片，但看到照片中示出的A从显示表面M突出。将对这种立体显示的原理进行简要描述。为了立体地示出显示对象，如图3所示，在显示表面上相互分离地显示用于右眼的显示对象和用于左眼的显示对象，并且使得用于右眼的显示对象只被右眼所看到，而用于左眼的显示对象只被左眼所看到。为了使用于右眼的显示对象只被右眼所看到而用于左眼的显示对象只被左眼所看到，在很多情况下使用了偏振。例如，通过在第一方向上线性偏振的光来显示用于右眼的显示对象，而通过在与第一方向正交的第二方向上线性偏振的光来显示用于左眼的显示对象。此外，通过在右眼上佩戴使得在第一方向上线性偏振的光通过的透镜而在左眼上佩戴使得在第二方向上线性偏振的光通过的透镜， 可以造成右眼只能看到用于右眼的显示对象而左眼只能看到用于左眼的显示对象的情形。</p>
    <p>[0068]	当造成了这样的情形时，用户感知到，显示对象被立体显示在连接右眼与用于右眼的显示对象的视线和连接左眼与用于左眼的显示对象的视线相交的位置。而且，通过控制用于右眼的显示对象与用于左眼的显示对象之间的距离，可以调节会聚角度。立体显示的显示对象的突出程度随着会聚角度的变化而变化。</p>
    <p>[0069]	即，通过经由改变显示表面上用于右眼和左眼的显示对象的深度量来控制显示位置，可以控制立体显示的显示对象的突出程度或拉回程度。此外，虽然这里描述了通过利用偏振来实现立体显示的方法，但本示例性实施例并不局限于此，而可能应用能够立体显示显示对象的任意立体显示方法。</p>
    <p>[0070]	返回参考图1，显示控制单元44通过控制对用于右眼和左眼的显示对象的显示， 来使显示对象被立体显示。由显示控制单元44确定的、指示显示对象的突出程度或拉回程度的信息（下文中的深度量或深度信息）被输入到立体显示单元40。由显示控制单元44 从存储单元60读取的显示对象的数据也被输入到立体显示单元40。当输入深度量时，立体显示单元40基于输入的深度量来显示显示对象。</p>
    <p>[0071]	此外，利用CPU 32等来实现显示控制单元44的功能。而且，通过ROM 34或RAM 36(或未示出的有形、非瞬时可拆卸记录介质等）来实现存储单元60的功能。</p>
    <p>[0072]	3.立体显示装置的深度控制（第一示例性实施例）</p>
    <p>[0073]	在利用触摸面板20来执行操作的情况下，立体照片从表面突出的部分有时与操作工具相互重叠。例如，在图3中，当操作工具靠近显示表面M时，出现了这样的情形。深度信息中出现了不一致，引起关于外观的奇怪感。例如，对于从显示表面突出显示的立体照片来说，操作工具显示为像凹陷到该立体照片中一样，从而给用户带来奇怪感或不愉快感。 因此，本示例性实施例执行以下自动深度控制来作为用于解决该现象的解决方案。根据该自动深度控制，触摸面板20检测到操作工具即将与立体照片相重叠，并且基于根据立体照片所持有的视差信息而获得的深度信息来自动改变立体照片在深度方向上的位置，使得立体照片不会与操作工具相重叠。</p>
    <p>[0074]	此外，立体照片本身包括多个具有视差的纹理（textures)(在这种情况下为立体照片），但对于公开的示例性实施例，将以存在两种视差的情况为例来给出说明。此时，立体照片包括将要投射到左右双眼的纹理（在这种情况下为用于右眼的照片和用于左眼的照片），因而可以估计出这些纹理当中的一个纹理中的哪个点对应于另一个纹理中的哪个点。 这样的方法包括被称为模板匹配的方法。</p>
    <p>[0075]	将参考图3和4进一步描述根据本示例性实施例的立体显示装置10的深度控制。 如图4所示，在检测（触摸检测）到显示表面M上的操作工具的接触的情况下，显示控制单元44将作为显示在触摸位置的深度方向上的显示对象的立体照片视为控制目标，并计算该立体照片在深度方向上的位置（深度量）。</p>
    <p>[0076]	当使用模板匹配时，例如关于图3中用于右眼的图像A中的任意点1&#190;接近于用于左眼的图像A中的哪点而在水平方向上执行搜索。用于右眼的图像A中的点1&#190;与用于左眼的图像A中的目标点Pa’之间的相对移位（像素差）为视差，并且用通过将相对移位应用于立体空间而获得的那个点来表示自触摸表面（显示表面24)起的深度量。</p>
    <p>[0077]	特别地，当令图4左图的立体照片的左图像与右图像之间的相对移位为D、眼睛与显示表面M之间的距离为Lc、左眼与右眼之间的间隔为Dc、并且待获得的立体照片在深度方向上的位置（深度量）为Z时，并且当使得显示表面M的深度为0时，立体照片的深度量Z由公式⑴表示如下：</p>
    <p>[0078]	Z = D/Dc χ Lc. (1)</p>
    <p>[0079]	以这种方式，计算操作工具的接近位置处或接触位置处的深度量Z，立体照片以深度量Z更深地移位，以使得做出从图4的右图到左图的转换，并使得立体照片自显示表面起的深度为Z。这使得状态从手指凹陷到立体照片的凸出部分（图4右图）的状态转变为立体照片的凸出部分与操作工具（手指）或显示表面M相一致（图4左图）的状态，并可以降低用户所经历的奇怪感或不愉快感。</p>
    <p>[0080]	此外，可以使用快速立体匹配（fast stereo matching)技术取代模板匹配来计算深度量Z，快速立体匹配技术用于基于由立体相机获取的两幅图像之间的视差来测量到目标对象的距离。当使用该技术时，能够提高深度量的计算精度。</p>
    <p>[0081]	如上所述，当通过接近检测单元42检测到操作工具在显示表面M上的接触时，显示控制单元44执行控制，使得作为控制目标的显示对象在深度方向上的位置与显示表面对相一致。</p>
    <p>[0082]	接下来，将参考图5描述用于既涉及接触状态、又涉及接近状态的情况的立体显示装置10的深度控制。如图5左图中所示，在通过接近检测单元42检测到操作工具对显示表面M的接近（即，接近检测单元42确定了操作工具的落入显示表面的阈值距离内的那部分的第一空间位置）的情况下，显示控制单元44将显示在接近位置（即，第一空间位置）的深度方向上的立体照片作为控制目标，并计算该立体照片在深度方向上的第一显示位置（深度量Z)。显示控制单元44基于所计算的深度量Z以及接近位置与显示表面之间的距离来执行控制，使得作为控制目标的立体照片在深度方向上的位置与操作工具的接近位置相靠近或相一致。</p>
    <p>[0083]	此外，如图5的中图和右图中所示，检测到操作工具的移动，并且连同该检测一起来通过显示控制单元44重复对深度量的计算。随着显示表面M与操作工具的接近位置 (即，第二空间位置）之间的距离降低，显示控制单元44对深度进行自动控制，使得立体照片在深度方向上的位置（即，第二显示位置）与显示表面M相靠近或相一致。接近检测单元42重复上述深度控制，直到操作工具与显示表面M至少分开预定距离为止。</p>
    <p>[0084]	4.深度控制处理（第一示例性实施例）</p>
    <p>[0085]	接下来，将描述根据本示例性实施例的立体显示装置10的操作。图6是示出用于立体显示装置10的操作的深度控制处理的流程图。当开始深度控制处理时，显示控制单元 44确定接近检测单元42是否检测到操作工具的接近或接触（步骤S605)。在未检测到任何接近或接触的情况下，显示控制单元44立即结束处理。另一方面，在检测到接近或接触的情况下，显示控制单元44确定检测到的接近位置或接触位置的深度方向上是否显示有立体照片（步骤S610)。此外，即使在立体照片显示在稍微偏离于检测到的接近位置或接触位置的深度方向的一定位置的情况下，显示控制单元44也可以确定在检测到的接近位置或接触位置的深度方向上显示有立体照片。</p>
    <p>[0086]	在未以这种方式显示立体照片的情况下，显示控制单元44确定不存在控制目标， 并立即结束处理。另一方面，在以这种方式显示立体照片的情况下，显示控制单元44通过上述计算方法来计算作为控制目标的立体照片的深度量（即，深度方向上的第一位移）（步骤 S615)。</p>
    <p>[0087]	接下来，显示控制单元44基于所计算的深度量来计算从立体照片到接近位置或接触位置的距离（即，深度方向上的第二位移）（步骤S620)。立体照片在深度方向上的位置基于计算结果而变化，使得立体照片与操作工具相靠近或相一致（步骤S625)。在该实施例中，如以上参考图4所述，第一空间位置与第一显示位置之间在深度方向上的位移超过第二空间位置与第二显示位置之间的对应位移，即，立体照片被布置成比第二空间位置更接近于操作工具部分。[0088]	如上所述，根据第一示例性实施例的立体显示装置10，当操作工具靠近或触摸到显示表面M时，检测到接近位置或接触位置。然后，当显示在接近位置或接触位置的深度方向上的立体照片正从显示表面M突出时，立体照片的位置被移至更深，使得将在彼此不相重叠的情况下显示操作工具和立体照片。另一方面，当立体照片显示为被压下得比显示表面M更深的情况下，以立体照片的位置被朝前移位的方式来显示立体照片，使得立体照片被拖拽至操作工具并触摸到操作工具。这能够使将要显示的立体照片被移动为与操作工具相靠近或相一致，同时防止了立体照片的突出或凹进在立体空间中与操作工具相重叠， 并且，可以在不带来奇怪感的情况下，针对包括立体照片的三维应用来实现诸如轻击、拖动以及轻弹的针对二维应用执行的操作。</p>
    <p>[0089]	5. XY坐标的控制（第一示例性实施例）</p>
    <p>[0090]	立体照片的显示位置被移动的方向可以是如上所述的深度方向，或者是与显示表面M平行的水平方向和垂直方向中的任一方向。例如，在图7的上图中，立体照片I^s和Pt 被显示为从显示表面M突出。图7示出了立体照片被显示成相互重叠的情况。这里，主体 Pt’（显示对象）包含在立体照片Pt中，而主体1^’（显示对象）包含在立体照片I3S中。 立体照片I3S的主体1^’位于立体照片Pt前面，而立体照片Pt的主体Pt’位于立体照片I^s 后面，而且，当作为整体来看时，看到后面的立体照片Pt的主体Pt’部分地挡住了前面的立体照片I3S的主体1^’（凸出部分）。这样的立体显示不会出现在真实空间中，因而导致用户经历奇怪感。</p>
    <p>[0091 ] 如图7上图中所示，在该显示状态下，操作工具接近于立体照片I^s和Pt。然后，根据操作工具的移动，显示控制单元44将立体照片I^s和立体照片Pt朝显示表面M的方向推回。接下来，如图7的中图中所示，当操作工具在与显示表面M平行的方向上（在该情况下为左）移动作为控制目标的立体照片I3S时，显示控制单元44在与显示表面M平行的方向上移动立体照片I^s的位置，并执行控制来使得立体照片I3S的位置与操作工具的接近位置相靠近或相一致。这使得立体照片I3S被显示在立体照片Pt的左边。结果，如图7的底图中所示，可以解决前面的立体照片Ps的主体1^’被后面的立体照片Pt的主体Pt’所阻挡的情况。此外，可以如图7所示，在改变立体照片I^s在深度方向上的位置之后在XY方向（与显示表面M平行的方向）上移动立体照片Ps，或者可以在不改变立体照片I3S在深度方向上的位置的情况下在XY方向上移位立体照片1^。</p>
    <p>[0092]	6.立体显示装置的功能配置（第二示例性实施例）</p>
    <p>[0093]	接下来，将参考图8描述根据第二实施例的立体显示装置10的功能配置。根据第二示例性实施例的立体显示装置10，连同在第一示例性实施例中描述的自动深度控制一起来执行诸如书写的编辑控制。</p>
    <p>[0094]	根据第二实施例的立体显示装置10包括立体显示单元40、接近检测单元42、显示控制单元44、深度调节单元46、图像编辑单元48和存储单元60。在以上各单元中，将主要描述未包括在第一实施例的功能配置中的深度调节单元46和图像编辑单元48。深度调节单元46根据用户进行的操作来调节作为控制目标的显示对象在深度方向上的位置。图像编辑单元48通过在立体照片或虚拟地覆盖于立体照片上的板面（sheet surface)上绘制图像而执行编辑，该编辑在立体显示图像内容的三维空间中获得期望图像。此时在其上执行绘制的板（纹理）可以是照片本身的纹理（显示表面对），或者可以通过提供用于在与照</p>
    <p>12片本身的纹理相同的位置进行书写的纹理（板面）而分开管理原始立体照片和编辑内容。 这里将描述在板面上绘制图像的情况。</p>
    <p>[0095]	7.立体显示装置的深度/编辑控制（第二示例性实施例）</p>
    <p>[0096]	图9示出了根据本示例性实施例的立体显示装置10的深度/编辑控制的示例。显示控制单元44首先执行自动深度控制。具体地，当检测到操作工具对显示表面M的接触或接近时，显示控制单元44把显示在接触位置或接近位置的深度方向上的立体照片作为控制目标，并计算该立体照片在深度方向上的位置（深度量）。在图9左图中，基于深度量来通过显示控制单元44使立体照片朝前移位，使得立体照片的凸出部分WA达到显示表面 24。以此方式来执行自动深度控制的结果是，立体照片的凸出部分WA的显示位置达到与操作工具接触或接近的位置。</p>
    <p>[0097]	接下来，如图9的中图中，深度调节单元46对立体照片将要显示的深度进行调节。 这里，将立体照片调节为显示在比自动控制之后的位置更深Z’量的位置。通过以该方式调节立体空间中深度方向上的位置，可以指向立体空间中的任意位置。在图9右图中，在立体空间中立体照片的板面（与立体照片相同的位置）上，用笔在已被指向的书写位置执行书写。这意味着，通过在立体照片前面的立体空间中书写任意图形或文字来执行编辑。</p>
    <p>[0098]	作为用户输入深度调节量Z’的方法，如图M右下图中所示，存在通过对设于显示表面M上的滑块2&#189;进行操作而输入调节量Z’的方法。也可以通过对把手或按钮（未示出）的操作来代替滑块2&#189;的操作而输入调节量Z’。如图对左下图中所示，还可能通过用户对捏夹器（pintch) 24b进行操作来输入调节量Z’。通过结合触摸面板20，还可能通过使得在空气中捏夹把手并使得检测到把手的接近位置，来输入调节量Z’。如图M左上图中所示，也可以通过用户对旋转器2&#189;进行操作来输入调节量Z’。如图M右上图中所示，可以通过轻击或双击而把立体照片24d的深度调节为0，使得在轻击位置或双击位置显示的立体照片Md的显示位置与显示表面M相一致。通过以这种方式经由用户操作来输入调节量Z’，可以在立体空间中的任意位置绘制图形。</p>
    <p>[0099]	例如，可以在立体空间中的立体照片中书写任意图形。按照以下方式来计算书写位置。如上文中那样，以立体照片本身包括两种视差的情况为例。如图10左图中所示，当令被视作目标的眼睛的位置向量为Vc、笔尖的位置向量为Vp、眼睛与显示表面之间的距离为Lc、而显示表面与立体照片之间的距离为Li时，书写位置的位置向量Vw由公式（2)示出如下：</p>
    <p>[0100]	Vw= (Lc+Li)/Lc χ (Vp-Vc) +Vc. (2)</p>
    <p>[0101]	在位于显示表面M后面的立体照片中进行绘制的情况下，在连接左眼的虚拟位置与书写位置的直线和立体照片的交点处在用于左眼的板面（被示出为板面）上书写圆点。同样，在连接右眼的虚拟位置与书写位置的直线和立体照片的交点处在用于右眼的板面（被示出为板面）上书写圆点。通过同时执行上述动作，看起来像是在立体照片上执行绘制一样。</p>
    <p>[0102]	如图10的中图中所示，在显示表面的后面显示立体照片的情况下，如果用笔在虚拟覆盖于立体照片上的板面上执行书写，则将假设在立体照片前面的空间中书写了图像。 另一方面，如图10右图中所示，在显示表面的前面显示立体照片的情况下，如果用笔在板面上执行书写，则将假设在立体照片后面的空间中书写了图像。[0103]	8.立体显示装置的深度/编辑控制（第二示例性实施例)</p>
    <p>[0104]	接下来，将描述根据本示例性实施例的立体显示装置10的操作。图11是示出用于立体显示装置10的操作的深度/编辑控制处理的流程图。当开始深度/编辑控制处理时，显示控制单元44执行由图6的步骤S605到S625示出的深度控制处理（步骤Sl 105)。 在第一示例性实施中已经描述了图6的深度控制处理，这里将省略对它的说明。例如，图12 的部分“a”和“b”示出在深度控制处理中执行的接近检测和自动深度控制。这里的立体照片包括具有不同深度的主体m、η和ο。</p>
    <p>[0105]	接下来，深度调节单元46确定是否从用户收到用于深度调节的指令（步骤 S1110)。在不存在来自用户的关于深度调节量Ζ’的输入指令的情况下，深度调节单元46 跳过步骤S1115。另一方面，在存在来自用户的关于深度调节量Ζ’的输入指令的情况下，深度调节单元46调节作为控制目标的立体照片的深度（步骤S1115)。在图12的“C”中，调节深度以使立体照片显示在更后面。</p>
    <p>[0106]	接下来，接近检测单元42检测操作工具（在这种情况下为手指）是否在预定时间内接触到了显示表面（步骤S1120)。在未检测到接触的情况下，结束处理。另一方面，在检测到接触的情况下，图像编辑单元48在板面上的书写位置执行所需的书写/编辑（步骤 S1125)。执行这个书写/编辑处理直到与显示表面M相接触的操作工具从显示表面M移开（重复步骤S1130和S1125)。结果，在图12的“d”中，将图像书写在了主体m的前面，以及，在“e”中，将图像书写在了主体η的后面。主体m和η对应于显示在操作工具的接近位置的深度方向上的作为控制目标的显示对象。</p>
    <p>[0107]	当与显示表面M相接触的操作工具从显示表面M移开时，处理返回至步骤 S1110，并且深度调节单元46再次确定是否从用户收到用于深度调节的指令。在存在指令的情况下，深度调节单元46再次调节立体照片的深度（步骤S1115 ：见图12，“f”）。然后， 在再次检测到操作工具的接触的情况下，图像编辑单元48在板面上的书写位置再次执行期望的书写/编辑（步骤S1125)。在图12的“g”中，在立体照片中主体η右侧的板面上的书写位置书写图像。</p>
    <p>[0108]	在操作工具已经从显示表面M移开（步骤S1130)、未曾有过用于深度调节的指令（步骤SlllO和Sl 115)、以及预定时间已经过去而操作工具并未接触显示表面24(步骤 S1120)的情况下，结束书写/编辑处理。</p>
    <p>[0109]	如上所述，根据第二示例性实施例的立体显示装置10，可以通过自动深度控制来使操作工具已对其发布指令的那个主体浮动至显示表面，并且可以在立体照片上书写任何图形或文字。例如，在图13右图中，使操作工具接近作为主体示例的背景中的山，结果，山被自动控制成处于与显示表面一致的状态。这可以从山的图形未包括相对移位（视差）来看出。当在这种状态下用笔在山上书写“Mt. ”时，执行编辑，以在山的图像上书写手写的 “Mt. ”。此外，在图13右图中，在二维中将位于显示表面前面或者后面的主体的图像的相对移位幅度表示为视差。右边的建筑以及中间的皇家护卫犬的图像包括相对移位。因此，可以理解为，建筑和皇家护卫犬被立体显示为向前突出或者向后内突。</p>
    <p>[0110]	例如，在希望在立体照片前面的空间中书写的情况下，根据来自用户的深度调节指令而调节深度，使得将立体照片和板面显示在显示表面的后面。当在这种情形下在板面上执行书写时，可以在立体照片的图像前面的空间中执行三维书写。</p>
    <p>1[0111]	另一方面，例如在希望在立体照片后面的空间中书写的情况下，根据来自用户的深度调节指令而调节深度，使得将立体照片显示在显示表面的前面。当在这种情形下在板面上执行书写时，可以在立体照片的图像后面的空间中执行三维书写。在图13左图中，在二维中将书写在显示表面的前面或后面的一对曲线的相对移位幅度表示为视差。虽然不能从图中知晓，但是离该女人最近的那对曲线是书写在前面的，并且具有小的相对移位。因此，这对曲线被显示为向该女人的前面突出一点。另一方面，虽然不能从图中知晓，但是远离该女人的那两对曲线是书写在后面的，并有大的相对移位。因此，可以理解，一对曲线越靠向侧面，这对曲线就被显示得越深入后面。用这种方式，根据第二示例性实施例的立体显示装置10，可以将图像书写在立体照片上或者立体照片的前面或者后面，并且可以执行编辑。</p>
    <p>[0112]	9.示例性深度/编辑控制处理（第二示例性实施例）</p>
    <p>[0113]	如上所述，当能够自由地在立体照片内的立体空间中进行绘制时，可能出现的情况是，产生了与原始立体照片和书写图像的视差有关的关于显示的奇怪感。例如，如果可以在被移至前面的立体照片的后面执行书写，则关于立体显示可能出现奇怪感或者不愉快感。为了防止这种情况，根据修改示例1，通过预先计算原始立体照片的左图像和右图像的像素之间的各相对移位、并且将这些相对移位与根据书写位置来计算的左右之间的相对移位进行比较，来确定立体照片在深度方向上的位置与图像的书写位置之间的位置关系，从而防止在立体照片的后面书写图像。下文中，将参考示出深度/编辑控制处理的图14的流程图来描述根据本实施例的修改示例1的立体显示装置10的操作。</p>
    <p>[0114]	当开始深度控制处理时，显示控制单元44执行图6中所示的深度控制处理（步骤 S1105)。该深度控制处理与第二实施例的深度控制处理相同，这里将省略对它的说明。</p>
    <p>[0115]	接下来，在从用户接收到用于深度调节的指令的情况下，深度调节单元46对立体照片的深度进行调节（步骤SlllO和S1115)。该深度调节处理也与第二实施例的深度调节处理相同，这里将省略对它的说明。</p>
    <p>[0116]	接下来，将描述修改示例1的书写控制。接近检测单元42检测操作工具是否在预定时间内接触到了显示表面24(步骤S1120)，并且，在未检测到接触的情况下，结束处理。 另一方面，在检测到接触的情况下，图像编辑单元48确定板面上的书写位置是否位于立体照片的后面（步骤S1405)。如上所述，通过预先计算原始立体照片的左图像和右图像的像素之间的各相对移位、并且将这些相对移位与根据书写位置来计算的左右之间的相对移位进行比较，来确定板面上的书写位置是否位于立体照片的后面。在书写位置未位于立体照片后面的情况下，图像编辑单元48照常在书写位置执行期望的书写/编辑（步骤S1125)。 执行该书写/编辑处理，直到与显示表面M相接触的操作工具从显示表面M移开为止（重复步骤Sl 130和Sl 125)。</p>
    <p>[0117]	另一方面，在书写位置位于立体照片后面的情况下，由于将必须在被移至前面的立体照片的后面执行书写，因此图像编辑单元48禁止在该书写位置进行书写（步骤 S1410)。在图15的“h”中，禁止在显示于显示表面前面的主体η的后面进行书写。</p>
    <p>[0118]	当与显示表面M相接触的操作工具从显示表面M移开时（步骤Sl 130)或者当书写被禁止时（步骤S1410)，处理返回步骤S1110，并且深度调节单元46再次确定是否从用户收到用于深度调节的指令。在存在指令的情况下，深度调节单元46再次调节立体照片的深度（见图15中“j”），并且在板面上的书写位置再次执行期望的书写/编辑。在图15 的“k”中，示出一种在再次调节之后、在显示于显示表面M后面的主体η的前面书写图像的情形。</p>
    <p>[0119]	在操作工具已经从显示表面M移开（步骤Sl 130)、不曾存在用于深度调节的指令 (步骤SlllO和S1115)、以及在预定时间已过去而操作工具并未与显示表面M相接触的情况下（步骤S1120)的情况下，结束书写/编辑处理。</p>
    <p>[0120]	如上所述，根据第二实施例的修改示例1，通过禁止在立体照片的后面书写图像， 能够防止引起与原始立体照片和书写图像的视差有关的关于显示的奇怪感。</p>
    <p>[0121]	10.另外的示例性深度/编辑控制处理（第二示例性实施例)</p>
    <p>[0122]	在修改示例1中，禁止了在立体照片的后面进行书写，以防止与原始立体照片和书写图像的视差有关的关于显示的奇怪感。另一方面，在修改示例2中，连同图像的书写/ 编辑一同执行自动深度控制，使得图像被书写在立体照片上。下文中，将参考示出深度/编辑控制处理的图16的流程图来描述根据本示例性实施例的修改示例2的立体显示装置10 的操作。</p>
    <p>[0123]	当开始深度控制处理时，显示控制单元44执行图6中所示的深度控制处理（例如参见步骤S1105以及图17的“ρ”）。该深度控制处理（自动）与第二示例性实施例的深度控制处理相同，这里将省略对它的说明。</p>
    <p>[0124]	接下来，将描述修改示例2的书写控制。接近检测单元42检测操作工具是否在预定时间内接触到了显示单元24(步骤S1120)，并且，在未检测到接触的情况下，结束处理。 另一方面，在检测到接触的情况下，图像编辑单元48在板面上的书写位置执行期望的书写 /编辑，同时执行图6的自动深度控制处理（步骤S160O。执行该书写/编辑处理，直到与显示表面对相接触的操作工具从显示表面对移开为止（重复步骤S1130和S16(^)。在图 17的“q”中，执行主体m上的书写，同时将深度自动控制为使得主体m与显示表面相一致。 在图17的“r”中，执行主体η上的书写，同时将深度自动控制为使得主体η与显示表面相一致。在图17的“S”中，执行主体ο上的书写，同时将深度自动控制为使得主体ο与显示表面相一致。</p>
    <p>[0125]	当与显示表面M相接触的操作工具从显示表面M移开（步骤S1130)时，处理返回步骤S1120，而且，在预定时间已过去而操作工具并未与显示表面M相接触（步骤 S1120)的情况下，结束书写/编辑处理。</p>
    <p>[0126]	如上所述，根据第二示例性实施例的修改示例2，连同图像的书写/编辑一起来执行自动深度控制，使得在立体照片上书写图像。这可以防止与原始立体照片和书写图像的视差有关的关于显示的奇怪感。</p>
    <p>[0127]	11.立体显示装置的缩小/放大控制（第三示例性实施例）</p>
    <p>[0128]	接下来，将对根据本公开的第三示例性实施例的立体显示装置10的功能和操作进行描述。通过图8中所示的功能模块的各个单元来实现根据第三示例性实施例的立体显示装置10的功能。然而，利用第三示例性实施例的显示控制单元44，在检测到操作工具的接近或者接触的情况下，在包括立体照片的图像内容被缩小到期望尺寸之后显示该图像内容。下面，将以这个区别为重点，对根据第三示例性实施例的立体显示装置10的深度控制处理进行描述。</p>
    <p>16[0129]	图18是示出根据第三示例性实施例的立体显示装置10的缩小/放大控制处理的流程图。当开始缩小/放大控制处理时，显示控制单元44确定接近检测单元42是否检测到接近或者接触（步骤S605)。在既未检测到接近、也未检测到接触的情况下，结束处理。 另一方面，在检测到接近或者接触（即，在显示表面的阈值距离内检测到操作工具的一部分的第一空间位置）的情况下，显示控制单元44将显示表面M上显示的图像内容（包括立体照片）缩小至第一尺寸，并且该第一尺寸的示例是与第一空间位置相关联的预定尺寸 (步骤S1805)。图19示出了在检测到操作工具的接近时自动缩小立体照片的情形。</p>
    <p>[0130]	接下来，在步骤S1810中，显示控制单元44确定操作工具是否被移开至第二空间位置，接近检测单元42在该第二空间位置无法检测到接近（即，第二空间位置未落入阈值距离之内）。在操作工具未被移开的情况下，结束处理，而图像内容被缩小至预定尺寸。在操作工具被移开至无法检测到接近的位置时，显示控制单元44将显示表面M上显示的图像内容恢复至其原始尺寸（步骤S1815)，并结束处理。</p>
    <p>[0131]	如上所述，根据第三示例性实施例的立体显示装置10，在立体照片从显示表面突出的部分与操作工具重叠或者可能重叠的情况下，改变立体照片的视觉尺寸以消除好像操作工具凹陷到立体照片中一样的基于失配的奇怪感。例如，当图20左图中所示的整个图像被缩小为图20的右图时，书写在女人两侧的曲线的相对移位变小。通过经由改变立体照片的视觉尺寸来以这种方式改变左图像和右图像之间关于视差的相对差异，可以减少立体照片的深度感。这能够减少操作工具与立体照片之间的重叠，并减少关于外观的奇怪感。</p>
    <p>[0132]	例如，如果将突出量为Icm的立体照片缩小一半，则照片的突出量将为0. 5cm。用这种方式可以减少由真实空间中的操作工具与虚拟空间中的对象之间的重叠而引起的关于显示的奇怪感。特别地，根据本示例性实施例，对于缩小/放大整个图像而言，如第一示例性实施例那样通过计算深度量来控制立体照片的深度并不是必要的。这样，根据本示例性实施例，用于深度控制的计算变得非必要，并且处理能够得到简化。</p>
    <p>[0133]	此外，显示控制单元44也可以根据图像内容中包括的一个或多个立体照片当中具有最大深度的那个立体照片的深度量，来确定图像内容的缩小比例。操作工具与立体照片彼此重叠时所引起的奇怪感随着最大突出量的增加而增加。因此，在该情况下通过增大缩小比例，可以减少用户所经历的奇怪感。</p>
    <p>[0134]	此外，还能够将本示例性实施例的图像缩小/放大处理与一个或多个公开的示例性实施例的深度控制相结合。除了图18的缩小/放大控制处理外，还可以根据用户的操作， 通过深度调节单元46来执行对作为控制目标的立体照片在深度方向上的位置调节。</p>
    <p>[0135]	12.另外的示例性实施例的组合</p>
    <p>[0136]	可以针对应用来酌情对上述公开的示例性实施例的立体显示方法进行组合。例如，在图像编辑单元48对图像进行编辑之前，显示控制单元44可以在控制作为控制目标的显示对象在深度方向上的位置之后，执行控制来放大图像内容并将图像内容显示为与显示表面（触摸表面）相一致或者位于触摸表面的后面。</p>
    <p>[0137]	此外，例如，在检测到操作工具的接近的情况下，显示控制单元44可以连同缩小并显示图像内容一起，将显示在操作对象的接近位置的深度方向上的那个显示对象作为控制目标，并控制该显示对象在深度方向上的位置，从而与操作工具的接近位置相靠近或相一致。[0138]	将参考图21和图22来具体描述公开的示例性实施例的组合示例。在多个立体照片的缩略图I3S如图21左上图中那样排列于立体显示装置10的显示表面M的后面的情况下，通过使操作工具触摸到显示表面M上的任意位置来选择期望的立体照片。在图21右上图中，通过触摸来选择两个立体照片Psl和1^2，并通过利用第一示例性实施例的深度控制使得立体照片的深度量为0，来令立体照片Psl和Ps2的显示位置与显示表面M相一致。 在图22中，当手接近显示表面M时，控制立体照片的深度以使它更靠近手的位置并且立体照片Psl浮动（图22右上图），并且，通过使手触摸显示表面M，将立体照片Psl显示在与显示表面M相一致的位置（图22左下图）。当手移开时，执行向立体照片Psl的全屏显示的切换（图22右下图）。期望的立体照片Psl也可以被放大至全屏并通过其它手势来显示（图21左下图）。在这种情形下，如第二示例性实施例中所指示的那样，利用与立体照片 Psl相接触的手来开始书写（图21右下图）。</p>
    <p>[0139]	当在以放大方式显示立体照片Psl的情况下尝试用手触摸显示表面M时，很可能在手和立体照片Psl之间出现干扰，但可以通过执行深度调节以在深度方向上将立体照片 Psl的图像拉回，来减小这种干扰。此外，也可以通过连同执行深度调节一起缩小立体照片 Psl的图像（图21右下图），来减少这种干扰。</p>
    <p>[0140]	此外，作为用于改变屏幕显示的手势，可以想到，如图23左上图中所示那样通过在附近晃动手来移至上一照片或下一照片，或者如图23右上图中所示那样通过拖拽来移至上一照片或下一照片，并且，在移至上一照片或下一照片期间，可以通过经由减小照片尺寸而减小深度感，来减少由于到立体显示的显示对象的距离感与到操作工具的距离感之间的失配引起的奇怪感。</p>
    <p>[0141]	如图23左下图中所示，还能够通过双击来从以放大方式显示一个立体照片的情形转至显示缩略图列表。如图23右下图所示，还能够通过捏夹来进行缩放，并在立体照片充分小时转至显示缩略图列表。而且在这些情况下，在立体照片的放大显示期间，执行深度调节来将照片拉到后面，并且减少了由于到立体显示的显示对象的距离感与到操作工具的距离感之间的失配而引起的奇怪感。然后，当已经转至显示缩略图列表时，执行深度调节来使照片接近于显示表面24，从而提高用户的可操作性。</p>
    <p>[0142]	用这种方式，在检测到操作工具的接近的情况下，显示控制单元44可以把显示在操作工具的接近位置的深度方向上的显示对象作为控制目标，并连同执行图像内容的缩小显示一起，移动显示对象在深度方向上的位置以使显示对象更加向后。此外，随着显示表面 M与操作工具的接触位置之间的距离变得更短，显示控制单元44可以将图像内容显示为更加缩小，并且随着显示表面M与操作工具之间的距离变得更长，可以将图像内容显示为更加放大。</p>
    <p>[0143]	如上所述，根据公开的示例性实施例，通过根据操作工具的接近或接触而对显示对象的显示方法进行适当控制，可以减少由于立体显示的显示对象与操作工具之间关于距离感的失配而引起的奇怪感。</p>
    <p>[0144]	例如，在第一示例性实施例中，通过使用能够进行接近检测的触摸面板20，根据操作工具接近的那个点处左图像与右图像之间的相对移位（视差）而估计出立体照片自显示表面M起的深度量，并且控制立体照片的位置以使操作工具的接近位置与该深度量彼此一致。这可以消除由于显示对象与操作工具之间关于距离感的失配而引起的奇怪感，并且还可以提高用户的可操作性。</p>
    <p>[0145]	此外，例如，在第二示例性实施例中，经由利用能够进行接近检测的触摸面板20， 通过操纵期望进行书写的XY坐标并且使Z坐标与显示表面（触摸表面）相匹配，可以用与指定二维中的位置相同的方式来指定三维中的位置，并且可以在显示立体照片的立体空间中的任意位置中书写文字或图形。</p>
    <p>[0146]	此外，例如，在第三示例性实施例中，当在从触摸面板20的显示表面M突出的位置处形成立体照片的情况下检测到操作工具的接近时，立体照片的尺寸被缩小。这可以容易地减少有关深度方向上的显示的奇怪感，同时为用户保持良好的可操作性。</p>
    <p>[0147]	此外，通过将以上示例性实施例的立体显示方法进行适当结合，可以有效减少由于显示对象与操作工具之间关于距离感的失配而引起的奇怪感。</p>
    <p>[0148]	在第一至第三示例性实施例以及上述修改示例中，各单元的操作是相互关联的， 并且能够以考虑到各单元的关系的一系列操作或一系列处理来进行替代。这可以使得信息处理设备的示例性实施例执行立体显示方法，并且信息处理设备的处理器可以执行有形、 非瞬时计算机可读介质中存储的指令，来使处理器实现信息处理设备的功能。</p>
    <p>[0149]	本领域技术人员应当理解，根据设计需求和其它因素，可以出现各种修改、组合、 子组合以及替换，只要这些修改、组合、子组合以及替换处于所附权利要求或其等同的范围内即可。</p>
    <p>[0150]	例如，在上述每一个示例性实施例中，虽然描述了使得触摸面板检测三种情形 (即，非接近、接近和接触）的方法以及根据检测结果来控制显示对象的显示方法，但是根据本公开的立体显示方法并不局限于此。例如，在可以通过触摸面板逐步地或顺序地检测显示表面与显示对象之间的距离的情况下，可以根据该距离来在深度方向上逐步地或连续地向后推动显示对象。这样的修改也在本公开的技术范畴内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1774937A?cl=zh">CN1774937A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年4月16日</td><td class="patent-data-table-td patent-date-value">2006年5月17日</td><td class="patent-data-table-td ">夏普株式会社</td><td class="patent-data-table-td ">三维图像生成装置、三维图像再现装置、三维图像处理装置、三维图像处理程序及记录该程序的记录介质</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1838778A?cl=zh">CN1838778A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年3月23日</td><td class="patent-data-table-td patent-date-value">2006年9月27日</td><td class="patent-data-table-td ">精工爱普生株式会社</td><td class="patent-data-table-td ">立体图像显示装置及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101042624A?cl=zh">CN101042624A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年3月22日</td><td class="patent-data-table-td patent-date-value">2007年9月26日</td><td class="patent-data-table-td ">松下电器产业株式会社</td><td class="patent-data-table-td ">显示装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101640762A?cl=zh">CN101640762A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年7月15日</td><td class="patent-data-table-td patent-date-value">2010年2月3日</td><td class="patent-data-table-td ">索尼株式会社</td><td class="patent-data-table-td ">信息处理设备、方法和程序</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5574836">US5574836</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">1996年1月22日</td><td class="patent-data-table-td patent-date-value">1996年11月12日</td><td class="patent-data-table-td ">Broemmelsiek; Raymond M.</td><td class="patent-data-table-td ">Interactive display apparatus and method with viewer position compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6175379">US6175379</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">1999年11月23日</td><td class="patent-data-table-td patent-date-value">2001年1月16日</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Stereoscopic CG image generating apparatus and stereoscopic TV apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100095206">US20100095206</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年10月13日</td><td class="patent-data-table-td patent-date-value">2010年4月15日</td><td class="patent-data-table-td ">Lg Electronics Inc.</td><td class="patent-data-table-td ">Method for providing a user interface using three-dimensional gestures and an apparatus using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2010103195A2?cl=zh">WO2010103195A2</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年9月22日</td><td class="patent-data-table-td patent-date-value">2010年9月16日</td><td class="patent-data-table-td ">Stantum</td><td class="patent-data-table-td ">Dispositif pour le controle d&#39;appareil electronique par la manipulation d&#39;objets graphiques sur un ecran tactile multicontacts</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04N0013000000">H04N13/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003041000">G06F3/041</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N13/0497">H04N13/0497</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N13/0022">H04N13/0022</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2013/0081">H04N2013/0081</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F2203/04101">G06F2203/04101</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=5X2LBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/041">G06F3/041</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">H04N13/04Y</span>, <span class="nested-value">H04N13/00P1D</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年5月23日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/e719729d751cba6c755a/CN102469333A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E8%AE%BE%E5%A4%87_%E7%AB%8B%E4%BD%93%E6%98%BE%E7%A4%BA%E6%96%B9%E6%B3%95%E5%92%8C.pdf?id=5X2LBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0xEN86VtH07ieJ16la-8AptXZbOg"},"sample_url":"https://www.google.com/patents/reader?id=5X2LBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>