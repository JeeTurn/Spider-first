<!DOCTYPE html><html><head><title>专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="综合利用人脸及人体辅助信息的交互式人脸识别系统及方法"><meta name="DC.contributor" content="振华于" scheme="inventor"><meta name="DC.contributor" content="南京搜拍信息技术有限公司" scheme="assignee"><meta name="DC.date" content="2007-3-16" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及图像识别系统及方法，是综合利用人脸及人体辅助信息的交互式人脸识别系统及方法，包括客户端、服务器，以及两者之间的通信线路，客户端包括人脸检测模块、特征提取模块、用户确认模块，服务器包括人脸数据库模块、识别引擎模块、调整识别引擎模块或服务器包括网络人脸数据库模块；客户端包括本地人脸数据库模块、人脸检测模块、特征提取模块、识别引擎模块、用户确认模块，用于确认识别结果、调整识别引擎模块，根据确认的识别结果来调整识别引擎。是一种交互式的人脸识别系统，通过引入用户反馈并调整识别引擎，可以提高识别的精度。另外，本发明可以应用于互联网，是大规模的基于客户端、服务器架构的人脸识别系统。"><meta name="DC.date" content="2007-8-22"><meta name="citation_patent_publication_number" content="CN:101021899:A"><meta name="citation_patent_application_number" content="CN:200710020642"><link rel="canonical" href="https://www.google.com/patents/CN101021899A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101021899A?cl=zh"/><meta name="title" content="专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法"/><meta name="description" content="本发明涉及图像识别系统及方法，是综合利用人脸及人体辅助信息的交互式人脸识别系统及方法，包括客户端、服务器，以及两者之间的通信线路，客户端包括人脸检测模块、特征提取模块、用户确认模块，服务器包括人脸数据库模块、识别引擎模块、调整识别引擎模块或服务器包括网络人脸数据库模块；客户端包括本地人脸数据库模块、人脸检测模块、特征提取模块、识别引擎模块、用户确认模块，用于确认识别结果、调整识别引擎模块，根据确认的识别结果来调整识别引擎。是一种交互式的人脸识别系统，通过引入用户反馈并调整识别引擎，可以提高识别的精度。另外，本发明可以应用于互联网，是大规模的基于客户端、服务器架构的人脸识别系统。"/><meta property="og:title" content="专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101021899A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101021899A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=PueGAAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101021899A&amp;usg=AFQjCNGq2o6oy2xAVAPZIG9JZolUCoTUPg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/c3b4fa2b241ecd71094a/CN101021899A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/c3b4fa2b241ecd71094a/CN101021899A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101021899A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101021899A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101021899A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN100580691C?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101021899A?cl=zh" style="display:none"><span itemprop="description">本发明涉及图像识别系统及方法，是综合利用人脸及人体辅助信息的交互式人脸识别系统及方法，包括客户端、服务器，以及两者之间的通信线路，客户端包括人脸检测模块、特征提取模块、用户确认模块，服务器包括人脸数据...</span><span itemprop="url">https://www.google.com/patents/CN101021899A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法" title="专利 CN101021899A - 综合利用人脸及人体辅助信息的交互式人脸识别系统及方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101021899 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200710020642</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2007年8月22日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2007年3月16日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2007年3月16日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN100580691C?hl=zh-CN&amp;cl=zh">CN100580691C</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200710020642.8, </span><span class="patent-bibdata-value">CN 101021899 A, </span><span class="patent-bibdata-value">CN 101021899A, </span><span class="patent-bibdata-value">CN 200710020642, </span><span class="patent-bibdata-value">CN-A-101021899, </span><span class="patent-bibdata-value">CN101021899 A, </span><span class="patent-bibdata-value">CN101021899A, </span><span class="patent-bibdata-value">CN200710020642, </span><span class="patent-bibdata-value">CN200710020642.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%8C%AF%E5%8D%8E%E4%BA%8E%22">振华于</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%8D%97%E4%BA%AC%E6%90%9C%E6%8B%8D%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">南京搜拍信息技术有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101021899A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101021899A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101021899A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (20),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (7)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=PueGAAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200710020642&amp;usg=AFQjCNGbjhREmixSP5JLb-DkWD316BwMUw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=PueGAAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101021899A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFGS8KF2dKMUERZaaIKi0CC5rk-jQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT121933755" lang="ZH" load-source="patent-office">综合利用人脸及人体辅助信息的交互式人脸识别系统及方法</invention-title>
      </span><br><span class="patent-number">CN 101021899 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA108167431" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及图像识别系统及方法，是综合利用人脸及人体辅助信息的交互式人脸识别系统及方法，包括客户端、服务器，以及两者之间的通信线路，客户端包括人脸检测模块、特征提取模块、用户确认模块，服务器包括人脸数据库模块、识别引擎模块、调整识别引擎模块或服务器包括网络人脸数据库模块；客户端包括本地人脸数据库模块、人脸检测模块、特征提取模块、识别引擎模块、用户确认模块，用于确认识别结果、调整识别引擎模块，根据确认的识别结果来调整识别引擎。是一种交互式的人脸识别系统，通过引入用户反馈并调整识别引擎，可以提高识别的精度。另外，本发明可以应用于互联网，是大规模的基于客户端、服务器架构的人脸识别系统。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(9)</span></span></div><div class="patent-text"><div mxw-id="PCLM50754942" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.综合利用人脸及人体辅助信息的交互式人脸识别系统，包括客户端、服务器，以及两者之间的通信线路，其特征在于：所述客户端包括以下模块：人脸检测模块，对输入的待识别图像，检测其中的人脸；特征提取模块，对于检测到的人脸，提取人脸及人体的辅助信息，以及图片的拍照时间，像机型号信息，并把相关特征向量通过通信线路传至服务器；用户确认模块，用于确认服务器传过来的识别结果，并把确认的识别结果通过通信线路传至服务器；所述服务器包括以下模块：人脸数据库模块，提供已训练的人物的特征向量；识别引擎模块，从人脸数据库中获得已训练的人物的特征向量，并把从客户端传过来的待识别人物的特征向量与之对比进行识别，来获得识别结果，并将识别结果通过通信线路传至用户确认模块；调整识别引擎模块，根据用户确认模块传过来的确认的识别结果来调整识别引擎。</div>
    </div>
    </div> <div class="claim"> <div num="2" class="claim">
      <div class="claim-text">2.综合利用人脸及人体辅助信息的交互式人脸识别系统，包括客户端、服务器，以及两者之间的通信线路，其特征在于：所述服务器包括以下模块：网络人脸数据库模块，提供人物特征向量数据；所述客户端包括以下模块：本地人脸数据库模块，在开始识别前，根据识别的任务，向服务器网络人脸数据库模块请求与识别任务匹配的人物特征向量集，并下载到本地人脸数据库中；人脸检测模块，对输入的待识别图像，检测其中的人脸；特征提取模块，对于检测到的人脸，提取人脸及人体的辅助信息，以及图片的拍照时间，像机型号信息；识别引擎模块，从本地人物数据库中获得已训练的人脸的特征向量，并把待识别人物的特征向量与之对比进行识别，得到识别结果；用户确认模块，用于确认识别结果；调整识别引擎模块，根据确认的识别结果来调整识别引擎。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求1或2所述的综合利用人脸及人体辅助信息的交互式人脸识别系统，其特征在于：所述特征提取模块包括以下子模块：人脸特征点定位子模块，对于检测到的人脸，定位其中的人脸特征点；人脸图像变换处理子模块，根据检测到的特征点，对人脸图像进行归一化及仿射变换，使两眼位于固定位置，并截取固定大小的人脸图像；规范化处理子模块，采用对图像进行直方图均衡或归一化或对图像边缘进行模糊化处理或根据姿态对图像进行基于人脸模型的几何变换的方法对光照、背景、姿态进行规范化处理；人脸特征向量提取子模块，采用主成分分析或对图像特征点提取小波变换系数的方法提取人脸图像中的人脸特征向量；人体辅助信息提取子模块，提取衣服信息、头发信息、图片拍照时间、像机型号信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求1或2所述的综合利用人脸及人体辅助信息的交互式人脸识别系统，其特征在于：所述识别引擎模块包括以下子模块：对比子模块，计算两个特征向量之间的距离，欧氏距离或X2距离，如果有人物的辅助信息，在判断该辅助信息为唯一的情况下，并且拍摄时间接近，则把人脸距离和辅助信息距离加权相加，否则只使用人脸距离，在多个候选特征向量中，采用最近邻法，即选取距离最小的已知特征向量，如果没有特殊的辅助信息，则只用人脸信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求1或2所述的综合利用人脸及人体辅助信息的交互式人脸识别系统，其特征在于：调整识别引擎模块至少包括以下一个子模块：正确识别结果入库子模块，把正确识别的结果加到人脸数据库；错误识别结果入库子模块，把识别错误的结果以非某人的形式记录到人脸数据库，供以后识别的时候排斥该结果；识别引擎调整子模块，根据识别反馈的结果，采用相关反馈的方法调整识别引擎。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.综合利用人脸及人体辅助信息的交互式人脸识别方法，其特征在于：包括以下步骤：(1)自动检测人脸；(2)根据步骤(1)检测到的人脸确定人体特征区域；(3)提取人脸及人体辅助信息以及图片的拍照时间、像机型号信息；(4)排除非特殊的人体辅助信息；(5)综合利用人脸及特殊的辅助信息以及图片的拍照时间、像机型号信息进行识别，获得识别结果。7.如权利要求6所述的综合利用人脸及人体辅助信息的交互式人脸识别方法，其特征在于：所述步骤(1)中，检测人脸的方法为Adaboost方法。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">8.如权利要求6所述的综合利用人脸及人体辅助信息的交互式人脸识别方法，其特征在于：所述步骤(2)中，根据检测到的人脸的大小、位置，根据经验值确定人体特征区域。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">9.如权利要求6所述的综合利用人脸及人体辅助信息的交互式人脸识别方法，其特征在于：所述步骤(3)中，提取人体辅助信息为采用颜色直方图的方法在人体特征区域提取颜色信息，采用在人体特征区域进行频域变换，提取频域分布信息的方法在人体特征区域提取纹理信息，或提取图像的局域二值模式信息作为纹理信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">10.如权利要求6所述的综合利用人脸及人体辅助信息的交互式人脸识别方法，其特征在于：所述步骤(5)包括以下步骤：①首先选取像机型号相同，拍照时间相近的图片；②决定非特殊辅助信息：通过扫描合影中的辅助信息，如果两个辅助信息的距离小于某阈值，则认为是非特殊的辅助信息，或者对于已经用户标注的人脸，两两比较它们的辅助信息，如果非同一个人且两个辅助信息的距离小于某阈值，则认为是非特殊的辅助信息，非特殊的辅助信息存储于数据库中，待识别的辅助信息与数据库中非特殊的辅助信息对比，如果小于某阈值，则确定不利用该辅助信息识别该人物；③综合利用人脸信息和特殊的辅助信息进行识别：加权人脸信息和特殊的辅助信息的距离，加权信息记录于数据库，如果没有特殊的辅助信息，则只用人脸信息的距离；④用户确认识别结果；⑤根据确认结果调整识别引擎，如果前次识别结果利用了大量的辅助信息而识别结果错误，则把该辅助信息加入到非特殊的辅助信息数据库中。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES57814281" lang="ZH" load-source="patent-office" class="description">
    <invention-title lang="ZH">综合利用人脸及人体辅助信息的交互式人脸识别系统及方法</invention-title>
    <technical-field>
      <p>技术领域</p>
      <p>本发明涉及图像识别系统及方法，具体的说是综合利用人脸及人体辅助信息的交互式人脸识别系统及方法。</p>
    </technical-field>
    <background-art>
      <p>背景技术</p>
      <p>现有人脸识别系统主要用于安全监控等场合，通常是小规模封闭的系统，并且在这些系统中，大多只是单一利用了人脸信息进行识别。专利号为：200310120624.9，专利名称为：“移动计算环境下分布式的人脸检测与识别方法”的中国专利，是一个基于客户端/服务器架构的适用于移动网络的人脸识别系统。但是，该系统只利用了人脸信息。人脸信息容易受外部环境(比如光照)以及人脸姿态的影响，只利用人脸信息，识别性能有一定的局限性，同时，该系统没有引入用户的反馈，从而无法利用用户的反馈提高识别的性能。中国专利申请号为：02153265.6，专利名称为：“利用身材信息辅助人脸信息的身份识别方法”的中国专利，其基本原理是首先通过运动检测来检测人体，再检测人脸，然后利用身材信息和人脸信息进行识别。这个系统有几个缺点：首先，因为需要运动检测，该方法不适用于静止图像；其次，身材信息需要采集到完整人体，这个条件在许多实用系统中不满足；再次，人体检测的准确率通常不高，因而整个系统的准确率不高；再次，该系统没有引入用户的反馈，从而无法利用用户的反馈提高识别的性能；再次，该系统没有明确引入时间的概念，而身高信息和人脸信息的加权是预先定死的，但是很多时候可以知道身高信息是不准确的，机械的加权会导致识别错误；最后，该系统不是一个网络化的系统。</p>
    </background-art>
    <disclosure>
      <p>发明内容</p>
      <p>本发明的目的在于提出一种可提高识别的精度，可以应用于互联网的大规模的基于客户端、服务器架构的综合利用人脸及人体辅助信息的交互式人脸识别系统及方法，本发明可广泛应用于静止及活动图像中。</p>
      <p>本发明的目的可以通过以下技术方案来实现：综合利用人脸及人体辅助信息的交互式人脸识别系统，包括客户端、服务器，以及两者之间的通信线路，客户端包括以下模块：人脸检测模块，对输入的待识别图像，检测其中的人脸；特征提取模块，对于检测到的人脸，提取人脸及人体的辅助信息，以及图片的拍照时间，像机型号信息，并把相关特征向量通过通信线路传至服务器；用户确认模块，用于确认服务器传过来的识别结果，并把确认的识别结果通过通信线路传至服务器；服务器包括以下模块：人脸数据库模块，提供已训练的人物的特征向量；识别引擎模块，从人脸数据库中获得已训练的人物的特征向量，并把从客户端传过来的待识别人物的特征向量与之对比进行识别，来获得识别结果，并将识别结果通过通信线路传至用户确认模块；调整识别引擎模块，根据用户确认模块传过来的确认的识别结果来调整识别引擎。</p>
      <p>本发明的综合利用人脸及人体辅助信息的交互式人脸识别系统还可以为另一种组成结构，包括客户端、服务器，以及两者之间的通信线路，服务器包括以下模块：网络人脸数据库模块，提供人物特征向量数据；客户端包括以下模块：本地人脸数据库模块，在开始识别前，根据识别的任务，向服务器网络人脸数据库模块请求与识别任务匹配的人物特征向量集，并下载到本地人脸数据库中；人脸检测模块，对输入的待识别图像，检测其中的人脸；特征提取模块，对于检测到的人脸，提取人脸及人体的辅助信息，以及图片的拍照时间，像机型号信息；识别引擎模块，从本地人物数据库中获得已训练的人脸的特征向量，并把待识别人物的特征向量与之对比进行识别，得到识别结果；用户确认模块，用于确认识别结果；调整识别引擎模块，根据确认的识别结果来调整识别引擎。</p>
      <p>实现本发明目的的综合利用人脸及人体辅助信息的交互式人脸识别方法包括以下步骤：(1)自动检测人脸；(2)根据步骤(1)检测到的人脸确定人体特征区域；(3)提取人脸及人体辅助信息以及图片的拍照时间、像机型号信息；(4)排除非特殊的人体辅助信息；(5)综合利用人脸及特殊的辅助信息以及图片的拍照时间、像机型号信息进行识别，获得识别结果。</p>
      <p>本发明的目的还可以通过以下技术措施来进一步实现：前述的综合利用人脸及人体辅助信息的交互式人脸识别系统，特征提取模块包括以下子模块：人脸特征点定位子模块，对于检测到的人脸，定位其中的人脸特征点；人脸图像变换处理子模块，根据检测到的特征点，对人脸图像进行归一化及仿射变换，使两眼位于固定位置，并截取固定大小的人脸图像；规范化处理子模块，采用对图像进行直方图均衡或归一化或对图像边缘进行模糊化处理或根据姿态对图像进行基于人脸模型的几何变换的方法对光照、背景、姿态进行规范化处理；人脸特征向量提取子模块，采用主成分分析或对图像特征点提取小波变换系数的方法提取人脸图像中的人脸特征向量；人体辅助信息提取子模块，提取衣服信息、头发信息、图片拍照时间、像机型号信息。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别系统，识别引擎模块包括对比子模块：计算两个特征向量之间的距离，欧氏距离或X2距离，如果有人物的辅助信息，在判断该辅助信息为唯一的情况下，并且拍摄时间接近，则把人脸距离和辅助信息距离加权相加，否则只使用人脸距离，在多个候选特征向量中，采用最近邻法，即选取距离最小的已知特征向量，如果没有特殊的辅助信息，则只用人脸信息。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别系统，调整识别引擎模块至少包括以下一个子模块：正确识别结果入库子模块，把正确识别的结果加到人脸数据库；错误识别结果入库子模块，把识别错误的结果以非某人的形式记录到人脸数据库，供以后识别的时候排斥该结果；识别引擎调整子模块，根据识别反馈的结果，采用相关反馈的方法调整识别引擎。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别方法，步骤(1)中，检测人脸的方法为Adaboost方法。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别方法，步骤(2)中，根据检测到的人脸的大小、位置，根据经验值确定人体特征区域。例如，根据经验值建立一个模版，根据检测到的人脸的大小、位置来应用这个模版来确定人体特征区域。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别方法，步骤(3)中，提取人体辅助信息为采用颜色直方图的方法在人体特征区域提取颜色信息，采用在人体特征区域进行频域变换，提取频域分布信息的方法在人体特征区域提取纹理信息，也可以提取图像的局域二值模式(LBP，Locally&#160;Binary&#160;Pattern)信息。</p>
      <p>前述的综合利用人脸及人体辅助信息的交互式人脸识别方法，步骤(5)包括以下步骤：①首先选取像机型号相同，拍照时间相近的图片；②通过扫描合影中的辅助信息，如果合影中两个人的辅助信息的距离小于某阈值，则认为是非特殊的辅助信息，或者对于已经用户标注的人脸，两两比较它们的辅助信息，如果非同一个人且两个辅助信息的距离小于某阈值，则认为是非特殊的辅助信息，非特殊的辅助信息存储于数据库中，待识别的辅助信息与数据库中非特殊的辅助信息对比，如果小于某阈值，则确定不利用该辅助信息识别该人物；③综合利用人脸信息和特殊的辅助信息进行识别：加权人脸信息和特殊的辅助信息的距离，加权信息记录于数据库，如果没有特殊的辅助信息，则只用人脸信息；④用户确认识别结果；⑤根据确认结果调整识别引擎，如果前次识别结果利用了大量的辅助信息而识别结果错误，则把该辅助信息加入到非特殊的辅助信息数据库中。</p>
      <p>本发明的优点为：本发明是一种综合利用人脸及人体辅助信息的人脸识别系统，综合利用人脸及人体辅助信息可以提高识别的精度，通过人体辅助信息可以识别常规方法难以识别的人物。本发明是一种交互式的人脸识别系统，通过引入用户反馈并调整识别引擎，可以提高识别的精度。另外，本发明可以应用于互联网，是大规模的基于客户端、服务器架构的人脸识别系统，从架构上解决了支持大量用户的并发请求。</p>
    </disclosure>
    <description-of-drawings>
      <p>附图说明</p>
      <p>图1为本发明实施例一的系统框图。</p>
      <p>图2为本发明实施例二的系统框图。</p>
    </description-of-drawings>
    <mode-for-invention>
      <p>具体实施方式</p>
      <p>实施例一本实施例的系统框图如图1所示，一种综合利用人脸及人体辅助信息的交互式人脸识别系统，包括客户端、服务器，以及两者之间的通信线路。客户端可以为个人计算机(PC)，也可以为专用的硬件终端(基于专用芯片或数字信号处理器等)，也可以为移动终端(如移动电话)。通信线路可以为互联网，也可以为无线网络，还可以为专用通信线路(如用于安防等领域的专用通信线路)。客户端包括以下模块：人脸检测模块、特征提取模块、用户确认模块，服务器包括以下模块：人脸数据库模块、识别引擎模块、调整识别引擎模块。</p>
      <p>人脸检测模块对输入的待识别图像，检测其中的人脸，人脸检测可以采用Adaboost的方法。Adaboost方法在Paul&#160;Viola&#160;and&#160;MichaelJones，Rapid&#160;object&#160;detection&#160;using&#160;a&#160;boosted&#160;cascade&#160;of&#160;simplefeatures，CVPR，2001一文中有详细描述，在此不再赘述。</p>
      <p>特征提取模块进行特征向量提取包括以下步骤：对于检测到的人脸，定位其中的人脸特征点；根据检测到的特征点，对人脸图像进行归一化及仿射变换，使两眼位于固定位置，截取固定大小的人脸图像；对光照、背景、姿态进行规范化处理，可以采用的方法包括对图像进行直方图均衡或归一化，对图像边缘进行模糊化处理，根据姿态对图像进行基于人脸模型的几何变换等。在此基础上，提取人脸图像中的人脸特征，可以采用的方法为主成分分析(PCA)，或对图像特征点提取小波变换(如Gabor变换)系数，由此得到待识别人脸的特征向量。除了人脸信息，亦可以提取人体的辅助信息，可以作为有用的识别信息，包括头发、衣服、体形等。另外，图片的拍照时间，像机型号也是有用的信息，同时可以传给服务器。人脸信息，人体的辅助信息以及图片的拍照时间，像机型号共同组合成一个人物的特征向量。人体的信息的提取，我们以衣服为例，具体执行如下：选定衣服区域，这可以根据检测到的人脸的大小、位置、据经验值选定；在衣服区域提取颜色信息，这可以采用颜色直方图；在衣服区域提取纹理信息，这可以采用在衣服区域进行频域变换(如小波、GABOR、离散余旋变换等)，提取频域的分布信息，或者提取图像的局域二值模式(LBP，Locally&#160;Binary&#160;Pattern)信息；提取图片的拍照时间、像机型号信息。</p>
      <p>客户端把待识别人物的特征向量通过通信线路传给服务器，服务器中的识别引擎模块从人脸数据库中获得已训练的人物的特征向量，并把待识别人物的特征向量与之对比进行识别。比对通常是计算两个特征向量之间的距离，该距离可以采用欧氏距离、X2距离等。如果有人物的辅助信息，在判断该辅助信息为唯一的情况下，并且拍摄时间接近，则把人脸距离和辅助信息距离加权相加，如果没有特殊的辅助信息，则只用人脸信息。在多个候选特征向量中，可以采用最近邻法(kNN)，即选取距离最小的已知特征向量，如果该距离小于某一个预先确定的阈值，该特征向量的人名即为待识别人物的人名。</p>
      <p>服务器把识别的结果通过通信线路传给客户端，用户确认识别结果，客户端把识别结果的确认传给服务器，服务器中调整识别引擎模块执行以下之一或全部：把正确识别的结果加到人脸数据库；把识别错误的结果以非某人的形式记录到人脸数据库，供以后识别的时候排斥该结果；根据识别反馈的结果，用相关反馈(Relevance&#160;Feedback)的方法调整识别引擎。一种相关反馈的具体实现方法是调整识别引擎中各维特征向量加权的权重，把更多的权重赋给有助于区分不同人的特征向量维数。</p>
      <p>在识别的时候，综合利用人脸及辅助信息的方法包括：首先选取像机型号相同，拍照时间相近的图片；决定非特殊的辅助信息：通过扫描合影中的辅助信息，如果两个辅助信息小于某阈值，则认为是非特殊的辅助信息。另一种决定非特殊辅助信息的方法是，对于已经用户标注的人脸，两两比较它们的辅助信息，如果非同一个人且两个辅助信息的距离小于某阈值，则认为是非特殊的辅助信息；非特殊的辅助信息存储于数据库中，待识别的辅助信息与数据库中非特殊的辅助信息进行对比，如果小于某阈值，则确定不利用特殊的辅助信息识别该人物；综合利用人脸信息和特殊的辅助信息进行识别，综合的方法是加权人脸信息和特殊的辅助信息的距离，加权信息记录于数据库；如果没有特殊的辅助信息，则只用人脸信息；用户确认识别结果；根据确认结果调整识别引擎，如果前次识别结果利用了大量的辅助信息而识别结果错误，则把该辅助信息加入到非特殊的辅助信息数据库中。</p>
      <p>实施例二本实施例的系统框图如图2所示，一种综合利用人脸及人体辅助信息的交互式人脸识别系统，包括客户端、服务器，以及两者之间的通信线路。客户端可以为个人计算机(PC)，也可以为专用的硬件终端(基于专用芯片或数字信号处理器等)，也可以为移动终端(如移动电话)。通信线路可以为互联网，也可以为无线网络，还可以为专用通信线路(如用于安防等领域的专用通信线路)。客户端包括以下模块：本地人脸数据库模块、人脸检测模块、特征提取模块、识别引擎模块、用户确认模块，服务器包括网络人脸数据库模块。</p>
      <p>在开始识别前，客户端需根据识别的任务，向服务器网络人脸数据库模块请求与识别任务匹配的人脸特征向量集、并下载到客户端本地人脸数据库模块中。</p>
      <p>人脸检测模块对输入的待识别图像，检测其中的人脸，人脸检测可以采用Adaboost的方法。Adaboost方法在Paul&#160;Viola&#160;and&#160;MichaelJones，Rapid&#160;object&#160;detection&#160;using&#160;a&#160;boosted&#160;cascade&#160;of&#160;simplefeatures，CVPR，2001一文中有详细描述，在此不再赘述。</p>
      <p>特征提取模块进行特征向量提取，具体执行与实施例一相同。客户端把待识别人物的特征向量及辅助信息输给识别引擎模块。识别引擎模块从本地人物数据库中获得已训练的人脸的特征向量，并把待识别人物的特征向量与之对比进行识别。比对通常是计算两个特征向量之间的距离，该距离可以采用欧氏距离、X2距离等。如果有人物的辅助信息，在判断该辅助信息为唯一的情况下，并且拍摄时间接近，则把人脸距离和辅助信息距离加权相加，如果没有特殊的辅助信息，则只用人脸信息。在多个候选特征向量中，可以采用最近邻法(kNN)，即选取距离最小的已知特征向量，如果该距离小于某一个预先确定的阈值，该特征向量的人名即为待识别人物的人名。</p>
      <p>用户确认识别结果，根据确认结果调整识别引擎，可以采用以下之一或全部：把正确识别的结果加到人脸数据库；把识别错误的结果以非某人的形式记录到人脸数据库，供以后识别的时候排斥该结果；根据识别反馈的结果，采用相关反馈(Relevance&#160;Feedback)的方法调整识别引擎。一种相关反馈的具体实现方法是调整识别引擎中各维特征向量加权的权重，把更多的权重赋给有助于区分不同人的特征向量维数。</p>
      <p>本实施例的综合利用人脸及辅助信息的方法与实施例一相同，在此不再赘述。</p>
      <p>本发明还可以有其它实施方式，凡采用同等替换或等效变换形成的技术方案，均落在本发明要求保护的范围之内。</p>
    </mode-for-invention>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101232571B?cl=zh">CN101232571B</a></td><td class="patent-data-table-td patent-date-value">2008年1月25日</td><td class="patent-data-table-td patent-date-value">2010年6月9日</td><td class="patent-data-table-td ">北京中星微电子有限公司</td><td class="patent-data-table-td ">一种人体图像匹配方法及视频分析检索系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102201061A?cl=zh">CN102201061A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2011年9月28日</td><td class="patent-data-table-td ">常州锐驰电子科技有限公司</td><td class="patent-data-table-td ">基于多阶层过滤人脸识别的智能安全监控系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102201061B?cl=zh">CN102201061B</a></td><td class="patent-data-table-td patent-date-value">2011年6月24日</td><td class="patent-data-table-td patent-date-value">2012年10月31日</td><td class="patent-data-table-td ">常州锐驰电子科技有限公司</td><td class="patent-data-table-td ">基于多阶层过滤人脸识别的智能安全监控系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102332086A?cl=zh">CN102332086A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年6月15日</td><td class="patent-data-table-td patent-date-value">2012年1月25日</td><td class="patent-data-table-td ">夏东</td><td class="patent-data-table-td ">一种基于双阈值局部二进制模式的人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102446269A?cl=zh">CN102446269A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2012年5月9日</td><td class="patent-data-table-td ">微盟电子(昆山)有限公司</td><td class="patent-data-table-td ">可抑制杂讯及环境影响的脸部识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102446269B?cl=zh">CN102446269B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年10月15日</td><td class="patent-data-table-td patent-date-value">2015年10月14日</td><td class="patent-data-table-td ">微盟电子(昆山)有限公司</td><td class="patent-data-table-td ">可抑制杂讯及环境影响的脸部识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102467088A?cl=zh">CN102467088A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年11月16日</td><td class="patent-data-table-td patent-date-value">2012年5月23日</td><td class="patent-data-table-td ">富士康科技股份有限公司</td><td class="patent-data-table-td ">人脸识别闹钟及其闹醒用户的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102831396A?cl=zh">CN102831396A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月23日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">常州蓝城信息科技有限公司</td><td class="patent-data-table-td ">一种计算机人脸识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102833486A?cl=zh">CN102833486A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年7月5日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">深圳泰山在线科技有限公司</td><td class="patent-data-table-td ">一种实时调节视频图像中人脸显示比例的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102981619A?cl=zh">CN102981619A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月19日</td><td class="patent-data-table-td patent-date-value">2013年3月20日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种基于移动终端用户衣服的颜色更换主题的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102981619B?cl=zh">CN102981619B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年11月19日</td><td class="patent-data-table-td patent-date-value">2015年12月2日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种基于移动终端用户衣服的颜色更换主题的方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103076879A?cl=zh">CN103076879A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年12月28日</td><td class="patent-data-table-td patent-date-value">2013年5月1日</td><td class="patent-data-table-td ">中兴通讯股份有限公司</td><td class="patent-data-table-td ">基于人脸信息的多媒体交互方法及装置及终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103119625A?cl=zh">CN103119625A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月16日</td><td class="patent-data-table-td patent-date-value">2013年5月22日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">一种视频人物分割的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103119625B?cl=zh">CN103119625B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月16日</td><td class="patent-data-table-td patent-date-value">2015年6月3日</td><td class="patent-data-table-td ">华为技术有限公司</td><td class="patent-data-table-td ">一种视频人物分割的方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103368745A?cl=zh">CN103368745A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月19日</td><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">江南大学</td><td class="patent-data-table-td ">一种教育信息资源保障的用户身份强认证方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103368929A?cl=zh">CN103368929A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年4月11日</td><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">一种视频聊天方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103368929B?cl=zh">CN103368929B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年4月11日</td><td class="patent-data-table-td patent-date-value">2016年3月16日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">一种视频聊天方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9094571">US9094571</a></td><td class="patent-data-table-td patent-date-value">2013年2月22日</td><td class="patent-data-table-td patent-date-value">2015年7月28日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">Video chatting method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013152639A1?cl=zh">WO2013152639A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年2月22日</td><td class="patent-data-table-td patent-date-value">2013年10月17日</td><td class="patent-data-table-td ">Tencent Technology (Shenzhen) Company Limited</td><td class="patent-data-table-td ">一种视频聊天方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014075430A1?cl=zh">WO2014075430A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月7日</td><td class="patent-data-table-td patent-date-value">2014年5月22日</td><td class="patent-data-table-td ">Guang Dong Oppo Mobile Telecommunications Corp., Ltd</td><td class="patent-data-table-td ">一种基于移动终端用户衣服的颜色更换主题的方法及系统</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=PueGAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0009320000">H04L9/32</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=PueGAAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2007年8月22日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2007年10月17日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年4月29日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年4月30日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090327</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">NANJING MINGMAI SHIXUN SCIENCE CO., LTD.</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: NANJING SOUPAI INFORMATION TECHNOLOGY CO., LTD.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年10月28日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SHANGHAI BOKANG INTELLIGENT INFORMATION TECHNOLOGY</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: NANJING MINGMAI SHIXUN SCIENCE CO., LTD.</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090925</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2009年10月28日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of the right of patent application or the patent right</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年1月13日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/c3b4fa2b241ecd71094a/CN101021899A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%BB%BC%E5%90%88%E5%88%A9%E7%94%A8%E4%BA%BA%E8%84%B8%E5%8F%8A%E4%BA%BA%E4%BD%93%E8%BE%85%E5%8A%A9%E4%BF%A1%E6%81%AF.pdf?id=PueGAAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0_qTI5OvEfhcIKGcYeZoath1fmoA"},"sample_url":"https://www.google.com/patents/reader?id=PueGAAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>