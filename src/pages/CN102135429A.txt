<!DOCTYPE html><html><head><title>专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_5115ea495017d9115e613207d3810e5a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_5115ea495017d9115e613207d3810e5a__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种基于视觉的机器人室内定位导航方法"><meta name="DC.contributor" content="杨彪" scheme="inventor"><meta name="DC.contributor" content="林国余" scheme="inventor"><meta name="DC.contributor" content="王东" scheme="inventor"><meta name="DC.contributor" content="王海" scheme="inventor"><meta name="DC.contributor" content="蔡英凤" scheme="inventor"><meta name="DC.contributor" content="东南大学" scheme="assignee"><meta name="DC.date" content="2010-12-29" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种基于视觉的机器人室内定位导航方法，属于视觉导航领域。该方法是根据二维码的思路，设计了一种简单方便、易于识别、内含绝对位置坐标且具有一定纠错能力的人工路标，将路标设置于天花板上，由安装在机器人上且光轴与天花板垂直的摄像机进行拍摄，再通过图像的阈值分割、连通域提取、轮廓曲线匹配以及路标特征识别一系列步骤定位路标，解析路标中所包含的坐标信息，最终通过机器人的位置估计算法获得机器人当前的绝对位置和航向角。本发明方法减少了遮挡及噪声干扰，大大降低了图像处理方法、时间以及周围环境的复杂度。"><meta name="DC.date" content="2011-7-27"><meta name="DC.relation" content="CN:101539426:A" scheme="references"><meta name="DC.relation" content="CN:101576384:A" scheme="references"><meta name="DC.relation" content="CN:101619985:A" scheme="references"><meta name="DC.relation" content="CN:1707223:A" scheme="references"><meta name="citation_reference" content="《机器人》 20070915 石朝侠等 大规模环境下的拓扑地图创建与导航 , 第05期 2"><meta name="citation_reference" content="《系统工程与电子技术》 20010720 肖海荣等 基于多传感器数据融合的移动机器人导航 , 第07期 2"><meta name="citation_reference" content="《高技术通讯》 20080425 郑睿等 一种用于移动机器人室内定位与导航的二维码 , 第04期 2"><meta name="citation_patent_publication_number" content="CN:102135429:A"><meta name="citation_patent_application_number" content="CN:201010611473"><link rel="canonical" href="https://www.google.com/patents/CN102135429A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102135429A?cl=zh"/><meta name="title" content="专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法"/><meta name="description" content="本发明公开了一种基于视觉的机器人室内定位导航方法，属于视觉导航领域。该方法是根据二维码的思路，设计了一种简单方便、易于识别、内含绝对位置坐标且具有一定纠错能力的人工路标，将路标设置于天花板上，由安装在机器人上且光轴与天花板垂直的摄像机进行拍摄，再通过图像的阈值分割、连通域提取、轮廓曲线匹配以及路标特征识别一系列步骤定位路标，解析路标中所包含的坐标信息，最终通过机器人的位置估计算法获得机器人当前的绝对位置和航向角。本发明方法减少了遮挡及噪声干扰，大大降低了图像处理方法、时间以及周围环境的复杂度。"/><meta property="og:title" content="专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102135429A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102135429A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=FMCXBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102135429A&amp;usg=AFQjCNG_Ji9M2JPW9gfdSncUI9SPYjYY1A" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/598f2e879a93c340d663/CN102135429A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/598f2e879a93c340d663/CN102135429A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102135429A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102135429A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102135429A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102135429B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102135429A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种基于视觉的机器人室内定位导航方法，属于视觉导航领域。该方法是根据二维码的思路，设计了一种简单方便、易于识别、内含绝对位置坐标且具有一定纠错能力的人工路标，将路标设置于天花板上，由安装在...</span><span itemprop="url">https://www.google.com/patents/CN102135429A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法" title="专利 CN102135429A - 一种基于视觉的机器人室内定位导航方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102135429 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010611473</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年7月27日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年12月29日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年12月29日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102135429B?hl=zh-CN&amp;cl=zh">CN102135429B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010611473.7, </span><span class="patent-bibdata-value">CN 102135429 A, </span><span class="patent-bibdata-value">CN 102135429A, </span><span class="patent-bibdata-value">CN 201010611473, </span><span class="patent-bibdata-value">CN-A-102135429, </span><span class="patent-bibdata-value">CN102135429 A, </span><span class="patent-bibdata-value">CN102135429A, </span><span class="patent-bibdata-value">CN201010611473, </span><span class="patent-bibdata-value">CN201010611473.7</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9D%A8%E5%BD%AA%22">杨彪</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9E%97%E5%9B%BD%E4%BD%99%22">林国余</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E4%B8%9C%22">王东</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%8E%8B%E6%B5%B7%22">王海</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%94%A1%E8%8B%B1%E5%87%A4%22">蔡英凤</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6%22">东南大学</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102135429A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102135429A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102135429A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#npl-citations">非专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (32),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (1),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (4)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=FMCXBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010611473&amp;usg=AFQjCNF7BcmUNP3uWZX7OTGl71UnireV4g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=FMCXBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102135429A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH2GSq9W0bvgAI-r838BURNr6F-YA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT104313005" lang="ZH" load-source="patent-office">一种基于视觉的机器人室内定位导航方法</invention-title>
      </span><br><span class="patent-number">CN 102135429 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA86216476" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种基于视觉的机器人室内定位导航方法，属于视觉导航领域。该方法是根据二维码的思路，设计了一种简单方便、易于识别、内含绝对位置坐标且具有一定纠错能力的人工路标，将路标设置于天花板上，由安装在机器人上且光轴与天花板垂直的摄像机进行拍摄，再通过图像的阈值分割、连通域提取、轮廓曲线匹配以及路标特征识别一系列步骤定位路标，解析路标中所包含的坐标信息，最终通过机器人的位置估计算法获得机器人当前的绝对位置和航向角。本发明方法减少了遮挡及噪声干扰，大大降低了图像处理方法、时间以及周围环境的复杂度。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(3)</span></span></div><div class="patent-text"><div mxw-id="PCLM37823015" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种基于视觉的机器人室内定位导航方法，其特征在于：该方法包括以下内容：(1)设计一种基于二维条形码的人工路标，并将此种路标作为机器人室内定位定向的 路标；(2)假设室内天花板是一个矩形，在天花板平面根据导航定位的需求进行网格划分，并 构建全局坐标系，确定每个网格交叉点的平面坐标，然后将路标中心对准网格交叉点粘贴 在天花板上；(3)在机器人上安装有光轴垂直于天花板平面的摄像机，由该摄像机拍摄天花板的图 像，机器人根据拍摄的图像进行路标检测、识别和解析，并计算出机器人当前位置和航向 角，从而实现机器人在室内环境中的导航定位。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的基于视觉的机器人室内定位导航方法，其特征在于：所述基 于二维条形码的人工路标是采用两种不同颜色的方块组成的正方形，一种颜色代表二进制 的1，另一种颜色代表二进制的0，该种路标包含隔离区、判别区和数据区三个部分。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的基于视觉的机器人室内定位导航方法，其特征在于：所述全 局坐标系的坐标轴离散为m’列η’行，形成m’ Xn'个网格交叉点，每个网格交叉点的坐标 为（ΧΛΥ/)，1彡i，彡m，，l彡j，彡n，，其中i，、j，、m，、n，均为自然数。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES43402055" lang="ZH" load-source="patent-office" class="description">
    <p>一种基于视觉的机器人室内定位导航方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及一种导航方法，尤其涉及一种基于视觉的机器人室内定位导航方法， 属于视觉导航领域。</p>
    <p>背景技术</p>
    <p>[0002]	室内机器人的定位定向是室内机器人领域的一个重要研究热点。由于室内存在卫 星信号屏蔽，因此GPS等卫星定位方法在室内无法发挥其定位快速准确的优势。利用无线 传感网进行室内定位是当前的热门研究方向，然而该方法一般采用基于链路质量指标或接 收信号强度获取节点相对位置的方法实现节点定位，定位精度差，误差甚至可达25%，无法 满足室内精确定位的要求。</p>
    <p>[0003]	随着图像处理技术的发展，基于人工路标的机器人视觉导航定位得到了广泛应 用。如文献“章小兵，宋爱国，唐鸿儒.基于视觉的室内移动机器人精确定位方法[J].数 据采集与处理，2007，22 O) =196-200. ”提出了利用贴在天花板上的人工混合编码路标进行 定位的方法，路标上标有序号编码和不对称方向沟道，能识别360度航向角，并容易进行扩 展；文献“陆军，穆海军，朱齐丹等.全景视觉在机器人自主定位中的应用[J].计算机应用， 2007，27 (7) :1677-1679.，，及文献 “Chih Jen Wu，Wen Hsiang Tsai. Location estimation for indoor autonomous vehicle navigation by omni-directional vision using circular landmarks on ceilings[J]. Robotics andAutonomous Systems,2009,57(5)： 546-555.，，提出了基于全景视觉的机器人自主定位方法，通过全景摄像机拍摄机器人周围 环境的全方位景物图像，从中识别出机器人周围环境的已知路标，通过三角定位法获得机 器人的当前坐标；文献“Weiguo Lin, Songmin Jia，Takafumi Abe，et al. . Localization of mobile robot based on ID tag and WEB camera[C]. Proceeding of the 2004IEEE Conference on Robotics，Automation and Mechatronics，Singapore，2004，2 :851-856. ” 提出了 RFID技术与计算机视觉相结合的定位方法，将室内环境用节点树表示，每个节点由 ID标签和颜色卡片两个路标组成，将其安装于天花板，通过RFID技术识别ID标签，并通过 摄像机识别路标位置和方向，从而实现机器人准确可靠的定位；文献“Jinwook Huh, Woong SikChung，Sang Yep Nam，et al. . Mobile Robot Exploration in Indoor Environment Using TopologicalStructure with Invisible Barcodes[C]. IEEE/RSJ International Conference on Intelligent Robots andSystems，Bei jing，2006，29 (2) :5265-5272.，，提 出了一种用于小型地面清洁机器人的定位方法，将包含绝对位置信息的二维条形码粘贴在 地面上作为路标，路标只有在紫外灯照射下可见，并采用红外测距模块测量机器人和路标 间的距离。</p>
    <p>[0004]	上述这些方法存以下缺点：1)路标常常放置于地面上，容易被周围过往的其它机 器人所干扰；幻一些简单的路标虽然图像处理简单，但是不具备纠错性，而一些复杂路标 虽然具有完整数据纠错性，但是图案过于复杂，实时性差；3)不容易扩展到大环境下的机 器人室内定位导航。发明内容</p>
    <p>[0005]	本发明针对现有技术的不足，而提出一种自动化程度高、路标设计简单且图像处 理实时性高的基于视觉的机器人室内定位导航方法。</p>
    <p>[0006]	该方法包括如下内容：</p>
    <p>[0007]	(1)设计一种基于二维条形码的人工路标，该人工路标是采用两种不同颜色的方 块组成的正方形，一种颜色代表二进制的1，另一种颜色代表二进制的0，该种路标包含隔 离区、判别区和数据区三个部分，将此种路标作为机器人室内定位定向的路标；</p>
    <p>[0008]	(2)假设室内天花板是一个矩形，在天花板平面根据导航定位的需求进行网格划 分，并构建全局坐标系，该全局坐标系的坐标轴离散为m’列η’行，形成m’ Xn'个网格交 叉点，每个网格交叉点的坐标为（Χ/，Υ/ )，1彡i，^mM ^ j，彡n’，其中i，、j，、m，、n， 均为自然数，然后将路标中心对准网格交叉点粘贴在天花板上；</p>
    <p>[0009]	(3)在机器人上安装有光轴垂直于天花板平面的摄像机，由该摄像机拍摄天花板 的图像，机器人根据拍摄的图像进行路标检测、识别和解析，并计算出机器人当前位置和航 向角，从而实现机器人在室内环境中的导航定位。</p>
    <p>[0010]	与现有技术相比，本发明具有以下技术效果：</p>
    <p>[0011]	(1)本发明采用相对空旷和背景简单的天花板作为人工路标的摆放位置，周围没 有其它活动物体的影响，有利于减少遮挡以及噪声干扰。</p>
    <p>[0012]	(2)本发明中所设计的二维码人工路标包含了平面坐标，并采用Hamming码进行 数据编码。与现有的不带数据编码功能的人工路标相比，本发明中的人工路标具有一定的 纠错性；与采用MR Code和QR Code进行数据编码的人工路标相比，本发明中的人工路标所 需的图像处理方法、时间复杂度以及周围环境复杂度的要求都大大降低。</p>
    <p>[0013]	(3)本发明中涉及的机器人位置估计算法属于一种绝对定位方法，只要在摄像机 视野中出现一个完整的路标，即可根据简单的数学计算公式推导出机器人当前位置和航 向。</p>
    <p>附图说明</p>
    <p>[0014]	图1为本发明中人工路标的构造示意图。</p>
    <p>[0015]	图2为本发明中的人工路标粘贴在天花板上的示意图。</p>
    <p>[0016]	图3为本发明中基于极值特征不变性的机器人定位导航功能算法的流程图。</p>
    <p>[0017]	图4为两个直线组生成新直线的示意图。</p>
    <p>[0018]	图5(a)&#12316;（d)分别为人工路标的四种摆放方式示意图。</p>
    <p>[0019]	图6为机器人位置估计示意图，图中：A表示拍摄的图像中的路标中心；B表示拍 摄的图像中心；C表示拍摄的图像中的路标判别区原点。</p>
    <p>具体实施方式</p>
    <p>[0020]	下面结合附图对本发明作进一步说明。</p>
    <p>[0021]	本发明的基于视觉的机器人室内定位导航方法，主要包括如下内容：</p>
    <p>[0022]	(1)设计一种基于二维条形码的人工路标，并将此种路标作为机器人室内定位定向的路标；</p>
    <p>[0023]	该人工路标的构造如图1所示，其是由两种不同颜色的方块组成的正方形，两种 颜色应尽量有强烈对比，图中以黑白两种颜色为例，黑色方块代表二进制的1，白色方块代 表二进制的0;</p>
    <p>[0024]	(2)假设室内天花板是一个宽度w米、长度h米的矩形，在天花板平面根据导航定 位的需求进行网格划分，并构建全局坐标系，该全局坐标系的坐标轴离散为m’列η’行，形 成m’ Χη’个网格交叉点，每个网格交叉点的坐标为（X/，Y/ )，1彡i’彡m’，1彡j’彡η’， 其中i’、j’、m’、n’均为自然数，然后将路标中心对准网格交叉点粘贴在天花板上，如图2所 示；</p>
    <p>[0025]	(3)在机器人上安装有光轴垂直于（不要求严格垂直）天花板平面的摄像机，由该 摄像机拍摄天花板的图像，机器人根据拍摄的图像进行路标检测、识别和解析，并计算出机 器人当前位置和航向角，从而实现机器人在室内环境中的导航定位。</p>
    <p>[0026]	本发明所设计的路标包含隔离区、判别区和数据区三个部分，每个部分的具体含 义如下：</p>
    <p>[0027]	i)隔离区。在路标判别区的外围保留一定宽度的空白区，称之为隔离区，它的作用 是进行图像二值化分割操作时能够保证将路标区域完整地分割出来；</p>
    <p>[0028]	ii)判别区。判别区具有两个作用：①根据判别区的存在与否来判断图像中某个 连通域是否属于路标；②判别区规定了数据区中数据的读取规则，比如当判别区处于如图 1所示的方位时（图中判别区原点C在路标的左下角），此时将按照从下到上、从左到右的 顺序读取数据，图 1 中数据区的数据为 00000000111000000011001000000000011100000110 0110 ；</p>
    <p>[0029]	iii)数据区。数据区表示路标在天花板平面上所处的平面坐标，共由8X6个黑白 方块组成。为了提高路标识别的鲁棒性，采用带自纠错功能的Hamming编码方法对数据进 行编码，当数据出现单比特错误时能进行自动纠错，采用Hamming编码是因为目前能够进 行任意位数据纠错的编码方法（如QR编码等）存在如下不足：①算法十分复杂，实时性差， 难以进行实时定位导航；②经过编码后的数据长度很长，这样在一定面积区域中，黑白方块 数量过于集中，降低了路标可视性，大大提高了图像的处理难度。而采用Hamming编码方法 后，算法相对简单，只需不到1毫秒的时间即可完成单比特错误的检测和自动纠错，实时性 高；而且Sbit长度的数据经过Hamming编码后长度仅为12bit，保证了路标的可视性。综 上所述，数据区中的8 X 6个黑白方块一共可以表示4个字节长度的数据（8 X 6/12 = 4)，分 别表示平面坐标X的高字节和低字节以及平面坐标Y的高字节和低字节。即平面坐标X、Y 各用两个字节表示，这样最多可以代表65536X65536个位置，由此可见其可以适用于大环 境下的定位导航。</p>
    <p>[0030]	本发明中机器人的定位导航功能算法流程如图3所示，具体包括如下步骤：</p>
    <p>[0031]	步骤1 ：根据不同颜色漫反射不同的原理进行图像阈值分割，获得黑白二值化图 像；</p>
    <p>[0032]	步骤2 ：采用基于邻域搜索的连通域检测算法，在黑白二值化图像中检测所有可 能属于路标目标的区域，记录这些区域内的目标点，并提取这些区域的轮廓；</p>
    <p>[0033]	该检测算法的具体内容如下：[0034]	1)在所获得的二值化图像中找出一个目标像素，并对其标记，再将其置于先入先 出的堆栈中；</p>
    <p>[0035]	2)从先入先出的堆栈中取出一个目标像素，在二值化图像中的该目标像素周围 5X5邻域中再次寻找未标记的目标像素，对此次找出的目标像素进行标记，并将其置于先 入先出的堆栈中；</p>
    <p>[0036]	3)按步骤2、所述，遍历先入先出堆栈中的各个目标像素；</p>
    <p>[0037]	4)对步骤3)所得的目标像素进行噪声判断，将总数量小于阈值T的目标像素作</p>
    <p>为噪声，并将其颜色改为背景色；反之，将目标像素作为一类可能的路标目标上的点予以保</p>
    <p>存，并将其颜色改为背景色，上述阈值T的计算公式为： f \2 f fxW 1 I</p>
    <p>[0038]	Γ = 0.3 χ J L χ &#8212;</p>
    <p>[0039]	其中：f表示摄像机的焦距，dp表示摄像机CXD上每个像素的大小，D表示摄像机 与天花板的距离，W^表示路标的实际边长，丨和&#12316;可以根据所采用摄像机型号的参数指标 获得；</p>
    <p>[0040]	5)重复步骤1)&#12316;4)，得到各类可能的路标目标上的点，并分别予以保存；</p>
    <p>[0041]	步骤3 ：对步骤2所获得的各类可能的路标目标进行初步判别，方法为：分别统计 每个可能路标目标最小横坐标^cmin，最大横坐标^liax，最小纵坐标ymin和最大纵坐标ymax，得 到包含这个可能路标目标的最小外接矩形，最小外接矩形的四个点坐标分别为Umin，yfflin), (x_，ymin)，Ocmax，y_)和（xmin，ymJ，最小外接矩形的两个边长Wjnw2分别为Umax^min)和 (yfflax-yfflin)；若边长W1大于边长W2，令σ =W2A1，否则，令σ = ；若σ &lt;0.6，则说明 该可能路标目标不是真实路标，予以剔除，否则予以保留，通过后续步骤进一步判断；</p>
    <p>[0042]	步骤4 ：对于步骤3判别后的各类可能的路标目标，分别提取它们的闭合轮廓，具 体方法如下：</p>
    <p>[0043]	1)对于某类可能的路标目标，在图像上按照从上到下的顺序进行扫描，将遇到的 第一个该类可能路标目标上的点保存起来；</p>
    <p>[0044]	2)对于同一类可能的路标目标，在图像上依次按照从下到上、从左到右和从右到 左的顺序进行扫描，判断扫描到的第一个该类可能路标目标上的点是否已经保存过，如果 未保存，则保存该点，否则继续扫描操作；</p>
    <p>[0045]	3)重复步骤1)和步骤幻，直至遍历完所有可能的路标目标；</p>
    <p>[0046]	步骤1)&#12316;幻所保存的各类点集就构成了各类可能的路标目标的闭合轮廓；</p>
    <p>[0047]	步骤5 ：由于实际路标为正方形，判断步骤4所获得的各类可能路标目标的闭合轮 廓是否近似于正方形；</p>
    <p>[0048]	这里采用基于极值特征的形状匹配算法进行外廓形状判别，若闭合轮廓符合正方 形形状，则执行下一步骤，从而进一步剔除了虚假目标；</p>
    <p>[0049]	步骤6 ：对于经过步骤5外廓形状判别后的可能路标目标的闭合轮廓，利用Hough 直线提取算法获得闭合轮廓的四条轮廓直线，此时闭合轮廓近似于正方形，所以这四条 轮廓直线可以分为两组相互近似垂直的直线组，且每组直线内包含两条近似平行的直 线，即假设四条轮廓直线为In、112、121、I22，可分为两组，其中In、I12为一组，121、、为 另一组，对应的角度和幅值分别为1011、1012、1021、Ie22和1A11、1A12&gt; 1a21&gt; Ia22，则它们应满足下面三个判别条件：① Il011-I012I &lt; E1 and Ie21-Ie22I &lt; (② 110 n_l 021_90 &lt; ε 2 and 110 n_l 0 22_90 | &lt; ε 2and 11012_1021_90 | &lt; ε 2and 11 θ 12-1 θ22-90 &lt; ε 2， ③ I 11Α11-1Α12 H 1Α21-1Α221 &lt; ε 3，其中 ε 1&gt; ε2&gt; ε 3 为阈值，分别取 10、20、15 ;</p>
    <p>[0050]	步骤7 ：对上述生成的两组直线分别进行新直线生成处理，假设直线1η、112、121、 I22的斜率和节距分别为kan、ka12、k&#163;i21、k&#163;i22和I^a11Ja12Ja21Ja22,以直线组中两条近似平 行的直线为基础，生成9条新直线，这样包括原先的两条直线，每组直线各自包含11条直线 (如图4所示）；</p>
    <p>[0051]	两组直线I1i和I2iG = 1，2... 11)的斜率Icji和节距、的计算公式如下：</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00071.png"> <img id="idf0001" file="CN102135429AD00071.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00071.png" class="patent-full-image" alt="Figure CN102135429AD00071"> </a> </div>
    <p>[0054]	如图4所示，此时在直线组中，原先的4条轮廓直线ln、l12、l21、U分别对应于1\、 I1 I2 I2 .</p>
    <p>&#19972;n、&#19972;i、&#19972;n ，</p>
    <p>[0055]	步骤8 ：如图4所示，利用两组直线I1i和I2i将可能路标目标分割成10行10列共 100个子方块，假设某个子方块位于第m行、第η列，则该子方块四个顶点的坐标可由直线 I1-、I1ffl.!和12η、12&#8222;+1分别计算交点获得，这样就获得了每个子方块四个顶点的坐标；</p>
    <p>[0056]	步骤9 ：将分割后的10行10列共100个子方块用10X10的二维数组A表示， 假设位于第m行、第η列子方块四个顶点的坐标分别为（Xl，yi)、（x2，y2)、(x3, y3)和（x4， y4)，子方块的长度和宽度分别为ws和hs，则子方块质心（χ。，y0) = ((χι+χ2+χ3+χ4) /4， (7:+72+73+74)/4)；在以质心（xQ，yQ)为中心、长和宽分别为（ws/2+l)和（hs/2+l)的区域内， 统计黑色像素的个数，记为队，如果满足队/((^/2+1)\0!3/2+1))彡70%，则A[m，n] = 1， 否则 A[m，η] = 0 ；</p>
    <p>[0057]	步骤10 ：根据路标的判别区特征，其最外面一圈为黑色，则二值化图像中其对应 的子方块为黑色像素构成，因此判断二维数组A的第1行、第1列、第10行、第10列共36个 数组元素是否都等于1，如果是，执行后续步骤，否则说明该可能的路标目标并不是路标；</p>
    <p>[0058]	步骤11 ：确定判别区原点C的位置；</p>
    <p>[0059]	根据路标设计时判别区的特点可知，判别区原点C可以是路标四个角点中的一 个，如图5所示，图5(a)中判别区原点C位于路标的左下角，图5(b)中判别区原点C位于 路标的右下角，图5(c)中判别区原点C位于路标的右上角，图5(d)中判别区原点C位于路 标的左上角；</p>
    <p>[0060]	图5中路标外部的数字代表二维数组A的下标，路标内部方块上标注的数字表示 二维数组A中该位置元素的值，箭头方向表示数据读取方向；</p>
    <p>[0061]	根据路标设计时数据判别区的特征，判断该可能的路标目标是否满足如下的某个 条件：</p>
    <p>[0062]	①以Α[2，1]和Α[3，1]为首的两列元素分别等于1010101011和1101010101 ；</p>
    <p>[0063]	②以Α[10，2]和Α[10，3]为首的两行元素分别等于1010101011和1101010101 ；</p>
    <p>[0064]	③以Α[9,10]和Α[8，10]为首的两列元素分别等于1010101011和1101010101 ；</p>
    <p>[0065]	④以A[l，9]和A[l，8]为首的两行元素分别等于1010101011和1101010101 ；[0066]	如果该可能的路标目标满足条件①，则说明该可能的路标目标是真正的路标目 标，且判别区原点C位于如图5 (a)所示的位置；如果满足条件②，则说明该可能的路标目标 是真正的路标目标，且判别区原点C位于位于如图5(b)所示的位置；如果满足条件③，则说 明该可能的路标目标是真正的路标目标，且判别区原点C位于位于如图5(c)所示的位置； 如果满足条件④，则说明该可能的路标目标是真正的路标目标，且判别区原点C位于位于 如图5(d)所示的位置；如果不满足上述①&#12316;④中任何一个条件，则说明该可能的路标目标 不是真实路标目标；</p>
    <p>[0067]	步骤12 ：经过上述步骤后即可确定真正的路标目标，然后根据步骤11获得的路标 目标的判别区原点C和数据读取规则得到数据区中的数值，进而利用Hamming码进行数据 验证、纠错和解码，从而获得路标中所包含的平面坐标（Χ/，Υ/ )；</p>
    <p>[0068]	步骤13 ：获得路标的平面坐标后，计算机器人在当前环境中的位置坐标和航向 角；</p>
    <p>[0069]	图6为机器人位置估计示意图，图6中B点表示图像的中心，其坐标为Ub，yb)= (Width/2, Height/2)，其中Width为图像的宽度，Height为图像的高度；A点表示图像中 路标的中心，其坐标为（xa，ya) = ((χ cl +xc2+xc3+xc4) /4，(yci+yc2+yc3+yC4) /4)，其中(xcl，ycl)、 (χ。2，y。2)、（χ。3，y。3)和（χ。4，yj分别为路标目标轮廓直线I11和I21的交点坐标、I11和I22 的交点坐标、I12和I21的交点坐标以及I12和I22的交点坐标；XAY坐标系代表自定义的路标 坐标系，X轴和Y轴分别与路标的两条边平行，且判别区原点C位于XAY坐标系的第三象限中；</p>
    <p>[0070]机器人的位置和航向的计算步骤如下：</p>
    <p>[0071]1)根据计算图像中心点B和图像中路标中心点Α之间的欧式距离IabI	；</p>
    <p>[0072]2)计算路标坐标系X轴和图像行方向的夹角α，该夹角α即为机器人行驶的航向角；</p>
    <p>[0073]3)计算向量AB和图像行方向的夹角β，计算公式如下</p>
    <p>[0074]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00081.png"> <img id="idf0002" file="CN102135429AD00081.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00081.png" class="patent-full-image" alt="Figure CN102135429AD00081"> </a> </div>
    <p>[0075] 4)计算向量AB和路标坐标系X轴的夹角θ，计算公式如下</p>
    <p>[0076]θ = β -α</p>
    <p>[0077] 5)采用如下公式计算路标坐标系XAY中图像中心点B的像素坐标（χΒ，yB)，</p>
    <p>[0078]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00082.png"> <img id="idf0003" file="CN102135429AD00082.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00082.png" class="patent-full-image" alt="Figure CN102135429AD00082"> </a> </div>
    <p>[0079]  6)假设由步骤1&#12316;步骤12所获得的某个路标的平面坐标为（Xg，Yg)，该坐标即为 路标在全局坐标系下的坐标，则根据下式可以获得机器人在全局坐标系下的坐标（&#190;，Yk)： </p>
    <p>[0080]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00083.png"> <img id="idf0004" file="CN102135429AD00083.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00083.png" class="patent-full-image" alt="Figure CN102135429AD00083"> </a> </div>
    <p>[0081]	其中，变量S是比例因子；</p>
    <p>[0082]	假设轧为实际路标边长，Mb表示图像中路标的边长，其计算公式为：[0083]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00091.png"> <img id="idf0005" file="CN102135429AD00091.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00091.png" class="patent-full-image" alt="Figure CN102135429AD00091"> </a> </div>
    <p>[0084]	其中（Xc;1，ycl)、(xc2, y。2)、(xc3, yc3)和（x。4，yc4)分别为步骤13中所提及的路标目 标轮廓直线的交点&#183;，</p>
    <p>[0085]	变量S通过如下公式获得：</p>
    <p>[0086]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00092.png"> <img id="idf0006" file="CN102135429AD00092.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102135429A/CN102135429AD00092.png" class="patent-full-image" alt="Figure CN102135429AD00092"> </a> </div>
    <p>[0087]	通过上述步骤，即可获得机器人当前的全局位置坐标0(K，YK)以及航向角α，从而 实现了机器人的室内定位导航。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1707223A?cl=zh">CN1707223A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年6月12日</td><td class="patent-data-table-td patent-date-value">2005年12月14日</td><td class="patent-data-table-td ">杨建华</td><td class="patent-data-table-td ">基于条形码的室内移动机器人定位系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101539426A?cl=zh">CN101539426A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年4月16日</td><td class="patent-data-table-td patent-date-value">2009年9月23日</td><td class="patent-data-table-td ">西安交通大学</td><td class="patent-data-table-td ">一种识别精度驱动的无线视觉传感器节点室内布置方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101576384A?cl=zh">CN101576384A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年6月18日</td><td class="patent-data-table-td patent-date-value">2009年11月11日</td><td class="patent-data-table-td ">北京航空航天大学</td><td class="patent-data-table-td ">一种基于视觉信息校正的室内移动机器人实时导航方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101619985A?cl=zh">CN101619985A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年8月6日</td><td class="patent-data-table-td patent-date-value">2010年1月6日</td><td class="patent-data-table-td ">上海交通大学</td><td class="patent-data-table-td ">基于可变形拓扑地图的服务机器人自主导航方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">非专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">参考文献</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《机器人》 20070915 石朝侠等 大规模环境下的拓扑地图创建与导航 , 第05期 2</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《系统工程与电子技术》 20010720 肖海荣等 基于多传感器数据融合的移动机器人导航 , 第07期 2</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td ">《高技术通讯》 20080425 郑睿等 一种用于移动机器人室内定位与导航的二维码 , 第04期 2</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102419178A?cl=zh">CN102419178A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月5日</td><td class="patent-data-table-td patent-date-value">2012年4月18日</td><td class="patent-data-table-td ">中国科学院自动化研究所</td><td class="patent-data-table-td ">基于红外路标的移动机器人定位系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102419178B?cl=zh">CN102419178B</a></td><td class="patent-data-table-td patent-date-value">2011年9月5日</td><td class="patent-data-table-td patent-date-value">2014年1月8日</td><td class="patent-data-table-td ">中国科学院自动化研究所</td><td class="patent-data-table-td ">基于红外路标的移动机器人定位系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102445681A?cl=zh">CN102445681A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年9月30日</td><td class="patent-data-table-td patent-date-value">2012年5月9日</td><td class="patent-data-table-td ">深圳市九洲电器有限公司</td><td class="patent-data-table-td ">一种可移动设备的室内定位方法与系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102445681B?cl=zh">CN102445681B</a></td><td class="patent-data-table-td patent-date-value">2011年9月30日</td><td class="patent-data-table-td patent-date-value">2013年7月3日</td><td class="patent-data-table-td ">深圳市九洲电器有限公司</td><td class="patent-data-table-td ">一种可移动设备的室内定位方法与系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102506851A?cl=zh">CN102506851A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年10月31日</td><td class="patent-data-table-td patent-date-value">2012年6月20日</td><td class="patent-data-table-td ">东软集团股份有限公司</td><td class="patent-data-table-td ">导航装置及导航方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102506851B?cl=zh">CN102506851B</a></td><td class="patent-data-table-td patent-date-value">2011年10月31日</td><td class="patent-data-table-td patent-date-value">2014年8月13日</td><td class="patent-data-table-td ">东软集团股份有限公司</td><td class="patent-data-table-td ">导航装置及导航方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102735217A?cl=zh">CN102735217A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月14日</td><td class="patent-data-table-td patent-date-value">2012年10月17日</td><td class="patent-data-table-td ">燕山大学</td><td class="patent-data-table-td ">一种室内机器人视觉自主定位方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102735217B?cl=zh">CN102735217B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月14日</td><td class="patent-data-table-td patent-date-value">2015年6月10日</td><td class="patent-data-table-td ">燕山大学</td><td class="patent-data-table-td ">一种室内机器人视觉自主定位方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102735235A?cl=zh">CN102735235A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年6月7日</td><td class="patent-data-table-td patent-date-value">2012年10月17日</td><td class="patent-data-table-td ">无锡普智联科高新技术有限公司</td><td class="patent-data-table-td ">基于二维码的室内移动机器人定位系统和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102789234A?cl=zh">CN102789234A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月14日</td><td class="patent-data-table-td patent-date-value">2012年11月21日</td><td class="patent-data-table-td ">广东科学中心</td><td class="patent-data-table-td ">基于颜色编码标识的机器人导航方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102789234B?cl=zh">CN102789234B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月14日</td><td class="patent-data-table-td patent-date-value">2015年7月8日</td><td class="patent-data-table-td ">广东科学中心</td><td class="patent-data-table-td ">基于颜色编码标识的机器人导航方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102829775A?cl=zh">CN102829775A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年8月29日</td><td class="patent-data-table-td patent-date-value">2012年12月19日</td><td class="patent-data-table-td ">成都理想境界科技有限公司</td><td class="patent-data-table-td ">一种室内导航方法、系统及设备</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102902948A?cl=zh">CN102902948A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年7月28日</td><td class="patent-data-table-td patent-date-value">2013年1月30日</td><td class="patent-data-table-td ">国际商业机器公司</td><td class="patent-data-table-td ">计算机、确定计算机位置的方法以及制造标签的系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102997910A?cl=zh">CN102997910A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年10月31日</td><td class="patent-data-table-td patent-date-value">2013年3月27日</td><td class="patent-data-table-td ">上海交通大学</td><td class="patent-data-table-td ">一种基于地面路标的定位导引系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102997910B?cl=zh">CN102997910B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年10月31日</td><td class="patent-data-table-td patent-date-value">2016年4月13日</td><td class="patent-data-table-td ">上海交通大学</td><td class="patent-data-table-td ">一种基于地面路标的定位导引系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103123682A?cl=zh">CN103123682A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月17日</td><td class="patent-data-table-td patent-date-value">2013年5月29日</td><td class="patent-data-table-td ">无锡普智联科高新技术有限公司</td><td class="patent-data-table-td ">基于规则图形码复合标签的移动机器人定位系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103123682B?cl=zh">CN103123682B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年1月17日</td><td class="patent-data-table-td patent-date-value">2015年9月16日</td><td class="patent-data-table-td ">无锡普智联科高新技术有限公司</td><td class="patent-data-table-td ">基于规则图形码复合标签的移动机器人定位系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103292805A?cl=zh">CN103292805A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月28日</td><td class="patent-data-table-td patent-date-value">2013年9月11日</td><td class="patent-data-table-td ">武汉理工大学</td><td class="patent-data-table-td ">一种室内导航系统及其室内导航方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103292805B?cl=zh">CN103292805B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月28日</td><td class="patent-data-table-td patent-date-value">2016年5月4日</td><td class="patent-data-table-td ">武汉理工大学</td><td class="patent-data-table-td ">一种室内导航系统及其室内导航方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103324194A?cl=zh">CN103324194A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月21日</td><td class="patent-data-table-td patent-date-value">2013年9月25日</td><td class="patent-data-table-td ">无锡普智联科高新技术有限公司</td><td class="patent-data-table-td ">基于二维码导航带的移动机器人定位系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103324194B?cl=zh">CN103324194B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年5月21日</td><td class="patent-data-table-td patent-date-value">2015年11月18日</td><td class="patent-data-table-td ">无锡普智联科高新技术有限公司</td><td class="patent-data-table-td ">基于二维码导航带的移动机器人定位系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103557859A?cl=zh">CN103557859A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年10月10日</td><td class="patent-data-table-td patent-date-value">2014年2月5日</td><td class="patent-data-table-td ">北京智谷睿拓技术服务有限公司</td><td class="patent-data-table-td ">图像采集定位方法及图像采集定位系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103557859B?cl=zh">CN103557859B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年10月10日</td><td class="patent-data-table-td patent-date-value">2015年12月23日</td><td class="patent-data-table-td ">北京智谷睿拓技术服务有限公司</td><td class="patent-data-table-td ">图像采集定位方法及图像采集定位系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103616894A?cl=zh">CN103616894A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月10日</td><td class="patent-data-table-td patent-date-value">2014年3月5日</td><td class="patent-data-table-td ">中国恩菲工程技术有限公司</td><td class="patent-data-table-td ">基于离散坐标系的小车行走定位监测方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103616895A?cl=zh">CN103616895A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月10日</td><td class="patent-data-table-td patent-date-value">2014年3月5日</td><td class="patent-data-table-td ">中国恩菲工程技术有限公司</td><td class="patent-data-table-td ">基于离散坐标系的小车行走定位控制方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103616895B?cl=zh">CN103616895B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年12月10日</td><td class="patent-data-table-td patent-date-value">2016年4月13日</td><td class="patent-data-table-td ">中国恩菲工程技术有限公司</td><td class="patent-data-table-td ">基于离散坐标系的小车行走定位控制方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103837147A?cl=zh">CN103837147A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年3月13日</td><td class="patent-data-table-td patent-date-value">2014年6月4日</td><td class="patent-data-table-td ">北京理工大学</td><td class="patent-data-table-td ">主动红外点阵式人工路标及智能体定位系统及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104007760A?cl=zh">CN104007760A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年4月22日</td><td class="patent-data-table-td patent-date-value">2014年8月27日</td><td class="patent-data-table-td ">济南大学</td><td class="patent-data-table-td ">一种自主机器人视觉导航中的自定位方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9170581">US9170581</a></td><td class="patent-data-table-td patent-date-value">2014年9月29日</td><td class="patent-data-table-td patent-date-value">2015年10月27日</td><td class="patent-data-table-td ">Crown Equipment Limited</td><td class="patent-data-table-td ">Industrial vehicles with overhead light based localization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9174830">US9174830</a></td><td class="patent-data-table-td patent-date-value">2014年9月29日</td><td class="patent-data-table-td patent-date-value">2015年11月3日</td><td class="patent-data-table-td ">Crown Equipment Limited</td><td class="patent-data-table-td ">Industrial vehicles with point fix based localization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US9340399">US9340399</a></td><td class="patent-data-table-td patent-date-value">2015年10月1日</td><td class="patent-data-table-td patent-date-value">2016年5月17日</td><td class="patent-data-table-td ">Crown Equipment Corporation</td><td class="patent-data-table-td ">Industrial vehicles with point fix based localization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015096717A1?cl=zh">WO2015096717A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年12月24日</td><td class="patent-data-table-td patent-date-value">2015年7月2日</td><td class="patent-data-table-td ">电信科学技术研究院</td><td class="patent-data-table-td ">一种定位方法及装置</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=FMCXBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G01C0021000000">G01C21/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年7月27日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年9月7日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年6月13日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Granted</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年2月26日</td><td class="patent-data-table-td ">C17</td><td class="patent-data-table-td ">Cessation of patent right</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/598f2e879a93c340d663/CN102135429A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_5115ea495017d9115e613207d3810e5a.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E8%A7%86%E8%A7%89%E7%9A%84%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%A4%E5%86%85%E5%AE%9A.pdf?id=FMCXBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3jCfZiRKovLOCsTS-i6Ae6SIQ4ow"},"sample_url":"https://www.google.com/patents/reader?id=FMCXBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>