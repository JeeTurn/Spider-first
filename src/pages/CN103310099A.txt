<!DOCTYPE html><html><head><title>专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="一种利用图像捕获和识别技术实现增强现实的方法和系统"><meta name="DC.contributor" content="郑继威" scheme="inventor"><meta name="DC.contributor" content="张敏" scheme="inventor"><meta name="DC.contributor" content="罗乐生" scheme="inventor"><meta name="DC.contributor" content="佛山电视台南海分台" scheme="assignee"><meta name="DC.date" content="2013-5-30" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种利用图像捕获和识别技术实现增强现实的方法和系统，其中，包括以下步骤：A.通过图像捕捉设备获取现实的图像；B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示。采用本发明可达到用户更加方便、直观明了的获得想要的信息或者进行更加真实的用户体验的技术效果。"><meta name="DC.date" content="2013-9-18"><meta name="DC.relation" content="CN:101189049:A" scheme="references"><meta name="DC.relation" content="CN:101510934:A" scheme="references"><meta name="DC.relation" content="CN:101553752:A" scheme="references"><meta name="DC.relation" content="CN:1588429:A" scheme="references"><meta name="DC.relation" content="US:20040077393:A1" scheme="references"><meta name="DC.relation" content="US:20060287748:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103310099:A"><meta name="citation_patent_application_number" content="CN:201310208905"><link rel="canonical" href="https://www.google.com/patents/CN103310099A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103310099A?cl=zh"/><meta name="title" content="专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统"/><meta name="description" content="本发明公开了一种利用图像捕获和识别技术实现增强现实的方法和系统，其中，包括以下步骤：A.通过图像捕捉设备获取现实的图像；B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示。采用本发明可达到用户更加方便、直观明了的获得想要的信息或者进行更加真实的用户体验的技术效果。"/><meta property="og:title" content="专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103310099A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103310099A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=jXTTCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103310099A&amp;usg=AFQjCNFtR1bvHNZStnu0z8AGMMZ21IvDSA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/3d7135ddbce74bbd67b7/CN103310099A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/3d7135ddbce74bbd67b7/CN103310099A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103310099A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103310099A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103310099A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种利用图像捕获和识别技术实现增强现实的方法和系统，其中，包括以下步骤：A.通过图像捕捉设备获取现实的图像；B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库 ...</span><span itemprop="url">https://www.google.com/patents/CN103310099A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统" title="专利 CN103310099A - 一种利用图像捕获和识别技术实现增强现实的方法和系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103310099 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201310208905</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年9月18日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2013年5月30日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2013年5月30日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201310208905.3, </span><span class="patent-bibdata-value">CN 103310099 A, </span><span class="patent-bibdata-value">CN 103310099A, </span><span class="patent-bibdata-value">CN 201310208905, </span><span class="patent-bibdata-value">CN-A-103310099, </span><span class="patent-bibdata-value">CN103310099 A, </span><span class="patent-bibdata-value">CN103310099A, </span><span class="patent-bibdata-value">CN201310208905, </span><span class="patent-bibdata-value">CN201310208905.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%83%91%E7%BB%A7%E5%A8%81%22">郑继威</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BC%A0%E6%95%8F%22">张敏</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%BD%97%E4%B9%90%E7%94%9F%22">罗乐生</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%BD%9B%E5%B1%B1%E7%94%B5%E8%A7%86%E5%8F%B0%E5%8D%97%E6%B5%B7%E5%88%86%E5%8F%B0%22">佛山电视台南海分台</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103310099A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103310099A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103310099A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=jXTTCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201310208905&amp;usg=AFQjCNHOqP-kEQDIxwEd_q60bt1ri6JSNA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=jXTTCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103310099A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGreKJuhGJ7Ap5RoadNrm8ujcbzyQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT128286796" lang="ZH" load-source="patent-office">一种利用图像捕获和识别技术实现增强现实的方法和系统</invention-title>
      </span><br><span class="patent-number">CN 103310099 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA121675969" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种利用图像捕获和识别技术实现增强现实的方法和系统，其中，包括以下步骤：A.通过图像捕捉设备获取现实的图像；B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示。采用本发明可达到用户更加方便、直观明了的获得想要的信息或者进行更加真实的用户体验的技术效果。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(8)</span></span></div><div class="patent-text"><div mxw-id="PCLM56285534" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种利用图像捕获和识别技术实现增强现实的方法，其特征在于，包括以下步骤:  A.通过图像捕捉设备获取现实的图像；  B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；  C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后在现实图像中显示；  所述步骤C中的多媒体信息的存储地址包括本地数据库的存储单元地址，或者云端存储地址，或者互联网网络地址；  所述预设的数据库中存储有描述不同类型图像的特征参数组信息，以及分别与每一个特征参数组对应的链接的多媒体信息的存储地址信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的利用图像捕获和识别技术实现增强现实的方法，其特征在于，所述步骤B具体包括以下步骤:  B1.每一个具体的图像对应设置一组描述该图像的特征参数组，把这些特征参数组信息存储在预设的数据库中；  B2.对获取到的图像进行识别，得到描述该图像特征的参数，所述图像特征包括图像中的物品形状、颜色或线条；  B3.把B2中得到的参数与BI中数据库中定义的特征参数组进行匹配。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2所述的利用图像捕获和识别技术实现增强现实的方法，其特征在于，所述步骤C中的优化处理包括对多媒体信息进行压缩、更换背景或颜色。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求2所述的利用图像捕获和识别技术实现增强现实的方法，其特征在于，对步骤C中显示后的多媒体信息进行交互操作。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求2所述的利用图像捕获和识别技术实现增强现实的方法，其特征在于，所述多媒体信息包括文字、图片、视频、音频、动画、模型和游戏。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.一种实现权利要求1-5任意一项所述的利用图像捕获和识别技术实现增强现实的系统，其特征在于，包括以下模块:  图像捕捉设备:用于即时获取现实图像；  图像识别模块:对获取到的图像进行识别处理，获取描述该图像的参数；  输入模块:对显示后的多媒体信息进行交互操作；  数据库:存储描述不同类型图像的特征参数组信息，以及分别与每一个特征参数组对应的链接的多媒体信息的存储地址信息，同时存储部分多媒体信息；  数据处理模块:利用图像识别模块得到的参数在数据库中进行查询匹配，获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示；  显示模块:显示多媒体信息或优化处理后的多媒体信息；  所述图像捕捉设备分别与图像识别模块和显示模块通信连接，所述图像识别模块、输入模块、数据库和显示模块分别与数据处理模块通信连接。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的利用图像捕获和识别技术实现增强现实的系统，其特征在于，所述数据库连接网络。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的利用图像捕获和识别技术实现增强现实的系统，其特征在于，所述图像捕捉设备 持续捕捉图像，直到系统运行结束。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES63273667" lang="ZH" load-source="patent-office" class="description">
    <p>一种利用图像捕获和识别技术实现增强现实的方法和系统</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及AR (Augmented Reality增强现实)技术领域,尤其涉及的是一种利用图像捕获和识别技术增强现实的方法和系统。</p>
    <p>背景技术</p>
    <p>[0002]	现实生活中，我们看到的各种物品(例如产品、海报、宣传画册等)展示的信息量和信息种类有限，用户需要了解更多关于物品相关的信息(视频、文字、图片、声音、模型等)，就需要向相关的公司和人员索取相关的资料，或者去互联网上搜索该物品相关的资料，现有技术中的这种获取信息的方式非常不便，一方面不利于信息的推广传递和分享，另一方面在传递和分享信息的过程中不够直观明了，不利于用户接收了解。</p>
    <p>[0003]	因此，现有技术还有待于改进和发展。</p>
    <p>发明内容</p>
    <p>[0004]	本发明的目的在于提供一种利用图像捕获和识别技术增强现实的方法和系统，旨在解决现有技术中的获取信息的方式不够丰富，直观性较差等技术问题。</p>
    <p>[0005]	本发明的技术方案如下:一种利用图像捕获和识别技术实现增强现实的方法，其中，包括以下步骤:</p>
    <p>  A.通过图像捕捉设备获取现实的图像；</p>
    <p>  B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；</p>
    <p>  C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后在现实图像中显示；</p>
    <p>  所述步骤C中的多媒体信息的存储地址包括本地数据库的存储单元地址，或者云端存储地址，或者互联网网络地址；</p>
    <p>  所述预设的数据库中存储有描述不同类型图像的特征参数组信息，以及分别与每一个特征参数组对应的链接的多媒体信息的存储地址信息。</p>
    <p>[0006]	所述的利用图像捕获和识别技术实现增强现实的方法，其中，所述步骤B具体包括以下步骤:</p>
    <p>  B1.每一个具体的图像对应设置一组描述该图像的特征参数组，把这些特征参数组信息存储在预设的数据库中；</p>
    <p>  B2.对获取到的图像进行识别，得到描述该图像特征的参数，所述图像特征包括图像中的物品形状、颜色或线条；</p>
    <p>  B3.把B2中得到的参数与BI中数据库中定义的特征参数组进行匹配。</p>
    <p>[0007]	所述的利用图像捕获和识别技术实现增强现实的方法，其中，所述步骤C中的优化处理包括对多媒体信息进行压缩、更换背景或颜色。</p>
    <p>[0008]	所述的利用图像捕获和识别技术实现增强现实的方法，其中，对步骤C中显示后的多媒体信息进行交互操作。</p>
    <p>[0009]	所述的利用图像捕获和识别技术实现增强现实的方法，其中，所述多媒体信息包括文字、图片、视频、音频、动画、模型和游戏。</p>
    <p>[0010]	所述的利用图像捕获和识别技术实现增强现实的系统，其中，包括以下模块:  图像捕捉设备:用于即时获取现实图像；</p>
    <p>  图像识别模块:对获取到的图像进行识别处理，获取描述该图像的参数；</p>
    <p>  输入模块:对显示后的多媒体信息进行交互操作；</p>
    <p>  数据库:存储描述不同类型图像的特征参数组信息，以及分别与每一个特征参数组对应的链接的多媒体信息的存储地址信息，同时存储部分多媒体信息；</p>
    <p>  数据处理模块:利用图像识别模块得到的参数在数据库中进行查询匹配，获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示；</p>
    <p>  显示模块:显示多媒体信息或优化处理后的多媒体信息；</p>
    <p>  所述图像捕捉设备分别与图像识别模块和显示模块通信连接，所述图像识别模块、输入模块、数据库和显示模块分别与数据处理模块通信连接。</p>
    <p>[0011]	所述的利用图像捕获和识别技术实现增强现实的系统，其中，所述数据库连接网络。</p>
    <p>[0012]	所述的利用图像捕获和识别技术实现增强现实的系统，其中，所述图像捕捉设备持续捕捉图像，直到系统运行结束。</p>
    <p>[0013]	本发明的有益效果:本发明通过图像捕捉设备捕获图像数据，利用图像识别模块分析图像数据。当图像数据与系统数据匹配之后，显示模块就会在现实场景中显示虚拟的图片、文字、视频、音频、动画或游戏等信息，用户只需要进行常规操作，即可进行人机交互，获取更多的信息和体验；本发明改变了传统的获取信息的方式，达到了用户更加方便、直观明了的获得想要的信息或者进行更加真实的用户体验的技术效果。</p>
    <p>附图说明</p>
    <p>[0014]	图1是本发明中的方法流程图。</p>
    <p>[0015]	图2是本发明中的步骤B的具体步骤流程图。</p>
    <p>[0016]	图3是本发明中的系统的模块图。</p>
    <p>具体实施方式</p>
    <p>[0017]	为使本发明的目的、技术方案及优点更加清楚、明确，以下参照附图并举实施例对本发明进一步详细说明。</p>
    <p>[0018]	本发明公开了一种利用图像捕获和识别技术增强现实的方法，其方法流程如图1所示，包括以下步骤:</p>
    <p>  A.通过图像捕捉设备获取现实的图像；</p>
    <p>  B.对获取到的图像进行识别处理，获取描述该图像特征的参数，并利用该参数在预设的数据库中进行查询匹配；</p>
    <p>  C.获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后在现实图像中显示；</p>
    <p>  实际应用中，为了方便用户操作以及节约本地数据库的存储空间，所述多媒体信息存储在本体数据库中，或者存储在云端，或者存储在互联网上。具体的，当多媒体信息的量较少，占据的存储空间不大时，可以优先选择储存在本地数据库中，当多媒体信息的量较多，占据的存储空间较大时，可以根据需要选择储存在云端，或者储存在互联网上。其中，所述步骤C中的多媒体信息的存储地址包括本地数据库的存储单元地址，或者云端存储地址，或者互联网网络地址。</p>
    <p>[0019]	其中，如图2所示，步骤B具体包括以下步骤:</p>
    <p>  B1.每一个具体的图像对应设置一组描述该图像的特征参数组，把这些特征参数组信息存储在预设的数据库中；</p>
    <p>  B2.对获取到的图像进行识别，得到描述该图像特征的参数，所述图像特征包括图像中的物品形状、颜色或线条；</p>
    <p>  B3.把B2中得到的参数与BI中数据库中定义的特征参数组进行匹配。</p>
    <p>[0020]	具体的，多媒体信息可以为文字、图片、视频、音频、动画、模型、游戏等信息；其中，多媒体信息一般设置为用户想要了解的信息，例如与得到的图像相关的信息(包括文字、图片、视频、音频、动画、模型和游戏等信息)，当这些相关的信息的量较小时，可以把这些相关的信息优先储存在本地数据库中，当这些相关的信息的量较大时，可以把这些相关的信息储存在云端或者互联网上，数据库中预先存储了多媒体信息的存储地址，并且多媒体信息的存储地址分别与特征参数组对应设置。</p>
    <p>[0021]	本发明还公开了实现本发明所述方法的系统，如图4所示，包括以下模块:</p>
    <p>  图像捕捉设备:用于即时获取现实图像，如摄像头等；</p>
    <p>  图像识别模块:对获取到的图像进行识别处理，获取描述该图像的参数；</p>
    <p>  输入模块:对显示后的多媒体信息进行交互操作，可以为语音输入模块，或者触屏文字(图案)输入模块；</p>
    <p>  数据库:存储描述不同类型图像的特征参数组信息，以及分别与每一个特征参数组对应的链接的多媒体信息的存储地址信息，同时存储部分多媒体信息；</p>
    <p>  数据处理模块:利用图像识别模块得到的参数在数据库中进行查询匹配，获取数据库中与该参数相对应的多媒体信息的存储地址，并将从存储地址获取的多媒体信息直接显示或进行优化处理后显示；</p>
    <p>  显示模块:显示多媒体信息或优化处理后的多媒体信息，具体可以为设备的显示屏；所述图像捕捉设备分别与图像识别模块和显示模块通信连接，所述图像识别模块、输入模块、数据库和显示模块分别与数据处理模块通信连接。</p>
    <p>[0022]	本系统的工作过程如下:首先打开图像捕捉设备，捕捉现实中的图像(可以为某一物体、平面图案、立体场景等)，图像捕捉设备得到图像后把图像以数据的形式传递给图像识别模块；图像识别模块开始识别图像，具体的，图像识别模块通过识别图像的颜色、图像中的物体的线条、形状、颜色、拍摄的角度等特征，得到描述该图像特征的参数，图像识别模块把这些参数传输给数据处理模块；数据处理模块接收到图像识别模块传输的参数后，把这些参数与数据库中已经定义的特征参数组进行匹配，匹配成功后，数据处理模块得到匹配成功的特征参数组对应设置的多媒体信息的存储地址信息，数据处理模块通过该地址信息把多媒体信息获取回来，直接显示到显示模块上，或者对多媒体信息进行优化处理后显示。在系统工作过程中，图像捕捉设备持续的对现实图形进行捕捉，直到系统运行结束。</p>
    <p>[0023]	具体的，对多媒体信息的优化处理包括对多媒体信息进行压缩、更换背景或颜色。</p>
    <p>[0024]	实际应用中，本发明可以根据图像捕捉设备获得的现实图像中物体的线条、形状和颜色进行识别，也可以根据现实图像的颜色、特殊的标识、拍摄角度等特性进行识别；或者，本发明通过在现实画面中设置一些特定的参数点，每一个具体的现实画面对应一组特定的参数点，通过该参数点识别具体现实图像。本发明在识别图像捕捉设备获得的现实图像的过程中，采取模糊处理。本发明并不限定具体的图像识别方式，本发明的系统中同时设置有多种现实图像识别方式，实际应用中系统需要根据实际环境自动选择具体的现实图像识别方式。</p>
    <p>[0025]	具体的，数据处理模块把多媒体信息直接调用显示到显示模块上，例如直接调用播放一段视频、音频等；或者对多媒体信息进行处理，把处理结果显示在显示模块上，例如在屏幕上显示一个可操作的图标，点开图标可以显示信息，或者当多媒体信息是游戏时，需要对现实捕捉得到的图像进行处理，把显示捕捉得到的图像以背景的形式叠加到游戏中</p>
    <p>坐寸ο</p>
    <p>[0026]	具体的，输入模块可以为语音输入模块，或者触屏文字(图案)输入模块等，通过输入模块可以实现对显示的多媒体信息进行交互、控制或操作；例如可以通过触屏的方式拉动信息，对信息进行编辑，可以通过语音输入的方式播放音频、视频等，也可以通过语音输入或者触屏输入进行人机交互操作。</p>
    <p>[0027]	实际应用中，本方法可以通过设置一个程序，安装在便携式设备上(例如手机、平板电脑、相机等具有摄像功能和显示功能的设备)，通过程序实现各模块之间的数据传输，实现用户随时随地打开摄像头就可以了解更多的信息。</p>
    <p>[0028]	实施例1</p>
    <p>  在数据库中事先对某一品牌的商标进行定义(在数据库中定义其特征参数组)，并在数据库中存储一段介绍该品牌的信息(包括视频、音频、文字等)，同时存储一个该品牌的官方网站IP地址信息，将这些多媒体信息的存储地址的信息与该商标的特征参数组对应设置。当用户利用设备的摄像头对准该商标时，捕捉得到该商标的图像，此时图像识别模块对图像进行识别，识别出描述该商标的参数并与数据库中定义的特征参数组进行匹配，匹配成功后，系统得到该商标对应设置的多媒体信息的存储地址，系统利用该存储地址把多媒体信息获取回来，在设备的显示屏幕上显示，用户可以选择播放关于该商标的视频、查看该商标的文字介绍等，同时用户可以通过预先存储的IP地址访问该商标的官方网站。</p>
    <p>[0029]	实施例2</p>
    <p>  在数据库中事先定义描述某一形状的物体的特征参数(比如具有四边形平面的物体，例如桌子、长方形瓷砖等)，在数据库中存储一个小游戏，并且把该小游戏的存储地址与该特征参数对应设置，本实施例中，小游戏为篮球投篮游戏，当用户利用设备对一个具有四边形平面形状的物体进行拍摄时(例如对桌子进行拍摄)，图像识别模块对图像进行识别，识别出描述该图像的参数，系统利用该参数与数据库中已经定义的特征参数组进行匹配，匹配成功后，得到与特征参数组对应设置的存储地址信息，系统利用该存储地址信息获取并运行篮球投篮游戏，其中游戏中的篮球场的背景为现实物体中的四边形平面，用户可以通过触屏输入模块进行小游戏体验。</p>
    <p>[0030]	应当理解的是，本发明的应用不限于上述的举例，对本领域普通技术人员来说，可以根据上述说明加以改进或变换，所有这些改进和变换都应属于本发明所附权利要求的保护范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1588429A?cl=zh">CN1588429A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年8月6日</td><td class="patent-data-table-td patent-date-value">2005年3月2日</td><td class="patent-data-table-td ">上海大学</td><td class="patent-data-table-td ">皮肤显微图像症状自动识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101189049A?cl=zh">CN101189049A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年4月5日</td><td class="patent-data-table-td patent-date-value">2008年5月28日</td><td class="patent-data-table-td ">苏黎士高等院校非金属材料联盟</td><td class="patent-data-table-td ">在移动设备中执行应用程序的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101510934A?cl=zh">CN101510934A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年3月20日</td><td class="patent-data-table-td patent-date-value">2009年8月19日</td><td class="patent-data-table-td ">北京中星微电子有限公司</td><td class="patent-data-table-td ">一种数码像框及其显示照片的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101553752A?cl=zh">CN101553752A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年4月24日</td><td class="patent-data-table-td patent-date-value">2009年10月7日</td><td class="patent-data-table-td ">Ydreams信息有限公司</td><td class="patent-data-table-td ">对叠加在真实图像之上的信息进行可视化的系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040077393">US20040077393</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2003年6月9日</td><td class="patent-data-table-td patent-date-value">2004年4月22日</td><td class="patent-data-table-td ">Kim Ju Wan</td><td class="patent-data-table-td ">Apparatus and method for video based shooting game</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060287748">US20060287748</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年8月29日</td><td class="patent-data-table-td patent-date-value">2006年12月21日</td><td class="patent-data-table-td ">Leonard Layton</td><td class="patent-data-table-td ">Sonic landscape system</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=jXTTCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009460000">G06K9/46</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=jXTTCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0019000000">G06F19/00</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年9月18日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年10月23日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/3d7135ddbce74bbd67b7/CN103310099A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%9B%BE%E5%83%8F%E6%8D%95%E8%8E%B7%E5%92%8C%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF.pdf?id=jXTTCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U3PV7b7DgqRLE01vrDP2MZ9jaax2w"},"sample_url":"https://www.google.com/patents/reader?id=jXTTCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>