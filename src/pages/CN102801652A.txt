<!DOCTYPE html><html><head><title>专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="通过表情数据添加联系人的方法、客户端及系统"><meta name="DC.contributor" content="马宇尘" scheme="inventor"><meta name="DC.contributor" content="上海量明科技发展有限公司" scheme="assignee"><meta name="DC.date" content="2012-8-14" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供了一种通过表情数据添加联系人的方法、客户端及系统，属于通信、网络技术领域。所述的方法包括有如下步骤：设置添加联系人对象时的表情匹配关系；启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。利用本发明，能够通过载入情绪数据的方式，便捷地添加联系人对象。"><meta name="DC.date" content="2012-11-28"><meta name="DC.relation" content="CN:101242374:A" scheme="references"><meta name="DC.relation" content="CN:102404357:A" scheme="references"><meta name="DC.relation" content="CN:102546462:A" scheme="references"><meta name="DC.relation" content="CN:102629919:A" scheme="references"><meta name="DC.relation" content="US:20050076090:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102801652:A"><meta name="citation_patent_application_number" content="CN:201210289541"><link rel="canonical" href="https://www.google.com/patents/CN102801652A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102801652A?cl=zh"/><meta name="title" content="专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统"/><meta name="description" content="本发明提供了一种通过表情数据添加联系人的方法、客户端及系统，属于通信、网络技术领域。所述的方法包括有如下步骤：设置添加联系人对象时的表情匹配关系；启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。利用本发明，能够通过载入情绪数据的方式，便捷地添加联系人对象。"/><meta property="og:title" content="专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102801652A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102801652A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=q6uwBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102801652A&amp;usg=AFQjCNHCgU5zPXj_kCmJ77l3_n3N1hwxgA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/f862d5d1cf4167f6d538/CN102801652A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/f862d5d1cf4167f6d538/CN102801652A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102801652A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102801652A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102801652A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102801652B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102801652A?cl=zh" style="display:none"><span itemprop="description">本发明提供了一种通过表情数据添加联系人的方法、客户端及系统，属于通信、网络技术领域。所述的方法包括有如下步骤：设置添加联系人对象时的表情匹配关系；启动表情添加联系人模式后，采集发起方的表情数据，推送至...</span><span itemprop="url">https://www.google.com/patents/CN102801652A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统" title="专利 CN102801652A - 通过表情数据添加联系人的方法、客户端及系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102801652 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201210289541</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年11月28日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2012年8月14日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2012年8月14日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102801652B?hl=zh-CN&amp;cl=zh">CN102801652B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201210289541.1, </span><span class="patent-bibdata-value">CN 102801652 A, </span><span class="patent-bibdata-value">CN 102801652A, </span><span class="patent-bibdata-value">CN 201210289541, </span><span class="patent-bibdata-value">CN-A-102801652, </span><span class="patent-bibdata-value">CN102801652 A, </span><span class="patent-bibdata-value">CN102801652A, </span><span class="patent-bibdata-value">CN201210289541, </span><span class="patent-bibdata-value">CN201210289541.1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%A9%AC%E5%AE%87%E5%B0%98%22">马宇尘</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%8A%E6%B5%B7%E9%87%8F%E6%98%8E%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">上海量明科技发展有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102801652A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102801652A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102801652A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=q6uwBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201210289541&amp;usg=AFQjCNGJfOLW6RBoOXDdvgUutpWwkMYbyg"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=q6uwBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102801652A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHkTxenmUBB5wVjyzjQ7g9LDtoXWw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT117621506" lang="ZH" load-source="patent-office">通过表情数据添加联系人的方法、客户端及系统</invention-title>
      </span><br><span class="patent-number">CN 102801652 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA102806090" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供了一种通过表情数据添加联系人的方法、客户端及系统，属于通信、网络技术领域。所述的方法包括有如下步骤：设置添加联系人对象时的表情匹配关系；启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。利用本发明，能够通过载入情绪数据的方式，便捷地添加联系人对象。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(21)</span></span></div><div class="patent-text"><div mxw-id="PCLM46752757" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种通过表情数据添加联系人的方法，其特征在于该方法包括有如下步骤：  步骤1，设置添加联系人对象时的表情匹配关系；  步骤2，启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；  步骤3，通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的联系人对象，是即时通信工具的联系人对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的表情匹配关系，是具有相同类型的表情具有匹配关系。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的表情匹配关系，是具有相对类型的表情具有匹配关系。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的采集发起方的表情数据，通过如下步骤进行实施，  启动所在终端上的摄像结构；  拍摄发起方的人脸图像数据，通过所在视窗的浏览界面输出代表相应表情状况的人脸图像；  对应着所输出的特定人脸图像，采集发起方的确定消息获取前述的特定图像；  将获得的图像通过所在的终端设备进行表情识别，获得表情数据，或者将前述的图像传输至识别服务器，在识别服务器中识别后获得表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述采集发起方的表情数据，通过如下步骤进行实施，  启动所在终端上的首频录制结构；  采集发起方发出的音频数据；  将获得的音频数据进行识别，根据识别获得的文字内容判定获得发起方的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述采集发起方的表情数据，通过如下步骤进行实施，  启动所在终端上的首频录制结构；  采集发起方发出的音频数据，推送至识别服务器；  在识别服务器中识别为文字内容后，根据文字内容的含义判定对应的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的采集发起方的表情数据，通过如下步骤进行实施，  采集表情图标控件的触发消息；  生成包括有图标项阵列的表情图标列表，其中的图标项和预设的表情数据构成映射关系;  采集对特定图标项的触发消息；  获取和前述特定图标项对应的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的采集发起方的表情数据，通过如下步骤进行实施，采集表情文字描述控件的触发消息；  生成包括有文字项的表情文字项列表，其中的文字项代表着预设的表情数据；  采集对特定文字项的触发消息；  获取和前述特定文字项对应的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的采集发起方的表情数据，通过如下步骤进行实施，  设置用以采集字符内容的数据采集栏，以及预设字符内容与表情数据之间的映射列表;  采集发起方所写入的字符内容；  根据所采集获得的字符内容比对前述的映射列表，识别获得对应的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的采集发起方的表情数据，通过如下步骤进行实施，  设置可供绘制图像的图像数据采集栏；  获取发起方通过前述图像数据采集栏所绘制的图形；  根据图形的内容，识别获得所表达的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的表情数据，包括采集发起方所载入的用以表达表情状况的主表情项，以及通过程度调节控件所设置的主表情程度量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的一种通过表情数据添加联系人的方法，其特征在于：所述的程度调节控件，包括有用以调节位置的程度滑块，以及对应着程度滑块所设置的程度量刻度。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的邻近时间段，是预设的和发起方发出表情数据所在时刻邻近之前的时间段，或者邻近之后的时间段，或者包括邻近前后的时间段。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求14所述的一种通过表情数据添加联系人的方法，其特征在于：所述的邻近时间段，在10分钟的范围之内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求15所述的一种通过表情数据添加联系人的方法，其特征在于：所述的邻近时间段，在30秒钟的范围之内。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：通过发起方客户端同时输出发起方和匹配获得联系人对象的表情数据。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：所述的邻近时间段，是获得第一个符合表情匹配关系的用户数据的最邻近时间段。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19.根据权利要求I所述的一种通过表情数据添加联系人的方法，其特征在于：在输出具有表情匹配关系的联系人对象数据时，同时输出联系人对象的表情数据和/或进行表情识别的初始数据。</div>
    </div>
    </div> <div class="claim"> <div num="20" class="claim">
      <div class="claim-text">20.	一种通过表情数据添加联系人的客户端，其特征在于该客户端包括：  表情匹配设置单元，用以设置添加联系人对象时的表情匹配关系；  表情数据采集单元，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；联系人获取单元，用以获取表情添加服务器所推送的符合表情添加联系人模式的特定联系人对象后输出。</div>
    </div>
    </div> <div class="claim"> <div num="21" class="claim">
      <div class="claim-text">21.	一种通过表情数据添加联系人的系统，其特征在于该系统包括：  发起方客户端，它包括，  发起方表情数据采集单元，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至下述的表情添加服务器；  发起方联系人获取单元，用以获取下述表情添加服务器所推送的符合表情添加联系人模式的特定外联系人对象后输出；  外联系人对象客户端，它包括，  外联系人对象表情数据采集单元，用以在启动表情添加联系人模式后，采集外联系人对象自身的表情数据，推送至下述的表情添加服务器；  外联系人对象获取单元，用以获取下述表情添加服务器所推送的符合表情添加联系人模式的特定用户数据后输出；  表情添加服务器，它包括，  服务器表情匹配设置单元，用以设置添加联系人对象时的表情匹配关系；  服务器表情数据采集单元，用以采集来自于前述发起方客户端与外联系人对象客户端所传送的表情数据；  服务器联系人获取单元，用以获取在邻近时间段外联系人对象客户端所载入的表情数据，从外联系人对象中采集具有表情匹配关系的特定外联系人对象数据；  服务器联系人推送单元，用以向前述的发起方客户端推送构成表情匹配关系的特定外联系人对象数据，和/或对应着符合匹配关系的特定外联系人对象客户端推送前述发起方的数据。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES53079810" lang="ZH" load-source="patent-office" class="description">
    <p>通过表情数据添加联系人的方法、客户端及系统</p>
    <p>技术领域</p>
    <p>[0001 ] 本发明属于通信、网络技术领域。</p>
    <p>技术背景</p>
    <p>[0002]	在人们使用通信工具的过程中，有多种添加联系人的方式。比如，目前在中国广泛应用的微信即时通信工具、米聊即时通信工具等，都可以通过晃动手持终端的形式，来寻找同一时间下也在进行同样摇动操作的其他用户。</p>
    <p>[0003]	这种添加联系人的方式，仅仅能够获得摇动一类的简单动作信息，在添加联系人对象时，实现形式是单调的。 发明内容</p>
    <p>[0004]	本发明的目的在于，提供一种通过表情数据添加联系人的方法，以及对应的客户端及系统，利用本发明，能够通过载入情绪数据的方式，便捷地添加联系人对象。</p>
    <p>[0005]	本发明所提供的一种通过表情数据添加联系人的方法，包括有如下步骤：</p>
    <p>[0006]	步骤1，设置添加联系人对象时的表情匹配关系；</p>
    <p>[0007]	步骤2，启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；</p>
    <p>[0008]	步骤3，通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。</p>
    <p>[0009]	进一步，所述的联系人对象，是即时通信工具的联系人对象。</p>
    <p>[0010]	进一步，所述的表情匹配关系，是具有相同类型的表情具有匹配关系。</p>
    <p>[0011]	进一步，所述的表情匹配关系，是具有相对类型的表情具有匹配关系。</p>
    <p>[0012]	进一步，所述的采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0013]启动所在终端上的摄像结构；</p>
    <p>[0014]	拍摄发起方的人脸图像数据，通过所在视窗的浏览界面输出代表相应表情状况的人脸图像；</p>
    <p>[0015]	对应着所输出的特定人脸图像，采集发起方的确定消息获取前述的特定图像；</p>
    <p>[0016]	将获得的图像通过所在的终端设备进行表情识别，获得表情数据，或者将前述的图像传输至识别服务器，在识别服务器中识别后获得表情数据。</p>
    <p>[0017]	进一步，所述采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0018]启动所在终端上的音频录制结构；</p>
    <p>[0019]	采集发起方发出的音频数据；</p>
    <p>[0020]	将获得的音频数据进行识别，根据识别获得的文字内容判定获得发起方的表情数据。</p>
    <p>[0021]	进一步，所述采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0022]启动所在终端上的音频录制结构；[0023]	采集发起方发出的音频数据，推送至识别服务器；</p>
    <p>[0024]	在识别服务器中识别为文字内容后，根据文字内容的含义判定对应的表情数据。</p>
    <p>[0025]	进一步，所述的采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0026]	采集表情图标控件的触发消息；</p>
    <p>[0027]	生成包括有图标项阵列的表情图标列表，其中的图标项和预设的表情数据构成映身寸关系;</p>
    <p>[0028]	采集对特定图标项的触发消息；</p>
    <p>[0029]	获取和前述特定图标项对应的表情数据。</p>
    <p>[0030]	进一步，所述的采集发起方的表情数据，通过如下步骤进行实施：&#183;</p>
    <p>[0031]	采集表情文字描述控件的触发消息；</p>
    <p>[0032]	生成包括有文字项的表情文字项列表，其中的文字项代表着预设的表情数据；</p>
    <p>[0033]	采集对特定文字项的触发消息；</p>
    <p>[0034]	获取和前述特定文字项对应的表情数据。</p>
    <p>[0035]	进一步，所述的采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0036]	设置用以采集字符内容的数据采集栏，以及预设字符内容与表情数据之间的映射列表；</p>
    <p>[0037]	采集发起方所写入的字符内容；</p>
    <p>[0038]	根据所采集获得的字符内容比对前述的映射列表，识别获得对应的表情数据。</p>
    <p>[0039]	进一步，所述的采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0040]	设置可供绘制图像的图像数据采集栏；</p>
    <p>[0041]	获取发起方通过前述图像数据采集栏所绘制的图形；</p>
    <p>[0042]	根据图形的内容，识别获得所表达的表情数据。</p>
    <p>[0043]	进一步，所述的表情数据，包括采集发起方所载入的用以表达表情状况的主表情项，以及通过程度调节控件所设置的主表情程度量。</p>
    <p>[0044]	进一步，所述的程度调节控件，包括有用以调节位置的程度滑块，以及对应着程度滑块所设置的程度量刻度。</p>
    <p>[0045]	进一步，所述的邻近时间段，是预设的和发起方发出表情数据所在时刻邻近之前的时间段，或者邻近之后的时间段，或者包括邻近前后的时间段。</p>
    <p>[0046]	进一步，所述的邻近时间段，在10分钟的范围之内。</p>
    <p>[0047]	进一步，所述的邻近时间段，在30秒钟的范围之内。</p>
    <p>[0048]	进一步，通过发起方客户端同时输出发起方和匹配获得联系人对象的表情数据。</p>
    <p>[0049]	进一步，所述的邻近时间段，是获得第一个符合表情匹配关系的用户数据的最邻近时间段。</p>
    <p>[0050]	进一步，在输出具有表情匹配关系的联系人对象数据时，同时输出联系人对象的表情数据和/或进行表情识别的初始数据。</p>
    <p>[0051]	本发明还提供一种通过表情数据添加联系人的客户端，该客户端包括：</p>
    <p>[0052]	表情匹配设置单元，用以设置添加联系人对象时的表情匹配关系；</p>
    <p>[0053]	表情数据采集单元，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；[0054]	联系人获取单元，用以获取表情添加服务器所推送的符合表情添加联系人模式的特定联系人对象后输出。</p>
    <p>[0055]	本发明还提供一种通过表情数据添加联系人的系统，该系统包括：</p>
    <p>[0056]	发起方客户端，它包括，</p>
    <p>[0057]	发起方表情数据采集单元，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至下述的表情添加服务器；</p>
    <p>[0058]	发起方联系人获取单元，用以获取下述表情添加服务器所推送的符合表情添加联系人模式的特定外联系人对象后输出；</p>
    <p>[0059]	外联系人对象客户端，它包括， </p>
    <p>[0060]	外联系人对象表情数据采集单元，用以在启动表情添加联系人模式后，采集外联系人对象自身的表情数据，推送至下述的表情添加服务器；</p>
    <p>[0061 ] 外联系人对象获取单元，用以获取下述表情添加服务器所推送的符合表情添加联系人模式的特定用户数据后输出；</p>
    <p>[0062]	表情添加服务器，它包括，</p>
    <p>[0063]	服务器表情匹配设置单元，用以设置添加联系人对象时的表情匹配关系；</p>
    <p>[0064]	服务器表情数据采集单元，用以采集来自于前述发起方客户端与外联系人对象客户端所传送的表情数据；</p>
    <p>[0065]	服务器联系人获取单元，用以获取在邻近时间段外联系人对象客户端所载入的表情数据，从外联系人对象中采集具有表情匹配关系的特定外联系人对象数据；</p>
    <p>[0066]	服务器联系人推送单元，用以向前述的发起方客户端推送构成表情匹配关系的特定外联系人对象数据，和/或对应着符合匹配关系的特定外联系人对象客户端推送前述发起方的数据。</p>
    <p>附图说明</p>
    <p>[0067]	图I是本发明所述通过表情数据添加联系人的方法的流程图，为实施例I。</p>
    <p>[0068]	图2是本发明所述通过表情数据添加联系人的方法的流程图，为实施例2。</p>
    <p>[0069]	图3是本发明所述通过表情数据添加联系人的客户端的结构框图，为实施例3。</p>
    <p>[0070]	图4是本发明所述通过表情数据添加联系人的系统结构框图，为实施例4。</p>
    <p>具体实施方式</p>
    <p>[0071]	实施例I</p>
    <p>[0072]	为了更好地说明本发明，这儿提供了一个具体实施例。参图I所示，该实施例包括如下步骤：</p>
    <p>[0073]	步骤S110，采集即时通信用户A通过所在的即时通信客户端，通过所在智能手机终端启动表情添加联系人对象的操作消息；</p>
    <p>[0074]	比如，可以在即时通信客户端的显示界面中，预设用以触发表情添加联系人对象的开启控件。在采集获得对该控件的触发消息的情况下，即可启动通过表情添加联系人对象的操作。</p>
    <p>[0075]	步骤S120，启动所在智能手机终端中的摄像结构，对即时通信用户A的脸部图像进行拍摄操作；</p>
    <p>[0076]	在本实施例中，即时通信用户A所在的终端为手机终端，当然，其它能够登录即时通信工具的终端形式也同样能够应用于本发明。</p>
    <p>[0077]	本实施例通过拍摄自身的脸部图像来识别获得表情数据，需要指出的是，还可以用多种方式获取表情数据，在下面所 述的其它实施例中另有说明。</p>
    <p>[0078]	步骤S130，在采集获得即时通信用户A做出笑脸表情的拍摄图像后，将该拍摄数据打包推送至表情添加服务器；</p>
    <p>[0079]	在本实施例中，通过所登录的智能手机终端拍摄即时通信用户A的具有笑脸表情的图像数据。该图像数据中的表情信息并不通过所在的智能手机终端识别，而是被推送至表情添加服务器中进行识别，以及做进一步的比对操作。</p>
    <p>[0080]	步骤S140，通过表情添加服务器预设的邻近时间段为五分钟，首先在即时通信用户A发出表情数据的前五分钟之内，遍历已经接收的外联系人对象推送的表情数据，判定是否有符合表情匹配关系的用户，如果有则转入下一步骤，否则启动发出表情数据的后五分钟之内时间段的匹配用户的搜索操作；</p>
    <p>[0081]	也就是说，计量即时通信用户A推送前述笑脸表情数据至表情添加服务器的时亥IJ，以该时刻为参照点，前后各取五分钟的时间量，作为寻找具有相同表情用户的时间量。优先开始的时间范围是前述参照点之前的五分钟之内，因为该时间段的数据为已接收数据，可以直接进行匹配比对，并快速向即时通信用户A推送匹配结果；若前五分钟之内无法找到合适的匹配用户，则增加到参照点之后的五分钟范围进行搜寻。</p>
    <p>[0082]	进一步，为了能够更方便地说明本发明，在下面的说明内容中，引入外联系人对象的概念。所述的外联系人对象，指的是所有符合邻近时间段条件，同样也采用表情匹配的方式添加联系人的其他用户，且需要除去发起方自身，以及发起方的原有联系人对象。外联系人对象，是符合邻近时间段条件的、发起方能够通过表情匹配添加联系人对象的总用户范围。下同。</p>
    <p>[0083]	需要指出的是，本发明并不局限于添加联系人对象，还可以通过表情匹配的方式筛选发起方已有的联系人对象，或进行其它的操作。</p>
    <p>[0084]	步骤S150，筛选获得在最相邻时间段具有类似笑脸表情的即时通信用户B，将该即时通信用户B作为具有匹配关系的用户，采集其数据推送至前述即时通信用户A的客户端中输出，以及采集即时通信用户A的数据推送至即时通信用户B所在的客户端输出；</p>
    <p>[0085]	在该步骤中，通过表情匹配，获取符合表情匹配判定条件的最相邻时间段的外联系人对象，作为匹配结果提供给前述即时通信用户A。</p>
    <p>[0086]	具体说来，判定即时通信用户B是在最相邻时间段内具有类似笑脸表情的联系人对象。于是，采集即时通信用户B的头像图标、用户识别号和用户名等数据；另外，如果即时通信用户B允许共享更多数据的话，比如，还可以共享其个人的照片数据，于是，就可以连带着所共享的各种数据，推送至即时通信用户A所在的即时通信客户端输出；当然，也可以仅推送各数据链接，采集即时通信用户A触发前述链接的消息后，再推送链接所对应的数据。</p>
    <p>[0087]	在本发明描述的通过表情添加联系人对象的实施过程中，作为优选的方式，发起方与外联系人对象之间的地位是等同的。于是，也同步采集即时通信用户A的数据推送至即时通信用户B所在的即时通信客户端输出，供即时通信用户B判定是否许可添加即时通信用户A为联系人对象。</p>
    <p>[0088]	步骤S160，通过即时通信用户A所在的即时通信客户端，同时输出即时通信用户A的表情数据和即时通信用户B的表情，以及即时通信用户B的共享数据，供即时通信用户A</p>
    <p>查看；</p>
    <p>[0089]	前述即时通信用户B的共享数据，泛指隶属于即时通信用户B的头像图标、用户名以及共享的照片、共享的日志等数据。</p>
    <p>[0090]	在该步骤中，将即时通信用户A的笑脸表情数据和即时通信用户B的笑脸表情数据两者并列着输出，以供即时通信用户A判定。需要指出的是，在输出的数据内容包括外联系人对象的人脸数据时，就会涉及到外联系人对象的隐私。因此，是否输出外联系人对象的 人脸数据，需要获得外联系人对象的许可。即只有在外联系人对象设置共享许可其拍摄的人脸数据的情况下，才可以将外联系人对象的人脸数据推送至发起方客户端输出。</p>
    <p>[0091]	进一步，还可以对应着各种表情状况设置图标，在进行表情数据比对时，不比对真实人脸，而比对所设置的图标。另外，也可以将各种拍摄获得的包括人脸的图像，将其转变为具有相应表情特征的卡通图案。进而在进行表情数据比对时，比对发起方和/或外联系人对象的卡通图像，这种方式也可以保护隐私。</p>
    <p>[0092]	步骤S170，在采集获得即时通信用户A添加即时通信用户B为联系人对象的确认消息时，将该确认消息推送至表情添加服务器中，由表情添加服务器对其注册，将添加即时通信用户B为联系人对象的消息推送至即时通信用户B所在的即时通信客户端；</p>
    <p>[0093]	在即时通信用户A觉得即时通信用户B是添加为联系人对象的合适人选的情况下，就可以触发确认控件，将确认消息推送至表情添加服务器进行注册。需要指出的是，完成该联系人对象的添加操作，还需要得到即时通信用户B的许可。</p>
    <p>[0094]	若即时通信用户B觉得即时通信用户A不适合添加为联系人对象，则不对即时通信用户A发起的添加联系人对象的确认操作做出响应，或者进行拒绝操作。如果即时通信用户B不许可联系人对象的添加操作，那么，即时通信用户A和即时通信用户B之间的联系人对象添加操作将终止。</p>
    <p>[0095]	步骤S180，当采集获得即时通信用户B的确认消息后，即可将即时通信用户A与即时通信用户B之间添加联系人对象的消息进行注册，将两者互相添加为联系人对象。</p>
    <p>[0096]	在相互确认添加为联系人对象的情况下，即可通过表情添加服务器分别将对方的数据信息，以具有联系人关系的形式进行注册。进而将对方的识别数据，比如头像图标、用户名、用户识别号等，推送至即时通信用户A与即时通信用户B所在的客户端，进而添加至对应客户端的联系人列表中，以该联系人列表中的ITEM项呈现出来。</p>
    <p>[0097]	另外，还可以进一步生成与对方进行交互操作的即时通信交互界面。</p>
    <p>[0098]	实施例2</p>
    <p>[0099]	前面的实施例1，是对本发明中一个具体实施例的描述。在本实施例中做进一步描述。</p>
    <p>[0100]	具体说来，参图2所示，本实施例所描述的通过表情数据添加联系人的方法包括如下步骤：</p>
    <p>[0101]	步骤S210，设置添加联系人对象时的表情匹配关系；[0102]	步骤S220，启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；</p>
    <p>[0103]	步骤S230，通过表情添加服务器获取在邻近时间段其他用户所输入的表情数据，采集具有表情匹配关系的用户数据提供给前述发起方。</p>
    <p>[0104]	本发明可以应用到各种添加联系人对象的场合。但作为优选的实施例，是在即时通信工具中实施本发明。其中所述的联系人对象，优选为即时通信工具中的联系人对象。</p>
    <p>[0105]	需要指出的是，其它添加联系人对象的场合，比如，在通过网页进行联络的网络社区中，各用户之间也可以利用这种方式添加联系人对象。或者，在使用同一网络游戏的各游戏参与者之间，可以通过这种方式相互之间添加为游戏伙伴。或者，对于目前广泛使用的手机来说，若手机用户A的通信录中已有300个联系人对象，而手机用户A希望筛选出某个联系人对象构成待通话的对象，则可以利用这种方式在前述已有的300个联系人对象之中发 起匹配关系，依据表情匹配的方式寻找符合匹配要求的特定联系人对象，利用手机网络构成通话关系，或者仅仅筛选出来供手机用户A进行选择。</p>
    <p>[0106]	需要指出的是，对于即时通信工具来说，同样可以利用这种方式不进行添加联系人对象的操作，而是在已有的联系人对象之间，通过表情匹配的方式筛选出特定的联系人对象供交互操作，等等。其应用范围非常广泛，具体不做限定。</p>
    <p>[0107]	进一步，前述的表情匹配关系，指的是预设多种表情项，然后在特定的表情项之间建立对应关系。</p>
    <p>[0108]	作为举例而非限定，表情项中可以包括喜、怒、哀、乐等各种表情；进一步，其中的“喜”可以用各种笑容来表达，而笑容又分出许多种，比如按程度来分，就包括：大笑、微笑，等等，当然还有其它各种分类分法。</p>
    <p>[0109]	作为典型的实施方式，前述的表情匹配关系，指的是具有相同类型的表情具有匹配关系。作为举例，发起方大笑的表情配套外联系人对象的大笑表情；发起方痛哭的表情匹配外联系人对象的痛哭表情，等等。进一步，如果表情的吻合度越高，则判定匹配关系的吻合度越好。</p>
    <p>[0110]	需要指出的是，这种匹配关系还可以由系统提供商或用户自行设定。比如，可以将大笑的表情和痛哭的表情之间预设为匹配关系，等等，具体是不限定的。</p>
    <p>[0111]	在本发明中，在启动表情添加联系人模式之后，对发起方表情数据的采集方式有多种多样。下面针对一些典型实施例描述如下：</p>
    <p>[0112]	方式1，通过拍摄人脸图像的方式，来获取发起方的表情数据。</p>
    <p>[0113]	在表达表情的人体部位中，人脸具有最为丰富的表情数据。不同的情感类型，比如笑、哭，等等，都会有不同的人脸特征与其对应。因此，能够预先建立表情数据与人脸数据之间的对应关系库，然后采集发起方的人脸图像，识别后获得对应的表情数据。</p>
    <p>[0114]	具体来说，所述采集发起方的表情数据，通过如下步骤进行实施：</p>
    <p>[0115]启动所在终端上的摄像结构；</p>
    <p>[0116]	拍摄人脸图像数据，通过所在视窗的浏览界面输出代表相应表情状况的人脸图像；</p>
    <p>[0117]	对应着所输出的特定人脸图像，采集发起方的确定消息获取前述的特定图像；</p>
    <p>[0118]	将获得的图像通过所在的终端设备进行表情识别，获得表情数据，或者将前述的图像传输至识别服务器，在识别服务器中识别后获得表情数据。</p>
    <p>[0119]	前述通过浏览界面输出人脸图像，其主要目的是为了能够让拍摄人脸图像的发起方对自身的表情数据有所了解，方便于获得能够表达自己特定表情的人脸图像。</p>
    <p>[0120]	方式2，采集发起方的音频数据，通过所在终端识别内容后获取表情数据。</p>
    <p>[0121]	这种方式是采集发起方的语音数据，识别后获得文字内容，然后根据文字内容识别获得对应的表情数据。其过程相当于通过语音输入的方式来输入表情数据。</p>
    <p>[0122]	比如，在发起方启动表情添加联系人对象的功能，并触发所在终端的音频录制设备进入到工作状态的情况下，发起方口述“我心里非常的高兴”，于是，通过所在终端上安装的语音识别程序，对其语音数据进行识别后，获得对应的文字，进而从这些文字内容中筛选出具有表情表达功能的数据，该表情类型为“高兴”，程度是“非常的”。</p>
    <p>&#183;[0123]	具体说来，利用所述音频数据识别的方式采集获取发起方表情数据的流程，包括有如下步骤：</p>
    <p>[0124]启动所在终端上的音频录制结构；</p>
    <p>[0125]	采集发起方发出的音频数据；</p>
    <p>[0126]	将获得的音频数据进行识别，根据识别获得的文字内容判定获得发起方的表情数据。</p>
    <p>[0127]	方式3，采集发起方的音频数据，推送至识别服务器，识别获得文字内容后获取表情数据。</p>
    <p>[0128]	这种方式，是通过所在终端采集发起方的语音数据后，将其推送至预先设置的识别服务器，在识别服务器中预设用以进行语音识别的功能模块，对其识别后获得文字内容，然后根据文字内容识别获得对应的表情数据。</p>
    <p>[0129]	这相当于通过语音输入的方式，来通过服务器的识别获得对应的表情数据。比如，在发起方启动表情添加联系人对象的功能，并触发所在终端的音频录制设备进入到工作状态的情况下，发起方口述“我心里非常的高兴”，将该音频数据推送至识别服务器进行识别之后，获得对应的文字。进而可以从这些文字内容中筛选出具有表情表达功能的数据，如表情类型是“高兴”，而程度是“非常的”。</p>
    <p>[0130]	具体说来，通过所在终端与识别服务器配合着进行音频识别，从而获得表情数据内容的方式，包括有如下步骤：</p>
    <p>[0131]启动所在终端上的音频录制结构；</p>
    <p>[0132]	采集发起方发出的音频数据，推送至识别服务器；</p>
    <p>[0133]	在识别服务器中识别为文字内容后，根据文字内容的含义判定对应的表情数据。</p>
    <p>[0134]	方式4，通过预设表情图标控件的方式，来获取表情数据。</p>
    <p>[0135]	这是一种便于实施的方式，具体来说，可以通过预设表情图标控件触发对图标项进行选择的功能。作为举例，该表情图标控件可以设置在即时通信工具的主面板上，用以接受即时通信用户的触发操作。</p>
    <p>[0136]	在触发了表情图标控件之后，能够生成包括预设的各个图标项的图标项阵列。该阵列将不同的表情对应设置有不同的图标项，然后将这些图标项以阵列的方式进行排布。用户通过查看这些图标项中的图像，就可以了解对应图标所表达的表情数据；如果无法获取准确描述的话，作为举例，还可以利用光标，如鼠标光标，在对应的图标项上进行停留，触发对应的控件输出表情数据的说明内容。</p>
    <p>[0137]	比如，用户看到一个具有笑脸图像的图标项，进而利用鼠标光标在其位置上进行停留，即可触发输出预设的字符内容“开心地大笑”。若能够采集获得发起方对该图标项的选择消息，即可采集获得表情数据“开心地大笑”等数据内容。</p>
    <p>[0138]	在本方式中，所描述的采集发起方表情数据的方式，包括有如下步骤：</p>
    <p>[0139]	采集表情图标控件的触发消息；</p>
    <p>[0140]	生成包括有各个图标项的图标项阵列，其中的图标项和预设的表情数据构成映射关系;</p>
    <p>[0141]	采集对特定图标项的触发消息；</p>
    <p>[0142]	获取和前述特定图标项对应的表情数据。 </p>
    <p>[0143]	进一步，用户还可以根据需要，预设特定的图标以及与其对应的表情数据，用以建立个性化的图标项。</p>
    <p>[0144]	方式5，预设代表特定表情数据的文字项，采集特定的文字项后获取预设的表情数据。</p>
    <p>[0145]	前面描述的方式4，是通过图标的方式表达不同的表情数据，而本方式是通过文字所表达的条目，说明相应的表情数据。通过这种方式构成的用以表达特定表情数据的条目，称为文字项。</p>
    <p>[0146]	比如，发起方选择的某个文字项，其内容是“很伤心”，于是，即可将该内容所表达的表情数据直接进行采集，从而获得发起方的表情数据。</p>
    <p>[0147]	该方式下，采集发起方表情数据的方式包括有如下步骤：</p>
    <p>[0148]	采集表情文字描述控件的触发消息；</p>
    <p>[0149]	生成包括有文字项的表情文字项列表，其中的文字项代表着预设的表情数据；</p>
    <p>[0150]	采集对特定文字项的触发消息；</p>
    <p>[0151]	获取和前述特定文字项对应的表情数据。</p>
    <p>[0152]	方式6，采集发起方所写入的字符内容，识别获得文字内容中的表情数据。</p>
    <p>[0153]	这种方式，是设置能够采集发起方所写入字符内容的数据采集栏，通过该数据采集栏采集发起方所写入的字符数据，该字符数据尤其指的是文字数据，但也不限定，也可以是各种用以表达特定表情数据的字符组合，该字符组合尤其指的是字符画。所述的字符画，比如“ Γο~)/”等等，或者是更为复杂的字符画形式，它是通过标点或符号或字母，以特定组合方式组合的具有图案的数据内容。</p>
    <p>[0154]	在本实施方式中，发起方所写入的字符内容，通常是用以表达特定表情数据的字符。用以表达表情数据的字符量并不多，比如“高兴、痛苦，……”，可以预先建立识别规则，通过不同的字符或字符组合获取预设的表情数据，构成映射列表。将采集获得的字符比对该映射列表，从而进行识别操作。</p>
    <p>[0155]	具体说来，该方式下，采集发起方表情数据的方式包括有如下步骤：</p>
    <p>[0156]	设置用以采集字符内容的数据采集栏，以及预设字符内容与表情数据之间的映射列表；</p>
    <p>[0157]	采集发起方所写入的字符内容；</p>
    <p>[0158]	根据所采集获得的字符内容比对前述的映射列表，识别获得对应的表情数据。[0159]	方式7，采集发起方绘制的图像数据，识别获得对应的表情数据。</p>
    <p>[0160]	本方式采集发起方表情数据的途径，与前面的实施方式具有较大的区别。具体来说，是预设图像数据采集栏，该图像数据采集栏包括有用以接受发起方绘图操作的空白区域，以及设置有用以进行绘图操作的画笔工具，以及各种编辑控件。 [0161]	作为举例，发起方对应着已经开启的图像数据采集栏，启动特定的画笔工具后，SP可在图像数据采集栏中的空白区域进行图像绘制操作。如果发起方绘制了一个哈哈大笑的笑脸图像，就可以采集该图像作为发起方通过绘制的方式所载入的表情数据。</p>
    <p>[0162]	如果发起方所绘制的图像无法进行表情数据的识别操作，则可以提醒发起方重新进行绘制操作。</p>
    <p>[0163]	这种方式下，采集发起方的表情数据的步骤包括如下：</p>
    <p>[0164]	设置可供绘制图像的图像数据采集栏；</p>
    <p>[0165]	获取发起方通过前述图像数据采集栏所绘制的图形；</p>
    <p>[0166]	根据图形的内容，识别获得所表达的表情数据。</p>
    <p>[0167]	进一步，还可以对发起方所表达的情感数据，单独增加用以表达程度的数据量。为了实现该目的，可将所述的表情数据分出两类，其中之一，是采集发起方所载入的用以表达表情状况的数据信息，作为主表情项；其中之二，是采集发起方通过程度调节控件所设置的主表情程度量。</p>
    <p>[0168]	作为举例，所述的程度调节控件，包括有能够调节位置的程度滑块，以及对应着程度滑块所设置的程度量刻度。比如，该程度量刻度可从1-100的范围进行调节。若发起方所选择的主表情项为具有大笑表情的图标，进而，可通过程度调节控件，拖动着程度滑块滑到51的位置。</p>
    <p>[0169]	于是，在利用表情数据添加联系人对象时，首先可以比对“大笑”这一主表情项之间的吻合程度，然后，比对主表情程度量的吻合程度，取吻合度最高的外联系人对象输出。</p>
    <p>[0170]	前述的邻近时间段，是预设的和发起方发出表情数据所在时刻邻近之前的时间段，或者邻近之后的时间段，或者包括邻近前后的时间段，具体是不限定的。</p>
    <p>[0171]	在搜索具有表情匹配关系的联系人对象时，有两类方式，一种是具有短期有效性的表情数据，另一种是长期有效的表情数据。</p>
    <p>[0172]	所述短期有效的表情数据，主要体现“即时性”这一特性。作为优选的实施例，所述邻近时间段在5分钟的时间范围之内；进一步，可将所述的邻近时间段，取为在30秒钟的邻近时间范围之内。</p>
    <p>[0173]	所述长期有效的表情数据，指的是将表情数据作为搜索联系人对象时的一个参照因素，因此，对应的表情因素可以长期有效，具体的时间范围是不限定的。</p>
    <p>[0174]	进一步，也可以将所述的邻近时间段作为一个灵活的时间量，尤其指的是在获得第一个符合表情匹配关系的联系人对象的情况下，该最邻近的时间段，时间量越短越优选。</p>
    <p>[0175]	在输出具有表情匹配关系的联系人对象数据时，还可以同时输出联系人对象的表情数据和/或进行表情识别的初始数据，该初始数据，比如，可以是拍摄获得的具有特定表情的人脸图像。</p>
    <p>[0176]	实施例3</p>
    <p>[0177]	对应着前面所描述的方法，本发明还提供一种通过表情数据添加联系人的客户端100。该客户端100能够完成和即时通信相关的各种预设功能。</p>
    <p>[0178]	进一步，参图3所示，该客户端100还可以通过采集发起方的表情数据，根据表情的匹配关系添加联系人对象。为实现该目的，所述的客户端100包括如下结构：</p>
    <p>[0179]	表情匹配设置单元110，用以设置添加联系人对象时的表情匹配关系；</p>
    <p>[0180]	表情数据采集单元120，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至进行用户表情采集及比对操作的表情添加服务器；</p>
    <p>[0181]	联系人获取单元130，用以获取表情添加服务器所推送的符合表情添加联系人模式的特定联系人对象后输出。</p>
    <p>[0182]	在具体实施时，通过表情匹配设置单元110，预设添加联系人对象时的表情匹配关系，该表情匹配关系，优选为具有相同的表情数据之间进行匹配，当然也并不限定。在操作过程中，作为举例，可以通过所在的即时通信客户端，触发其上设置的用以进行表情匹配添 加联系人对象的控件，从而启动本发明所描述的功能。进而通过表情数据采集单元120，采集发起方的表情数据，推送至用以进行用户表情采集及比对操作的表情添加服务器。在表情添加服务器中，如果能够获得符合匹配条件的其他用户数据，则向前述的客户端100进行推送操作。通过客户端100中的联系人获取单元130，接收表情添加服务器所推送的符合表情添加联系人模式的特定联系人对象数据后，通过所在的客户端100输出，供发起方进行选择。如果发起方觉得合适，就启动添加联系人对象的确认操作，否则，触发取消操作就可以。</p>
    <p>[0183]	实施例4</p>
    <p>[0184]	对应着前面所描述的方法及客户端，参图4所示，本发明还提供一种通过表情数据添加联系人的系统200。该系统200可以是即时通信系统，也可以是其它的通信系统，或者是网络社区，或者是游戏社区，等等，具体是不限定的。</p>
    <p>[0185]	进一步，本发明所描述的系统200可以通过输入表情数据的方式，经识别后实现添加联系人对象的目的。为实现该目的，所述的系统200还包括如下结构：</p>
    <p>[0186]	发起方客户端210，它包括，</p>
    <p>[0187]	发起方表情数据采集单元211，用以在启动表情添加联系人模式后，采集发起方的表情数据，推送至下述的表情添加服务器230 ；</p>
    <p>[0188]	发起方联系人获取单元212，用以获取下述表情添加服务器230所推送的符合表情添加联系人模式的特定外联系人对象后输出；</p>
    <p>[0189]	外联系人对象客户端220，它包括，</p>
    <p>[0190]	外联系人对象表情数据采集单元221，用以在启动表情添加联系人模式后，采集外联系人对象自身的表情数据，推送至下述的表情添加服务器230 ；</p>
    <p>[0191]	外联系人对象获取单元222，用以获取下述表情添加服务器230所推送的符合表情添加联系人模式的特定用户数据后输出；</p>
    <p>[0192]	表情添加服务器230，它包括，</p>
    <p>[0193]	服务器表情匹配设置单元231，用以设置添加联系人对象时的表情匹配关系；</p>
    <p>[0194]	服务器表情数据采集单元232，用以采集来自于前述发起方客户端210与外联系人对象客户端220所传送的表情数据；</p>
    <p>[0195]	服务器联系人获取单元233，用以获取在邻近时间段外联系人对象客户端220所载入的表情数据，从外联系人对象中采集具有表情匹配关系的特定外联系人对象数据；</p>
    <p>[0196]	服务器联系人推送单元234，用以向前述的发起方客户端210推送构成表情匹配关系的特定外联系人对象数据，和/或对应着符合匹配关系的特定外联系人对象客户端220推送前述发起方的数据。</p>
    <p>[0197]	在具体实施时，可以通过表情添加服务器230中的服务器表情匹配设置单元231，预设添加联系人对象时的表情匹配关系，比如预设相同的表情之间具有表情匹配关系，其中相似性越高匹配性越好。当然，所述的表情匹配关系也可以通过发起方客户端210进行设置，将设置结果推送至表情添加服务器230后，由服务器表情匹配设置单元231进行存储。</p>
    <p>[0198]	在发起方利用表情识别的方式进行联系人对象的添加操作时，通过发起方表情数据采集单元211，在启动表情添加联系人模式之后，启动所在终端上的摄像结构或其它类型 的表情数据录制结构，采集发起方的表情数据后，将其推送至表情添加服务器230。</p>
    <p>[0199]	进一步，在本实施例中，对应着发起方客户端210，还同步设置了外联系人对象客户端220。相对于表情添加服务器230，它们是地位相同的客户端。对于操作外联系人对象客户端220的外联系人对象来说，也是向表情添加服务器230推送表情数据，希望能够在得到响应的情况下，通过表情识别的方式添加联系人对象。</p>
    <p>[0200]	外联系人对象客户端220所推送的表情数据，提供了用以和发起方匹配表情数据的基础。具体来说，外联系人对象客户端220中所设置的结构形式可以和发起方客户端210中的结构一致。在进行操作的过程中，所述的外联系人对象客户端220至少包括外联系人对象表情数据采集单元221，用以在启动表情添加联系人模式后，采集外联系人对象自身的表情数据，推送至表情添加服务器230。</p>
    <p>[0201]	在表情添加服务器230中，通过服务器表情数据采集单元232，采集来自于前述发起方客户端210与外联系人对象客户端220所传送的表情数据，进而通过服务器联系人获取单元233，依据服务器表情匹配设置单元231所设置的添加联系人对象时的表情匹配关系，获取在邻近时间段外联系人对象客户端220所载入的表情数据，从外联系人对象中采集具有表情匹配关系的特定外联系人对象数据。进而通过服务器联系人推送单元234，向前述的发起方客户端210推送前述具有表情匹配关系的特定外联系人对象数据。进一步，还可以将发起方的数据信息传输至前述特定外联系人对象所在的外联系人对象客户端220中输出，供该外联系人对象判定是否要添加前述的发起方为联系人对象。</p>
    <p>[0202]	对应着前述表情添加服务器230推送的识别数据，在发起方客户端210中设置有发起方联系人获取单元212，在获取表情添加服务器230所推送的符合表情添加联系人模式的特定外联系人对象数据后输出，供发起方进行选择。</p>
    <p>[0203]	类似地，前述外联系人对象客户端220还配套设置有外联系人对象获取单元222，用以在获取了表情添加服务器230所推送的符合表情添加联系人模式的特定用户数据后，通过所在的客户端输出，供外联系人对象进行选择。其中，符合表情添加联系人模式的特定用户未必是前述的发起方。</p>
    <p>[0204]	以上是对本发明的描述而非限定，基于本发明思想的其它实施例，亦均在本发明的保护范围之中。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101242374A?cl=zh">CN101242374A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年3月11日</td><td class="patent-data-table-td patent-date-value">2008年8月13日</td><td class="patent-data-table-td ">腾讯科技（深圳）有限公司</td><td class="patent-data-table-td ">即时通讯中匹配用户列表的系统、方法和即时通讯终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102404357A?cl=zh">CN102404357A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年9月10日</td><td class="patent-data-table-td patent-date-value">2012年4月4日</td><td class="patent-data-table-td ">北京创新方舟科技有限公司</td><td class="patent-data-table-td ">通过社区网络更新移动终端联系人信息的方法和设备</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102546462A?cl=zh">CN102546462A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月18日</td><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">上海量明科技发展有限公司</td><td class="patent-data-table-td ">即时通信中推荐联系人的方法、客户端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102629919A?cl=zh">CN102629919A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月27日</td><td class="patent-data-table-td patent-date-value">2012年8月8日</td><td class="patent-data-table-td ">上海量明科技发展有限公司</td><td class="patent-data-table-td ">即时通信中用以添加联系人的方法、客户端及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050076090">US20050076090</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2003年10月7日</td><td class="patent-data-table-td patent-date-value">2005年4月7日</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method, system, and apparatus for selective automated electronic mail replies</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103207890A?cl=zh">CN103207890A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年2月21日</td><td class="patent-data-table-td patent-date-value">2013年7月17日</td><td class="patent-data-table-td ">北京百纳威尔科技有限公司</td><td class="patent-data-table-td ">联系人信息获取方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103401981A?cl=zh">CN103401981A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月25日</td><td class="patent-data-table-td patent-date-value">2013年11月20日</td><td class="patent-data-table-td ">深圳市金立通信设备有限公司</td><td class="patent-data-table-td ">一种发起通信请求的方法和移动终端</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103401981B?cl=zh">CN103401981B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年7月25日</td><td class="patent-data-table-td patent-date-value">2016年3月30日</td><td class="patent-data-table-td ">深圳市金立通信设备有限公司</td><td class="patent-data-table-td ">一种发起通信请求的方法和移动终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=q6uwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=q6uwBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0012580000">H04L12/58</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年11月28日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年6月12日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年1月6日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/f862d5d1cf4167f6d538/CN102801652A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E9%80%9A%E8%BF%87%E8%A1%A8%E6%83%85%E6%95%B0%E6%8D%AE%E6%B7%BB%E5%8A%A0%E8%81%94%E7%B3%BB%E4%BA%BA%E7%9A%84%E6%96%B9.pdf?id=q6uwBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U38ii00TchD2AZs78jvbMGgHEU9XA"},"sample_url":"https://www.google.com/patents/reader?id=q6uwBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>