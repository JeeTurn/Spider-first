<!DOCTYPE html><html><head><title>专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于图像匹配与地理位置信息来获取信息的方法及系统"><meta name="DC.contributor" content="罗希平" scheme="inventor"><meta name="DC.contributor" content="镇立新" scheme="inventor"><meta name="DC.contributor" content="陈青山" scheme="inventor"><meta name="DC.contributor" content="龙腾" scheme="inventor"><meta name="DC.contributor" content="上海合合信息科技发展有限公司" scheme="assignee"><meta name="DC.date" content="2011-12-16" scheme="dateSubmitted"><meta name="DC.description" content="本发明提供一种基于图像匹配与地理位置信息来获取信息的方法及系统。根据本发明的方法，先将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；随后，基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；并当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户，由此能基于图像匹配以及地理位置信息来提供信息给用户，确保了信息的安全。"><meta name="DC.date" content="2012-6-27"><meta name="DC.relation" content="CN:101000623:A" scheme="references"><meta name="DC.relation" content="CN:102129812:A" scheme="references"><meta name="DC.relation" content="JP:2007219615" scheme="references"><meta name="citation_patent_publication_number" content="CN:102521621:A"><meta name="citation_patent_application_number" content="CN:201110425567"><link rel="canonical" href="https://www.google.com/patents/CN102521621A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102521621A?cl=zh"/><meta name="title" content="专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统"/><meta name="description" content="本发明提供一种基于图像匹配与地理位置信息来获取信息的方法及系统。根据本发明的方法，先将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；随后，基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；并当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户，由此能基于图像匹配以及地理位置信息来提供信息给用户，确保了信息的安全。"/><meta property="og:title" content="专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102521621A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102521621A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102521621A&amp;usg=AFQjCNGaH43ue5O70MS43HGz5nRB8Ql0hA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/859ce18a8046b26aafdf/CN102521621A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/859ce18a8046b26aafdf/CN102521621A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102521621A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102521621A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102521621A?cl=zh" style="display:none"><span itemprop="description">本发明提供一种基于图像匹配与地理位置信息来获取信息的方法及系统。根据本发明的方法，先将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用...</span><span itemprop="url">https://www.google.com/patents/CN102521621A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统" title="专利 CN102521621A - 基于图像匹配与地理位置信息来获取信息的方法及系统"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102521621 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110425567</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年6月27日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年12月16日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年12月16日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110425567.X, </span><span class="patent-bibdata-value">CN 102521621 A, </span><span class="patent-bibdata-value">CN 102521621A, </span><span class="patent-bibdata-value">CN 201110425567, </span><span class="patent-bibdata-value">CN-A-102521621, </span><span class="patent-bibdata-value">CN102521621 A, </span><span class="patent-bibdata-value">CN102521621A, </span><span class="patent-bibdata-value">CN201110425567, </span><span class="patent-bibdata-value">CN201110425567.X</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E7%BD%97%E5%B8%8C%E5%B9%B3%22">罗希平</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%95%87%E7%AB%8B%E6%96%B0%22">镇立新</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E9%9D%92%E5%B1%B1%22">陈青山</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%BE%99%E8%85%BE%22">龙腾</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%8A%E6%B5%B7%E5%90%88%E5%90%88%E4%BF%A1%E6%81%AF%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">上海合合信息科技发展有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102521621A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102521621A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102521621A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110425567&amp;usg=AFQjCNG4iQ6gVguEpIbVCez0Y86popu9Zw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102521621A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHOA6JdShzBNOrhtpxxAeWeaChHVg"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT113596644" lang="ZH" load-source="patent-office">基于图像匹配与地理位置信息来获取信息的方法及系统</invention-title>
      </span><br><span class="patent-number">CN 102521621 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA97599406" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明提供一种基于图像匹配与地理位置信息来获取信息的方法及系统。根据本发明的方法，先将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；随后，基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；并当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户，由此能基于图像匹配以及地理位置信息来提供信息给用户，确保了信息的安全。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(6)</span></span></div><div class="patent-text"><div mxw-id="PCLM43130480" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种基于图像匹配与地理位置信息来获取信息的方法，其特征在于，所述基于图像匹配与地理位置信息来获取信息的方法至少包括步骤：1)将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；2)基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；3)当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的基于图像匹配与地理位置信息来获取信息的方法，其特征在于：所述步骤2)还包括：由来自第二用户的图像信息提取至少一个特征向量，并基于所述至少一个特征向量中的每一个与各验证用图像信息各自相应的特征向量之间的距离来确定是否有匹配的验证用图像信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的基于图像匹配与地理位置信息来获取信息的方法，其特征在于：第一用户包括以下至少一项：个人；网站。</div>
    </div>
    </div> <div class="claim"> <div num="4" class="claim">
      <div class="claim-text">4.	一种基于图像匹配与地理位置信息来获取信息的获取系统，其特征在于，所述基于图像匹配与地理位置信息来获取信息的获取系统至少包括：关联模块，用于将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；确定模块，用于基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；提供模块，用于当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4所述的基于图像匹配与地理位置信息来获取信息的获取系统，其特征在于：所述确定模块还包括：特征提取模块，用于由来自第二用户的图像信息提取至少一个特征向量，并基于所述至少一个特征向量中的每一个与各验证用图像信息各自相应的特征向量之间的距离来确定是否有匹配的验证用图像信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求4所述的基于图像匹配与地理位置信息来获取信息的获取系统，其特征在于：第一用户包括以下至少一项：个人；网站。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES47687332" lang="ZH" load-source="patent-office" class="description">
    <p>基于图像匹配与地理位置信息来获取信息的方法及系统</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及计算机领域，特别是涉及一种基于图像匹配与地理位置信息来获取信息的方法及系统。</p>
    <p>背景技术</p>
    <p>[0002]	图像匹配是指判断两张图像中拍摄的物体是不是同一个物体。学术界对图像匹配的研究已经有很多年了，一般的做法是找出图像中所拍摄物体的一些特征点，然后依据这些特征点周边一定范围内的像素值来得到一个特征向量，通过特征点和特征向量的匹配来判断图像中拍摄的是不是同一个物体。从目前的技术而言，利用图像匹配技术从包含成千上万的物体图像的数据库中找出匹配的图像，所需要的时间比较长，准确率也不高。</p>
    <p>[0003]	而随着网络技术的发展，用户基于网络来获取信息已经日益频繁，如何将图像匹配技术应用于信息的获取，以确保信息的安全，已经成为本领域技术人员研究的热点。</p>
    <p>发明内容</p>
    <p>[0004]	鉴于以上所述现有技术的缺点，本发明的目的在于提供一种基于图像匹配与地理位置信息来获取信息的方法及系统。</p>
    <p>[0005]	为实现上述目的及其他相关目的，本发明提供一种基于图像匹配与地理位置信息来获取信息的方法，其至少包括以下步骤：</p>
    <p>[0006]	1)将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；</p>
    <p>[0007]	2)基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；以及</p>
    <p>[0008]	3)当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</p>
    <p>[0009]	优选地，所述步骤幻还包括：</p>
    <p>[0010]	由来自第二用户的图像信息提取至少一个特征向量，并基于所述至少一个特征向量中的每一个与各验证用图像信息各自相应的特征向量之间的距离来确定是否有匹配的验证用图像信息。</p>
    <p>[0011]	本发明提供一种基于图像匹配与地理位置信息来获取信息的获取系统，其至少包括：</p>
    <p>[0012]	关联模块，用于将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联；</p>
    <p>[0013]	确定模块，用于基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息；[0014]	提供模块，用于当确定有匹配的验证用图像信息时，将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</p>
    <p>[0015]	优选地，第一用户包括个人、网站等。</p>
    <p>[0016]	如上所述，本发明的基于图像匹配与地理位置信息来获取信息的方法及系统，具有以下有益效果：能基于图像匹配以及地理位置信息来提供信息给用户，确保了信息的安全。</p>
    <p>附图说明</p>
    <p>[0017]	图1显示为本发明的基于图像匹配与地理位置信息来获取信息的方法流程图。</p>
    <p>[0018]	图2显示为本发明的基于图像匹配与地理位置信息来获取信息的获取系统示意图。</p>
    <p>[0019]	元件标号说明</p>
    <p>[0020]	1	获取系统</p>
    <p>[0021]	11	关联模块</p>
    <p>[0022]	12	确定模块</p>
    <p>[0023]	13	提供模块</p>
    <p>[0024]	Sl-S3 步骤</p>
    <p>具体实施方式</p>
    <p>[0025]	以下通过特定的具体实例说明本发明的实施方式，本领域技术人员可由本说明书所揭露的内容轻易地了解本发明的其他优点与功效。本发明还可以通过另外不同的具体实施方式加以实施或应用，本说明书中的各项细节也可以基于不同观点与应用，在没有背离本发明的精神下进行各种修饰或改变。</p>
    <p>[0026]	请参阅图1至图2。需要说明的是，本实施例中所提供的图示仅以示意方式说明本发明的基本构想，遂图式中仅显示与本发明中有关的组件而非按照实际实施时的组件数目、形状及尺寸绘制，其实际实施时各组件的型态、数量及比例可为一种随意的改变，且其组件布局型态也可能更为复杂。</p>
    <p>[0027]	如图所示，本发明提供一种基于图像匹配与地理位置信息来获取信息的方法。其中，本发明所述的方法主要由获取系统来执行，所述获取系统为安装在计算机设备中的应用模块等。该计算机设备为一种能够按照事先存储的程序，自动、高速地进行大量数值计算和各种信息处理的现代化智能电子设备，其硬件包括但不限于微处理器、FPGA、DSP、嵌入式设备等。所述计算机设备包括但不限于单个网络服务器、多个网络服务器组成的服务器组或基于云计算（Cloud Computing)的由大量计算机或网络服务器构成的云，其中，云计算是分布式计算的一种由一群松散耦合的计算机集组成的一个超级虚拟计算机。</p>
    <p>[0028]	在步骤Sl中，所述获取系统将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联。</p>
    <p>[0029]	其中，所述第一用户包括任何想向其他用户提供信息的用户，优选地，包括但不限于：个人、网站等。例如，提供在线观看音视频的网站等。[0030]	其中，待提供给用户的信息包括任何能提供给用户的信息，优选地，包括但不限于：1)由个人上传给所述获取系统的信息，例如，个人Bl上传的自身名片图像信息；又例如，个人B2上传的音频信息等；2)由网站提供给用户的信息；例如，由专业视频网站提供给授权用户的视频信息等等。</p>
    <p>[0031]	其中，所述获取系统获取地理位置信息的方式包括：1)由所能访问的地理位置信息库中随机选择一个或多个来添加；例如，所述获取系统由所能访问的地理位置信息库中随机选择的地理位置信息包括北京与山东，则所述获取系统将来自第一用户的图像信息添加北京后形成验证用图像信息ml、添加山东后形成验证用图像信息m2 ；2)将自身所存储的地理位置信息中的每一个均添加给来自第一用户的图像信息，以形成多个验证用信息；3) 基于第一用户的要求信息来添加；例如，所述获取系统基于个人B3在显示有地理位置信息列表的界面中所选择的地理位置信息来添加；又例如，所述获取系统基于网站Xl所提供的地理位置信息来添加等。</p>
    <p>[0032]	需要说明的是，本领域技术人员应该理解，上述所示仅仅只是列示，而非对本发明的限制，事实上，任何获取地理位置信息的方式，均应包含在本发明的范围内。</p>
    <p>[0033]	其中，所述指示信息包括将一个验证用图像信息与哪一个或多个待提供给其他用户的信息相关联的信息。例如，将验证用图像信息m3与待提供给其他用户的动漫信息yl 相关联的指示信息。</p>
    <p>[0034]	例如，所述获取系统将来自个人Bll的图像信息添加地理位置信息“烟台”后形成验证用图像信息mil、添加地理位置信息“洛阳”后形成验证用图像信息ml2，将来自网站 Xll的图像信息添加地理位置信息“北京大学”后形成验证用图像信息ml3，并基于个人Bll 的指示信息将个人Bll对应的验证信息mil与待提供给其他用户的信息Vl相关联、将个人 Bll对应的验证信息ml2与待提供给其他用户的信息V2相关联，基于网站Xll的指示信息将网站Xll对应的验证信息ml3与待提供给其他用户的信息V3相关联。</p>
    <p>[0035]	在步骤S2中，所述获取系统基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息。</p>
    <p>[0036]	其中，所述获取系统获取第二用户的地理位置信息的方式包括但不限于：由第二用户的提供等。例如，所述获取系统基于第二用户A32在自身所提供的地理位置信息输入界面中输入“北京”，来获得第二用户A32所在的地理位置信息为“北京”。又例如，第二用户A33启动自身所携带的手机的GPS模块来确定自身的地理位置信息后，将该地理位置信息提供给所述获取系统。</p>
    <p>[0037]	具体地，所述获取系统基于来自第二用户的图像信息及该第二用户的地理位置信息与验证图像信息是否相同或相似来判断两者是否匹配。</p>
    <p>[0038]	例如，所述获取系统先选择出验证用图像信息中的地理位置信息与该第二用户的地理位置信息相同者，随后，再将所选择出的验证用图像信息中的每一个包含的像素点与来自第二用户的图像信息包含的像素点逐一比对来确定来自第二用户的图像信息与验证图像信息是否相同。</p>
    <p>[0039]	又例如，所述获取系统先选择出验证用图像信息中的地理位置信息与该第二用户的地理位置信息相同者，随后，再将所选择出的验证用图像信息中的每一个包含的像素点与来自第二用户的图像信息包含的像素点逐一比对，当一个验证用图像信息中超过80%的像素点的像素值均与来自第二用户的图像信息对应的像素点的像素值相同，则确定该个验证用图像信息与来自第二用户的图像信息匹配。</p>
    <p>[0040]	需要说明的是，本领域技术人员应该理解，上述所示仅仅只是列示，而非对本发明的限制，事实上，任何基于来自第二用户的图像信息及该第二用户的地理位置信息与验证图像信息是否相同或相似来判断两者是否匹配的方式，均包含在本发明的范围内。</p>
    <p>[0041]	在步骤S3中，当确定有匹配的验证用图像信息时，所述获取系统将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</p>
    <p>[0042]	例如，所述获取系统在步骤S2中确定验证用图像信息m21与来自第二用户A41的图像信息匹配，则所述获取系统将与验证用图像信息m21关联的待提供给其他用户的信息 Vll提供给该第二用户A41。</p>
    <p>[0043]	作为一种优选方案，根据本发明的方法，步骤S2还包括步骤S2’ (未予图示）。</p>
    <p>[0044]	在步骤S2’中，所述获取系统由各验证用图像信息中选择出地理位置信息与该第二用户的地理位置信息相同者，并由来自第二用户的图像信息提取至少一个特征向量，并基于所述至少一个特征向量中的每一个与所选择出的各验证用图像信息各自相应的特征向量之间的距离来确定是否有匹配的验证用图像信息。</p>
    <p>[0045]	具体地，所述获取系统先由各验证用图像信息中选择出地理位置信息与该第二用户的地理位置信息相同者，再由来自第二用户的图像信息中提取至少一个特征点，并基于每一个特征点周围预定范围内的像素点来形成一个特征向量，随后再判断所形成的每一个特征向量与所选择出的各验证图像信息各自相应的特征向量之间的距离是否小于预定距离阈值，并当来自第二用户的图像信息中与一个验证图像信息的特征向量之间的距离小于预定距离阈值的特征向量的数量超过预定数值，则所述获取系统确定该来自第二用户的图像信息与该个验证图像信息匹配，否则，确定该来自第二用户的图像信息与该个验证图像信息不匹配。</p>
    <p>[0046]	例如，所述获取系统先由各验证用图像信息中选择出地理位置信息与第二用户 A51的地理位置信息相同者包括验证用图像信息m31，随后，所述获取系统再由来自第二用户A51的图像信息中提取特征点il、i2……ik，并基于特征点il、i2……i3各自周围预定范围内的像素点来分别形成特征向量jl、j2……jk，接着，所述获取系统再分别判断特征向量jl与验证用图像信息m31对应的特征向量11、特征向量j2与验证用图像信息m31对应的特征向量12、……特征向量jk与验证用图像信息m31对应的特征向量Ik之间的距离是否小于预定距离阈值，当来自第二用户A51的图像信息中与验证图像信息m31的特征向量之间的距离小于预定距离阈值的特征向量的数量超过预定数值，则所述获取系统确定该来自第二用户A51的图像信息与该个验证图像信息m31匹配，否则，则确定该来自第二用户 A51的图像信息与该个验证图像信息m31不匹配。</p>
    <p>[0047]	需要说明的是，本领域技术人员应该已经理解特征向量与特征向量之间的距离， 例如，欧氏距离等，故在此不再详述。</p>
    <p>[0048]	如图所示，本发明提供一种基于图像匹配与地理位置信息来获取信息的获取系统。其中，所述获取系统1包括关联模块11、确定模块12、及提供模块13。</p>
    <p>[0049]	所述关联模块11将来自第一用户的图像信息添加地理位置信息以形成验证用图像信息，并基于每一个第一用户的指示信息将该个第一用户的各验证用图像信息分别与至少一待提供给其他用户的信息相关联。</p>
    <p>[0050]	其中，所述第一用户包括任何想向其他用户提供信息的用户，优选地，包括但不限于：个人、网站等。例如，提供在线观看音视频的网站等。</p>
    <p>[0051]	其中，待提供给用户的信息包括任何能提供给用户的信息，优选地，包括但不限于：1)由个人上传给所述获取系统1的信息，例如，个人Bl上传的自身名片图像信息；又例如，个人B2上传给所述获取系统1的音频信息等；2)由网站提供给用户的信息；例如，由专业视频网站提供给授权用户的视频信息等等。</p>
    <p>[0052]	其中，所述关联模块11获取地理位置信息的方式包括：1)由所能访问的地理位置信息库中随机选择一个或多个来添加；例如，所述关联模块11由所能访问的地理位置信息库中随机选择的地理位置信息包括北京与山东，则所述关联模块11将来自第一用户的图像信息添加北京后形成验证用图像信息ml、添加山东后形成验证用图像信息m2 ；2)将自身所存储的地理位置信息中的每一个均添加给来自第一用户的图像信息，以形成多个验证用信息；3)基于第一用户的要求信息来添加；例如，所述关联模块11基于个人B3在显示有地理位置信息列表的界面中所选择的地理位置信息来添加；又例如，所述关联模块11基于网站Xl所提供的地理位置信息来添加等。</p>
    <p>[0053]	需要说明的是，本领域技术人员应该理解，上述所示仅仅只是列示，而非对本发明的限制，事实上，任何获取地理位置信息的方式，均应包含在本发明的范围内。</p>
    <p>[0054]	其中，所述指示信息包括将一个验证用图像信息与哪一个或多个待提供给其他用户的信息相关联的信息。例如，将验证用图像信息m3与待提供给其他用户的动漫信息yl 相关联的指示信息。</p>
    <p>[0055]	例如，所述关联模块11将来自个人Bll的图像信息添加地理位置信息“烟台”后形成验证用图像信息mil、添加地理位置信息“洛阳”后形成验证用图像信息ml2，将来自网站Xll的图像信息添加地理位置信息“北京大学”后形成验证用图像信息ml3，并基于个人 Bll的指示信息将个人Bll对应的验证信息mil与待提供给其他用户的信息Vl相关联、将个人Bll对应的验证信息ml2与待提供给其他用户的信息V2相关联，基于网站Xll的指示信息将网站Xll对应的验证信息ml3与待提供给其他用户的信息V3相关联。</p>
    <p>[0056]	所述确定模块12基于来自第二用户的图像信息及该第二用户的地理位置信息来确定是否有匹配的验证用图像信息。</p>
    <p>[0057]	其中，所述确定模块12获取第二用户的地理位置信息的方式包括但不限于：由第二用户的提供等。例如，所述确定模块12基于第二用户A32在自身所提供的地理位置信息输入界面中输入“北京”，来获得第二用户A32所在的地理位置信息为“北京”。又例如，第二用户A33启动自身所携带的手机的GPS模块来确定自身的地理位置信息后，将该地理位置信息提供给所述确定模块12。</p>
    <p>[0058]	具体地，所述确定模块12基于来自第二用户的图像信息及该第二用户的地理位置信息与验证图像信息是否相同或相似来判断两者是否匹配。</p>
    <p>[0059]	例如，所述确定模块12先选择出验证用图像信息中的地理位置信息与该第二用户的地理位置信息相同者，随后，再将所选择出的验证用图像信息中的每一个包含的像素点与来自第二用户的图像信息包含的像素点逐一比对来确定来自第二用户的图像信息与验证图像信息是否相同。[0060]	又例如，所述确定模块12先选择出验证用图像信息中的地理位置信息与该第二用户的地理位置信息相同者，随后，再将所选择出的验证用图像信息中的每一个包含的像素点与来自第二用户的图像信息包含的像素点逐一比对，当一个验证用图像信息中超过 80%的像素点的像素值均与来自第二用户的图像信息对应的像素点的像素值相同，则确定该个验证用图像信息与来自第二用户的图像信息匹配。</p>
    <p>[0061]	需要说明的是，本领域技术人员应该理解，上述所示仅仅只是列示，而非对本发明的限制，事实上，任何基于来自第二用户的图像信息及该第二用户的地理位置信息与验证图像信息是否相同或相似来判断两者是否匹配的方式，均包含在本发明的范围内。</p>
    <p>[0062]	当确定有匹配的验证用图像信息时，所述提供模块13将与所述匹配的验证用图像信息关联的待提供给其他用户的信息提供给所述第二用户。</p>
    <p>[0063]	例如，所述确定模块12确定验证用图像信息m21与来自第二用户A41的图像信息匹配，则所述提供模块13将与验证用图像信息m21关联的待提供给其他用户的信息Vl 1提供给该第二用户A41。</p>
    <p>[0064]	作为一种优选方案，所述确定模块12还包括特征提取模块（未予图示）。</p>
    <p>[0065]	所述特征提取模块由各验证用图像信息中选择出地理位置信息与该第二用户的地理位置信息相同者，并由来自第二用户的图像信息提取至少一个特征向量，并基于所述至少一个特征向量中的每一个与所选择出的各验证用图像信息各自相应的特征向量之间的距离来确定是否有匹配的验证用图像信息。</p>
    <p>[0066]	具体地，所述特征提取模块先由各验证用图像信息中选择出地理位置信息与该第二用户的地理位置信息相同者，再由来自第二用户的图像信息中提取至少一个特征点，并基于每一个特征点周围预定范围内的像素点来形成一个特征向量，随后再判断所形成的每一个特征向量与所选择出的各验证图像信息各自相应的特征向量之间的距离是否小于预定距离阈值，并当来自第二用户的图像信息中与一个验证图像信息的特征向量之间的距离小于预定距离阈值的特征向量的数量超过预定数值，则所述特征提取模块确定该来自第二用户的图像信息与该个验证图像信息匹配，否则，确定该来自第二用户的图像信息与该个验证图像信息不匹配。</p>
    <p>[0067]	例如，所述特征提取模块先由各验证用图像信息中选择出地理位置信息与第二用户A51的地理位置信息相同者包括验证用图像信息m31，随后，所述特征提取模块再由来自第二用户A51的图像信息中提取特征点il、i2……ik，并基于特征点il、i2……i3各自周围预定范围内的像素点来分别形成特征向量jl、j2……jk，接着，所述特征提取模块再分别判断特征向量jl与验证用图像信息m31对应的特征向量11、特征向量j2与验证用图像信息m31对应的特征向量12、……特征向量jk与验证用图像信息m31对应的特征向量Ik之间的距离是否小于预定距离阈值，当来自第二用户A51的图像信息中与验证图像信息m31 的特征向量之间的距离小于预定距离阈值的特征向量的数量超过预定数值，则所述特征提取模块确定该来自第二用户A51的图像信息与该个验证图像信息m31匹配，否则，则确定该来自第二用户A51的图像信息与该个验证图像信息m31不匹配。</p>
    <p>[0068]	需要说明的是，本领域技术人员应该已经理解特征向量与特征向量之间的距离， 例如，欧氏距离等，故在此不再详述。。</p>
    <p>[0069]	综上所述，本发明基于图像匹配与地理位置信息来获取信息的方法及系统基于来自第二用户的图像信息及地理位置信息与验证用图像信息是否匹配来来确定用户是否有权获取信息，由此可确保信息的安全，而且基于地理位置信息进行筛选后，再来将基于来自第二用户的图像信息与验证图像信息进行图像匹配，图像匹配所耗费时间少，准确度高。所以，本发明有效克服了现有技术中的种种缺点而具高度产业利用价值。 [0070] 上述实施例仅例示性说明本发明的原理及其功效，而非用于限制本发明。任何熟悉此技术的人士皆可在不违背本发明的精神及范畴下，对上述实施例进行修饰或改变。因此，举凡所属技术领域中具有通常知识者在未脱离本发明所揭示的精神与技术思想下所完成的一切等效修饰或改变，仍应由本发明的权利要求所涵盖。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101000623A?cl=zh">CN101000623A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年1月8日</td><td class="patent-data-table-td patent-date-value">2007年7月18日</td><td class="patent-data-table-td ">深圳市宜搜科技发展有限公司</td><td class="patent-data-table-td ">通过手机拍照进行图像识别搜索的方法及采用该方法的装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102129812A?cl=zh">CN102129812A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年1月11日</td><td class="patent-data-table-td patent-date-value">2011年7月20日</td><td class="patent-data-table-td ">微软公司</td><td class="patent-data-table-td ">在街道级图像的上下文中观看媒体</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2007219615A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH4OvXj9ZhzuUPpiDdOy1ttA5guNw">JP2007219615A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013182101A1?cl=zh">WO2013182101A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年6月27日</td><td class="patent-data-table-td patent-date-value">2013年12月12日</td><td class="patent-data-table-td ">Zte Corporation</td><td class="patent-data-table-td ">目标人的确定方法、装置及移动终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009640000">G06K9/64</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VA1bBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年6月27日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年9月5日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/859ce18a8046b26aafdf/CN102521621A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D%E4%B8%8E%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF.pdf?id=VA1bBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2K4DTHU_itdH2L11mMDsBKsuycnw"},"sample_url":"https://www.google.com/patents/reader?id=VA1bBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>