<!DOCTYPE html><html><head><title>专利 CN103902046A - 智能提醒方法和终端 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="智能提醒方法和终端"><meta name="DC.contributor" content="赵欣" scheme="inventor"><meta name="DC.contributor" content="深圳市中兴移动通信有限公司" scheme="assignee"><meta name="DC.date" content="2014-4-10" scheme="dateSubmitted"><meta name="DC.description" content="本发明公开了一种智能提醒方法和终端，所述智能提醒方法包括步骤：获取人脸图像；根据所述人脸图像识别出人物的状态信息；输出所述状态信息。从而，本发明通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时输出该状态信息来提醒用户，提高了终端的灵活性，满足了用户对终端的主动交流要求。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。"><meta name="DC.date" content="2014-7-2"><meta name="DC.relation" content="CN:102929660:A" scheme="references"><meta name="DC.relation" content="CN:1830389:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:103902046:A"><meta name="citation_patent_application_number" content="CN:201410142502"><link rel="canonical" href="https://www.google.com/patents/CN103902046A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103902046A?cl=zh"/><meta name="title" content="专利 CN103902046A - 智能提醒方法和终端"/><meta name="description" content="本发明公开了一种智能提醒方法和终端，所述智能提醒方法包括步骤：获取人脸图像；根据所述人脸图像识别出人物的状态信息；输出所述状态信息。从而，本发明通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时输出该状态信息来提醒用户，提高了终端的灵活性，满足了用户对终端的主动交流要求。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。"/><meta property="og:title" content="专利 CN103902046A - 智能提醒方法和终端"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103902046A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103902046A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103902046A&amp;usg=AFQjCNGiUaMW4C2QeniAW3XA4-XdywIiSQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/9cbd5a5d9b4abd92cd7a/CN103902046A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/9cbd5a5d9b4abd92cd7a/CN103902046A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103902046A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103902046A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103902046A?cl=zh" style="display:none"><span itemprop="description">本发明公开了一种智能提醒方法和终端，所述智能提醒方法包括步骤：获取人脸图像；根据所述人脸图像识别出人物的状态信息；输出所述状态信息。从而，本发明通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状...</span><span itemprop="url">https://www.google.com/patents/CN103902046A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103902046A - 智能提醒方法和终端</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103902046A - 智能提醒方法和终端" title="专利 CN103902046A - 智能提醒方法和终端"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103902046 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201410142502</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2014年7月2日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2014年4月10日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2014年4月10日</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201410142502.8, </span><span class="patent-bibdata-value">CN 103902046 A, </span><span class="patent-bibdata-value">CN 103902046A, </span><span class="patent-bibdata-value">CN 201410142502, </span><span class="patent-bibdata-value">CN-A-103902046, </span><span class="patent-bibdata-value">CN103902046 A, </span><span class="patent-bibdata-value">CN103902046A, </span><span class="patent-bibdata-value">CN201410142502, </span><span class="patent-bibdata-value">CN201410142502.8</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B5%B5%E6%AC%A3%22">赵欣</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E6%B7%B1%E5%9C%B3%E5%B8%82%E4%B8%AD%E5%85%B4%E7%A7%BB%E5%8A%A8%E9%80%9A%E4%BF%A1%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">深圳市中兴移动通信有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103902046A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103902046A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103902046A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201410142502&amp;usg=AFQjCNECETMcMekG_4ZTtvZHOdAbntkaQw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103902046A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHhEZkMzMQrUBNZnPhaKlgwBlng8g"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT137884817" lang="ZH" load-source="patent-office">智能提醒方法和终端</invention-title>
      </span><br><span class="patent-number">CN 103902046 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA135724280" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明公开了一种智能提醒方法和终端，所述智能提醒方法包括步骤：获取人脸图像；根据所述人脸图像识别出人物的状态信息；输出所述状态信息。从而，本发明通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时输出该状态信息来提醒用户，提高了终端的灵活性，满足了用户对终端的主动交流要求。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM64296769" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种智能提醒方法，其特征在于，包括步骤:  获取人脸图像；  根据所述人脸图像识别出人物的状态信息；  输出所述状态信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的智能提醒方法，其特征在于，所述状态信息为情绪状态信息，则所述根据人脸图像识别出人物的状态信息，包括:  从所述人脸图像中提取出面部特征；  从表情特征库中选出与所述面部特征相匹配的表情特征，据此识别出与所述表情特征相对应的情绪状态信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的智能提醒方法，其特征在于，所述状态信息为精神状态信息，则所述根据人脸图像识别出人物的状态信息，包括:  从所述人脸图像中提取出眼部信息；  根据所述眼部信息识别出人物的精神状态信息；   其中，所述眼部信息包括瞳孔大小信息、眨眼次数信息或闭眼时间信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1-3任一项所述的智能提醒方法，其特征在于，所述获取人脸图像包括:通过摄像头获取人脸图像，或获取外设传输过来的人脸图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1-3任一项所述的智能提醒方法，其特征在于，所述输出所述状态信息包括:以图像、文字、声音或/和指示灯方式输出所述状态信息。</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6.一种终端，其特征在于，包括获取模块、识别模块和输出模块，其中:  获取模块，用于获取人脸图像；  识别模块，用于根据所述人脸图像识别出人物的状态信息；  输出模块，用于输出所述状态信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求6所述的终端，其特征在于，所述状态信息为情绪状态信息，所述识别模块用于:从所述人脸图像中提取出面部特征，从表情特征库中选出与所述面部特征相匹配的表情特征，据此识别出与所述表情特征相对应的情绪状态信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求6所述的终端，其特征在于，所述状态信息为精神状态信息，所述识别模块用于:从所述人脸图像中提取出眼部信息，根据所述眼部信息识别出人物的精神状态信息；其中，所述眼部信息包括瞳孔大小信息、眨眼次数信息或/和闭眼时间信息。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求6-8任一项所述的终端，其特征在于，所述获取模块用于:调用摄像头获取人脸图像或获取外设传输过来的人脸图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求6-8任一项所述的终端，其特征在于，所述输出模块用于:以图像、文字、声音或/和指不灯方式输出所述状态信息。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES72717717" lang="ZH" load-source="patent-office" class="description">
    <p>智能提醒方法和终端</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及通信技术领域，尤其是涉及一种智能提醒方法和终端。</p>
    <p>背景技术</p>
    <p>[0002]	个人电脑、手机、平板电脑等终端极大的丰富了人们的娱乐生活，方便了人与人之间的交流和沟通。随着通信技术的发展，终端的智能化程度得以逐步提高，但用户对终端的智能化和人性化程度要求也越来越高，不再满足于终端被动接收指令提供服务，而是需要终端主动与用户交流，提供必要的讯息。然而现有的终端的灵活性还不够，不能满足用户对终端的主动交流要求,用户体验不佳。</p>
    <p>发明内容</p>
    <p>[0003]	本发明的主要目的在于提供一种智能提醒方法和终端，旨在提高终端的灵活性，满足用户对终端的主动交流要求，提升用户体验。</p>
    <p>[0004]	为达以上目的，本发明提出一种智能提醒方法，包括步骤:</p>
    <p>[0005]	获取人脸图像；</p>
    <p>[0006]	根据所述人脸图像识别出人物的状态信息；</p>
    <p>[0007]	输出所述状态信息。</p>
    <p>[0008]	优选地，所述状态信息为情绪状态信息，所述根据人脸图像识别出人物的状态信息包括:</p>
    <p>[0009]	从所述人脸图像中提取出面部特征；</p>
    <p>[0010]	从表情特征库中选出与所述面部特征相匹配的表情特征，据此识别出与所述表情特征相对应的情绪状态信息。</p>
    <p>[0011]	优选地，所述状态信息为精神状态信息，所述根据人脸图像识别出人物的状态信息包括:</p>
    <p>[0012]	从所述人脸图像中提取出眼部信息；</p>
    <p>[0013]	根据所述眼部信息识别出人物的精神状态信息；</p>
    <p>[0014]	其中，所述眼部信息包括瞳孔大小信息、眨眼次数信息或/和闭眼时间信息。</p>
    <p>[0015]	优选地，所述获取人脸图像包括:调用摄像头获取人脸图像或获取外设传输过来的人脸图像。</p>
    <p>[0016]	优选地，所述输出所述状态信息包括:以图像、文字、声音或/和指示灯方式输出所述状态信息。</p>
    <p>[0017]	本发明同时提出一种终端，包括获取模块、识别模块和输出模块，其中:</p>
    <p>[0018]	获取模块，用于获取人脸图像；</p>
    <p>[0019]	识别模块，用于根据所述人脸图像识别出人物的状态信息；</p>
    <p>[0020]	输出模块，用于输出所述状态信息。</p>
    <p>[0021]	优选地，所述状态信息为情绪状态信息，所述识别模块用于:从所述人脸图像中提取出面部特征，从表情特征库中选出与所述面部特征相匹配的表情特征，据此识别出与所述表情特征相对应的情绪状态信息。</p>
    <p>[0022]	优选地，所述状态信息为精神状态信息，所述识别模块用于:从所述人脸图像中提取出眼部信息，根据所述眼部信息识别出人物的精神状态信息；其中，所述眼部信息包括瞳孔大小信息、眨眼次数信息或/和闭眼时间信息。</p>
    <p>[0023]	优选地，所述获取模块用于:调用摄像头获取人脸图像或获取外设传输过来的人脸图像。</p>
    <p>[0024]	优选地，所述输出模块用于:以图像、文字、声音或/和指示灯方式输出所述状态信息。</p>
    <p>[0025]	本发明所提供的一种智能提醒方法，通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时主动的输出该状态信息来提醒用户，实现了人机交流，提高了终端的灵活性，满足了用户对终端的主动交流要求，提高了终端的智能化和人性化程度。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。</p>
    <p>附图说明</p>
    <p>[0026]	图1是本发明的智能提醒方法一实施例的流程图；</p>
    <p>[0027]	图2是本发明中根据人脸图像识别出人物的情绪状态信息的流程图；</p>
    <p>[0028]	图3是本发明中根据人脸图像识别出人物的精神状态信息的流程图；</p>
    <p>[0029]	图4是本发明的终端一实施例的结构框图。</p>
    <p>[0030]	本发明目的的实现、功能特点及优点将结合实施例，参照附图做进一步说明。具体实施方式</p>
    <p>[0031]	应当理解，此处所描述的具体实施例仅仅用以解释本发明，并不用于限定本发明。</p>
    <p>[0032]	参见图1，提出本发明的智能提醒方法一实施例，所述智能提醒方法包括以下步骤:</p>
    <p>[0033]	步骤SlOl:获取人脸图像</p>
    <p>[0034]	终端利用现有的人脸识别技术，可以调用摄像头采集人脸图像并获取，也可以获取从外设(外部设备)传输过来的人脸图像，还可以从本地存储的视频或图片中获取人脸图像。</p>
    <p>[0035]	步骤S102:根据人脸图像识别出人物的状态信息</p>
    <p>[0036]	所述状态信息可以是情绪状态信息及精神状态信息等等。其中，情绪状态信息表示该人物的喜、怒、哀、乐等情绪状态，精神状态信息则表示该人物是否疲倦，以及该人物的疲倦程度等。</p>
    <p>[0037]	根据人脸图像识别出人物的情绪状态信息的具体流程如下:</p>
    <p>[0038]	步骤SllO:从人脸图像中提取出面部特征</p>
    <p>[0039]	所述面部特征为从人脸图像中提取出的眉毛、眼睛、嘴角等关键部位的特征，如眉毛的弯曲角度或弧度，眼睛的形状或大小，嘴角上翘或下撇的角度或弧度。</p>
    <p>[0040]	步骤Slll:从表情特征库中选出与面部特征相匹配的表情特征</p>
    <p>[0041]表情特征库中预存了若干代表人物喜、怒、哀、乐、惊等情绪状态的表情特征，终端将提取出的面部特征与表情特征库中的表情特征进行比较，选出与该面部特征最相匹配的表情特征。如比较面部特征与表情特征中眉毛的弯曲角度或弧度的相似度是否达到预设阈值，或/和嘴角上翘或下撇的角度或弧度是否达到预设阈值等等。</p>
    <p>[0042]	步骤S112:根据匹配出的表情特征识别出与之相对应的情绪状态信息</p>
    <p>[0043]	每一表情特征对应一情绪状态信息，从而根据匹配出的表情特征获得对应的情绪状态信息。</p>
    <p>[0044]	根据人脸图像识别出人物的精神状态信息的具体流程如下:</p>
    <p>[0045]	步骤S120:从人脸图像中提取出眼部信息</p>
    <p>[0046]	所述眼部信息包括瞳孔信息、眨眼信息、闭眼信息、眼球信息等，如瞳孔大小信息、眨眼次数信息、闭眼时间信息等。</p>
    <p>[0047]	步骤S121:根据眼部信息识别出人物的精神状态信息</p>
    <p>[0048]	可以通过瞳孔信息识别出人物的精神状态信息。具体的，根据瞳孔的大小进行判断，如瞳孔较大或大于某一阈值，则说明精神较佳；如瞳孔较小或小于某一阈值，则说明精神较差，比较疲倦，并根据瞳孔小于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0049]	可以通过眨眼信息识别出人物的精神状态信息。具体的，计算预设时间内人物的眨眼次数，若眨眼次数小于某一阈值，则说明精神较佳；若眨眼次数大于某一阈值，则说明精神较差，比较疲倦，并根据眨眼次数大于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0050]	可以通过闭眼信息识别出人物的精神状态信息。具体的，计算预设时间内人物的累积闭眼时间或者单次闭眼最长时间，若小于某一阈值，则说明精神较佳；如大于某一阈值，则说明精神较差，比较疲倦，并根据闭眼时间大于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0051]	也可以将前述眼部信息中的任意两个或多个组合起来综合判断出人物的精神状态息。</p>
    <p>[0052]	步骤S103:输出人物的状态信息</p>
    <p>[0053]	终端可以以图像、文字、声音或/和指示灯方式输出人物的状态信息以提醒用户自己或他人当时的情绪状态或精神状态等状态信息。</p>
    <p>[0054]	例如，通过显示屏显示代表喜、怒、哀、乐、惊等情绪状态的表情图像或文字信息，或者代表精神较佳、不同疲倦等级等精神状态的表情图像或文字信息；通过声音播放装置播放代表不同的情绪状态或精神状态等人物状态信息的声音；通过显示不同颜色的指示灯或控制指示灯以不同的频率进行闪烁，来代表不同的情绪状态或精神状态等人物状态信息。也可以综合前述两种或多种方式来输出状态信息。</p>
    <p>[0055]	本发明的智能提醒方法可以应用于视频录制、视频观看、图像浏览、视频聊天、视频通话等应用场景，或者摄像头启动后就自动开启智能提醒功能。</p>
    <p>[0056]	例如，当用户正在进行视频聊天时，通过摄像头获取用户的人脸图像，并根据人脸图像识别出用户当前的情绪状态、精神状态等状态信息，并及时以图像、文字、声音或/和指示灯方式输出该状态信息以提醒用户。同时，还可以获取对方终端传输过来的对方用户的人脸图像，根据该人脸图像识别出对方用户当前的情绪状态、精神状态等状态信息，并及时输出给本端用户或通过聊天框自动输出至对方用户。[0057]	从而，本发明的智能提醒方法，通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时主动的输出该状态信息来提醒用户，实现了人机交流，提高终端的灵活性，满足了用户对终端的主动交流要求，提高了终端的智能化和人性化程度。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。</p>
    <p>[0058]	参见图4，提出本发明的终端一实施例，所述终端可以是个人电脑、手机、平板电脑等。所述终端包括依次连接的获取模块110、识别模块120和输出模块130。</p>
    <p>[0059]	获取模块110:用于获取人脸图像，并发送给识别模块120。获取模块110利用现有的人脸识别技术，可以调用摄像头采集人脸图像并获取，也可以获取从外设传输过来的人脸图像，还可以从本地存储的视频或图片中获取人脸图像。</p>
    <p>[0060]	识别模块120:用于根据人脸图像识别出人物的状态信息，并发送给输出模块130。所述状态信息可以是情绪状态信息、精神状态信息等。其中，情绪状态信息反映人物的喜、怒、展、乐等情绪状态，精神状态&#943;目息反映人物是否疲倦及疲倦程度等精神状态。</p>
    <p>[0061]	根据人脸图像识别出人物的情绪状态信息时，首先，识别模块120从人脸图像中提取出面部特征，所述面部特征为从人脸图像中提取出的眉毛、眼睛、嘴角等关键部位的特征。然后，识别模块120从表情特征库中选出与面部特征相匹配的表情特征，具体的，表情特征库中预存了若干代表人物喜、怒、哀、乐、惊等情绪状态的表情特征，识别模块120将提取出的面部特征与表情特征库中的表情特征进行比较，选出与该面部特征最相匹配的表情特征。每一表情特征对应一情绪状态信息，因此，最后识别模块120根据匹配出的表情特征识别出与之相对应的情绪状态信息。</p>
    <p>[0062]	根据人脸图像识别出人物的精神状态信息时，首先，识别模块120从人脸图像中提取出眼部信息，所述眼部信息包括瞳孔信息、眨眼信息、闭眼信息、眼球信息等，如瞳孔大小信息、眨眼次数信息、闭眼时间信息等。然后，识别模块120根据眼部信息识别出人物的精神状态信息。</p>
    <p>[0063]	识别模块120可以通过瞳孔信息识别出人物的精神状态信息。具体的，识别模块120根据瞳孔的大小进行判断，如瞳孔较大或大于某一阈值，则判定精神较佳；如瞳孔较小或小于某一阈值，则判定精神较差，比较疲倦，并根据瞳孔小于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0064]	识别模块120也可以通过眨眼信息识别出人物的精神状态信息。具体的，识别模块120计算预设时间内人物的眨眼次数，若眨眼次数小于某一阈值，则判定精神较佳；若眨眼次数大于某一阈值，则判定精神较差，比较疲倦，并根据眨眼次数大于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0065]	识别模块120还可以通过闭眼信息识别出人物的精神状态信息。具体的，识别模块120计算预设时间内人物的累积闭眼时间或者单次闭眼最长时间，若小于某一阈值，则判定精神较佳；如大于某一阈值，则判定精神较差，比较疲倦，并根据闭眼时间大于预设的不同阈值，来判断人物的疲倦程度或疲倦等级。</p>
    <p>[0066]	识别模块120还可以将前述眼部信息中的任意两个或多个组合起来综合判断出人物的精神状态信息。</p>
    <p>[0067]	输出模块130:用 于输出人物的状态信息。</p>
    <p>[0068]	输出模块130可以以图像、文字、声音或/和指示灯方式输出人物的状态信息以提醒用户自己或他人当时的情绪状态或精神状态等状态信息。</p>
    <p>[0069]	例如，输出模块130通过显示屏显示代表喜、怒、哀、乐、惊等情绪状态的表情图像或文字信息，或者代表精神较佳、不同疲倦等级等精神状态的表情图像或文字信息；通过声音播放装置播放代表不同的情绪状态或精神状态等人物状态信息的声音；通过显示不同颜色的指示灯或控制指示灯以不同的频率进行闪烁，来代表不同的情绪状态或精神状态等人物状态信息。也可以综合前述两种或多种方式来输出状态信息。</p>
    <p>[0070]	据此，本发明的终端，通过获取人脸图像来快速识别出用户或他人的情绪状态、精神状态等状态信息，并及时主动的输出该状态信息来提醒用户，实现了人机交流，提高终端的灵活性，满足了用户对终端的主动交流要求，提高了终端的智能化和人性化程度。用户或对方用户可以根据提醒及时调整自己状态，提升了用户体验。</p>
    <p>[0071]	本领域普通技术人员可以理解，实现上述实施例方法中的全部或部分步骤可以通过程序来控制相关的硬件完成，所述的程序可以存储于一计算机可读取存储介质中，所述的存储介质可以是R0M/RAM、磁盘、光盘等。</p>
    <p>[0072]	以上参照附图说明了本发明的优选实施例，并非因此局限本发明的权利范围。本领域技术人员不脱离本发明的范围和实质内所作的任何修改、等同替换和改进，均应在本发明的权利范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1830389A?cl=zh">CN1830389A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年4月21日</td><td class="patent-data-table-td patent-date-value">2006年9月13日</td><td class="patent-data-table-td ">太原理工大学</td><td class="patent-data-table-td ">疲劳驾驶状态监控装置及方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102929660A?cl=zh">CN102929660A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年10月9日</td><td class="patent-data-table-td patent-date-value">2013年2月13日</td><td class="patent-data-table-td ">广东欧珀移动通信有限公司</td><td class="patent-data-table-td ">一种终端设备心情主题的控制方法及其终端设备</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0003010000">G06F3/01</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=A0AOCQABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009460000">G06K9/46</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2014年7月2日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年12月31日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/9cbd5a5d9b4abd92cd7a/CN103902046A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E6%99%BA%E8%83%BD%E6%8F%90%E9%86%92%E6%96%B9%E6%B3%95%E5%92%8C%E7%BB%88%E7%AB%AF.pdf?id=A0AOCQABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0p6inFmR8hyKipVIf0XptDAoWD2w"},"sample_url":"https://www.google.com/patents/reader?id=A0AOCQABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>