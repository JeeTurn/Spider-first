<!DOCTYPE html><html><head><title>专利 CN103187053A - 输入方法和电子设备 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="输入方法和电子设备"><meta name="DC.contributor" content="尉伟东" scheme="inventor"><meta name="DC.contributor" content="联想(北京)有限公司" scheme="assignee"><meta name="DC.date" content="2011-12-31" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种输入方法和电子设备。该输入方法包括：利用声音采集单元采集用户的语音；确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型；确定第二数据库，其中所述第二数据库记录通用的语音模型；根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及获取使用所述第三数据库识别该用户的声音采集内容的结果。"><meta name="DC.date" content="2013-7-3"><meta name="DC.relation" content="CN:101051372:A" scheme="references"><meta name="DC.relation" content="CN:1591571:A" scheme="references"><meta name="DC.relation" content="CN:1790483:A" scheme="references"><meta name="DC.relation" content="CN:1920946:A" scheme="references"><meta name="DC.relation" content="EP:1426896:A1" scheme="references"><meta name="DC.relation" content="US:20080077409:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:103187053:A"><meta name="citation_patent_application_number" content="CN:201110459933"><link rel="canonical" href="https://www.google.com/patents/CN103187053A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN103187053A?cl=zh"/><meta name="title" content="专利 CN103187053A - 输入方法和电子设备"/><meta name="description" content="本发明涉及一种输入方法和电子设备。该输入方法包括：利用声音采集单元采集用户的语音；确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型；确定第二数据库，其中所述第二数据库记录通用的语音模型；根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及获取使用所述第三数据库识别该用户的声音采集内容的结果。"/><meta property="og:title" content="专利 CN103187053A - 输入方法和电子设备"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN103187053A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN103187053A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=yaLDCAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN103187053A&amp;usg=AFQjCNF3cLrQmHczmy1RYjHm-0fWUbubOw" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/8b267d83cb7195ba6802/CN103187053A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/8b267d83cb7195ba6802/CN103187053A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN103187053A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN103187053A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN103187053A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN103187053B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN103187053A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种输入方法和电子设备。该输入方法包括：利用声音采集单元采集用户的语音；确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型...</span><span itemprop="url">https://www.google.com/patents/CN103187053A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN103187053A - 输入方法和电子设备</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN103187053A - 输入方法和电子设备" title="专利 CN103187053A - 输入方法和电子设备"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN103187053 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110459933</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年7月3日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年12月31日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年12月31日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103187053B?hl=zh-CN&amp;cl=zh">CN103187053B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110459933.3, </span><span class="patent-bibdata-value">CN 103187053 A, </span><span class="patent-bibdata-value">CN 103187053A, </span><span class="patent-bibdata-value">CN 201110459933, </span><span class="patent-bibdata-value">CN-A-103187053, </span><span class="patent-bibdata-value">CN103187053 A, </span><span class="patent-bibdata-value">CN103187053A, </span><span class="patent-bibdata-value">CN201110459933, </span><span class="patent-bibdata-value">CN201110459933.3</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%B0%89%E4%BC%9F%E4%B8%9C%22">尉伟东</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E8%81%94%E6%83%B3(%E5%8C%97%E4%BA%AC)%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">联想(北京)有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103187053A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103187053A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN103187053A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (6),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (2),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=yaLDCAABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110459933&amp;usg=AFQjCNFm4k8-NNqwKy6GKPBJlrVVQUcnOA"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=yaLDCAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D103187053A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGwFX42EudQ6NrqXsxiBUUjzT522A"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT125793767" lang="ZH" load-source="patent-office">输入方法和电子设备</invention-title>
      </span><br><span class="patent-number">CN 103187053 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA117198763" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种输入方法和电子设备。该输入方法包括：利用声音采集单元采集用户的语音；确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型；确定第二数据库，其中所述第二数据库记录通用的语音模型；根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及获取使用所述第三数据库识别该用户的声音采集内容的结果。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM53495798" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.一种输入方法，应用于电子设备中，该电子设备包括声音米集单兀，该方法包括:  利用所述声音采集单元采集用户的语音；  确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型；  确定第二数据库，其中所述第二数据库记录通用的语音模型；  根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及  获取使用所述第三数据库识别该用户的声音采集内容的结果。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.如权利要求1所述的输入方法，其中  所述第一数据库和所述第二数据库都存储在与所述电子设备连接的服务器端；或者所述第一数据库和所述第二数据库都存储在该电子设备本地端；或者所述第一数据库存储在本地端，而所述第二数据库存储在与所述电子设备连接的服务器端。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.如权利要求1或2所述的输入方法，其中确定与该用户对应的第一数据库包括:  根据与所述电子设备相关联的预定标识来确定所述第一数据库；或者  根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.如权利要求3所述的输入方法，其中根据与所述电子设备相关联的预定标识来确定所述第一数据库包括:  根据所述电子设备的预定硬件标识来确定所述第一数据库；或者  根据所述电子设备的预定软件标 识来确定所述第一数据库；或者  根据与所述电子设备连接的附接设备的预定硬件标识来确定所述第一数据库；或者  根据与所述电子设备连接的附接设备的预定软件标识来确定所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.如权利要求1所述的输入方法，其中根据预定策略从所述第一数据库和所述第二数据库生成第三数据库包括:  只使用所述第一数据库作为所述第三数据库；或者  只使用所述第二数据库作为所述第三数据库；或者  使用所述第一数据库和所述第二数据库作为所述第三数据库；或者  使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.如权利要求1所述的输入方法，还包括:  根据获取的识别结果调整所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.如权利要求1所述的输入方法，还包括:  执行根据获取的识别结果的操作。</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.&#8212;种电子设备,包括:  声音采集单元，配置为采集用户的语音；  确定单元，配置为确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型，以及配置为确定第二数据库，其中所述第二数据库记录通用的语音模型；  生成单元，配置为根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及  获取单元，配置为获取使用所述第三数据库识别该用户的声音采集内容的结果。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.如权利要求8所述的电子设备，其中  所述第一数据库和所述第二数据库都存储在与所述电子设备连接的服务器端；或者所述第一数据库和所述第二数据库都存储在该电子设备本地端；或者所述第一数据库存储在本地端，而所述第二数据库存储在与所述电子设备连接的服务器端。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.如权利要求8或9所述的电子设备，其中所述确定单元进一步配置为:  根据与所述电子设备相关联的预定标识来确定所述第一数据库；或者  根据用户的声音输 入提取声纹特征，并根据声纹特征确定所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.如权利要求10所述的电子设备，其中所述确定单元进一步配置为:  根据所述电子设备的预定硬件标识来确定所述第一数据库；或者  根据所述电子设备的预定软件标识来确定所述第一数据库；或者  根据与所述电子设备连接的附接设备的预定硬件标识来确定所述第一数据库；或者  根据与所述电子设备连接的附接设备的预定软件标识来确定所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.如权利要求8所述的电子设备，其中所述生成单元进一步配置为括:  只使用所述第一数据库作为所述第三数据库；或者  只使用所述第二数据库作为所述第三数据库；或者  使用所述第一数据库和所述第二数据库作为所述第三数据库；或者  使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.如权利要求8所述的电子设备，还包括调整单元，配置为根据获取的识别结果调整所述第一数据库。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.如权利要求8所述的电子设备，还包括执行单元，配置为执行根据获取的识别结果的操作。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES60535216" lang="ZH" load-source="patent-office" class="description">
    <p>输入方法和电子设备</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及电子设备的领域，更具体地，本发明涉及一种输入方法和电子设备。</p>
    <p>背景技术</p>
    <p>[0002]	近年来，具有语音识别系统的电子设备得到广泛应用。现有的语音识别系统架构有两种:终端本地识别以及云端(即，远程端)识别，这两种方式各有缺陷。具体地，对于终端本地识别，由于数据库小，识别能力弱，因此识别准确率有限。对于云端识别，由于数据库大，识别能力高于终端本地识别，但是通用语音模型具有普遍适用的意义，但是对于偏离基准值的用户，可能始终无法达到较高准确率。</p>
    <p>发明内容</p>
    <p>[0003]	因此，期望提供一种输入方法和电子设备，其能够以较高准确率对各种用户进行语音识别。</p>
    <p>[0004]	根据本发明一个实施例，提供了一种输入方法，应用于电子设备中，该电子设备包括声音采集单元，该方法包括:</p>
    <p>[0005]	利用所述声音采集单元采集用户的语音；</p>
    <p>[0006]	确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型；</p>
    <p>[0007]	确定第二数据库，其中所述第二数据库记录通用的语音模型；</p>
    <p>[0008]	根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及</p>
    <p>[0009]	获取使用所述第三数据库识别该用户的声音采集内容的结果。</p>
    <p>[0010]	优选地，所述第一数据库和所述第二数据库都存储在与所述电子设备连接的服务器端；或者</p>
    <p>[0011]	所述第一数据库和所述第二数据库都存储在该电子设备本地端；或者</p>
    <p>[0012]	所述第一数据库存储在本地端，而所述第二数据库存储在与所述电子设备连接的服务器端。</p>
    <p>[0013]	优选地，确定与该用户对应的第一数据库包括:</p>
    <p>[0014]	根据与所述电子设备相关联的预定标识来确定所述第一数据库；或者</p>
    <p>[0015]	根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</p>
    <p>[0016]	优选地，根据与所述电子设备相关联的预定标识来确定所述第一数据库包括:</p>
    <p>[0017]	根据所述电子设备的预定硬件标识来确定所述第一数据库；或者</p>
    <p>[0018]	根据所述电子设备的预定软件标识来确定所述第一数据库；或者</p>
    <p>[0019]	根据与所述电子设备连接的附接设备的预定硬件标识来确定所述第一数据库；或者</p>
    <p>[0020]	根据与所述电子设备连接的附接设备的预定软件标识来确定所述第一数据库。</p>
    <p>[0021]	优选地，根据预定策略从所述第一数据库和所述第二数据库生成第三数据库包括:</p>
    <p>[0022]	只使用所述第一数据库作为所述第三数据库；或者</p>
    <p>[0023]	只使用所述第二数据库作为所述第三数据库；或者</p>
    <p>[0024]	使用所述第一数据库和所述第二数据库作为所述第三数据库；或者</p>
    <p>[0025]	使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。</p>
    <p>[0026]	优选地，所述的输入方法还包括:</p>
    <p>[0027]	根据获取的识别结果调整所述第一数据库。</p>
    <p>[0028]	优选地，所述的输入方法还包括:</p>
    <p>[0029]	执行根据获取的识别结果的操作。</p>
    <p>[0030]	根据本发明另一实施例，提供了一种电子设备，包括:</p>
    <p>[0031]	声音采集单元，配置为采集用户的语音；</p>
    <p>[0032]	确定单元，配置为确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型，以及配置为确定第二数据库，其中所述第二数据库记录通用的语音模型；</p>
    <p>[0033]	生成单元，配置为根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及</p>
    <p>[0034]	获取单元，配置为获取使用所述第三数据库识别该用户的声音采集内容的结果。</p>
    <p>[0035]	优选地，所述第一数据库和所述第二数据库都存储在与所述电子设备连接的服务器端；或者</p>
    <p>[0036]	所述第一数据库和所述第二数据库都存储在该电子设备本地端；或者</p>
    <p>[0037]	所述第一数据库存储在本地端，而所述第二数据库存储在与所述电子设备连接的服务器端。</p>
    <p>[0038]	优选地，所述确定单元进一步配置为:</p>
    <p>[0039]	根据与所述电子设备相关联的预定标识来确定所述第一数据库；或者</p>
    <p>[0040]	根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</p>
    <p>[0041]	优选地，所述确定单元进一步配置为:</p>
    <p>[0042]	根据所述电子设备的预定硬件标识来确定所述第一数据库；或者</p>
    <p>[0043]	根据所述电子设备的预定软件标识来确定所述第一数据库；或者</p>
    <p>[0044]	根据与所述电子设备连接的附接设备的预定硬件标识来确定所述第一数据库；或者</p>
    <p>[0045]	根据与所述电子设备连接的附接设备的预定软件标识来确定所述第一数据库。</p>
    <p>[0046]	优选地，所述生成单元进一步配置为括:</p>
    <p>[0047]	只使用所述第一数据库作为所述第三数据库；或者</p>
    <p>[0048]	只使用所述第二数据库作为所述第三数据库；或者</p>
    <p>[0049]	使用所述第一数据库和所述第二数据库作为所述第三数据库；或者</p>
    <p>[0050]	使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。</p>
    <p>[0051]	优选地，所述电子设备还包括调整单元，配置为根据获取的识别结果调整所述第一数据库。</p>
    <p>[0052]	优选地，所述电子设备还包括执行单元，配置为执行根据获取的识别结果的操作。[0053]	因此，根据本发明实施例的输入方法和电子设备，能够以较高准确率对各种用户进行语音识别。</p>
    <p>附图说明</p>
    <p>[0054]	图1是根据本发明第一实施例的显示方法的流程图；以及</p>
    <p>[0055]	图2是根据本发明第二实施例的电子设备的框图。</p>
    <p>具体实施方式</p>
    <p>[0056]	以下，将参照附图详细描述本发明的实施例。</p>
    <p>[0057]	&lt;第一实施例&gt;</p>
    <p>[0058]	首先，将参考图1描述根据本发明第一实施例的输入方法。根据本发明第一实施例的输入方法可应用于任何包括声音采集单元的电子设备。这样的电子设备的例子包括手机、Pad电脑、带有麦克风的个人计算机等等。以下将以手机作为例子进行描述。</p>
    <p>[0059]	图1是根据本发明第一实施例的输入方法的流程图。</p>
    <p>[0060]	根据第一实施例的输入方法应用于具有声音采集单元的电子设备，所述输入方法包括:</p>
    <p>[0061]	步骤SlOl:利用所述声音采集单元采集用户的语音。</p>
    <p>[0062]	在该步骤中，利用声音采集单元采集用户的语音。例如，用户可以利用手机内置的麦克风采集语音。此外，用户可以利用外接的带有麦克风功能的耳机采集语音。另外，在电子设备是Pad电脑的情况下，也可以利用内置的麦克风或外接的麦克风等采集语音。</p>
    <p>[0063]	步骤SlOl:确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型。</p>
    <p>[0064]	在该步骤中，确定与正在使用该电子设备的用户对应的第一数据库，在该第一数据库中，记录与该用户对应的特定语音模型，例如，记录该用户使用普通话或者方言等等。此外，还可以记录该用户的特定语句方式、词汇、词频、与特定方言语音对应的普通话词汇等等。另外，该语音模型是用于识别用户的声音采集内容的模型。语音模型的示例有多种，例如隐马尔可夫模型，RIA (Rich Internet Application,丰富因特网应用)模型等等。</p>
    <p>[0065]	此外，例如，在第一数据库中还可以与该特定语音模型相关联地记录用户的个人数据，例如该用户的姓名、性别、籍贯等等。从而，当存在多个第一数据库时，可以根据该用户的个人数据(例如姓名)方便地确定该用户的第一数据库。该用户的个人数据也可以用作下面将描述的与电子设备相关联的预定标识。</p>
    <p>[0066]	步骤S102:确定第二数据库，其中所述第二数据库记录通用的语音模型。</p>
    <p>[0067]	在该步骤中，确定一个通用的第二数据库。该通用的第二数据库是一个具有普遍使用意义的数据库，其中记录基础的、通用的语音模型。也就是说，在步骤SlOl中，确定用户的个性化数据库，该个性化数据库更能体现该用户的语音特点，能够有助于识别该用户的个性化语音内容，例如，该个性化数据库能够记录某个使用方言的用户的方言词汇。另一方面，在步骤SlOl中，确定适用于所有人的基础数据库，该基础数据库包括对所有人适用的语音模型，但是可能不包括某个特定用户的特定语音词汇等，例如，该基础数据库可能没有记录某个使用方言的用户的方言词汇。[0068]	步骤S103:根据预定策略从所述第一数据库和所述第二数据库生成第三数据库。</p>
    <p>[0069]	在该步骤中，因为步骤SlOl中确定的个性化数据库通常比较小，并且通常记录特定用户的个性化数据，所以在有些情况下可能不能准确地识别用户的语音内容。另外，步骤S102中确定的基础数据库虽然比较大，但是通常可能没有记录特定用户的个性化数据，因此在有些情况下可能还是不能准确地识别用户的语音内容。为此，需要根据预定策略从所述第一数据库和所述第二数据库生成第三数据库。</p>
    <p>[0070]	例如，当分析用户的数据发现该用户主要使用普通话时，例如可以只使用所述第一数据库作为所述第三数据库。或者，当分析用户的数据发现该用户主要使用方言时，可以只使用所述第二数据库作为所述第三数据库。或者，当分析用户的数据发现该用户有时候使用普通话并且有时候使用方言时，可以使用所述第一数据库和所述第二数据库作为所述第三数据库，或者可以根据需要只使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。通过利用第一数据库和第二数据库生成第三数据库，可以根据需要，更准确地识别用户的语音内容。</p>
    <p>[0071]	步骤S104:获取使用所述第三数据库识别该用户的声音采集内容的结果。</p>
    <p>[0072]	在该步骤中，使用所述第三数据库识别该用户的声音采集内容，并且获得识别的结果。也就是说，在该步骤中，因为使用根据需要生成的第三数据库来识别语音采集内容，所以能够获得更准确的识别结果。</p>
    <p>[0073]	此外，根据电子设备的配置和能力，第一数据库和第二数据库的存储位置可以存储以下几种情况:</p>
    <p>[0074]	(I)所述第一数据库和所述第二数据库可以都存储在与所述电子设备连接的服务器端。也就是说，如果电子设备的存储器容量较小，则可以将第一数据库和第二数据库(即，用户的个性化数据库以及基础数据库)都存储在服务器端，当用户需要进行语音识别时，向服务器发出请求，并且将语音采集单元采集的语音数据发送给服务器，并且在服务器中利用从第一数据库和第二数据库生成的第三数据库对从电子设备发送的语音数据进行分析，从而获得语音内容，并且将或的语音内容再发送给电子设备。</p>
    <p>[0075]	(2)所述第一数据库和所述第二数据库也都可以存储在该电子设备本地端。也就是说，如果电子设备的存储器容量较大，则可以将第一数据库和第二数据库都存储在电子设备中。当用户需要进行语音识别时，可以直接利用从第一数据库和第二数据库生成的第三数据库对从由声音采集单元采集的语音数据进行分析，从而获得语音内容。与所述第一数据库和所述第二数据库可以都存储在与所述电子设备连接的服务器端的情况相比，语音识别的速度显然更快，当然要求电子设备的配置也更高。</p>
    <p>[0076]	(3)还可以将所述第一数据库存储在本地端，而将所述第二数据库存储在与所述电子设备连接的服务器端。在该情况下，当用户需要进行语音识别时，可以根据用户需要或电子设备的处理能力，将语音采集单元采集的语音数据发送给服务器，并且在服务器中利用从第一数据库和第二数据库生成的第三数据库对从电子设备发送的语音数据进行分析，从而获得语音内容，并且将或的语音内容再发送给电子设备。也可以在电子设备中利用从第一数据库和第二数据库生成的第三数据库对从由声音采集单元采集的语音数据进行分析，从而获得语音内容。</p>
    <p>[0077]	(4)还可以将将所述第二数据库存储在本地端，而将所述第一数据库存储在与所述电子设备连接的服务器端。在该情况下，与情况(3)的处理方式类似，在此不做详细描述。</p>
    <p>[0078]	此外，确定与该用户对应的第一数据库包括:根据与所述电子设备相关联的预定标识来确定所述第一数据库；或者根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</p>
    <p>[0079]	例如，当电子设备是手机时，因为通常认为用户的手机号码是其个人独有的识别方式，所以，当第一数据库存储在远端服务器中时，可以通过该用户的手机号码作为硬件标识(比如MEI号或SM卡号)，确定与该用户对应的第一数据库。</p>
    <p>[0080]	或者，当电子设备是Pad电脑时，当用户使用账户名和密码进行登陆，可以利用该用户的账户作为软件标识来确定与该用户对应的第一数据库。</p>
    <p>[0081]	或者，当电子设备是手机时，并且当第一数据库存储在该手机中时，如果另外的用户使用该手机，他/她可以将自己的耳机(或耳麦)插入手机，然后通过该耳机(耳麦)对应的硬件标识来识别与该用户对应的第一数据库。</p>
    <p>[0082]	或者，当电子设备是台式机时，当用户将其Pad电脑连接到台式机时，用户可以使用Pad电脑的账户名和密码进行登陆，并利用该用户的账户作为软件标识来确定与该用户对应的第一数据库。</p>
    <p>[0083]	另外，因为每个人的声音都有自己的声纹特征，因此可以根据声音输入提取该声纹特征，并依据提取的声纹特征确定与该用户对应的第一数据库。</p>
    <p>[0084]	上面仅仅描述了一些使用预定标识确定第一数据库的示例，但是使用预定标识确定第一数据库的方式不限于此，用户可以根据实际情况采用各种适当的方式确定第一数据库。</p>
    <p>[0085]	此外，还可以根据获取的识别结果调整所述第一数据库。当然，用户可以手动调整第一数据库中的数据，例如个人信息、词汇等等。此外，也可以根据每次获取的识别结果，自动地将本地识别结果中的词汇等添加到第一数据库中。</p>
    <p>[0086]	在获得识别的语音内容后，电子设备还可以执行根据获取的识别结果的操作。例如，当用户通过声音采集单元输入的通话内容是“启动电话簿”时，当电子设备获得识别的语音内容后，可以自动地启动“电话簿”应用程序。或者，当用户准备发送短信息，并且通过声音采集单元输入的通话内容是“晚上八点在电影院门口见”，当电子设备获得识别的语音内容后，可以自动地将识别的内容“晚上八点在电影院门口见”作为短信息中的文字信息，并且用户可以发送短信息。</p>
    <p>[0087]	当然，电子设备执行根据获取的识别结果的操作不限于以上示例，而是可以根据用户需要进行各种操作，只要该操作是基于获取的识别结果即可。</p>
    <p>[0088]	因此，利用根据本发明实施例的输入方法，能够以较高准确率对各种用户进行语音识别。</p>
    <p>[0089]	&lt;第二实施例&gt;</p>
    <p>[0090]	接着，将参考图2描述根据本发明第二实施例的电子设备的框图。</p>
    <p>[0091]	根据本发明第二实施例的电子设备200包括:</p>
    <p>[0092]	声音采集单元201，配置为采集用户的语音；</p>
    <p>[0093]	确定单元202，配置为确定与该用户对应的第一数据库，其中该第一数据库记录该用户特定的语音模型，并且语音模型是用于识别用户的声音采集内容的模型，以及配置为确定第二数据库，其中所述第二数据库记录通用的语音模型；</p>
    <p>[0094]	生成单元203，配置为根据预定策略从所述第一数据库和所述第二数据库生成第三数据库；以及</p>
    <p>[0095]	获取单元204，配置为获取使用所述第三数据库识别该用户的声音采集内容的结果。</p>
    <p>[0096]	根据电子设备200的配置和能力，第一数据库和第二数据库的存储位置可以存储以下几种情况:</p>
    <p>[0097]	(I)所述第一数据库和所述第二数据库可以都存储在与所述电子设备200连接的服务器端。也就是说，如果电子设备200的存储器容量较小，则可以将第一数据库和第二数据库(即，用户的个性化数据库以及基础数据库)都存储在服务器端，当用户需要进行语音识别时，向服务器发出请求，并且将语音采集单元采集的语音数据发送给服务器，并且在服务器中利用从第一数据库和第二数据库生成的第三数据库对从电子设备200发送的语音数据进行分析，从而获得语音内容，并且将或的语音内容再发送给电子设备200。</p>
    <p>[0098]	(2)所述第一数据库和所述第二数据库也都可以存储在该电子设备200本地端。也就是说，如果电子设备200的存储器容量较大，则可以将第一数据库和第二数据库都存储在电子设备200中。当用户需要进行语音识别时，可以直接利用从第一数据库和第二数据库生成的第三数据库对从由声音采集单元采集的语音数据进行分析，从而获得语音内容。与所述第一数据库和所述第二数据库可以都存储在与所述电子设备200连接的服务器端的情况相比，语音识别的速度显然更快，当然要求电子设备200的配置也更高。</p>
    <p>[0099]	(3)还可以将所述第一数据库存储在本地端，而将所述第二数据库存储在与所述电子设备200连接的服务器端。在该情况下，当用户需要进行语音识别时，可以根据用户需要或电子设备200的处理能力，将语音采集单元采集的语音数据发送给服务器，并且在服务器中利用从第一数据库和第二数据库生成的第三数据库对从电子设备200发送的语音数据进行分析，从而获得语音内容，并且将或的语音内容再发送给电子设备200。也可以在电子设备200中利用从第一数据库和第二数据库生成的第三数据库对从由声音采集单元采集的语音数据进行分析，从而获得语音内容。</p>
    <p>[0100]	(4)还可以将将所述第二数据库存储在本地端，而将所述第一数据库存储在与所述电子设备200连接的服务器端。在该情况下，与情况(3)的处理方式类似，在此不做详细描述。</p>
    <p>[0101]	此外，确定与该用户对应的第一数据库包括:根据与所述电子设备200相关联的预定标识来确定所述第一数据库；或者根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</p>
    <p>[0102]	此外，所述确定单元202进一步配置为:根据与所述电子设备200相关联的预定标识来确定所述第一数据库；或者根据用户的声音输入提取声纹特征，并根据声纹特征确定所述第一数据库。</p>
    <p>[0103]	此外，所述确定单元202进一步配置为:根据所述电子设备200的预定硬件标识来确定所述第一数据库；或者根据所述电子设备200的预定软件标识来确定所述第一数据库；或者根据与所述电子设备200连接的附接设备的预定硬件标识来确定所述第一数据库；或者根据与所述电子设备200连接的附接设备的预定软件标识来确定所述第一数据库。</p>
    <p>[0104]	此外，所述生成单元203进一步配置为括:只使用所述第一数据库作为所述第三数据库；或者只使用所述第二数据库作为所述第三数据库；或者使用所述第一数据库和所述第二数据库作为所述第三数据库；或者使用所述第一数据库的一部分和所述第二数据库的一部分作为所述第三数据库。</p>
    <p>[0105]	此外，所述电子设备200还可以包括调整单元205，配置为根据获取的识别结果调</p>
    <p>整所述第一数据库。</p>
    <p>[0106]	此外，所述电子设备200还可以包括执行单元206，配置为执行根据获取的识别结果的操作。</p>
    <p>[0107]	因此，利用根据本发明实施例的电子设备，能够以较高准确率对各种用户进行语音识别。</p>
    <p>[0108]	以上，参照附图描述了根据本发明实施例的输入方法和电子设备。</p>
    <p>[0109]	需要说明的是，在本说明书中，术语“包括”、“包含”或者其任何其他变体意在涵盖非排他性的包含，从而使得包括一系列要素的过程、方法、物品或者设备不仅包括那些要素，而且还包括没有明确列出的其他要素，或者是还包括为这种过程、方法、物品或者设备</p>
    <p>所固有的要素。在没有更多限制的情况下，由语句“包括一个......”限定的要素，并不排</p>
    <p>除在包括所述要素的过程、方法、物品或者设备中还存在另外的相同要素。</p>
    <p>[0110]	最后，还需要说明的是，上述一系列处理不仅包括以这里所述的顺序按时间序列执行的处理，而且包括并行或分别地、而不是按时间顺序执行的处理。</p>
    <p>[0111]	通过以上的实施方式的描述，本领域的技术人员可以清楚地了解到本发明可借助软件加必需的硬件平台的方式来实现，当然也可以全部通过硬件来实施。基于这样的理解，本发明的技术方案对背景技术做出贡献的全部或者部分可以以软件产品的形式体现出来，该计算机软件产品可以存储在存储介质中，如R0M/RAM、磁碟、光盘等，包括若干指令用以使得一台计算机设备(可以是个人计算机，服务器，或者网络设备等)执行本发明各个实施例或者实施例的某些部分所述的方法。</p>
    <p>[0112]	以上对本发明进行了详细介绍，本文中应用了具体个例对本发明的原理及实施方式进行了阐述，以上实施例的说明只是用于帮助理解本发明的方法及其核心思想；同时，对于本领域的一般技术人员，依据本发明的思想，在具体实施方式及应用范围上均会有改变之处，综上所述，本说明书内容不应理解为对本发明的限制。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1591571A?cl=zh">CN1591571A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年9月2日</td><td class="patent-data-table-td patent-date-value">2005年3月9日</td><td class="patent-data-table-td ">三星电子株式会社</td><td class="patent-data-table-td ">提供个性化服务的音频/视频装置和方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1790483A?cl=zh">CN1790483A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年12月16日</td><td class="patent-data-table-td patent-date-value">2006年6月21日</td><td class="patent-data-table-td ">通用汽车公司</td><td class="patent-data-table-td ">嵌入式语音识别的多语言姓名标签的管理</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1920946A?cl=zh">CN1920946A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年7月3日</td><td class="patent-data-table-td patent-date-value">2007年2月28日</td><td class="patent-data-table-td ">伯斯有限公司</td><td class="patent-data-table-td ">汽车接口</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101051372A?cl=zh">CN101051372A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年4月6日</td><td class="patent-data-table-td patent-date-value">2007年10月10日</td><td class="patent-data-table-td ">北京易富金川科技有限公司</td><td class="patent-data-table-td ">电子商务中对金融业务信息安全认证的方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1426896A1?cl=zh">EP1426896A1</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2001年8月23日</td><td class="patent-data-table-td patent-date-value">2004年6月9日</td><td class="patent-data-table-td ">Fujitsu Frontech Limited</td><td class="patent-data-table-td ">Portable terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080077409">US20080077409</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年9月25日</td><td class="patent-data-table-td patent-date-value">2008年3月27日</td><td class="patent-data-table-td ">Mci, Llc.</td><td class="patent-data-table-td ">Method and system for providing speech recognition</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104123857A?cl=zh">CN104123857A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年7月16日</td><td class="patent-data-table-td patent-date-value">2014年10月29日</td><td class="patent-data-table-td ">北京网梯科技发展有限公司</td><td class="patent-data-table-td ">一种实现个性化点读的设备及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=yaLDCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0015060000">G10L15/06</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=yaLDCAABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G10L0015020000">G10L15/02</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年7月3日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年7月31日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2016年3月30日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/8b267d83cb7195ba6802/CN103187053A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E8%BE%93%E5%85%A5%E6%96%B9%E6%B3%95%E5%92%8C%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87.pdf?id=yaLDCAABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U0HFKseBXLUszRawYRcOQUaNtOHkw"},"sample_url":"https://www.google.com/patents/reader?id=yaLDCAABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>