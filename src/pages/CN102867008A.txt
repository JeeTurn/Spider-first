<!DOCTYPE html><html><head><title>专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="基于增强现实和远端计算的识别系统和方法"><meta name="DC.contributor" content="陈烈武" scheme="inventor"><meta name="DC.contributor" content="曾煜棋" scheme="inventor"><meta name="DC.contributor" content="彭昱豪" scheme="inventor"><meta name="DC.contributor" content="宏&#30849;股份有限公司" scheme="assignee"><meta name="DC.date" content="2011-9-19" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及网络通信领域，特别涉及一种基于增强现实和远端计算的识别系统和方法，一种用户终端和识别方法，以及一种远端运算识别装置和识别方法，包括：终端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用于将待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；远端数据库，用于存储和待辨识对象的识别特征对应的数据；远端运算单元，用于接收待辨识对象的识别特征和所需执行的应用程序的图标，将所需要的姓名和地址信息传输给终端处理单元进入所需执行的应用程序，故只需一指拖曳人脸到应用程序图标或网页图标上或将所述应用程序图标或网页图标拖曳到所述人脸上，即可轻松完成执行应用程序或网站功能的过程。"><meta name="DC.date" content="2013-1-9"><meta name="DC.relation" content="CN:101359334:A" scheme="references"><meta name="DC.relation" content="CN:101408928:A" scheme="references"><meta name="DC.relation" content="CN:102035930:A" scheme="references"><meta name="DC.relation" content="US:20110064281:A1" scheme="references"><meta name="citation_patent_publication_number" content="CN:102867008:A"><meta name="citation_patent_application_number" content="CN:201110277622"><link rel="canonical" href="https://www.google.com/patents/CN102867008A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102867008A?cl=zh"/><meta name="title" content="专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法"/><meta name="description" content="本发明涉及网络通信领域，特别涉及一种基于增强现实和远端计算的识别系统和方法，一种用户终端和识别方法，以及一种远端运算识别装置和识别方法，包括：终端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用于将待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；远端数据库，用于存储和待辨识对象的识别特征对应的数据；远端运算单元，用于接收待辨识对象的识别特征和所需执行的应用程序的图标，将所需要的姓名和地址信息传输给终端处理单元进入所需执行的应用程序，故只需一指拖曳人脸到应用程序图标或网页图标上或将所述应用程序图标或网页图标拖曳到所述人脸上，即可轻松完成执行应用程序或网站功能的过程。"/><meta property="og:title" content="专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102867008A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102867008A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102867008A&amp;usg=AFQjCNGQ94XsPsEknTK6DVYo2qEBM35bJQ" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/e02ba10195799737fa3e/CN102867008A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/e02ba10195799737fa3e/CN102867008A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102867008A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102867008A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102867008A?cl=zh" style="display:none"><span itemprop="description">本发明涉及网络通信领域，特别涉及一种基于增强现实和远端计算的识别系统和方法，一种用户终端和识别方法，以及一种远端运算识别装置和识别方法，包括：终端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用...</span><span itemprop="url">https://www.google.com/patents/CN102867008A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法" title="专利 CN102867008A - 基于增强现实和远端计算的识别系统和方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102867008 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110277622</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2013年1月9日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年9月19日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2011年7月6日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP2544126A1?hl=zh-CN&amp;cl=zh">EP2544126A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130011009?hl=zh-CN&amp;cl=zh">US20130011009</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110277622.5, </span><span class="patent-bibdata-value">CN 102867008 A, </span><span class="patent-bibdata-value">CN 102867008A, </span><span class="patent-bibdata-value">CN 201110277622, </span><span class="patent-bibdata-value">CN-A-102867008, </span><span class="patent-bibdata-value">CN102867008 A, </span><span class="patent-bibdata-value">CN102867008A, </span><span class="patent-bibdata-value">CN201110277622, </span><span class="patent-bibdata-value">CN201110277622.5</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%99%88%E7%83%88%E6%AD%A6%22">陈烈武</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9B%BE%E7%85%9C%E6%A3%8B%22">曾煜棋</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%BD%AD%E6%98%B1%E8%B1%AA%22">彭昱豪</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%AE%8F%E7%A2%81%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%22">宏&#30849;股份有限公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102867008A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102867008A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102867008A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (6),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110277622&amp;usg=AFQjCNG65p6xPbc53jSAPfW0uaAV1E8l9g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102867008A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNG83PDA4-9HS9TFsYEIChfRZ8l5Sw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT118550175" lang="ZH" load-source="patent-office">基于增强现实和远端计算的识别系统和方法</invention-title>
      </span><br><span class="patent-number">CN 102867008 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA104020257" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及网络通信领域，特别涉及一种基于增强现实和远端计算的识别系统和方法，一种用户终端和识别方法，以及一种远端运算识别装置和识别方法，包括：终端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用于将待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；远端数据库，用于存储和待辨识对象的识别特征对应的数据；远端运算单元，用于接收待辨识对象的识别特征和所需执行的应用程序的图标，将所需要的姓名和地址信息传输给终端处理单元进入所需执行的应用程序，故只需一指拖曳人脸到应用程序图标或网页图标上或将所述应用程序图标或网页图标拖曳到所述人脸上，即可轻松完成执行应用程序或网站功能的过程。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM48066311" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	�种基于增强现实和远端计算的识别系统，其特征为，包括：  &#32066;端触摸屏，用于调取待辨识对象的识别特征；  &#32066;端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；  远端数据库，用于存储和待辨识对象的识别特征对应的数据；以及  远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输给所述终端处理单元，使&#32066;端模块进入所需执行的应用程序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求I所述的系统，其特征为，所述待辨识对象的识别特征为人脸图像；以及所述终端触摸屏调取待辨识对象的识别特征为在所述终端触摸屏上按下一张图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述的图片和坐标位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求I所述的系统，其特征为，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述远端运算单元根据所述图片和坐标判断出对应的人脸图像，并将所述人脸图像与所述远端数据库中的人脸图像做人脸比对。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求I所述的系统，其特征为，所述应用程序包括但不限干：电子邮件即E-mail、即时通信即MSN、脸书即Facebook、文件传输协议网路协定即FTP IP、线上游戏、名片、谷歌即Google、视频分享网站即YouTube、网络即时语音沟通工具即Skype或易趣购物即e-Bay ；以及所述远端数据库包括但不限于，E-mail地址、MSN账户、FaceBook账户、FTPIP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e_Bay账户所组成的群组。</div>
    </div>
    </div> <div class="claim"> <div num="5" class="claim">
      <div class="claim-text">5.	一种用户&#32066;端，其特征为，包括：  &#32066;端触摸屏，用于调取待辨识对象的识别特征；以及  &#32066;端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元以执行应用程序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的装置，其特征为，所述待辨识对象的识别特征为人脸图像；以及所述终端触摸屏调取待辨识对象的识别特征为在所述终端触摸屏上按下一张图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述图片和坐标位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求5所述的装置，其特征为，所述应用程序包括但不限干，E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e-Bay账户所组成的群组</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8.	&#8212;种远端运算识别装置，其特征为，包括：  远端数据库，用于存储和待辨识对象的识别特征对应的数据；以及  远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输出去。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求8所述的装置，其特征为，所述待辨识对象的识别特征为人脸图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求8所述的装置，其特征为，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述远端运算单元根据所述图片和坐标判断出对应的人脸图像，并将所述人脸图像与所述远端数据库中的人脸图像做人脸比对。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.根据权利要求8所述的装置，其特征为，所述远端数据库包括但不限干，E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e-Bay账户所组成的群组。</div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12.	一种基于增强现实和远端计算的识别方法，其特征为，包括：  调取待辨识对象的识别特征；  将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；  根据所述待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；以及  将所述对应的姓名和地址信息传输给用户终端执行应用程序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12所述的方法，其特征为，所述待辨识对象的识别特征为人脸图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求12所述的方法，其特征为，所述调取待辨识对象的识别特征为在所述用户&#32066;端上按下图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述坐标位置。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求12所述的方法，其特征为，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述调取对应的姓名和地址信息为将判断出的人脸图像与所述远端数据库中的人脸图像做人脸辨识后调取对应的姓名和地址信息。</div>
    </div>
    </div> <div class="claim"> <div num="16" class="claim">
      <div class="claim-text">16.	�种远端运算识别方法，其特征为，包括：  接收待辨识对象的识别特征和所需执行的应用程序图标；  根据所述&#32066;端中待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；以及  将所述对应的姓名和地址信息传输给用户终端。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求16所述的方法，其特征为，所述待辨识对象的识别特征为人脸图像。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求16所述的方法，其特征为，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述调取对应的姓名和地址信息为将判断出的人脸图像与所述远端数据库中的人脸图像做人脸辨识后得到对应的姓名和地址信息。</div>
    </div>
    </div> <div class="claim"> <div num="19" class="claim">
      <div class="claim-text">19.	�种用户终端的识别方法，其特征为，  调取待辨识对象的识别特征；  将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；以及  从远端服务器得到所需的姓名和地址信息以执行应用程序。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20.根据权利要求19所述的方法，其特征为，所述待辨识对象的识别特征为人脸图像；以及所述调取待辨识对象的识别特征为在所述用户&#32066;端上按下图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述坐标位置。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES55151401" lang="ZH" load-source="patent-office" class="description">
    <p>基于增强现实和远端计算的识别系统和方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及网络通信领域，特别涉及一种基于增强现实和远端计算的识别系统和方法，一种用户&#32066;端和识别方法，以及�种远端运算识别装置和识别方法。</p>
    <p>背景技术</p>
    <p>[0002]	现有网络应用软件或网站服务的操作往往必需事先得知想要通信或查询对象的识别帐号，并且需要输入其帐号至应用程序或网页中，例如电子邮件位址、即时通信（MSN) 识别、脸书（Facebook)识别、文件传输协议网路协定（FTPIP)、关键字等，对于网际网络用户具有高度的不方便性与耗时性。</p>
    <p>[0003]	通信科技的日益求精，不仅在硬件、数据与网络等架构层均已达到高速与稳定的传输要求，在应用层的软件开发方面也有很大的发展，通信应用程序的各种辨识方法与用户连结状态成为现今社会发展如何能突破人与人间的屏障的关键，然而，一般用户常在使用多个应用程序和别人联系与沟通时需要输入对应于所述人的账户或地址信息，账户地址每人不一样，要想都记住是不可能的，这样在与人联系的时候就变得很困难，且在使用时也无法在各种应用程序中切&#25563;，会产生对网络应有的便利性无法掌握，也相对的丧失了信息科技带来的划时代革新。</p>
    <p>[0004]	云端运算推行已有几年，云运算的核心思想，是将大量用网络连接的计算资源统一管理和调度，构成�个计算资源池向用户按需服务。网际网络用户可以利用云运算中的资源来解决上述的问题，使得应用程序在通信时变得方便快捷。</p>
    <p>发明内容</p>
    <p>[0005]	本发明解决的技术问题是提供只需一指拖曳人脸到应用程式图标或网页图标上或将所述应用程式图标或网页图标拖曳到所述人脸上，即可轻松完成执行应用程式或网站功能的过程的一种基于增强现实和远端计算系统和方法，以及所述系统中的&#32066;端和远端的系统和方法。</p>
    <p>[0006]	为解决上述的技术问题，本发明提供了一种基于增强现实和远端计算的识别系统，包括：&#32066;端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；远端数据库，用于存储和待辨识对象的识别特征对应的数据；远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输给所述终端处理单元，使&#32066;端模块进入所需执行的应用程序。</p>
    <p>[0007]	&#8212;种用户&#32066;端，包括：&#32066;端触摸屏，用于调取待辨识对象的识别特征；终端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元以执行应用程序。</p>
    <p>[0008]	�种远端运算识别装置，包括：远端数据库，用于存储和待辨识对象的识别特征对应的数据；远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输出去。</p>
    <p>[0009]	一种基于增强现实和远端计算的识别方法，包括：调取待辨识对象的识别特征；将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；根据所述待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；将所述对应的姓名和地址信息传输给用户终端执行应用程序。</p>
    <p>[0010]	�种远端运算识别方法，包括：接收待辨识对象的识别特征和所需执行的应用程序图标；根据所述&#32066;端中待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；将所述对应的姓名和地址信息传输给用户终端。</p>
    <p>[0011]	�种用户终端的识别方法，调取待辨识对象的识别特征；将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；从远端服务器得到所需的姓名和地址信息以执行应用程序。 </p>
    <p>[0012]	本发明的优点为：本发明提供创新的人机操控介面，利用触控式方法拖曳人脸图像至应用软件标识上或将所述应用软件标识拖曳到人脸图像上，即可由服务器取得其通讯ID帐号并汇入应用程序中，不仅可用于现有的网络通信程序，还可应用于未来新兴的网络应用程序。</p>
    <p>附图说明</p>
    <p>[0013]	图I为本发明实施例的基于增强现实和远端计算的识别系统示意图。</p>
    <p>[0014]	图2为本发明用户终端的流程示意图。</p>
    <p>[0015]	图3为本发明基于增强现实与远端计算的智能手机操作介面示意图。</p>
    <p>[0016]	图4为本发明基于增强现实与远端计算的用户注册协议的流程图。</p>
    <p>[0017]	图5为本发明基于增强现实与远端计算的系统工作的作业图。</p>
    <p>[0018]	其中，附图标记说明如下：</p>
    <p>[0019]	10:流程示意图	11 :人脸图像</p>
    <p>[0020]	12 :人脸辨识	13 :识别帐号</p>
    <p>[0021]	14:应用程式	15 :程序专属功能</p>
    <p>[0022]	20 :智慧型手机操作介面	21 :应用程序列表</p>
    <p>[0023]	22 :应用程式图标/网页图标	30 :使用者注册协议</p>
    <p>[0024]	步骤31 :注册	步骤32 :传送照片</p>
    <p>[0025]	步骤33 :等待回传信息	步骤34 :传送使用者相关信息</p>
    <p>[0026]	40 :识别方法</p>
    <p>具体实施方式</p>
    <p>[0027]	下面结合附图对技术方案进行进一&#27497;的详细描述。</p>
    <p>[0028]	�种基于增强现实和远端计算的识别系统，包括：&#32066;端触摸屏，用于调取待辨识对象的识别特征；&#32066;端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；[0029]	远端数据库，用于存储和待辨识对象的识别特征对应的数据；以及</p>
    <p>[0030]	远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输给所述终端处理单元，使&#32066;端模块进入所需执行的应用程序。</p>
    <p>[0031]	进�步的，所述待辨识对象的识别特征为人脸图像；以及所述终端触摸屏调取待辨识对象的识别特征为在所述终端触摸屏上按下一张图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述的图片和坐标位置。</p>
    <p>[0032]	进�步的，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述远端运算单元根据所述图片和坐标判断出对应的人脸图像，并将所述人脸图像与远端数据库中的人脸图像做人脸比对。 [0033]	进�步的，所述应用程序包括但不限干：电子邮件即E-mail、即时通信即MSN、脸书即Facebook、文件传输协议网路协定即FTP IP、线上游戏、名片、谷歌即Google、视频分享网站即YouTube、网络即时语音沟通工具即Skype或易趣购物即e_Bay ；</p>
    <p>[0034]	进�步的,所述远端数据库包括但不限于,E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e_Bay账户所组成的群组。</p>
    <p>[0035]	一种用户&#32066;端，包括：&#32066;端触摸屏，用于调取待辨识对象的识别特征；以及终端处理单元，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元以执行应用程序。</p>
    <p>[0036]	进�步的，所述待辨识对象的识别特征为人脸图像；以及所述终端触摸屏调取待辨识对象的识别特征为在所述终端触摸屏上按下一张图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述图片和坐标位置。</p>
    <p>[0037]	进�步的,所述应用程序包括但不限于，E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e_Bay账户所组成的群组</p>
    <p>[0038]	�种远端运算识别装置，包括：远端数据库，用于存储和待辨识对象的识别特征对应的数据；以及远端运算单元，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库中调取所需的姓名和地址信息，将所述姓名和地址信息传输出去。</p>
    <p>[0039]	进�步的，所述待辨识对象的识别特征为人脸图像。</p>
    <p>[0040]	进�步的，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述远端运算单元根据所述图片和坐标判断出对应的人脸图像，并将所述人脸图像与所述远端数据库中的人脸图像做人脸比对。</p>
    <p>[0041]	进�步的,所述远端数据库包括但不限于,E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e_Bay账户所组成的群组</p>
    <p>[0042]	一种基于增强现实和远端计算的识别方法，包括：调取待辨识对象的识别特征；将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；根据所述待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；以及</p>
    <p>[0043]	将所述对应的姓名和地址信息传输给用户终端执行应用程序。</p>
    <p>[0044]	进�步的，所述待辨识对象的识别特征为人脸图像。</p>
    <p>[0045]	进�步的，所述调取待辨识对象的识别特征为在所述用户&#32066;端上按下图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述坐标位置。</p>
    <p>[0046]	进�步的，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述调取对应的姓名和地址信息为将判断出的人脸图像与所述远端数据库中的人脸图像做人脸辨识后调取对应的姓名和地址信息。</p>
    <p>[0047]	�种远端运算识别方法，包括：接收待辨识对象的识别特征和所需执行的应用程 序图标；根据所述&#32066;端中待辨识对象的识别特征和所需执行的应用程序的图标从远端数据库中调取对应的姓名和地址信息；以及将所述对应的姓名和地址信息传输给用户终端。</p>
    <p>[0048]	进�步的，所述待辨识对象的识别特征为人脸图像。</p>
    <p>[0049]	进�步的，所述远端数据库包括满足识别数量的清晰且合格的多个人脸图像，作为所述特定的人的图像辨识比对依据；以及所述调取对应的姓名和地址信息为将判断出的人脸图像与所述远端数据库中的人脸图像做人脸辨识后得到对应的姓名和地址信息。</p>
    <p>[0050]	�种用户终端的识别方法，调取待辨识对象的识别特征；</p>
    <p>[0051]	将所述待辨识对象的识别特征和所需执行的应用程序图标传输给远端服务器；以及从远端服务器得到所需的姓名和地址信息以执行应用程序。</p>
    <p>[0052]	进�步的，所述待辨识对象的识别特征为人脸图像；以及所述调取待辨识对象的识别特征为在所述用户&#32066;端上按下图片中人脸图像的坐标位置到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述坐标位置。</p>
    <p>[0053]	本发明可以通过具有摄像机和屏幕的电子产品和装置与云计算平台来完成。请&#21443;考图1，图I为本发明的一实施例的�种基于增强现实和远端计算的识别系统100示意图，包括：用户终端101和远端运算识别装置110，用户终端101包括&#32066;端触摸屏102，用于调取待辨识对象的识别特征，&#32066;端处理单元103，用于将所述待辨识对象的识别特征和所需执行的应用程序的图标传输给远端运算单元；远端运算识别装置110包括远端数据库112，用于存储和待辨识对象的识别特征对应的数据，远端运算单元111，用于接收所述待辨识对象的识别特征和所需执行的应用程序的图标，井根据所述待辨识对象的识别特征和所需执行的应用程序图标从远端数据库112中调取所需的姓名和地址信息，将所述姓名和地址信息传输给所述终端处理单元103，使&#32066;端模块进入所需执行的应用程序。依据本实施例的不同变化，用户终端101可以是智能手机、平板电脑或具有摄像机和屏幕的电子产品和装置，但这仅是为了说明用途，并不以此为限。</p>
    <p>[0054]	如图2和3所示，待辨识对象的识别特征为人脸图像；终端触摸屏调取待辨识对象的识别特征为在&#32066;端触摸屏102上按下�张图片中人脸图像并记录下坐标位置再将头像拖拽到应用程序的图标上或拖曳所述应用程序的图标至所述人脸图像而得到所述的图片和坐标位置，这样用户将所选取人脸图像11通过人脸辨识12对应至其识别帐号13，并根据想要执行的应用程序14来供用户选择其程序的专属功能15。此方式结合现在人脸辨识技术，包含与云端服务器中各种人脸图片比对，撷取通过认证的用户身份，并提供相关程式动作或网站服务所需的用户验证资料，来执行应用程式的各项功能与服务，能节省用户使用各个应用程序的时间，并整合与简化各种不同应用程式的启动方式，达到提升用户网路服务满意度的效果。</p>
    <p>[0055]	其中远端数据库112包括满足识别数量的清晰且合格的多个人脸图像11，作为特定的人的图像辨识比对依据，远端运算单元111根据终端触摸屏102中的图片和坐标判断出对应的人脸图像11，并将人脸图像11与远端数据库112中的人脸图像做人脸比对。</p>
    <p>[0056]	在本发明的实施例中，用户操作手机时可以见到如图3的智能手机操作介面20。下方占据画面约六分之一的长条型横轴为应用程序列表21，应用程序列表中显示为手机中内建储存空间或手机本地储存装置，如SD卡中的各式各样的应用程序图标22或网页图标，用户可将画面中人脸图像11拖曳到应用程序列表中任意的应用程序图标22或网页图标上，或将所述应用程序图标22或网页图标拖曳到所述人脸图像11上，而所述应用程序或特定网站将会执行相关程序动作或网站服务。此作法将有助于快速筛选特定用户、管理众多 联络人与更有效率地使用各种网路服务程式。</p>
    <p>[0057]	在本发明中的应用程序包括但不限于：电子邮件即E-mail、即时通信即MSN、脸书即Facebook、文件传输协议网路协定即FTP IP、线上游戏、名片、谷歌即Google、视频分享网站即YouTube、网络即时语音沟通工具即Skype或易趣购物即e_Bay。</p>
    <p>[0058]	本实施例以Facebook为例进行说明。请&#21443;阅图4的用户注册协议30的流程图，在开始使用本系统之前，在步骤31中用户可先向云端服务器进行注册，或是自动引入脸书的人脸资料库，用户只要拥有脸书帐号，即可使用已上传的脸书注册信息与人脸图像来取得其电子邮件等识别帐号资料，可简化自行上传资料至云端的步骤。注册时用户必须先照下包含自己脸孔的数张相片，相片中必须包含清晰的脸部画面，在步骤32中这些相片将会传送到云端服务器，步骤33中来判定是否为合格的脸部相片，步骤34中直到用户传送的照片数量满足服务器所设定的为止，这些合格的相片将会储存在远端数据库112作为脸部辨识重要的比对依据。系统会在远端数据库112中制作一个用户列表，列表中纪录了用户的手机端信息，E-mail地址、MSN账户、FaceBook账户、FTP IP、线上游戏、名片、Google账户、YouTube账户、Skype账户或e_Bay账户所组成的群组，当注册完毕后即可使用本系统。</p>
    <p>[0059]	图5为扩增实境与云端计算的识别方法40的流程图，扩增实境与云端计算的识别方法40可对应图I所示的基于增强现实和远端计算的识别系统100，扩增实境与云端计算的识别方法40包括用户终端的识别方法400和远端运算识别方法410，分别对应图I中的用户终端101和远端运算识别装置110，对扩增实境与云端计算的识别方法40说明如下：</p>
    <p>[0060]	步骤401 :从用户手机中的图片中调取人脸图像；</p>
    <p>[0061]	步骤402 :用户按下图片中的人脸图像11并记录坐标位置，再将人脸头像11拖拽到应用程序图标22上，或者将所述应用程序的图标22或网页图标拖曳到所述人脸图像11上，在这个步骤中拖拽至人脸图像11或应用程序的图标22后，放开手，此时手机会照下镜头撷取的画面，并取得有人脸图像11的图片；</p>
    <p>[0062]	步骤403 :将图片、坐标和应用程序图标22传输给远端服务器；</p>
    <p>[0063]	步骤404 :远端的服务器检测坐标位置最近的人脸图像11 ；</p>
    <p>[0064]	步骤405 :将人脸图像11与远端数据库112中的人脸图像11做辨识，在这个步骤中；</p>
    <p>[0065]	步骤406 :从远端数据库112中调取对应的姓名和地址信息；</p>
    <p>[0066]	步骤407 :将对应的姓名和地址信息回传给用户终端；</p>
    <p>[0067]	最后步骤408 :执行所述的应用程序。</p>
    <p>[0068]	通过前述方法，不须输入任何想要联系的人的识别帐号，用户也不需前往询问所述想要联系的人的各应用程序相关识别帐号或地址，也不须记忆任何相关识别帐号或地址，可以有效的&#28187;少用户的困扰。</p>
    <p>[0069]	本发明的技术特点为以扩增实境为基础，让用户可将画面中人脸图像11拖曳到应用程序列表中任意的应用程序图标22或网页图标上,或将所述应用程序图标22或网页图标拖曳到所述人脸图像11上，即可取得其通讯识别帐号并触发特定程式功能或网站服务，应用情境为将人脸影像拖曳至应用程序或网页或将所述应用程序或网页拖曳至所述人脸影像上，系统可以自动执行任何需要对方用户识别之网络软件或网站服务，无须额外进行识别帐号输入，大大&#28187;少ロ头询问与电脑纪录的不便性。此外，用户只要拥有某网页帐号，亦可使用已上传的注册资讯与人脸照片来取得其通讯识别帐号资料，或是事先下载针对此服务专属设计的软体来进行注册与执行应用程序或网站服务的动作。 [0070]	以上所述仅为本发明的优选实施例，凡依本发明权利要求所做的均等变化与修饰，皆应属本发明的涵盖范围。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101359334A?cl=zh">CN101359334A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年7月31日</td><td class="patent-data-table-td patent-date-value">2009年2月4日</td><td class="patent-data-table-td ">Lg电子株式会社</td><td class="patent-data-table-td ">便携终端及其图像信息管理方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101408928A?cl=zh">CN101408928A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年10月12日</td><td class="patent-data-table-td patent-date-value">2009年4月15日</td><td class="patent-data-table-td ">宏&#30849;股份有限公司</td><td class="patent-data-table-td ">结合生物特征辨识的物件执行系统及其方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102035930A?cl=zh">CN102035930A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2009年9月29日</td><td class="patent-data-table-td patent-date-value">2011年4月27日</td><td class="patent-data-table-td ">宏达国际电子股份有限公司</td><td class="patent-data-table-td ">图像的应用操作方法及系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110064281">US20110064281</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2010年6月4日</td><td class="patent-data-table-td patent-date-value">2011年3月17日</td><td class="patent-data-table-td ">Mediatek Inc.</td><td class="patent-data-table-td ">Picture sharing methods for a portable device</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN103150658A?cl=zh">CN103150658A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2013年4月2日</td><td class="patent-data-table-td patent-date-value">2013年6月12日</td><td class="patent-data-table-td ">武汉友睿科技有限公司</td><td class="patent-data-table-td ">一种面向终端用户的现实增强定制系统及方法</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009640000">G06K9/64</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00288">G06K9/00288</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=j0u4BwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00979">G06K9/00979</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06K9/00Y</span>, <span class="nested-value">G06K9/00F</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2013年1月9日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2013年2月20日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年10月28日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/e02ba10195799737fa3e/CN102867008A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%9F%BA%E4%BA%8E%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E%E5%92%8C%E8%BF%9C%E7%AB%AF%E8%AE%A1%E7%AE%97%E7%9A%84%E8%AF%86.pdf?id=j0u4BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2lTBXlPMXU3bUHZFPeBJBUGsK0KQ"},"sample_url":"https://www.google.com/patents/reader?id=j0u4BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>