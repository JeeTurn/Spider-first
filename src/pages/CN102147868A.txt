<!DOCTYPE html><html><head><title>专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="学习装置、学习方法、识别装置、识别方法和程序"><meta name="DC.contributor" content="岩井嘉昭" scheme="inventor"><meta name="DC.contributor" content="本间俊一" scheme="inventor"><meta name="DC.contributor" content="芦原隆之" scheme="inventor"><meta name="DC.contributor" content="索尼公司" scheme="assignee"><meta name="DC.date" content="2010-12-22" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及学习装置、学习方法、识别装置、识别方法和程序。本发明提供了一种学习装置，包括：特征点提取单元，从多个产生用图像的每一个提取特征点；特征点特征量提取单元，从产生用图像提取表示特征点的特征的特征点特征量；整体特征量计算单元，基于共享码本从产生用图像的特征点特征量计算表示产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别不同的识别对象的每一个的识别器的产生用特征量；以及识别器产生单元，基于产生用图像的整体特征量和表示产生用图像是正像还是负像的正确答案标签产生识别器。"><meta name="DC.date" content="2011-8-10"><meta name="DC.relation" content="CN:101030244:A" scheme="references"><meta name="DC.relation" content="CN:101458764:A" scheme="references"><meta name="citation_patent_publication_number" content="CN:102147868:A"><meta name="citation_patent_application_number" content="CN:201010599524"><link rel="canonical" href="https://www.google.com/patents/CN102147868A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102147868A?cl=zh"/><meta name="title" content="专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序"/><meta name="description" content="本发明涉及学习装置、学习方法、识别装置、识别方法和程序。本发明提供了一种学习装置，包括：特征点提取单元，从多个产生用图像的每一个提取特征点；特征点特征量提取单元，从产生用图像提取表示特征点的特征的特征点特征量；整体特征量计算单元，基于共享码本从产生用图像的特征点特征量计算表示产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别不同的识别对象的每一个的识别器的产生用特征量；以及识别器产生单元，基于产生用图像的整体特征量和表示产生用图像是正像还是负像的正确答案标签产生识别器。"/><meta property="og:title" content="专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102147868A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102147868A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102147868A&amp;usg=AFQjCNF8KHNrGKtUyTf1SbliWuxi3FJD-Q" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/2bc0f899c59369f93937/CN102147868A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/2bc0f899c59369f93937/CN102147868A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102147868A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102147868A?cl=en&amp;hl=zh-CN"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102147868A?cl=zh" style="display:none"><span itemprop="description">本发明涉及学习装置、学习方法、识别装置、识别方法和程序。本发明提供了一种学习装置，包括：特征点提取单元，从多个产生用图像的每一个提取特征点；特征点特征量提取单元，从产生用图像提取表示特征点的特征的特征...</span><span itemprop="url">https://www.google.com/patents/CN102147868A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序" title="专利 CN102147868A - 学习装置、学习方法、识别装置、识别方法和程序"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102147868 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201010599524</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2011年8月10日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2010年12月22日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年1月27日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8340403?hl=zh-CN&amp;cl=zh">US8340403</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110182515?hl=zh-CN&amp;cl=zh">US20110182515</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201010599524.9, </span><span class="patent-bibdata-value">CN 102147868 A, </span><span class="patent-bibdata-value">CN 102147868A, </span><span class="patent-bibdata-value">CN 201010599524, </span><span class="patent-bibdata-value">CN-A-102147868, </span><span class="patent-bibdata-value">CN102147868 A, </span><span class="patent-bibdata-value">CN102147868A, </span><span class="patent-bibdata-value">CN201010599524, </span><span class="patent-bibdata-value">CN201010599524.9</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%B2%A9%E4%BA%95%E5%98%89%E6%98%AD%22">岩井嘉昭</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E6%9C%AC%E9%97%B4%E4%BF%8A%E4%B8%80%22">本间俊一</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%8A%A6%E5%8E%9F%E9%9A%86%E4%B9%8B%22">芦原隆之</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E7%B4%A2%E5%B0%BC%E5%85%AC%E5%8F%B8%22">索尼公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102147868A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102147868A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102147868A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (7),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201010599524&amp;usg=AFQjCNF5nYYkinV_rvHhjSfNfVq4XugE8g"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102147868A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFLY_Pny9-yCa7legFRdVcM1VZ0dQ"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT104365680" lang="ZH" load-source="patent-office">学习装置、学习方法、识别装置、识别方法和程序</invention-title>
      </span><br><span class="patent-number">CN 102147868 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA86266710" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及学习装置、学习方法、识别装置、识别方法和程序。本发明提供了一种学习装置，包括：特征点提取单元，从多个产生用图像的每一个提取特征点；特征点特征量提取单元，从产生用图像提取表示特征点的特征的特征点特征量；整体特征量计算单元，基于共享码本从产生用图像的特征点特征量计算表示产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别不同的识别对象的每一个的识别器的产生用特征量；以及识别器产生单元，基于产生用图像的整体特征量和表示产生用图像是正像还是负像的正确答案标签产生识别器。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(22)</span></span></div><div class="patent-text"><div mxw-id="PCLM37855968" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种学习装置，包括：特征点提取部件，被构造为从多个产生用图像的每一个提取特征点，其中所述多个产 生用图像用于产生识别存在于图像上的被摄体是否是预定的待识别对象的识别器，并且所 述多个产生用图像由存在所述待识别对象的正像和不存在所述待识别对象的负像组成；特征点特征量提取部件，被构造为从所述产生用图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算部件，被构造为基于共享码本，从所述产生用图像的所述特征点特征 量计算表示所述产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生识 别不同待识别对象的每一个的识别器的产生用特征量；以及识别器产生部件，被构造为基于所述产生用图像的所述整体特征量和表示所述产生用 图像是所述正像还是所述负像的正确答案标签产生所述识别器。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1的学习装置，还包括：共享码本存储部件，被构造为存储共享码本，所述共享码本包括：码本，按照与用于标识所述产生用特征量的标识符相关的方式保持多个所述产生用特 征量的每一个，以及共享信息，是针对用于识别不同的待识别对象的每一个的每个识别器建立的多个共享 信息，并且还包括所述多个产生用特征量中的、在计算所述整体特征量时使用的所述产生 用特征量的所述标识符；其中，所述整体特征量计算部件使用保持在所述码本中的所述多个产生用特征量中 的、与包括在针对由所述识别器产生部件产生的所述识别器创建的所述共享信息中的标识 符相关的产生用特征量计算所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求2的学习装置，其中，所述多个共享信息中的预定的共享信息具有与 包括在其它共享信息中的所述标识符相同的标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求3的学习装置，其中，所述预定的共享信息具有还与从作为正像的模 型图像提取的特征点相关的所述标识符；并且其中，所述整体特征量计算部件使用与所述标识符相关的产生用特征量和存在于 所述产生用图像上的整体范围中的、基于与所述标识符相关的所述特征点确定的范围上的 特征点的特征点特征量计算所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求4的学习装置，其中，包括在所述预定的共享信息中的所述标识符与 不同于下列特征点的特征点相关，所述特征点相关于与包括在所述其它共享信息中的所述标识符相同的标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5的学习装置，还包括：模型图像特征点提取部件，被构造为从作为正像的模型图像提取特征点；以及量化部件，被构造为基于所述模型图像的特征点中的频率分布对所述特征点进行量化；其中，所述共享信息具有与量化后的所述特征点相关的所述标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.根据权利要求1的学习装置，其中，所述整体特征量计算部件计算表示包括在所述 共享码本中的所述产生用特征量与所述产生用图像的所述特征点特征量之间的相关的相 关值作为所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求1的学习装置，其中，所述识别器产生部件产生所述识别器和表示减 小所述误差值的所述维度特征量的维度的维度信息，所述识别器用于使用在多个维度特征 量中的、减小表示所述正像和所述负像的识别错误的程度的误差值的所述维度特征量来执 行识别，所述多个维度特征量是由多个维度矢量表示的所述整体特征量的每个维度要素。</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9.	一种学习用于识别预定的待识别对象的识别器的学习装置的学习方法，所述学习装 置包括：特征点提取部件， 特征点特征量提取部件， 整体特征量计算部件，以及 识别器产生部件， 所述学习方法包括如下步骤：通过所述特征点提取部件，从多个产生用图像的每个提取特征点，所述产生用图像用 于产生识别存在于图像上的被摄体是否是预定的待识别对象的识别器，并且所述产生用图 像由存在所述待识别对象的正像和不存在所述待识别对象的负像组成；通过所述特征点特征量提取部件，从所述产生用图像提取表示所述特征点的特征的特 征点特征量；通过所述整体特征量计算部件，基于共享码本从所述产生用图像的所述特征点特征量 计算表示所述产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生识别 不同的待识别对象的每一个的识别器的产生用特征量；以及通过所述识别器产生部件，基于所述产生用图像的所述整体特征量和表示所述产生用 图像是所述正像还是所述负像的正确答案标签产生所述识别器。</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10.	一种程序，使得计算机充当以下部件：特征点提取部件，被构造为从多个产生用图像的每一个提取特征点，所述产生用图像 用于产生识别存在于图像上的被摄体是否是预定的待识别对象的识别器，并且所述产生用 图像由存在所述待识别对象的正像和不存在所述待识别对象的负像组成；特征点特征量提取部件，被构造为从所述产生用图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算部件，被构造为基于共享码本从所述产生用图像的所述特征点特征量 计算表示所述产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生识别 不同的待识别对象的每一个的识别器的产生用特征量；以及识别器产生部件，被构造为基于所述产生用图像的所述整体特征量和表示所述产生用 图像是所述正像还是所述负像的正确答案标签产生所述识别器。</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11.	一种识别装置，包括：特征点提取部件，被构造为从待处理图像提取特征点，所述待处理图像用作用于识别 存在于图像上的被摄体是否是预定的待识别对象的处理对象；特征点特征量提取部件，被构造为从所述待处理图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算部件，被构造为基于共享码本从所述待处理图像的特征点特征量计算 表示所述待处理图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别不同的待识别对象的每一个的识别器的产生用特征量；以及识别部件，被构造为基于用于识别存在于图像上的被摄体是否是预定的待识别对象的 识别器和所述整体特征量识别存在于所述待处理图像上的被摄体是否是预定的待识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.根据权利要求11的识别装置，还包括：共享码本存储部件，被构造为存储共享码本，所述共享码本包括：码本，按照与用于标识所述产生用特征量的标识符相关的方式保持多个所述产生用特 征量的每一个，以及共享信息，是针对用于识别不同的待识别对象的每一个的每个识别器建立的多个共享 信息，并且还包括所述多个产生用特征量中的、在计算所述整体特征量时使用的所述产生 用特征量的所述标识符；其中，所述整体特征量计算部件使用保持在所述码本中的所述多个产生用特征量中 的、与包括在针对由所述标识部件使用的所述识别器创建的所述共享信息中的所述标识符 相关的产生用特征量计算所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13.根据权利要求12的识别装置，其中，所述多个共享信息中的预定的共享信息具有 与包括在其它共享信息中的所述标识符相同的标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.根据权利要求13的识别装置，其中，所述预定的共享信息具有还与从存在所述预 定的待识别对象的模型图像提取的特征点相关的所述标识符；并且其中，所述整体特征量计算部件使用与所述标识符相关的产生用特征量和存在于 所述待处理图像上的整体范围中的、基于与所述标识符相关的所述特征点确定的范围上的 特征点的特征点特征量计算所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.根据权利要求14的识别装置，其中，包括在所述共享信息中的所述标识符与不同 于下列特征点的特征点相关，所述特征点相关于与包括在所述其它共享信息中的所述标识符相同的标识符。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16.根据权利要求11的识别装置，其中，所述整体特征量计算部件计算表示包括在所 述共享码本中的所述产生用特征量与所述待处理图像的所述特征点特征量之间的相关的 相关值作为所述整体特征量。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17.根据权利要求11的识别装置，其中，所述整体特征量计算部件基于所述共享码本， 从所述待处理图像的特征点特征量计算表示所述待处理图像的整体特征的、由多个维度特 征量组成的整体特征量；并且其中，所述识别部件通过将组成所述整体特征量的所述多个维度特征量中的预定 维度特征量提供给识别存在于图像上的被摄体是否是预定的待识别对象的识别器作为输 入，识别存在于所述待处理图像上的被摄体是否是预定的待识别对象。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18.根据权利要求17的识别装置，其中，所述识别部件将组成所述整体特征量的所述 多个维度特征量中的、维度信息所表示的维度的维度特征量提供给用于识别存在于图像上 的被摄体是否是预定的待识别对象的识别器作为输入，从而识别在所述图像上出现的被摄 体是否是预定的待识别对象；并且其中，所述识别器使用表示所述整体特征量的所述多个维度特征量中的、减小误 差值的所述维度特征量执行识别，所述误差值表示对于是所述待识别对象存在于图像上的正像还是所述待识别对象不存在于图像上的负像的识别错误的程度；并且其中，所述维度信息表示减小所述误差值的所述维度特征量的维度。</div>
    </div>
    </div> <div class="claim"> <div num="19" class="claim">
      <div class="claim-text">19.	一种识别在图像上出现的被摄体是否是预定的待识别对象的识别装置的识别方 法，所述识别装置包括：特征点提取部件， 特征点特征量提取部件， 整体特征量计算部件，以及 识别部件，所述识别方法包括如下步骤：通过所述特征点提取部件，从作为用于识别存在于图像上的被摄体是否是预定的待识 别对象的处理对象的待处理图像提取特征点；通过所述特征点特征量提取部件，从所述待处理图像提取表示所述特征点的特征的特 征点特征量；通过所述整体特征量计算部件，基于共享码本从所述待处理图像的特征点特征量计算 表示所述待处理图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别 不同的待识别对象的每一个的识别器的产生用特征量；以及通过所述识别部件，基于用于识别存在于图像上的被摄体是否是预定的待识别对象的 识别器和所述整体特征量来识别存在于所述待处理图像上的被摄体是否是预定的待识别 对象。</div>
    </div>
    </div> <div class="claim"> <div num="20" class="claim">
      <div class="claim-text">20.	一种程序，使得计算机充当以下部件：特征点提取部件，被构造为从待处理图像提取特征点，所述待处理图像作为用于识别 存在于图像上的被摄体是否是预定的待识别对象的处理对象；特征点特征量提取部件，被构造为从所述待处理图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算部件，被构造为基于共享码本从所述待处理图像的特征点特征量计算 表示所述待处理图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别 不同的待识别对象的每一个的识别器的产生用特征量；以及识别部件，被构造为基于用于识别存在于图像上的被摄体是否是预定的待识别对象的 识别器和所述整体特征量识别存在于所述待处理图像上的被摄体是否是预定的待识别对 象。</div>
    </div>
    </div> <div class="claim"> <div num="21" class="claim">
      <div class="claim-text">21.	一种学习装置，包括：特征点提取单元，被构造为从多个产生用图像的每一个提取特征点，所述产生用图像 用于产生识别存在于图像上的被摄体是否是预定的待识别对象的识别器，并且所述产生用 图像由存在所述待识别对象的正像和不存在所述待识别对象的负像组成；特征点特征量提取单元，被构造为从所述产生用图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算单元，被构造为基于共享码本从所述产生用图像的所述特征点特征量 计算表示所述产生用图像的整体特征的整体特征量，所述共享码本包括共同用于产生识别 不同的待识别对象的每一个的识别器的产生用特征量；以及识别器产生单元，被构造为基于所述产生用图像的所述整体特征量和表示所述产生用 图像是所述正像还是所述负像的正确答案标签产生所述识别器。</div>
    </div>
    </div> <div class="claim"> <div num="22" class="claim">
      <div class="claim-text">22. &#8212;种识别装置，包括：特征点提取单元，被构造为从待处理图像提取特征点，所述待处理图像作为用于识别 存在于图像上的被摄体是否是预定的待识别对象的处理对象；特征点特征量提取单元，被构造为从所述待处理图像提取表示所述特征点的特征的特 征点特征量；整体特征量计算单元，被构造为基于共享码本从所述待处理图像的特征点特征量计算 表示所述待处理图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于识别 不同的待识别对象的每一个的识别器的产生用特征量；以及识别单元，被构造为基于用于识别存在于图像上的被摄体是否是预定的待识别对象的 识别器和所述整体特征量，识别存在于所述待处理图像上的被摄体是否是预定的待识别对 象。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES43435008" lang="ZH" load-source="patent-office" class="description">
    <p>学习装置、学习方法、识别装置、识别方法和程序</p>
    <p>技术领域</p>
    <p>[0001]	本发明涉及一种学习装置、学习方法、识别装置、识别方法和程序，更具体地讲，涉 及适于在识别存在于图像上的被摄体是否是预定的待识别对象的情况下采用的学习装置、 学习方法、识别装置、识别方法和程序。</p>
    <p>背景技术</p>
    <p>[0002]	作为用于从相机获得的图像识别（认出）该图像上存在的用作待识别对象的对象 的根据现有技术的识别方法，存在一种采用在某种广泛的意义上描述待识别对象的模板执 行匹配的识别方法。</p>
    <p>[0003]	利用这个识别方法，预先准备在某种广泛的意义上描述待识别对象的模板，具体 地讲，预先准备整个待识别对象的纹理的模板，并且在待识别图像的模板与待识别图像 (待处理图像）之间执行匹配。</p>
    <p>[0004]	然而，通过采用描述待识别对象的模板进行匹配，很难处理存在于待处理图像上 的待识别对象的局部隐藏或畸变。</p>
    <p>[0005]	因此，提出了一种识别方法，其中，关注待处理图像的局部区域，从每个局部区域 提取特征量，并且采用每个局部区域的特征量的组合（局部区域的特征量的集合，即例如 以每个局部区域的特征量作为要素的矢量）执行识别。</p>
    <p>[0006]	根据采用局部区域的特征量集合的识别方法，在一定程度上消除了通过采用在某 种广泛的意义上描述待识别对象的模板的识别方法很难进行处理的问题（例如待识别对 象的局部隐藏或畸变），由此能够执行高精度识别。</p>
    <p>[0007]	除了单个对象的识别以外，局部区域的特征量还用于识别对象的类别。例如，已 经提出了一种使用局部区域的特征量识别特定类别（例如人脸）的识别方法（例如，见 P. Viola, Μ. Jones, Robust Real-time Face Detection，cvpr2001)。</p>
    <p>[0008]	另外，对于识别类别，已经提出了各种识别方法。针对类别的识别提出的识别方法 的例子包括采用BoF(特征包，Bag of Features)柱状图的识别方法（例如，参见G. Csurka, C. Bray, C. Dance,and L. Fan. Visual categorization with bags of keypoint,ECCV2004) 和采用特征量的相关的识别方法（例如，参见日本未审专利申请公布No. 2007-128195)。</p>
    <p>[0009]	例如，通过采用BoF柱状图的识别方法，采用称作视觉码本（Visual codebook)的 代表性特征量，从而抑制图像表达的维度。</p>
    <p>[0010]	然而，在采用这种视觉码本的情况下，图像区域中特征量的出现位置的信息丢失， 因此识别精度出现下降。</p>
    <p>[0011]	因此，为了处理这个问题，提出了一种通过以网格形状（栅格）划分图像区域提供 弱位置约束的方法（例如，见 S. Lazebnik，C. Schmid, J. Ponce "Beyond Bag of Features ： Spatial Pyramid Matching for Recognizing Natural Scene Categories，，，CVPR2006)。发明内容</p>
    <p>[0012]	然而，即使使用以上的视觉码本抑制图像表达的维度，在将它应用到识别多个类 别（多个类）的情况下，必须建立特征量池，该特征量池即为用于根据类别识别类别的多个 特征量的集合，并且在类别的数目增加的情况下，与每个类别对应的特征量变得非常大。</p>
    <p>[0013]	因此，在使用视觉码本执行类别识别的情况下，例如，用于存储视觉码本的存储器 的容量增加。</p>
    <p>[0014]	另外，根据通过以网格形状划分图像区域提供弱位置约束的方法，位置约束对每 个类别是共同的，从而识别待识别对象的精度下降。</p>
    <p>[0015]	在这种情况下，为了抑制识别精度的下降，必须通过产生用于提高识别精度的每 个类别中固有的视觉码本提高识别精度，从而特征量变得很大，并且由此，存储视觉码本的 存储器的容量同样增加。</p>
    <p>[0016]	已经发现希望共享用于识别单个对象的特征量或在待识别对象之间的待识别对 象的类别，从而高精度检测待识别对象并且抑制特征量的增加。</p>
    <p>[0017]	根据本发明的第一实施例的学习装置是如下学习装置，包括：特征点提取单元，被 构造为从多个产生用图像的每一个提取特征点，其中所述多个产生用图像用于产生识别存 在于图像上的被摄体是否是预定的待识别对象的识别器，并且所述多个产生用图像由存在 所述待识别对象的正像和不存在所述待识别对象的负像组成；特征点特征量提取单元，被 构造为从所述产生用图像提取表示所述特征点的特征的特征点特征量；整体特征量计算单 元，被构造为基于共享码本，从所述产生用图像的所述特征点特征量计算表示所述产生用 图像的整体特征的整体特征量，所述共享码本包括共同用于产生识别不同待识别对象的每 一个的识别器的产生用特征量；以及识别器产生单元，被构造为基于所述产生用图像的所 述整体特征量和表示所述产生用图像是正像还是负像的正确答案标签产生所述识别器。</p>
    <p>[0018]	基于根据第一实施例的学习装置，还可以设置有共享码本存储单元，被构造为存 储共享码本，所述共享码本包括：码本，按照与用于标识所述产生用特征量的标识符相关 的方式保持多个所述产生用特征量的每一个，以及共享信息，是针对用于识别不同的待识 别对象的每一个的每个识别器建立的多个共享信息，并且还包括所述多个产生用特征量中 的、在计算所述整体特征量时使用的所述产生用特征量的标识符；所述整体特征量计算单 元使用保持在所述码本中的所述多个产生用特征量中的、与包括在针对由所述识别器产生 单元产生的所述识别器创建的所述共享信息中的标识符相关的产生用特征量计算所述整 体特征量。</p>
    <p>[0019]	基于根据第一实施例的学习装置，所述多个共享信息中的预定的共享信息具有与 包括在其它共享信息中的标识符相同的标识符。</p>
    <p>[0020]	基于根据第一实施例的学习装置，所述预定的共享信息具有还与从作为正像的模 型图像提取的特征点相关的所述标识符；所述整体特征量计算部件使用与所述标识符相关 的产生用特征量和存在于所述产生用图像上的整体范围中的、基于与所述标识符相关的所 述特征点确定的范围上的特征点的特征点特征量计算所述整体特征量。</p>
    <p>[0021]	基于根据第一实施例的学习装置，包括在所述预定的共享信息中的所述标识符与 不同于下列特征点的特征点相关，所述特征点相关于与包括在所述其它共享信息中的标识 符相同的标识符。[0022]	基于根据第一实施例的学习装置，还设置有：模型图像特征点提取单元，被构造为 从作为正像的模型图像提取特征点；以及量化单元，被构造为基于所述模型图像的特征点 中的频率分布对所述特征点进行量化；其中，所述共享信息具有与量化后的所述特征点相 关的所述标识符。</p>
    <p>[0023]	基于根据第一实施例的学习装置，其中，所述整体特征量计算单元计算表示包括 在所述共享码本中的所述产生用特征量与所述产生用图像的所述特征点特征量之间的相 关的相关值作为所述整体特征量。</p>
    <p>[0024]	基于根据第一实施例的学习装置，其中，所述识别器产生单元产生所述识别器和 表示减小所述误差值的所述维度特征量的维度的维度信息，所述识别器用于使用在多个维 度特征量中的、减小表示所述正像和所述负像的识别错误的程度的误差值的所述维度特征 量来执行识别，所述多个维度特征量是由多个维度矢量表示的所述整体特征量的每个维度要素。</p>
    <p>[0025]	根据本发明第一实施例的学习方法是一种学习用于识别预定的待识别对象的识 别器的学习装置的学习方法，所述学习装置包括：特征点提取单元，特征点特征量提取单 元，整体特征量计算单元，以及识别器产生单元，所述学习方法包括如下步骤：通过所述特 征点提取单元，从多个产生用图像的每个提取特征点，所述产生用图像用于产生识别存在 于图像上的被摄体是否是预定的待识别对象的识别器，并且所述产生用图像由存在所述待 识别对象的正像和不存在所述待识别对象的负像组成；通过所述特征点特征量提取单元， 从所述产生用图像提取表示所述特征点的特征的特征点特征量；通过所述整体特征量计算 单元，基于共享码本从所述产生用图像的所述特征点特征量计算表示所述产生用图像的整 体特征的整体特征量，所述共享码本包括共同用于产生识别不同的待识别对象的每一个的 识别器的产生用特征量；以及通过所述识别器产生单元，基于所述产生用图像的所述整体 特征量和表示所述产生用图像是正像还是负像的正确答案标签产生所述识别器。</p>
    <p>[0026]	根据本发明第一实施例的第一程序是一种使得计算机充当以下单元的程序：特征 点提取单元，被构造为从多个产生用图像的每一个提取特征点，所述产生用图像用于产生 识别存在于图像上的被摄体是否是预定的待识别对象的识别器，并且所述产生用图像由存 在所述待识别对象的正像和不存在所述待识别对象的负像组成；特征点特征量提取单元， 被构造为从所述产生用图像提取表示所述特征点的特征的特征点特征量；整体特征量计算 单元，被构造为基于共享码本从所述产生用图像的所述特征点特征量计算表示所述产生用 图像的整体特征的整体特征量，所述共享码本包括共同用于产生识别不同的待识别对象的 每一个的识别器的产生用特征量；以及识别器产生单元，被构造为基于所述产生用图像的 所述整体特征量和表示所述产生用图像是正像还是负像的正确答案标签产生所述识别器。</p>
    <p>[0027]	根据本发明的第一实施例，从多个产生用图像（用于产生识别存在于图像上的被 摄体是否是预定的待识别对象的识别器并且由存在待识别的对象的正像和不存在待识别 的对象的负像组成）的每一个提取特征点，从产生用图像提取表示特征点的特征的特征点 特征量，基于共享码本（包括共同用于产生识别不同的待识别对象的每一个的识别器的产 生用特征量）从产生用图像的特征点特征量计算表示产生用图像的整体特征的整体特征 量，以及基于产生用图像的整体特征量和表示产生用图像是正像还是负像的正确答案标签 产生识别器。[0028]	根据本发明第二实施例的识别装置，包括：特征点提取单元，被构造为从待处理图 像提取特征点，所述待处理图像用作用于识别存在于图像上的被摄体是否是预定的待识别 对象的处理对象；特征点特征量提取单元，被构造为从所述待处理图像提取表示所述特征 点的特征的特征点特征量；整体特征量计算单元，被构造为基于共享码本从所述待处理图 像的特征点特征量计算表示所述待处理图像的整体特征的整体特征量，所述共享码本包括 共同用于产生用于识别不同的待识别对象的每一个的识别器的产生用特征量；以及识别单 元，被构造为基于用于识别存在于图像上的被摄体是否是预定的待识别对象的识别器和所 述整体特征量识别存在于所述待处理图像上的被摄体是否是预定的待识别对象。</p>
    <p>[0029]	基于根据第二实施例的识别装置，还设置有：共享码本存储单元，被构造为存储共 享码本，所述共享码本包括：码本，按照与用于标识所述产生用特征量的标识符相关的方式 保持多个所述产生用特征量的每一个，以及共享信息，是针对用于识别不同的待识别对象 的每一个的每个识别器建立的多个共享信息，并且还包括所述多个产生用特征量中的、在 计算所述整体特征量时使用的所述产生用特征量的所述标识符；其中，所述整体特征量计 算单元使用保持在所述码本中的所述多个产生用特征量中的、与包括在针对由所述标识部 件使用的所述识别器创建的所述共享信息中的所述标识符相关的产生用特征量计算所述 整体特征量。</p>
    <p>[0030]	基于根据第二实施例的识别装置，其中，所述多个共享信息中的预定的共享信息 具有与包括在其它共享信息中的所述标识符相同的标识符。</p>
    <p>[0031]	基于根据第二实施例的识别装置，其中，所述预定的共享信息具有还与从存在所 述预定的待识别对象的模型图像提取的特征点相关的所述标识符；并且其中，所述整体特 征量计算部件使用与所述标识符相关的产生用特征量和存在于所述待处理图像上的整体 范围中的、基于与所述标识符相关的所述特征点确定的范围上的特征点的特征点特征量计 算所述整体特征量。</p>
    <p>[0032]	基于根据第二实施例的识别装置，其中，包括在所述共享信息中的所述标识符与 不同于下列特征点的特征点相关，所述特征点相关于与包括在所述其它共享信息中的所述 标识符相同的标识符。</p>
    <p>[0033]	基于根据第二实施例的识别装置，其中，所述整体特征量计算单元计算表示包括 在所述共享码本中的所述产生用特征量与所述待处理图像的所述特征点特征量之间的相 关的相关值作为所述整体特征量。</p>
    <p>[0034]	基于根据第二实施例的识别装置，其中，所述整体特征量计算单元基于所述共享 码本，从所述待处理图像的特征点特征量计算表示所述待处理图像的整体特征的、由多个 维度特征量组成的整体特征量；并且其中，所述识别单元通过将组成所述整体特征量的所 述多个维度特征量中的预定维度特征量提供给识别存在于图像上的被摄体是否是预定的 待识别对象的识别器作为输入，识别存在于所述待处理图像上的被摄体是否是预定的待识 别对象。</p>
    <p>[0035]	基于根据第二实施例的识别装置，其中，所述识别单元通过将组成所述整体特征 量的所述多个维度特征量中的、维度信息所表示的维度的维度特征量提供给用于识别存在 于图像上的被摄体是否是预定的待识别对象的识别器作为输入，从而识别在所述图像上出 现的被摄体是否是预定的待识别对象；并且其中，所述识别器使用表示所述整体特征量的所述多个维度特征量中的、减小误差值的所述维度特征量执行识别，所述误差值表示对于 是所述待识别对象存在于图像上的正像还是所述待识别对象不存在于图像上的负像的识 别错误的程度；并且其中，所述维度信息表示减小所述误差值的所述维度特征量的维度。</p>
    <p>[0036]	根据本发明第二实施例的识别方法是一种识别在图像上出现的被摄体是否是预 定的待识别对象的识别装置的识别方法，所述识别装置包括：特征点提取单元，特征点特征 量提取单元，整体特征量计算单元，以及识别单元，所述识别方法包括如下步骤：通过所述 特征点提取单元，从作为用于识别存在于图像上的被摄体是否是预定的待识别对象的处理 对象的待处理图像提取特征点；通过所述特征点特征量提取单元，从所述待处理图像提取 表示所述特征点的特征的特征点特征量；通过所述整体特征量计算单元，基于共享码本从 所述待处理图像的特征点特征量计算表示所述待处理图像的整体特征的整体特征量，所述 共享码本包括共同用于产生用于识别不同的待识别对象的每一个的识别器的产生用特征 量；以及通过所述识别单元，基于用于识别存在于图像上的被摄体是否是预定的待识别对 象的识别器和所述整体特征量来识别存在于所述待处理图像上的被摄体是否是预定的待 识别对象。</p>
    <p>[0037]	根据本发明第二实施例的第二程序是一种使得计算机充当以下单元的程序：特征 点提取单元，被构造为从待处理图像提取特征点，所述待处理图像作为用于识别存在于图 像上的被摄体是否是预定的待识别对象的处理对象；特征点特征量提取单元，被构造为从 所述待处理图像提取表示所述特征点的特征的特征点特征量；整体特征量计算单元，被构 造为基于共享码本从所述待处理图像的特征点特征量计算表示所述待处理图像的整体特 征的整体特征量，所述共享码本包括共同用于产生用于识别不同的待识别对象的每一个的 识别器的产生用特征量；以及识别单元，被构造为基于用于识别存在于图像上的被摄体是 否是预定的待识别对象的识别器和所述整体特征量识别存在于所述待处理图像上的被摄 体是否是预定的待识别对象。</p>
    <p>[0038]	根据本发明的第二实施例，从待处理图像提取特征点，所述待处理图像作为用于 识别存在于图像上的被摄体是否是预定的待识别对象的处理对象；从所述待处理图像提取 表示所述特征点的特征的特征点特征量；基于共享码本从所述待处理图像的特征点特征量 计算表示所述待处理图像的整体特征的整体特征量，所述共享码本包括共同用于产生用于 识别不同的待识别对象的每一个的识别器的产生用特征量；以及基于用于识别存在于图像 上的被摄体是否是预定的待识别对象的识别器和所述整体特征量，识别存在于所述待处理 图像上的被摄体是否是预定的待识别对象。</p>
    <p>[0039]	根据本发明，在识别存在于图像上的被摄体是否是预定的待识别对象的情况下， 能够以更加准确的方式检测待识别对象并且抑制用于识别的特征量的增加。</p>
    <p>附图说明</p>
    <p>[0040]	图1是示出应用本发明的实施例的学习装置的第一结构例子的框图；</p>
    <p>[0041]	图2是示出共享码本产生单元的结构例子的框图；</p>
    <p>[0042]	图3是用于描述由特征量置换单元和量化单元执行的处理的例子的图；</p>
    <p>[0043]	图4是示出了共享码本的例子的图；</p>
    <p>[0044]	图5A到5C是描述由量化单元执行的处理的例子的图；[0045]	图6是描述由图1中的整体特征量计算单元执行的处理的例子的图；</p>
    <p>[0046]	图7是描述识别器产生方法的例子的图；</p>
    <p>[0047]	图8是描述由图1中的学习装置执行的学习处理的流程图；</p>
    <p>[0048]	图9是描述共享码本产生处理的流程图；</p>
    <p>[0049]	图10是描述码本产生处理的流程图；</p>
    <p>[0050]	图11是描述识别器产生处理的流程图；</p>
    <p>[0051]	图12是示出使用通过图1中的学习装置的学习产生的识别器识别待识别对象的 第一识别装置的结构例子的框图；</p>
    <p>[0052]	图13是描述由图12中的识别装置执行的识别处理的流程图；</p>
    <p>[0053]	图14是示出应用本发明的实施例的学习装置的第二结构例子的框图；</p>
    <p>[0054]	图15是描述由范围确定单元执行的处理的例子的图；</p>
    <p>[0055]	图16是描述由图14中的整体特征量计算单元执行的处理的例子的图；</p>
    <p>[0056]	图17是描述由图14中的学习装置执行的学习处理的流程图；</p>
    <p>[0057]	图18是描述范围确定处理的流程图；</p>
    <p>[0058]	图19是示出使用由图14中的学习装置的学习产生的识别器识别待识别对象的第 二识别装置的结构例子的框图；</p>
    <p>[0059]	图20是描述通过图19中的识别器执行的识别处理的流程图；以及</p>
    <p>[0060]	图21是示出计算机的结构例子的框图。</p>
    <p>具体实施方式</p>
    <p>[0061]	将在下文中描述用于执行本发明的实施方式（下文称作实施例）。</p>
    <p>[0062]	注意：将按照下面顺序进行描述。</p>
    <p>[0063]	1.第一实施例（不同的待识别对象共同使用特征点特征量的例子）</p>
    <p>[0064]	2.第二实施例（针对每个待识别对象使用不同范围的例子）</p>
    <p>[0065]	3.变型</p>
    <p>[0066]	第一实施例</p>
    <p>[0067]	学习装置1的结构例子</p>
    <p>[0068]	图1示出了应用本发明的第一实施例的学习装置1的结构例子。</p>
    <p>[0069]	这个学习装置1使用学习用图像产生用于识别存在于图像上的被摄体是否是预 定的待识别对象的识别器（函数），和产生后述的维度信息。</p>
    <p>[0070]	这里，学习用图像是用于产生（学习）识别器的图像，包括多个模型图像、多个原 始图像和多个产生用图像。</p>
    <p>[0071]	模型图像是存在可作为待识别对象（例如，笔记型个人计算机（笔记本计算机）、 汽车、等等）的被摄体的图像。另外，原始图像是包括不依赖于特定的待识别对象的多个特 征量的图像，即与特定的待识别对象的特征量无关地、用于提取各种类型的特征量的图像。</p>
    <p>[0072]	关于原始图像的例子，采用存在人工对象或例如风景的自然对象的图像。</p>
    <p>[0073]	另外，产生用图像既包括正像又包括负像，在正像上存在待识别对象（例如，笔记 本计算机），在负像上不存在待识别对象。</p>
    <p>[0074]	另外，对产生用图像添加有正确答案标签。这个正确答案标签存在于每个产生用图像，表示每个产生用图像是正像还是负像。</p>
    <p>[0075]	具体地讲，这个学习装置1产生共享码本，其中，从多个原始图像提取的特征量被 共享作为能够作为待识别对象的被摄体（例如，笔记本计算机、汽车、等等）的特征量。</p>
    <p>[0076]	接下来，学习装置1使用产生的共享码本产生用于识别存在于图像上的被摄体是 否是预定的待识别对象（例如，汽车）的识别器和对应的维度信息。</p>
    <p>[0077]	学习装置1被构造为包括输入单元21、共享码本产生单元22、共享码本存储单元 23、特征点提取单元M、特征量提取单元25、整体特征量计算单元沈和识别器产生单元27。</p>
    <p>[0078]	多个模型图像、多个原始图像和多个产生用图像被提供给输入单元21作为学习 用图像。输入单元21将提供的多个模型图像和多个原始图像输入（提供）给共享码本产 生单元22。</p>
    <p>[0079]	另外，输入单元21将提供的多个产生用图像输入到特征点提取单元24。</p>
    <p>[0080]	共享码本产生单元22基于来自输入单元21的多个模型图像和多个原始图像产生 共享码本（在该共享码本中共享能够作为待识别对象的被摄体的特征量），并且将它提供 并存储到共享码本存储单元23。</p>
    <p>[0081]	注意：将在以后参照图2描述共享码本产生单元22的细节。</p>
    <p>[0082]	共享码本存储单元23存储来自共享码本产生单元22的共享码本。</p>
    <p>[0083]	特征点提取单元M从输入单元21顺序选择多个产生用图像的每一个作为关注的 产生用图像，并且从关注的产生用图像提取特征点。接下来，特征点提取单元M将提取的 特征点和关注的产生用图像一起提供给特征量提取单元25。</p>
    <p>[0084]	这里，由于图像的局部信息通常包括在角点（corner point)中，所以特征点提取 单元M提取角点（用作角点的像素）作为特征点。</p>
    <p>[0085]	可以使用哈里斯角探测器执行角点的提取。通过哈里斯角探测器，如果我们假设 某位置（χ，y)的像素的像素值（例如，亮度）表示为I (χ，y)，则通过下面表达式（1)获得 的亮度梯度的二阶矩L的两个本征值等于或大于预定阈值的像素被检测为角点。</p>
    <p>[0086]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00131.png"> <img id="idf0001" file="CN102147868AD00131.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00131.png" class="patent-full-image" alt="Figure CN102147868AD00131"> </a> </div>
    <p>[0087]	注意：在表达式（1)中，通过省去（X，y)将像素值I (X，y)表示为I。</p>
    <p>[0088]	另外，通过特征点提取单元M，除了角点以外，例如还可以采用作为边缘的像素、 预定的固定位置处的像素等等作为特征点。</p>
    <p>[0089]	特征量提取单元25从来自特征点提取单元M的关注的产生用图像提取表示来自 特征点提取单元M的特征点的特征的特征点特征量，并且将它提供给整体特征量计算单 元26。另外，特征量提取单元25提取添加到来自特征点提取单元M的关注的产生用图像 的正确答案标签，并且将它提供给整体特征量计算单元26。</p>
    <p>[0090]	整体特征量计算单元沈基于存储在共享码本存储单元23中的共享码本从来自特 征量提取单元25的特征点特征量计算表示关注的产生用图像的整体特征的整体特征量。</p>
    <p>[0091]	这里，例如，通过多个维度矢量（包括多个值作为一个要素的矢量）表示整体特征量。</p>
    <p>[0092]	整体特征量计算单元沈将计算的关注的产生用图像的整体特征量和来自特征量 提取单元25的关注的产生用图像的正确答案标签一起提供给识别器产生单元27。</p>
    <p>[0093]	响应于来自整体特征量计算单元沈的关于多个产生用图像的每一个的对应整体 特征量和正确答案标签，识别器产生单元27使用多个产生用图像的每一个的整体特征量 以及多个产生用图像的每一个的正确答案标签产生识别器（执行学习以计算规定识别器 的参数）。</p>
    <p>[0094]	这里，如果我们假设采用用作整体特征量的多个维度矢量的要素作为维度特征 量，则整体特征量由多个（数目等于矢量的维度）维度特征量组成。</p>
    <p>[0095]	识别器产生单元27产生不使用组成整体特征量的全部维度特征量而使用从组成 整体特征量的维度特征量中选择的维度特征量的一部分进行识别的识别器。</p>
    <p>[0096]	另外，识别器产生单元27产生表示用于由这个识别器进行识别的维度特征量的维 度的信息（表示维度特征量是用作整体特征量的矢量的多少要素的信息）作为维度信息。</p>
    <p>[0097]	共享码本产生单元22的结构例子</p>
    <p>[0098]	图2示出了共享码本产生单元22的详细结构例子。</p>
    <p>[0099]	这个共享码本产生单元22被构造为包括特征点提取单元41、特征量提取单元42、 码本产生单元43、码本存储单元44、特征点提取单元45、特征量提取单元46、特征量置换单 元47和量化单元48。</p>
    <p>[0100]	多个原始图像从输入单元21输入到特征点提取单元41。特征点提取单元41顺序 采用来自输入单元21的多个原始图像的每一个作为关注的原始图像。接下来，特征点提取 单元41从关注的原始图像提取特征点，并且将它与关注的原始图像一起提供给特征量提 取单元42。</p>
    <p>[0101]	特征量提取单元42相似地从来自特征点提取单元41的关注的原始图像提取表示 来自特征点提取单元41的特征点的特征的特征点特征量以将它提供给码本产生单元43。</p>
    <p>[0102]	具体地讲，特征量提取单元42将从在特征点提取单元41选择作为关注的原始图 像的多个原始图像的每一个提取的多个特征点特征量提供给码本产生单元43。</p>
    <p>[0103]	码本产生单元43例如通过在特征量空间中执行例如K-means方法的群集方法将 从特征量提取单元42提供的多个特征点特征量分组成多组。接下来，码本产生单元43对 于通过分组获得的每一个多组确定属于该多组的特征点特征量的重心作为表示该多组的 特征点特征量。</p>
    <p>[0104]	码本产生单元43将对于每一个多组确定的特征点特征量与用于唯一识别该特征</p>
    <p>点特征量的标识符Cbn(n= 1、2.....N)进行相关。另外，码本产生单元43产生包括与标</p>
    <p>识符Cbn相关的特征点特征量的码本以将它提供并存储到码本存储单元44。</p>
    <p>[0105]	码本存储单元44存储该码本，在该码本中，标识符Cbn与由标识符Cbn识别的特 征点特征量相关。</p>
    <p>[0106]	多个模型图像从输入单元21输入到特征点提取单元45。特征点提取单元45根据 存在于模型图像上的被摄体的类别将从输入单元21输入的多个模型图像分组成多组。注 意：模型图像包括表示存在于图像上的被摄体的类别的类别信息，特征点提取单元45被设 置为基于包括在模型图像中的类别信息执行分组。[0107]	接下来，特征点提取单元45顺序选择根据类别进行分组的多组的每一个作为关 注的组。</p>
    <p>[0108]	另外，特征点提取单元45顺序选择包括在关注的组中的多个图像的每一个作为 关注的模型图像。接下来，特征点提取单元45从关注的模型图像提取特征点以将它与关注 的模型图像一起提供给特征量提取单元46。</p>
    <p>[0109]	特征量提取单元46类似地从来自特征点提取单元45的关注的模型图像提取表示 来自特征点提取单元45的特征点的特征的特征点特征量。接下来，特征量提取单元46将 来自特征点提取单元45的特征点与提取的特征点特征量进行相关。</p>
    <p>[0110]	因此，特征量提取单元46获得包括在从包括在关注的组中的多个模型图像的每 一个提取的多个特征点特征量中的、包括与对应特征点相关的特征点特征量的初始特征量 池。</p>
    <p>[0111]	特征量提取单元46将获得的初始特征量池提供给特征量置换单元47。</p>
    <p>[0112]	特征量置换单元47将包括在来自特征量提取单元46的初始特征量池中的特征点 特征量与包括在存储在码本存储单元44中的码本中的标识符Cbn进行置换。</p>
    <p>[0113]	具体地讲，例如，特征量置换单元47从码本存储单元44读取码本。接下来，特征 量置换单元47将包括来自特征量提取单元46的初始特征量池的特征点特征量与用于识别 包括读取的码本的多个特征点特征量的最相似的特征点特征量的标识符Cbn进行置换。</p>
    <p>[0114]	这样，特征量置换单元47将包括在来自特征量提取单元46的初始特征量池中的 多个特征点特征量的每一个与包括在存储在码本存储单元44中的码本中的标识符Cbn进 行置换。</p>
    <p>[0115]	因此，特征量置换单元47从包括与特征点相关的特征点特征量的初始特征量池 产生包括与特征点相关的标识符Cbn的特征量池。特征量置换单元47将产生的特征量池 提供给量化单元48。</p>
    <p>[0116]	另外，特征量置换单元47将从码本存储单元44读出的码本提供给量化单元48。</p>
    <p>[0117]	量化单元48将包括在来自特征量置换单元47的特征池中的与标识符Cbn相关的 特征点进行量化以获得作为其量化结果获得的量化的特征量池。</p>
    <p>[0118]	另外，量化单元48获得通过对包括在获得的量化的特征量池中的标识符Cbn中的 相同标识符Cbn进行分组而获得的共享信息。</p>
    <p>[0119]	接下来，量化单元48将根据类别获得的共享信息与来自特征量置换单元47的码 本的组合提供并存储到共享码本存储单元23作为共享码本。</p>
    <p>[0120]	由特征量置换单元47和量化单元48执行的处理的例子</p>
    <p>[0121]	接下来，图3示出了由特征量置换单元47和量化单元48执行的处理的例子。</p>
    <p>[0122]	注意：图3所示的码本61是存储在码本存储单元44中的码本，包括标识符Cbn和 由标识符Cbn进行识别的特征点特征量fVec。</p>
    <p>[0123]	特征量置换单元47从码本存储单元44读出码本61。另外，特征量置换单元47从 由特征量提取单元46提供的、包括预定类别的多个特征点特征量的初始特征量池62 (以十 字表示）提取预定的特征点特征量，从而顺序选择它作为关注的特征点特征量fVec'。</p>
    <p>[0124]	接下来，特征量置换单元47将关注的特征点特征量fvec'与包括在读取的码本 61中的标识符Cbn进行置换。具体地讲，例如，特征量置换单元47将关注的特征点特征量fvec'与用于识别包括在读取的码本61中的多个特征点特征量的与关注的特征点特征量 fvec'最相似的特征点特征量fVec的标识符Cbn进行置换。</p>
    <p>[0125]	特征量置换单元47通过选择包括在初始特征量池62中的所有的多个特征点特征 量作为关注的特征点特征量fVec'，将包括在初始特征量池62中的所有的多个特征点特 征量与标识符Cbn进行置换。</p>
    <p>[0126]	因此，特征量置换单元47将关注的特征点特征量fvec'与对应的特征点（X，y) 相关的初始特征量池62转换成标识符Cbn与对应于关注的特征点特征量fVec'的特征点 (x，y)相关的特征量池63。</p>
    <p>[0127]	特征量置换单元47将转换的特征量池63和从码本存储单元44读出的码本61 &#8212; 起提供给量化单元48。</p>
    <p>[0128]	量化单元48执行量化以将包括在来自特征量置换单元47的特征量池63中的若 干特征点转换成一个特征点，并且获得作为结果而获得的量化的特征量池64。注意：将在 以后参照图4详细描述由量化单元48执行的量化。</p>
    <p>[0129]	另外，量化单元48对包括在获得的量化的特征量池64中的标识符Cbn中的相同 标识符Cbn进行分组，并且将这样获得的共享信息65提供并存储到共享码本存储单元23。</p>
    <p>[0130]	具体地讲，例如，量化单元48对与包括在量化的特征量池64中的标识符Cbn中的 相同标识符Cbn相关的特征点进行分组，从而针对每个标识符Cbn产生与一个或多个特征 点相关的共享信息65。</p>
    <p>[0131]	接下来，量化单元48将产生的共享信息65与来自特征量置换单元47的码本61 之间的组合提供并存储到共享码本存储单元23作为共享码本81。</p>
    <p>[0132]	注意：针对多个类别的每一个基于该类别的初始特征量池62产生共享信息65。因 此，由针对多个类别的每一个产生的共享信息6&#190;和码本61构成的共享码本81存储在共 享码本存储单元23中。</p>
    <p>[0133]	另外，如上所述，量化单元48被设置为通过对包括在量化的特征量池64中的标识 符Cbn中的相同标识符Cbn进行分组获得共享信息65，但是不限于此。</p>
    <p>[0134]	具体地讲，例如，量化单元48能够通过对不是包括在量化的特征量池64中而是包 括在特征量池63中的标识符Cbn中的相同标识符Cbn进行分组获得共享信息65，而不对来 自特征量置换单元47的特征量池63进行量化。</p>
    <p>[0135]	共享码本的例子</p>
    <p>[0136]	接下来，图4示出了存储在由共享码本产生单元22产生并存储在共享码本存储单 元23中的共享码本81中的共享码本81的例子。</p>
    <p>[0137]	图4所示的共享码本81由笔记本个人计算机所属的类别A中的共享信息65i和 汽车所属的类别B中的共享信息6&#190;组成。</p>
    <p>[0138]	共享信息65i是基于包括类别A中的多个特征点特征量的初始特征量池62产生 的共享信息。</p>
    <p>[0139]	利用共享信息651;标识符Cb2与特征点（Xl，Y1)和（X2，y2)相关。另外，通过共享 信息651;标识符Cb3tl与特征点（x3，y3)相关。</p>
    <p>[0140]	共享信息6&#190;是基于包括类别B中的多个特征点特征量的初始特征量池62产生 的共享信息。[0141]	通过共享信息652，标识符Cb3tl与特征点（x4，y4)和（x5，y5)相关。另外，通过共享 信息652，标识符Cb45与特征点Oc6，y6)和(x7, y7)相关。</p>
    <p>[0142]	具体地讲，通过特征点特征量fvec与用于识别特征点特征量fVec的标识符Cb3tl 之间的组合61a，组合61a的标识符Cb3tl与类别A中的特征点（x3，y3)和类别B中的特征点 (χ4，y4)禾口（χ5' y5)相关°</p>
    <p>[0143]	因此，在识别类别A的情况和识别类别B的情况的任一情况下，共同采用由标识符 Cb30识别的特征点特征量fvec。</p>
    <p>[0144]	另外，例如，从类别A中的模型图像提取的特征点与从类别B中的模型图像提取的 特征点通常不同。因此，类别A中与标识符Cb3tl相关的特征点（X3，y3)和类别B中与标识 符Cb3tl相关的特征点（x4，y4)和（x5，y5)不同。</p>
    <p>[0145]	因此，在识别类别A的情况下以及在识别类别B的情况下，采用不同的特征点。</p>
    <p>[0146]	由量化单元48执行的量化的例子</p>
    <p>[0147]	接下来，将参照图5A到5C详细描述由量化单元48执行的量化。</p>
    <p>[0148]	图5A到5C是详细描述由量化单元48执行的量化的图。</p>
    <p>[0149]	图5A示出了例如四个模型图像，在这些模型图像上存在作为被摄体的笔记本个 人计算机。注意：通过图5A所示的四个模型图像，例如示出了角点（十字所示）作为特征</p>
    <p>点ο</p>
    <p>[0150]	图5B示出了由作为图5A所示的四个模型图像中的亮度值存在的、具有特征点的 频率（程度）的像素构成的特征点频率图像101。</p>
    <p>[0151]	图5C示出了一个场景的例子，其中，图5B所示的特征点频率图像101中亮度值大 于周围像素的亮度值的像素被选择为特征点（十字所示）。</p>
    <p>[0152]	量化单元48顺序选择包括在来自特征量置换单元47的特征量池63中的特征点， 即例如图5A所示的模型图像的每一个的角点（十字所示）的每一个作为关注的特征点。</p>
    <p>[0153]	另外，通过量化单元48，制备了尺寸与图5A所示的模型图像相同并且每个像素的 亮度值为零的特征点频率图像101。</p>
    <p>[0154]	接下来，在组成制备的特征点频率图像101的多个像素中，量化单元48对与关注 的特征点对应的像素以及围绕该像素的像素的亮度值投票（添加）与高斯权重（遵照高斯 分布的权重）对应的值。</p>
    <p>[0155]	因此，通过特征点频率图像101，1被投票给与关注的特征点对应的像素的亮度 值，并且随着与关注的特征点对应的像素与位于与关注的特征点对应的像素的位置分离的 位置的像素之间的距离变长，较小的值被投票给与关注的特征点对应的像素的位置分离的 位置的像素。</p>
    <p>[0156]	量化单元48通过选择包括在特征量池63中的所有的特征点作为关注的特征点执 行投票，从而产生特征点频率图像101，其中特征点根据特征点所在的频率具有不同亮度。</p>
    <p>[0157]	接下来，量化单元48执行非最大化抑制处理，其中，与亮度值大于周围像素的亮 度值的像素对应的特征点被提取作为关于产生的特征点频率图像101的代表性特征点。</p>
    <p>[0158]	具体地讲，例如，量化单元48从组成特征点频率图像101的像素的亮度值中，提取 具有最大亮度值的像素的位置作为代表性特征点。接下来，量化单元48从处理对象排除包 括提取的代表性特征点在内的围绕该代表性特征点的区域以提取新的代表性特征点。[0159]	接下来，量化单元48在从处理对象排除围绕提取的代表性特征点的区域以后的 组成特征点频率图像101的像素的亮度值中，提取具有最大亮度值的像素的位置作为代表 性特征点。接下来，量化单元48从处理对象排除包括提取的代表性特征点在内的围绕该代 表性特征点的区域，然后重复相同的处理。</p>
    <p>[0160]	这样，在从如图5C所示的特征点频率图像101提取预定的代表性特征点（十字所 示）的情况下，量化单元48终止非最大化抑制处理。</p>
    <p>[0161]	量化单元48将包括在特征量池63中的特征点量化成通过非最大化抑制处理提取 的多个代表性特征点之一。</p>
    <p>[0162]	具体地讲，例如，量化单元48顺序选择包括在特征量池63中的特征点作为关注的 特征点。接下来，量化单元48执行量化以将关注的特征点转换成多个代表性特征点中的位 于最靠近关注的特征点的位置的代表性特征点。</p>
    <p>[0163]	量化单元48将包括在特征量池63中的所有特征点量化成多个代表性特征点之 一，并且获得通过这种量化获得的量化的特征量池64。</p>
    <p>[0164]	接下来，如上所述，量化单元48对包括在量化的特征量池64中的相同标识符Cbn 之间的多个标识符Cbn进行分组。另外，量化单元48将通过进行分组获得的共享信息65 与来自特征量置换单元47的码本61之间的组合提供并存储到共享码本存储单元23作为 共享码本81。</p>
    <p>[0165]	相关值的计算的例子</p>
    <p>[0166]	接下来，将参照图6描述由整体特征量计算单元沈执行的计算整体特征量的处理 的例子。</p>
    <p>[0167]	在图6中，例如，关于用于产生识别器的整体特征量和用于识别待识别对象是否 属于汽车的类别B的维度信息，将描述用于计算相关值的整体特征量计算单元26。</p>
    <p>[0168]	具体地讲，图6示出了整体特征量计算单元沈使用汽车的类别B的共享信息652 和存储在共享码本存储单元23中的共享码本81中的码本61计算产生用图像的整体特征 量的情况下的例子。</p>
    <p>[0169]	图6的上侧示出了包括在码本61 (包括在共享码本81中）中的多个特征点特征 量中的、分别与包括在共享信息6&#190;中的标识符Cbn对应的特征点特征量Ul1到1211(|。</p>
    <p>[0170]	另外，图6的下侧示出了已经在特征点提取单元M提取特征点以及已经在特征量 提取单元25计算特征量的产生用图像141到145。</p>
    <p>[0171]	整体特征量计算单元沈计算与包括在共享信息652 (包括在共享码本81中）中的 标识符Cbn的每一个对应的特征点特征量Ul1到1211(1的每一个与产生用图像141到145 的每一个之间的相关值作为整体特征量。</p>
    <p>[0172]	具体地讲，例如，整体特征量计算单元沈把基于与组成产生用图像141的整个区 域的特征点特征量121n(n是从1到10的自然数）对应的特征点的预定区域（例如，把与 特征点特征量121η的特征点对应的位置作为中心的矩形区域）作为检索范围。</p>
    <p>[0173]	整体特征量计算单元沈计算特征点特征量121η与存在于产生用图像141的检索 范围上的每个特征点的特征点特征量之间的相关值，并且把这样计算获得的多个相关值中 的最大相关值作为特征点特征量121η与产生用图像141之间的最终相关值161η。</p>
    <p>[0174]	整体特征量计算单元沈针对产生用图像141计算关于特征点特征量Ul1到1211(|</p>
    <p>18的相关值Iei1到1611(|，并且采取以计算的相关值Iei1到iei1(l为要素的矢量作为产生用图 像141的整体特征量。</p>
    <p>[0175]	按照与计算产生用图像141的整体特征量的情况相同的方式，整体特征量计算单 元沈计算产生用图像142到145的每一个的整体特征量。</p>
    <p>[0176]	整体特征量计算单元沈将多个产生用图像141到145的每一个的整体特征量提 供给识别器产生单元27。</p>
    <p>[0177]	识别器产生单元27执行的处理</p>
    <p>[0178]	接下来，图7示出了由识别器产生单元27执行的处理的概要。</p>
    <p>[0179]	识别器产生单元27根据例如Boosting算法以在组成来自整体特征量计算单元沈 的整体特征量的维度特征量之中选择用于识别的维度特征量（的维度），并且使用该维度 特征量产生用于执行识别的识别器。</p>
    <p>[0180]	具体地讲，识别器产生单元27在组成来自整体特征量计算单元沈（图1)的整体 特征量的多个维度特征量（矢量的要素）之中，利用减小表示正像与负像之间的识别错误 的程度的误差值的维度特征量来产生用于执行识别的识别器和表示减小误差值的维度特 征量的维度的维度信息。</p>
    <p>[0181]	具体地讲，现在，我们假设存在多个（N个）图像作为产生用图像，并且在整体特 征量计算单元26，如图7所示，获得了用作N个产生用图像的N个采样的整体特征量Xl、 X”.......Xn的矢量。</p>
    <p>[0182]	另外，如图7所示，假定整体特征量&amp;(1 = 1、2.........N)是具有多个（M个）</p>
    <p>要素（维度特征量）XipXi2........Xi,M的M维矢量。</p>
    <p>[0183]	另外，如图1所述，正确答案标签从整体特征量计算单元沈提供给识别器产生单 元27，但是这里，第i个采样Xi(第i个产生用图像）的正确答案标签被表示为yi。假定在 第i个产生用图像是正像的情况下，正确答案标签Yi是+1，并且假定在第i个产生用图像 是负像的情况下，正确答案标签Yi是_1。</p>
    <p>[0184]	识别器产生单元27产生的识别器是使用组成整体特征量Xi的M个维度特征量Xi, ！到Xi,M中的、减小表示正像与负像之间的识别错误的程度的误差值的维度特征量Xi,d执行 识别的函数，并且由多个弱学习器ht,d(Xi,d)构成。</p>
    <p>[0185]	这里，弱学习器ht,d(Xi,d)的下标t是用于对弱学习器ht,d(Xi,d)的数目进行计数 的变量，并且识别器由多个（T个）弱学习器比，力^化，力^)........hT,d(Xi,d)构成。</p>
    <p>[0186]	关于弱学习器ht,d(Xi,d)的数目T，例如通过实验设置等于或小于M的值或者使得 由识别器识别的识别率变成一定值。</p>
    <p>[0187]	弱学习器ht,d(Xi,d)是输出识别结果的函数，即以产生用图像的整体特征量Xi的第 d个维度特征量Xi,d (用作整体特征量Xi的矢量的第d个要素）为输入来识别产生用图像是 正像还是负像，并且分别例如输出+1作为识别结果以表示产生用图像是正像以及输出-1 作为识别结果以表示产生用图像是负像。</p>
    <p>[0188]	现在，如果弱学习器ht,d(Xi,d)的识别结果的误差值表示为ε t,d，则识别器产生单 元27确定弱学习器ht,d(Xi,d)以使得误差值&#163;t,d变小。</p>
    <p>[0189]	注意：为了简化说明，作为弱学习器ht,d(Xi,d)，这里假定采用一个函数，其中，例 如，在作为自变量的第d个维度特征量Xi, d等于或大于预定阈值的情况下，输出+1，这表示产生用图像是正像的识别结果，在作为自变量的第d个维度特征量d小于预定阈值的情 况下，输出-1，这表示产生用图像是负像的识别结果。</p>
    <p>[0190]	在这种情况下，确定弱学习器ht,d(Xi,d)以使得误差值ε t,d变小是指确定弱学习</p>
    <p>器ht,d(Xi,d)的阈值。在能够用作自变量的N个第d个维度特征量Xl,d、X2,d........之</p>
    <p>中，最小值与最大值之间的值被确定为弱学习器ht, d (Xi, d)的阈值。</p>
    <p>[0191]	识别器产生单元27确定弱学习器K1 (xia)、ht,2(Xi,2)........htjM(xijM)的每一个</p>
    <p>以减小误差值ε"、et,2........ ε t, M的每一个，并且获得维度d(t)，由此能够获得误差</p>
    <p>值ε u到ε t,d的最小值（下文中，称作“最小误差维度”）。</p>
    <p>[0192]	另外，识别器产生单元27获得权重Dt (i)以使得产生用图像的识别结果的误差根 据通过弱学习器ht,d(Xi,d)产生的第i个图像以后的识别结果是否与正确答案标签71匹配 (即表达式ht,d(Xi,d) =71还是1^,(10^(1) ^yi)影响每个产生用图像的误差值et,d。</p>
    <p>[0193]	这里，通过把N个产生用图像中的通过弱学习器ht,d(Xi,d)进行的识别结果产生误 差的产生用图像的权重Dt (i)相加来获得误差值&#163;t,d。</p>
    <p>[0194]	识别器产生单元27重复确定弱学习器ht,d(Xi,d)以减小误差值ε t,d，获得维度（最 小误差维度）d(t)，从而通过弱学习器ht,d(Xi,d)获得产生用图像的识别结果的误差值ε u 到ε t, Μ的最小值，并且T次获得用于计算误差值ε t,d的权重Dt (i)，由此产生由T个弱学</p>
    <p>习器Uxiid^h2id(Xiid)........hTjd(xijd)组成的识别器H(x)和表示最小误差维度d(l)、</p>
    <p>d(2)........d(T)的维度信息。</p>
    <p>[0195]	学习装置1的操作说明</p>
    <p>[0196]	接下来，将参照图8中的流程图描述由学习装置1执行的学习处理（下文称作“第 一学习处理”）。</p>
    <p>[0197]	当用于学习的图像被提供给输入单元21时，开始该第一学习处理。此时，在产生 用图像、原始图像和模型图像（即，待提供的学习的图像）之中，输入单元21将原始图像和 模型图像提供给共享码本产生单元22，并且将产生用图像提供给特征点提取单元M。</p>
    <p>[0198]	在步骤Sl中，共享码本产生单元22执行共享码本产生处理，以基于来自输入单元 21的原始图像和模型图像产生共享码本81以将它存储在共享码本存储单元23中。注意： 将在以后参照图9中的流程图详细描述共享码本产生处理。</p>
    <p>[0199]	在步骤S2中，特征点提取单元M从输入单元21顺序获取多个产生用图像的每一 个作为关注的产生用图像。</p>
    <p>[0200]	在步骤S3中，特征点提取单元M从关注的产生用图像提取特征点以将它和关注 的产生用图像一起提供给特征量提取单元25。</p>
    <p>[0201]	在步骤S4中，特征量提取单元25类似地从来自特征点提取单元M的关注的产生 用图像提取表示来自特征点提取单元M的特征点的特征的特征点特征量，并且按照与来 自特征点提取单元M的特征点相关的方式将它提供给整体特征量计算单元26。</p>
    <p>[0202]	另外，特征量提取单元25提取添加到来自特征点提取单元M的关注的产生用图 像的正确答案标签，并且将它提供给整体特征量计算单元26。</p>
    <p>[0203]	在步骤S5中，整体特征量计算单元沈基于存储在共享码本存储单元23中的共享 码本81，从来自特征量提取单元25的特征点特征量计算表示关注的产生用图像的整体特 征的整体特征量。[0204]	具体地讲，例如，如参照图6所述，整体特征量计算单元沈基于与包括在包括在共 享码本81中的共享信息65 (例如，在产生用于识别待识别对象是否属于汽车的类别B的识 别器和维度信息的情况下的共享信息652)中的标识符Cbn的每一个相关的特征点特征量 计算关注的产生用图像的整体特征量。</p>
    <p>[0205]	整体特征量计算单元沈将计算的关注的产生用图像的整体特征量与来自特征量 提取单元25的正确答案标签一起提供给识别器产生单元27。</p>
    <p>[0206]	在步骤S6中，特征点提取单元M确定是否已经把来自输入单元21的所有的多个 产生用图像作为关注的产生用图像，并且在确定还没有把来自输入单元21的所有的多个 产生用图像作为关注的产生用图像的情况下，使处理返回到步骤S2。</p>
    <p>[0207]	接下来，在步骤S2中，特征点提取单元M把来自输入单元21的多个产生用图像 中的还没有被作为关注的产生用图像的产生用图像作为新的关注的产生用图像，处理进入 步骤S3，然后执行相同处理。</p>
    <p>[0208]	另外，在步骤S6中确定来自输入单元21的所有的多个产生用图像已经作为关注 的产生用图像的情况下，处理进入步骤S7。</p>
    <p>[0209]	在步骤S7中，响应于从整体特征量计算单元沈关于多个产生用图像的每一个提 供对应的整体特征量和正确答案标签，识别器产生单元27使用多个产生用图像的每一个 的整体特征量和多个产生用图像的每一个的正确答案标签执行产生识别器和维度信息的 识别器产生处理。这是第一学习处理的终止。注意：将在以后参照图11中的流程图详细描 述第一学习处理。</p>
    <p>[0210]	共享码本产生处理的细节</p>
    <p>[0211]	接下来，将参照图9中的流程图描述图8中的步骤Sl中的共享码本产生处理的细 节。</p>
    <p>[0212]	在步骤S21中，共享码本产生单元22的特征点提取单元41到码本产生单元43执 行码本产生处理，用于产生从来自输入单元21的多个原始图像提取的特征点特征量与用 于唯一识别该特征点特征量的标识符Cb相关的码本并且将它提供并存储到码本存储单元 44中。注意：将参照图10中的流程图详细描述码本产生处理。</p>
    <p>[0213]	在步骤S22中，特征点提取单元45获得来自输入单元21的多个模型图像之中的 存在属于预定类别的待识别对象（例如，笔记本个人计算机）的模型图像。</p>
    <p>[0214]	在步骤S23中，特征点提取单元45顺序采用在步骤S22的处理中获得的模型图像 的每一个作为关注的模型图像。</p>
    <p>[0215]	在步骤S24中，特征点提取单元45从关注的模型图像提取特征点，并且将它与关 注的模型图像一起提供给特征量提取单元46。</p>
    <p>[0216]	在步骤S25中，特征量提取单元46类似地从来自特征点提取单元45的关注的模 型图像提取表示来自特征点提取单元45的特征点的特征的特征点特征量。接下来，特征量 提取单元46将提取的特征点特征量与来自特征点提取单元45的特征点进行相关。</p>
    <p>[0217]	在步骤S26中，特征点提取单元45确定在步骤S22的处理中获得的所有的模型图 像是否都已经被作为关注的模型图像，并且在还没有把在步骤S22的处理中获得的所有的 模型图像作为关注的模型图像的情况下，使处理返回到步骤S23。</p>
    <p>[0218]	接下来，在步骤S23中，特征点提取单元45把在步骤S22的处理中获得的模型图像中还没有被作为关注的模型图像的模型图像作为新的关注的模型图像，处理进入步骤 S24，然后执行相同处理。</p>
    <p>[0219]	另外，在步骤S26中确定已经把在步骤S22的处理中获得的所有的模型图像作为 关注的模型图像的情况下，特征点提取单元45相应地通知特征量提取单元46。</p>
    <p>[0220]	响应于来自特征点提取单元45的通知，特征量提取单元46产生包括在步骤S25 的处理中提取的特征点特征量的初始特征量池62，将它提供给特征量置换单元47，处理进 入步骤S27。</p>
    <p>[0221]	在步骤S27中，特征量置换单元47将包括在来自特征量提取单元46的初始特征 量池62中的特征点特征量与包括在存储在码本存储单元44中的码本61中的标识符Cbn 进行置换。</p>
    <p>[0222]	具体地讲，例如，特征量置换单元47从码本存储单元44读出码本61。接下来，特 征量置换单元47将包括在来自特征量提取单元46的初始特征量池62中的特征点特征量 fvec'置换为用于识别包括在读取的码本61中的多个特征点特征量中的、与特征点特征 量fvec'最相似的特征点特征量fVec的标识符Cbn。</p>
    <p>[0223]	这样，特征量置换单元47将包括在来自特征量提取单元46的初始特征量池62中 的多个特征点特征量的每一个置换为包括在存储在码本存储单元44中的码本61中的标识 符 Cbn0</p>
    <p>[0224]	因此，特征量置换单元47产生包括与来自包括与特征点相关的特征点特征量 fvec'的初始特征量池62的该特征点相关的标识符Cbn的特征量池63。特征量置换单元 47将产生的特征量池63提供给量化单元48。</p>
    <p>[0225]	另外，特征量置换单元47将从码本存储单元44读出的码本61提供给量化单元 48。</p>
    <p>[0226]	在步骤S^中，量化单元48对与包括在来自特征量置换单元47的特征量池63中 的标识符Cbn相关的特征点进行量化，并且由此获得量化的特征量池64。</p>
    <p>[0227]	接下来，量化单元48获得共享信息65，该共享信息65是通过对包括在获得的量化 的特征量池64中的标识符Cbn的相同标识符Cbn进行分组获得的。</p>
    <p>[0228]	在步骤S29中，特征点提取单元45确定是否在步骤S22中的处理中已经获得了来 自输入单元21的多个模型图像中的关于所有类别的模型图像，并且在确定还没有获得关 于所有类别的模型图像的情况下，处理返回到步骤S22。</p>
    <p>[0229]	接下来，在步骤S22中，特征点提取单元45获得来自输入单元21的多个模型图像 中的属于还没有被获得的类别（例如，汽车）的待识别对象的模型图像，处理进入步骤S23， 然后执行相同处理。</p>
    <p>[0230]	另外，在步骤幻9中确定已经获得了来自输入单元21的多个模型图像中的关于所 有类别的模型图像的情况下，特征点提取单元45使处理进入步骤S30。</p>
    <p>[0231]	在步骤S30中，量化单元48针对每个类别将在步骤幻8的处理中获得的共享信息 65 (例如，类别A的共享信息65i、类别B的共享信息652、等等）和来自特征量置换单元47 的码本61提供并存储到共享码本存储单元23作为共享码本81，然后将处理返回图8的步 马聚Sl0</p>
    <p>[0232]	码本产生处理的细节[0233]	接下来，将参照图10中的流程图详细描述在图9的步骤S21中由共享码本产生单 元22的特征点提取单元41到码本产生单元43执行的用于产生码本61的码本产生处理。</p>
    <p>[0234]	在步骤S51中，特征点提取单元41顺序采用来自输入单元21的多个原始图像的 每一个作为关注的原始图像。</p>
    <p>[0235]	在步骤S52中，特征点提取单元41从关注的原始图像提取特征点，然后将它与关 注的原始图像一起提供给特征量提取单元42。</p>
    <p>[0236]	在步骤S53中，特征量提取单元42类似地从来自特征点提取单元41的原始图像 提取表示来自特征点提取单元41的特征点的特征的特征点特征量，并且将它提供给码本 产生单元43。</p>
    <p>[0237]	在步骤S54中，特征点提取单元41确定来自输入单元21的所有的多个原始图像 是否都已经作为关注的原始图像，并且在确定还没有把来自输入单元21的所有的多个原 始图像都作为关注的原始图像的情况下，处理返回到步骤S51。</p>
    <p>[0238]	接下来，在步骤S51中，特征点提取单元41把来自输入单元21的多个原始图像中 的还没有被作为关注的原始图像的原始图像作为新的关注的原始图像，处理进入步骤S52， 然后执行相同处理。</p>
    <p>[0239]	另外，在步骤SM中确定来自输入单元21的所有的多个原始图像都已经被作为关 注的原始图像的情况下，特征点提取单元41将处理进入步骤S55。</p>
    <p>[0240]	在步骤S55中，码本产生单元43基于从特征量提取单元42提供的多个特征点特 征量，产生由表示通过对多个特征点特征量进行分组获得的每一组的特征点特征量构成的 码本。</p>
    <p>[0241]	具体地讲，例如，码本产生单元43通过在特征量空间内执行例如K-means方法的 群集方法将从特征量提取单元42提供的多个特征点特征量分组成多个组。</p>
    <p>[0242]	接下来，码本产生单元43针对通过分组获得的多个组的每一个，确定属于这些组 的特征点特征量的重心，作为表示这些组的特征点特征量。</p>
    <p>[0243]	另外，码本产生单元43将针对多个组的每一个确定的特征点特征量与唯一识别 该特征点特征量的标识符Cbn进行相关。另外，码本产生单元43产生包括与标识符Cbn相 关的特征点特征量的码本61，将它提供并存储到码本存储单元44，然后将处理返回到图9 中的步骤S21。识别器产生处理的细节</p>
    <p>[0244]	接下来，将参照图11中的流程图详细描述在图8的步骤S7中由识别器产生单元 27执行的用于产生识别器和维度信息的识别器产生处理。</p>
    <p>[0245]	在步骤S71中，识别器产生单元27例如根据下面的表达式（&#190;设置权重Dt (i)的</p>
    <p>初始值D1(I)A1 (2)........D1(N)以使得产生用图像的识别结果的误差影响表示弱学习器</p>
    <p>ht,d(Xi,d)识别错误的程度的误差值ε t,d，然后处理进入步骤S72。</p>
    <p>[0246]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00231.png"> <img id="idf0002" file="CN102147868AD00231.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00231.png" class="patent-full-image" alt="Figure CN102147868AD00231"> </a> </div>
    <p>[0247]	在步骤S72中，识别器产生单元27将用于对组成识别器H(X)的弱学习器ht,d(Xi, d)的数目进行计数的变量t初始化为1，然后处理进入步骤S73。</p>
    <p>[0248]	在步骤S73中，识别器产生单元27关于整体特征量Xi的维度d = 1、2.......M的</p>
    <p>每一个确定弱学习器ht,d(Xi,d)的阈值THt,d，以使得通过使用权重Dt(i)获得的误差值广变得最小，然后处理进入步骤S74。</p>
    <p>[0249]	这里，在步骤S73中，例如，识别器产生单元27确定弱学习器ht,d(Xi,d)的阈值THt, d，以使得根据下面表达式C3)计算的误差值et,d变得最小。 </p>
    <p>[0250]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00241.png"> <img id="idf0003" file="CN102147868AD00241.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00241.png" class="patent-full-image" alt="Figure CN102147868AD00241"> </a> </div>
    <p>[0251]	在表达式(3)中，[yi^ht,d(Xi,d)]是指示器函数，其中，当表达式[yi^ht,d(Xi, d)]成立时为1，当表达式[Yi兴ht,d(Xi,d)]不成立时为0。</p>
    <p>[0252]	因此，根据表达式（3)，通过仅仅把N个产生用图像中的弱学习器ht,d (Xi,d)的识别 结果发生错误的产生用图像（表达式[Yi^htid(Xiid)]成立的产生用图像）的权重DJi) 相加来获得误差值ε t,d。</p>
    <p>[0253]	在步骤S74中，识别器产生单元27使用在步骤S73中的最后处理中针对维度d = 1、2........M的每一个确定的弱学习器ht,d(Xi,d)获得根据表达式C3)计算的误差值</p>
    <p>et,2........ε t,M中的最小值&#163;t。另外，识别器产生单元27获得维度（最小误差维度）</p>
    <p>d(t)(l到M的范围内的整数值）从而能够获得误差值ε"到et,M的最小值&#163;t，然后处理 进入步骤S75。</p>
    <p>[0254]	这里，最小误差维度d(t)是用于由组成整体特征量的维度特征量的识别器H(x) 进行识别的维度特征量的维度。因此，通过由识别器H(X)进行识别，从组成整体特征量的 维度特征量中选择最小误差维度d(t)的维度特征量，并且将该最小误差维度d(t)的维度 特征量用于进行识别。</p>
    <p>[0255]	另外，如果误差值ε u、et&gt;2........&#163;t,M的最小值ε t是最小误差值&#163;t，则能</p>
    <p>够获得最小误差值ε t的弱学习器ht,d(t) (Xi,d(t))变成组成识别器H(x)的第t个弱学习器。</p>
    <p>[0256]	在步骤S75中，识别器产生单元27使用在步骤S74的最后处理中获得的最小误差 ε t，根据下面表达式⑷获得表示由组成识别器H(X)的第t个弱学习器ht,d(t) (Xi,d(t)) 识别产生用图像的可靠性的可靠性α，然后处理进入步骤S76。</p>
    <p>[0257]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00242.png"> <img id="idf0004" file="CN102147868AD00242.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00242.png" class="patent-full-image" alt="Figure CN102147868AD00242"> </a> </div>
    <p>[0258]	这里，在表达式（4)中，In表示自然对数，并且根据表达式G)，最小误差值ε 1越 大（或越小），获得的可靠性α t的值越小（或越大）。</p>
    <p>[0259]	在步骤S76中，识别器产生单元27根据下面的表达式（&#190;将权重Dt(i)更新为 Dt+1(i)，然后处理进入步骤S77。</p>
    <p>[0260]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00243.png"> <img id="idf0005" file="CN102147868AD00243.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00243.png" class="patent-full-image" alt="Figure CN102147868AD00243"> </a> </div>
    <p>[0261]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00251.png"> <img id="idf0006" file="CN102147868AD00251.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00251.png" class="patent-full-image" alt="Figure CN102147868AD00251"> </a> </div>
    <p>[0262]	这里，在表达式（5)中，系数Zt是用于对权重Dt+1(i)进行标准化的系数，并且由下 面表达式（6)进行表示。</p>
    <p>[0263]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00252.png"> <img id="idf0007" file="CN102147868AD00252.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00252.png" class="patent-full-image" alt="Figure CN102147868AD00252"> </a> </div>
    <p>[0264]	根据表达式（6)，关于弱学习器ht,d(t) (Xi,d(t))的识别结果正确的第i个产生用 图像（即识别结果与正确答案标签Yi匹配的产生用图像），权重Dt (i)更新为具有更小值 的权重Dt+1(i)。其结果是，在接下来的步骤S73中，通过使用权重Dt (i)计算的误差值d变成更小值。</p>
    <p>[0265]	另一方面，关于弱学习器ht,d(t) (Xi,d(t))的识别结果不正确的第i个产生用图像 (即识别结果与正确答案标签Yi不匹配的产生用图像），权重Dt (i)更新为具有更大值的权 重Dt+1(i)。其结果是，在接下来的步骤S73中，通过使用权重Dt (i)计算的误差值et,d变 成更大值。</p>
    <p>[0266]	在步骤S77中，识别器产生单元27确定变量t是否等于组成识别器H(X)的弱学 习器ht,d(Xi,d)的数目T。</p>
    <p>[0267]	在步骤S77中确定变量t不等于弱学习器的数目T的情况下，识别器产生单元27 使处理进入步骤S78，将变量t增加1，使处理从步骤S78返回到步骤S73，然后执行相同的处理。</p>
    <p>[0268]	另外，在步骤S77中确定变量t等于弱学习器的数目T的情况下，即在已经产生组</p>
    <p>成识别器 H(X)的 T 个弱学习器 Kd(I) (Xi,d(l))、h2,d(2) (Xi,d(2))........hT,d(T) (Xi,d(T))</p>
    <p>和T个最小误差维度d(l), d(2)........d(T)的情况下，识别器产生单元27使处理进入步骤S79。</p>
    <p>[0269]	在步骤S79中，识别器产生单元27输出T个弱学习器Kd(I) (Xi,d(l))、h2,d(2) (χ,,</p>
    <p>d(2))........hT,d(T) (xijd(T))和T个可靠性αι、Ci2........ατ作为规定识别器Η(χ)的参数。</p>
    <p>[0270]	另外，在步骤S79中，识别器产生单元27输出T个最小误差维度d(l)、</p>
    <p>d(2)........d(T)作为维度信息，终止识别器产生处理，然后使处理返回到图8中的步骤S7。</p>
    <p>[0271]	通过识别器产生单元27，如上所述，根据基于boosting的统计学习（第一学习处 理），获得组成整体特征量的维度特征量中的、表示用于识别待识别对象的T个维度特征量 的维度（最小误差维度）d(l)到d(T)以及使用最小误差维度d(t)的维度特征量执行识别 的识别器H(X)。</p>
    <p>[0272]	这样，通过由学习装置1执行的第一学习处理，在产生用作维度信息的最小误差 维度d(l)到d(T)和识别器H(x)的情况下，采用共享码本81，该共享码本81共享待识别 的不同类别（例如，类别A和B)之间的包括在码本61中的特征点特征量（例如，由标识符 Cb30识别的特征点特征量fvec)。</p>
    <p>[0273]	因此，与通过使用针对每一个类别产生的码本产生识别器等等的情况相比较，通过第一学习处理能够产生用于识别不同的待识别对象的每一个的多个识别器，而不会增加 包括在码本61 (包括在共享码本81中）中的特征点特征量。</p>
    <p>[0274]	另外，通过第一学习处理，包括在共享码本61中的共享信息65保持针对每个类别 从模型图像提取的特征点。具体地讲，例如，共享信息65i保持从属于类别A的笔记本个人 计算机所在的模型图像提取的特征点，共享信息6&#190;保持从属于类别B的汽车所在的模型 图像提取的特征点。</p>
    <p>[0275]	这里，从属于类别A的笔记本个人计算机所在的模型图像提取的特征点通常与从 属于类别B的汽车所在的模型图像提取的特征点不同。</p>
    <p>[0276]	因此，包括在共享码本61中的共享信息65针对每个类别保持不同的特征点。</p>
    <p>[0277]	因此，在第一学习处理的步骤S5中整体特征量计算单元沈计算整体特征量的情 况下，基于保持在共享信息65中的特征点确定的产生用图像的检索区域所在的位置针对 每个待识别的类别而不同。</p>
    <p>[0278]	因此，通过整体特征量计算单元沈，例如，与产生用图像上的整个区域划分成网状 检索范围并且采用多个类别之间共同的检索范围（位于相同位置的检索范围）的情况相比 较，能够以更加准确的方式计算用于产生识别器的整体特征量。</p>
    <p>[0279]	因此，在第一学习处理的步骤S7中，识别器产生单元27能够基于计算的整体特征 量以更高精度产生识别器（以及维度信息）。</p>
    <p>[0280]	识别装置181的结构例子</p>
    <p>[0281]	图12示出了使用由学习装置1获得的识别器H(X)和维度信息d(l)、 d(2)........d(T)执行识别的识别装置181的结构例子。</p>
    <p>[0282]	这个识别装置181使用由学习装置1获得的识别器H(X)和用作维度信息的最小 误差维度d(l)到d(T)来识别待处理图像上的被摄体是否是预定的待识别对象，具体地讲， 待处理图像上的被摄体是否属于预定类别。</p>
    <p>[0283]	具体地讲，这个识别装置181包括共享码本存储单元201、维度信息存储单元202、 识别器存储单元203、特征点提取单元204、特征量提取单元205、整体特征量计算单元206 和识别单元207。</p>
    <p>[0284]	共享码本存储单元201预先存储与存储在学习装置1的共享码本存储单元23 (图 1)中的共享码本81相同的共享码本81。</p>
    <p>[0285]	维度信息存储单元202预先存储关于在学习装置1的识别器产生单元27进行识 别的预定对象获得的、作为维度信息的最小误差维度d(l)到d(T)。</p>
    <p>[0286]	识别器存储单元203预先存储关于在学习装置1的识别器产生单元27识别的预</p>
    <p>定对象获得的、作为识别器H(X)的T个弱学习器Ul) (Xi,d(l))、h2,d(2) (Xi,d(2))........</p>
    <p>hT,d(T) (xijd(T))和 T 个可靠性 α” α2........α τ。</p>
    <p>[0287]	待处理图像（即关于存在于该图像上的被摄体是否是待识别对象进行识别的对 象）被提供给特征点提取单元204。特征点提取单元204按照与学习装置1的特征点提取 单元M相同的方式从所提供的待处理图像中提取特征点，并且将它与待处理图像一起提 供给特征量提取单元205。</p>
    <p>[0288]	特征量提取单元205按照与学习装置1的特征量提取单元25相同的方式类似地 从来自特征点提取单元204的待处理图像提取来自特征点提取单元204的特征点的特征点特征量。</p>
    <p>[0289]	接下来，特征量提取单元205按照与来自特征点提取单元204进行相关的方式将 提取的特征点特征量提供给整体特征量计算单元206。</p>
    <p>[0290]	整体特征量计算单元206按照与学习装置1的整体特征量计算单元沈相同的 方式，基于与包括在包括在存储在共享码本存储单元201中的共享码本81中的共享信息 65 (例如，在识别待识别对象是否属于汽车的类别B的情况下的类别B的共享信息652)中 的标识符Cbn的每一个对应的特征点特征量，从来自特征量提取单元205的待处理图像的 特征点特征量，获得组成待处理图像的整体特征量的维度特征量。</p>
    <p>[0291]	然而，通过整体特征量计算单元206，并非获得组成待处理图像的整体特征量的所 有的M个维度特征量，而是选择性获得M个维度特征量中的、存储在维度存储单元202中 的、用作维度信息的最小误差维度d(l)到d(T)的维度特征量。</p>
    <p>[0292]	注意：通过整体特征量计算单元206，从待处理图像的整体特征量开始，可以仅仅 获得用作维度信息的最小误差维度d(l)到d(T)的维度特征量，或者在获得待处理图像的 整体特征量以后，可以在整体特征量之中获得最小误差维度d(l)到d(T)的维度特征量。</p>
    <p>[0293]	现在，假定以M个维度特征量为要素（由M个维度特征量构成）并且用作待处理 图像的整体特征量的矢量表示为X'。另外，待处理图像的整体特征量X'的M个维度特征 量的第m个表示为ι'。</p>
    <p>[0294]	在这种情况下，待处理图像的整体特征量χ'的M个维度特征量中的最小误差维 度d(l)到d(T)的维度特征量表示为,xd(2)' ........xd(T)'。</p>
    <p>[0295]	整体特征量计算单元206选择（选择性获得）待处理图像的整体特征量χ'的M 个维度特征量中的最小误差维度d(l)到d (T)的T个维度特征量到Xdm'。</p>
    <p>[0296]	识别单元207通过将待处理图像的最小误差维度d(l)到d(T)的维度特征量 xd(1)‘到提供给存储在识别器存储单元203中的识别器H(x')作为输入X'，识别 存在于待处理图像上的被摄体是否是预定的待识别对象，并且输出识别结果。</p>
    <p>[0297]	具体地讲，识别单元207使用T个弱学习器Kd(I) (Xda) ‘ )、h2, d(2)</p>
    <p>(&#190;⑵‘)........hT, d(T) (Xdtt)‘)以及T个可靠性a ” a .........ατ作为存储在识别</p>
    <p>器存储单元203中的识别器H(χ')，以计算用作识别器H(x')的下面表达式（7)的函数 Η(χ')。</p>
    <p>T</p>
    <p>[0298]</p>
    <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00271.png"> <img id="idf0008" file="CN102147868AD00271.tif" img-content="drawing" img-format="tif" src="//patentimages.storage.googleapis.com/CN102147868A/CN102147868AD00271.png" class="patent-full-image" alt="Figure CN102147868AD00271"> </a> </div>
    <p>[0299]	这里，在表达式（7)中，例如，当括号内的符号是正时，函数signO输出+1;当括 号内的符号为负时，函数signO输出-1。因此，表达式（7)中的函数H(x')的值变成+1 或-I。</p>
    <p>[0300]	在表达式（7)中的函数H(x')的值是+1的情况下，这表示存在于待处理图像上 的被摄体是预定的待识别对象的识别结果，在表达式（7)中的函数H(x')的值是-1的情 况下，这表示存在于待处理图像上的被摄体不是预定的待识别对象的识别结果。</p>
    <p>[0301]	识别装置181的操作说明</p>
    <p>[0302]	接下来，将参照图13中的流程图描述由识别装置181执行的识别处理（下文中称作“第一识别处理”）。</p>
    <p>[0303]	例如，在待处理图像被提供给识别装置181的特征点提取单元204的情况下，开始 该第一识别处理。</p>
    <p>[0304]	在步骤S91中，特征点提取单元204从提供的待处理图像提取特征点，将它与待处 理图像一起提供给特征量提取单元205，然后处理进入到步骤S92。</p>
    <p>[0305]	在步骤S92中，特征量提取单元205类似地从特征点提取单元204提供的待处理 图像提取来自特征点提取单元204的特征点的特征点特征量，将它提供给整体特征量计算 单元206，然后处理进入步骤S93。</p>
    <p>[0306]	在步骤S93中，整体特征量计算单元206基于存储在共享码本存储单元201中的 共享码本81，从由特征量提取单元205提供的待处理图像的特征点特征量中，获得组成待 处理图像的整体特征量的维度特征量中的、用作存储在维度信息存储单元202中的维度信 息的最小误差维度d(l)到d(T)的维度特征量到xdm'。</p>
    <p>[0307]	具体地讲，例如，整体特征量计算单元206基于与包括在包括在共享码本81中的 共享信息65 (例如，在识别待识别对象是否属于汽车的类别B的情况下的共享信息652)中 的标识符Cbn的每一个相关的特征点特征量，获得最小误差维度d(l)到d(T)的维度特征</p>
    <p>量&amp;⑴'Xd(T) ‘ ο</p>
    <p>[0308]	接下来，整体特征量计算单元206将最小误差维度d(l)到d(T)的维度特征量 Xd(1)‘到提供给识别单元207，然后处理进入步骤S94。</p>
    <p>[0309]	在步骤S94中，识别单元207通过将待处理图像的最小误差维度d(l)到d(T)的 维度特征量到提供给存储在识别器存储单元203中并且由表达式（7)进行表 示的识别器H(x')作为输入χ'，识别待处理图像上的被摄体是否为预定的待识别对象， 输出识别结果，然后第一识别处理终止。</p>
    <p>[0310]	如上所述，通过由识别装置181执行的第一识别处理，在在步骤S93中整体特征量 计算单元206获得维度特征量到、(τ)'的情况下，采用共享码本81，其中，在待识别 的不同类别（例如，类别A和B)之间共享特征点特征量（例如，由标识符Cb3tl进行识别的 特征点特征量fVec)。</p>
    <p>[0311]	因此，例如，通过识别装置181，即使在存在多个待识别的类别的情况下，与针对多 个类别的每一个产生不同码本的情况不同，能够防止包括在码本61 (包括在共享码本81 中）中的特征点特征量的增加。</p>
    <p>[0312]	另外，在第一识别处理的步骤S93中，整体特征量计算单元206按照与第一学习处 理的步骤S5中的整体特征量计算单元沈相同的方式，计算组成待处理图像的整体特征量 的维度特征量的最小误差维度d(l)到d(T)的维度特征量、(1)‘到Xdm'。</p>
    <p>[0313]	因此，通过整体特征量计算单元206，按照与整体特征量计算单元沈相同的方式， 例如，与待处理图像上的整个区域划分成网状检索范围并且在多个类别之间使用共同检索 范围（存在于相同位置的检索范围）的情况相比较，能够以更加准确的方式计算组成待处 理图像的整体特征量的维度特征量的最小误差维度d(l)到d(T)的维度特征量到</p>
    <p>Xd(T) ‘。</p>
    <p>[0314]	因此，在第一识别处理的步骤S94中，通过识别单元207，与在待识别的多个类别 之间使用共同检索范围的情况相比较，基于由整体特征量计算单元206计算的维度特征量xd(1)‘到xdm'，能够以更加准确的方式识别待识别对象。</p>
    <p>[0315]	通过第一实施例，在学习装置1的整体特征量计算单元沈处，在计算相关值作为 整体特征量的要素（维度特征量）的情况下，关于任何待识别对象在相同尺寸的检索范围 内计算产生用图像的整体特征量而不管待识别对象的类型如何，但是期望根据待识别对象 将检索范围的尺寸设置为不同尺寸。</p>
    <p>[0316]	具体地讲，例如，能够想到，在已经确定待识别对象的形状（例如，汽车）的情况 下，采用相对小的检索范围，并且在没有确定待识别对象的形状（例如，动物）的情况下，采 用相对大的检索范围。</p>
    <p>[0317]	另外，在待识别的对象是位于相对高处的屋顶的情况下，能够想到，以特征点为基 准在向上方向上将检索范围设置为较大。</p>
    <p>[0318]	这样，如果针对每个待识别对象确定合适的检索范围，则能够以更加准确的方式 计算产生用图像的整体特征量，由此能够提高基于整体特征量产生的识别器的识别的精度。</p>
    <p>[0319]	第二实施例</p>
    <p>[0320]	学习装置221的结构例子</p>
    <p>[0321]	接下来，图14描述为包括在共享信息65 (包括在共享码本81中）中的每个特征 点确定检索范围以计算整体特征量的学习装置221。图14示出了应用本发明的第二实施例 的学习装置221的结构例子。</p>
    <p>[0322]	注意：按照与根据第一实施例的图1中的学习装置1相同的方式构建的部分由相 同标号进行表示，从而在下文中将省去对它们的描述。</p>
    <p>[0323]	具体地讲，通过学习装置221，新提供范围确定单元M1，并且还提供共享码本存 储单元242和整体特征量计算单元M3以替代共享码本存储单元23和整体特征量计算单 元26，但是按照与学习装置1相同的方式构建其它部分。</p>
    <p>[0324]	产生的图像从输入单元21提供给范围确定单元Ml。范围确定单元241读出存储 在共享码本存储单元M2中的共享码本81。</p>
    <p>[0325]	接下来，范围确定单元241针对包括在包括在共享码本81中的共享信息65中的 每个特征点执行范围确定处理，用于确定表示将要被检索以获得关于来自输入单元21的 产生用图像的相关值的产生用图像上的范围的检索范围。注意：将在以后参照图15详细描 述由范围确定单元241执行的范围确定处理。</p>
    <p>[0326]	范围确定单元Ml基于共享码本81产生共享码本81'，并且将它提供并存储到共 享码本存储单元对2，该共享码本81'中确定的检索范围与包括在包括在共享码本81中的 共享信息65中的特征点相关。</p>
    <p>[0327]	共享码本存储单元242存储来自共享码本产生单元22的共享码本81。另外，共享 码本存储单元242存储从范围确定单元241产生并提供的共享码本81 ‘。</p>
    <p>[0328]	注意：可以进行一种设置，其中，共享码本产生单元22没有将产生的共享码本81 提供给共享码本存储单元242而是提供给范围确定单元Ml，并且范围确定单元241基于来 自共享码本产生单元22的共享码本81产生共享码本81'，并且将它提供并存储到共享码 本存储单元M2中。</p>
    <p>[0329]	在这种情况下，共享码本存储单元242仅仅存储来自范围确定单元241的共享码本 81'。</p>
    <p>[0330]	按照与整体特征量计算单元沈相同的方式，把关注的产生用图像的正确答案标 签和从关注的产生用图像提取的特征点特征量提供给整体特征量计算单元M3。</p>
    <p>[0331]	整体特征量计算单元243基于存储在共享码本存储单元M2中的共享码本81'， 从来自特征量提取单元25的特征点特征量计算表示关注的产生用图像的整体特征的整体 特征量。注意：将在以后参照图16描述由整体特征量计算单元243执行的处理。</p>
    <p>[0332]	接下来，整体特征量计算单元243将计算的关注的产生用图像的整体特征量与来 自特征量提取单元25的关注的产生用图像的正确答案标签一起提供给识别器产生单元 27。</p>
    <p>[0333]	由范围确定单元241执行的范围确定处理</p>
    <p>[0334]	图15示出了由范围确定单元Ml执行的范围确定处理的例子。</p>
    <p>[0335]	图15的左侧示出了包括在共享码本81中的共享信息65和产生用图像^l1到 沈15。注意：在产生用图像^l1到沈15之中，产生用图像^l1到沈13表示正像，产生用图 像2614和2615表示负像。</p>
    <p>[0336]	图5的中部示出了从产生用图像^l1到沈15的每一个计算的、用作预定维度特征 量的相关值Xi (Corr_l到Corr_5)，以及产生用图像^l1到沈15的每一个的正确答案标签 Yi (Yi的值是+1或-1)。</p>
    <p>[0337]	图15的右侧示出了误差地图观1，该误差地图281保持误差率ErroH由矩形所 示)，该误差率Error表示对于每个候选范围（即检索范围的候选），产生用图像^l1到沈15 的每一个是正像还是负像的识别错误的程度。</p>
    <p>[0338]	注意：通过误差地图观1，水平轴karch χ表示候选范围的水平方向（χ方向）的 长度，垂直轴karch y表示候选范围的垂直方向（y方向）的长度。</p>
    <p>[0339]	因此，通过误差地图观1，例如，多个矩形中的矩形301示出了 IOX 10像素（宽 度X高度）的候选范围中的误差率Error。</p>
    <p>[0340]	这里，由于误差率Error是表示产生用图像（正像或负像）的识别错误的程度的 误差信息，所以误差率Error与上述误差值匹配。</p>
    <p>[0341]	然而，误差值用于产生识别器和维度信息，并且由于误差率Error用于在多个候 选范围之中确定检索范围，所以误差值与误差率Error不同，由此根据本说明书，对误差率 Error和误差值进行不同的描述。</p>
    <p>[0342]	范围确定单元241从共享码本存储单元242读出存储在共享码本存储单元242中 的共享码本81。</p>
    <p>[0343]	范围确定单元241顺序采用包括在包括在读取的共享码本81中的共享信息 65(例如，共享信息65i和652)的每一条中的多个特征点作为关注的特征点。</p>
    <p>[0344]	接下来，范围确定单元241针对作为关注的特征点的检索范围的候选的多个候选 范围的每一个计算误差率Error。</p>
    <p>[0345]	具体地讲，例如，检索确定单元241关于产生用图像^l1通过与10X 10像素（宽 度X高度）的候选范围261Si内的产生用图像^l1上的与关注的特征点对应的位置^lC1 的关注的特征点对应的特征点特征量计算相关值Xi ( = Corr_l)。</p>
    <p>[0346]	范围确定单元241按照与产生用图像^U1的情况相同的方式，关于产生用图像2612到沈15的每一个，根据与关注的特征点对应的特征点特征量计算相关值Xi ( = Corr_2 到 Corr_5)。</p>
    <p>[0347]	接下来，范围确定单元241使用下面的表达式（8)，基于关于产生用图像^l1到 2615的每一个计算的相关值Xi ( = Corr_l到Corr_5)和产生用图像^l1到沈15的每一个 的正确答案标签Ii来计算IOX 10像素的检索范围内的误差率。</p>
    <p>[0348]	Error = Ew [1 (Gi 乒 f (Xi))]</p>
    <p>[0349]	... (8)</p>
    <p>[0350]	注意：在表达式(8)中，f (Xi)是基于相关值Xi识别产生用图像261!到2615的每 一个是正像还是负像的函数。</p>
    <p>[0351]	在相关值Xi等于或大于阈值Thresh的情况下，函数f (Xi)输出值1以表示对应 的产生用图像已经被识别为正像，在相关值Xi小于阈值Thresh的情况下，函数f (Xi)输出 值-1以表示对应的产生用图像已经被识别为负像。</p>
    <p>[0352]	注意：阈值Thresh被取为相关值Xi的最小值与最大值之间的值，以及取为使正确 答案标签Yi与对应函数f (Xi)的值之间的差最小的值（即使误差率Error变得最小的值）。</p>
    <p>[0353]	具体地讲，例如，把计算的相关值Xi ( = Corr_l到Corr_5)的每一个作为用作阈 值Thresh的候选的候选阈值，并且通过表达式（8)计算误差率Error。接下来，把多个候 选阈值中的使正确答案标签Yi与函数f (Xi)的值之间的差变得最小的候选阈值作为阈值 Thresh0</p>
    <p>[0354]	另外，在表达式⑶中，通过函数Ew [1 ((yi兴f (Xi)))],当正确答案标签yi与函数 f(Xi)的输出值不匹配时，输出值是1，当正确答案标签Yi与函数f (Xi)的输出值匹配时，输 出值是2。</p>
    <p>[0355]	范围确定单元241将使用表达式（8)计算的10X 10像素的候选范围内的误差率 Error存储在对应的误差地图观1中。因此，误差地图保持10 X 10像素的候选范围（矩形 301所示)内的误差率Error。</p>
    <p>[0356]	范围确定单元241按照与计算10X10像素的候选范围内的误差率Error的情况 相同的方式计算另一个候选范围（例如，10X20像素或20X30像素的候选范围）内的误差 率Error，并且将它保持在误差地图的对应误差保持区域中。</p>
    <p>[0357]	这样，范围确定单元241针对例如在图15的左侧上所示的每一个不同候选范围产 生用于保持误差率Error的误差地图观1。</p>
    <p>[0358]	接下来，范围确定单元Ml确定包括在产生的误差地图281中的多个误差率Error 中的、与最小误差率Error对应的候选范围作为关注的特征点的检索范围。</p>
    <p>[0359]	范围确定单元241将确定的检索范围（表示确定的检索范围的信息）与关注的特 征点相关。这样，范围确定单元241产生包括含有与检索范围相关的特征点的共享信息65 的共享码本81 ‘，并且将它提供并存储在共享码本存储单元M2中。</p>
    <p>[0360]	通过整体特征量计算单元对3，使用存储在共享码本存储单元M2中的共享码本 81'计算产生用图像的整体特征量。</p>
    <p>[0361]	由整体特征量计算单元243执行的相关值计算的例子</p>
    <p>[0362]	接下来，图16是用于描述由整体特征量计算单元243执行的处理的例子的图。</p>
    <p>[0363]	注意：通过整体特征量计算单元M3，按照与图6相同的方式进行构建的部分由相同标号进行表示，从而将在下文中适当地省去它们的描述。</p>
    <p>[0364]	具体地讲，除了示出共享码本81'以替代共享码本81以外，按照与图6的情况相 同的方式构建整体特征量计算单元对3。</p>
    <p>[0365]	整体特征量计算单元243针对与包括在包括在共享码本81'的共享信息6&#190;中的 标识符Cbn的每一个对应的特征点特征量Ul1到1211(|的每一个计算确定的检索范围内的 产生用图像141到145的相关值。</p>
    <p>[0366]	具体地讲，例如，整体特征量计算单元243从包括在共享码本81 ‘中的共享信息 6&#190;读出与与组成产生用图像141的整个区域（整个范围）的特征点特征量121n(n是从1 到10的自然数）对应的特征点相关的检索范围。</p>
    <p>[0367]	接下来，整体特征量计算单元243计算特征点特征量121η与存在于读取的产生用 图像141的检索范围上的每个特征点的特征点特征量之间的相关值，并且采用通过该计算 获得的多个相关值的最大相关值作为关注的特征点特征量121η与产生用图像141之间的 最终相关值161η。</p>
    <p>[0368]	整体特征量计算单元243针对产生用图像141关于特征点特征量Ul1到1211(|计 算相关值Iei1到Ieiltl，并且把以计算的相关值Iei1到iei1(l为要素的矢量作为产生用图像 141的整体特征量。</p>
    <p>[0369]	整体特征量计算单元243按照与计算产生用图像141的整体特征量的情况相同的 方式计算产生用图像142到145的每一个的整体特征量。</p>
    <p>[0370]	整体特征量243将多个产生用图像141到145的每一个的整体特征量提供给识别 器产生单元27。</p>
    <p>[0371]	学习装置221的操作说明</p>
    <p>[0372]	接下来，将参照图17中的流程图描述由学习装置221执行的学习操作（下文中称 作第二学习处理）。</p>
    <p>[0373]	在用于学习的图像被提供给输入单元21的情况下，开始该第二学习处理。此时， 输入单元21将要提供用作学习的图像的产生用图像、原始图像和模型图像中的原始图像 和模型图像提供给共享码本产生单元22，并且将产生用图像提供给特征点提取单元M和 范围确定单元Ml。</p>
    <p>[0374]	在步骤Slll中，执行与图8中的步骤Sl相同的处理。</p>
    <p>[0375]	在步骤Sl 12中，范围确定单元241读取存储在共享码本存储单元242中的共享码 本81。</p>
    <p>[0376]	接下来，范围确定单元241针对包括在包括在共享码本81中的共享信息65中的 每个特征点，执行范围确定处理，以确定表示进行检索的产生用图像上的范围的检索范围， 以获得关于来自输入单元21的产生用图像的相关值。注意：将在以后参照图18中的流程 图详细描述由范围确定单元241执行的范围确定处理。</p>
    <p>[0377]	在步骤Sl 13到Sl 15中，执行的处理与图8中的步骤S2到S4中的处理相同。</p>
    <p>[0378]	在步骤Sl 16中，整体特征量计算单元243基于存储在共享码本存储单元242中的 共享码本81'，从来自特征量提取单元25的特征点特征量，计算表示关注的产生用图像的 整体特征的整体特征量。</p>
    <p>[0379]	具体地讲，例如，如图16所述，整体特征量计算单元243基于与包括在包括在共享码本81'中的共享信息65(例如，产生识别待识别的对象是否属于汽车的类别B的识别器 和维信息的情况下的共享信息652)中的每个特征点相关的检索范围，计算关注的产生用图 像的整体特征量和与包括在共享信息65中的标识符Cbn的每一个相关的特征点特征量。</p>
    <p>[0380]	接下来，整体特征量计算单元243将计算的关注的产生用图像的整体特征量与来 自特征量提取单元25的关注的产生用图像的正确答案标签一起提供给识别器产生单元 27。</p>
    <p>[0381]	在步骤S117中，特征点提取单元对确定是否来自输入单元21的所有的产生用图 像都已经作为关注的产生用图像。接下来，在确定来自输入单元21的所有的产生用图像还 没有都作为关注的产生用图像的情况下，特征点提取单元M使处理返回到步骤S113。</p>
    <p>[0382]	在步骤Sl 13中，特征点提取单元M采用来自输入单元21的多个产生用图像中的 还没有被作为关注的产生用图像的产生用图像作为新的关注的产生用图像，处理进入到步 骤S114，然后执行相同处理。</p>
    <p>[0383]	另外，在步骤S117中确定来自输入单元21的所有的多个产生用图像都已经被作 为关注的产生用图像的情况下，特征点提取单元M使处理进入到步骤S118。</p>
    <p>[0384]	在步骤S118中，执行与步骤S7相同的处理。到此，第二学习处理结束。</p>
    <p>[0385]	范围确定单元24l的操作说明</p>
    <p>[0386]	接下来，将参照图18中的流程图描述在图17的步骤S112中由范围确定单元241 执行的范围确定处理。</p>
    <p>[0387]	在步骤S131中，范围确定单元241从共享码本存储单元242读取存储在共享码本 存储单元M2中的共享码本81。</p>
    <p>[0388]	接下来，范围确定单元24l顺序采用包括在包括在读取的共享码本81中的共享信 息65(例如，共享信息65i或共享信息652)的每一条中的多个特征点作为关注的特征点。</p>
    <p>[0389]	在步骤S132中，范围确定单元241基于来自输入单元21的多个产生用图像（例 如，产生用图像26l1到2615)指定多个候选范围（即，关注的特征点中检索范围的候选）之一。</p>
    <p>[0390]	具体地讲，例如，范围确定单元241针对多个产生用图像指定10X 10像素（宽 度X高度）的候选范围作为与关注的特征点对应的候选范围。</p>
    <p>[0391]	在步骤S133中，范围确定单元241计算存在于多个产生用图像的每一个的指定的 候选范围上的特征点的特征点特征量以及与关注的特征点对应的特征点之间的相关值Xi。</p>
    <p>[0392]	在步骤S134中，范围确定单元241基于计算的关于多个产生用图像的相关值Xi和 多个产生用图像的正确答案标签使用表达式（8)计算在步骤S132的最后处理中指定的 检索范围内的误差率。</p>
    <p>[0393]	接下来，范围确定单元241将使用表达式（8)计算的10 X 10像素的候选范围内的 误差率Error保持在误差地图观1的对应误差保持区域（例如，误差保持区域301)内。</p>
    <p>[0394]	在步骤S135中，范围确定单元241确定是否已经指定了所有的多个候选范围，并 且在还没有指定所有的多个候选范围的情况下，处理返回到步骤S132。</p>
    <p>[0395]	接下来，在步骤S132中，范围确定单元241指定多个候选范围中的还没有进行指 定的候选范围，处理进入到步骤S133，然后执行相同的处理。</p>
    <p>[0396]	另外，在步骤S135中确定已经指定了所有的多个候选范围的情况下，范围确定单元241使处理进入到步骤S136。</p>
    <p>[0397]	在步骤S136中，范围确定单元241确定是否已经采用包括在包括在共享码本81 中的共享信息65的每一条中的所有的多个特征点作为关注的特征点，并且在确定还没有 采用所有的多个特征点作为关注的特征点的情况下，处理返回到步骤S131。</p>
    <p>[0398]	接下来，在步骤S131中，范围确定单元241采用包括在共享信息65的每一条中的 多个特征点中的、还没有被采用作为关注的特征点的特征点作为新的关注的特征点，处理 进入步骤S132，然后执行相同处理。</p>
    <p>[0399]	另外，在步骤S136中确定已经采用包括在包括在共享码本81中的共享信息65的 每一条中的所有的多个特征点作为关注的特征点的情况下，范围确定单元241使处理返回 到图17中的步骤S112，进入到步骤S113，并且在步骤S113中，执行参照图17中的流程图 描述的处理。</p>
    <p>[0400]	如上所述，通过由学习装置221执行的第二学习处理，针对包括在包括在共享码 本81'中的共享信息65(例如，共享信息652)中的每个特征点，使产生用图像的识别错误 的误差率Error变得最小的的范围的尺寸被确定为检索范围，并且使用确定的检索范围计 算组成产生用图像的整体特征量的维度特征量。</p>
    <p>[0401]	因此，通过第二学习处理，与使用针对包括在共享信息65中的每个特征点的相同 尺寸的检索范围计算组成产生用图像的整体特征量的维度特征量的情况相比较，能够以更 加准确的方式计算整体特征量。因此，能够产生能够使用计算的整体特征量以更加准确的 方式识别待识别对象的识别器。</p>
    <p>[0402]	识别装置321的结构例子</p>
    <p>[0403]	图19示出了基于通过学习装置221的学习获得的识别器和维度信息执行存在于 待处理图像上的被摄体的识别的识别装置321的结构例子。</p>
    <p>[0404]	这个识别装置321使用在范围确定单元241确定的检索范围以及由学习装置 221(图14)获得的识别器H(X)以及用作维度信息的最小误差维度d(l)到d(T)来识别存 在于待处理图像上的被摄体是否是待识别对象。</p>
    <p>[0405]	注意：通过识别装置321，按照与图12中的识别装置181相同的方式构建的部分 由相同标号进行表示，从而在下文中省去它们的描述。</p>
    <p>[0406]	具体地讲，除了提供共享码本存储单元341和整体特征量计算单元342以替代共 享码本存储单元201和整体特征量计算单元206以外，按照与图12中的识别装置181相同 的方式构建图19中的识别装置321。</p>
    <p>[0407]	共享码本存储单元341预先存储与存储在学习装置221的共享码本存储单元 图14)中的共享码本81'相同的共享码本81'。</p>
    <p>[0408]	待处理图像的特征点特征量从特征量提取单元205提供给整体特征量计算单元 342。</p>
    <p>[0409]	整体特征量计算单元342按照与学习装置221的整体特征量计算单元243相同的 方式，基于存储在共享码本存储单元341中的共享码本81 ’，从来自特征量提取单元205的 待处理图像的特征点特征量获得组成该待处理图像的整体特征量的维度特征量。</p>
    <p>[0410]	识别装置321的操作说明</p>
    <p>[0411]	接下来，参照图20中的流程图描述由识别装置321执行的识别处理（下文中称作“第二识别处理”）。</p>
    <p>[0412]	例如，在待处理图像被提供给特征点提取单元204的情况下，开始该第二识别处理。</p>
    <p>[0413]	在步骤S151和S152中，分别执行与图13中的步骤S91和S92相同的处理。</p>
    <p>[0414]	在步骤S153中，整体特征量计算单元342基于存储在共享码本存储单元341中的 共享码本81'，从来自特征量提取单元205的待处理图像的特征点特征量获得组成该待处 理图像的整体特征量的维度特征量中的、用作存储在维度信息存储单元202中的维度信息 的最小误差维度d(l)到d(T)的维度特征量到xdm'。</p>
    <p>[0415]	具体地讲，例如，整体特征量计算单元342基于与包括在包括在共享码本81 ‘中 的共享信息65 (例如，识别待识别对象是否属于汽车的类别B的情况下的共享信息652)中 的特征点的每一个相关的检索范围和与包括在共享信息65中的标识符Cbn的每一个相关 的特征点特征量，获得最小误差维度d(l)到d(T)的维度特征量到xdm'。</p>
    <p>[0416]	接下来，整体特征量计算单元342将最小误差维度d(l)到d(T)的维度特征量 Xd(1)‘到提供给识别单元207，然后处理进入步骤SIM。</p>
    <p>[0417]	在步骤SlM中，执行与图13中的步骤S94相同的处理。至此，第二识别处理结束。</p>
    <p>[0418]	如上所述，通过第二识别处理，针对包括在包括在共享码本81'中的共享信息 65 (例如，共享信息652)中的每个特征点，使产生用图像的识别错误的误差率Error变得最 小的范围的尺寸被确定为检索范围，并且使用确定的检索范围获得最小误差维度d(l)到 d(T)的维度特征量到xdm'。</p>
    <p>[0419]	因此，通过第二识别处理，与针对包括在共享信息65中的每个特征点使用相同尺 寸的检索范围获得维度特征量到的情况相比较，能够以更加准确的方式识别 待识别对象。</p>
    <p>[0420]	修改例</p>
    <p>[0421]	根据第一实施例，整体特征量计算单元沈已经以相关值作为维度特征量计算整 体特征量，但是整体特征量不限于此，此外，例如，产生用图像的柱状图可以被计算作为整 体特征量。</p>
    <p>[0422]	在整体特征量计算单元沈计算产生用图像的柱状图作为整体特征量的情况下， 例如，采用待识别对象所属的类别的K个特征点特征量的值作为阶数。</p>
    <p>[0423]	接下来，整体特征量计算单元沈计算产生用图像的柱状图以使得将阶数的频率 (其中，关于产生用图像中的关注的特征点的特征点特征量的值的差绝对值最小）增加1。</p>
    <p>[0424]	根据第一实施例，作为图7中的识别器产生单元27遵照的算法（即，选择维度特 征量并且产生识别器），采用了 Boosting算法，但是算法并不限于此。</p>
    <p>[0425]	具体地讲，只要识别器产生单元27能够选择维度特征量并且还能够产生识别器， 则识别器产生单元27就能够遵照Boosting算法以外的任何类型的算法。</p>
    <p>[0426]	另外，根据第一实施例，进行了一种设置，其中，在学习装置1，选择了用于识别待 识别对象的类别的维度信息并且还产生识别器，并且识别装置181识别待识别对象是否是 属于预定类别的待识别对象，但是该设置不限于此。</p>
    <p>[0427]	具体地讲，例如，可以进行一种设置，其中，学习装置1选择用于识别待识别对象 是否是预定对象自身的维度信息并且还产生识别器，并且识别装置181识别待识别对象是否是预定对象自身。在这种情况下，不是针对每个类别而是针对每个对象产生共享码本81 中的共享信息65。根据第二实施例，学习装置221和识别装置321是这样设置的。</p>
    <p>[0428]	另外，根据第一实施例，学习装置1和识别装置181已经被构建为分开的装置，但 是学习装置1和识别装置181可以构建为单个装置。根据第二实施例，学习装置221和识 别装置321是这样设置的。</p>
    <p>[0429]	根据第二实施例，通过针对包括在包括在共享码本81中的共享信息65中的每个 特征点确定检索范围来产生共享码本81'，但是确定检索范围的对象不限于此。</p>
    <p>[0430]	具体地讲，例如，检索范围必须被确定为将确定检索范围的对象，并且可以采用任 何类型的对象只要可以按照与共享码本81相同的方式采用这个对象即可。</p>
    <p>[0431]	顺便说一句，既能够通过专用硬件又能够通过软件执行以上的一系列处理。在通 过软件执行该一些列处理的情况下，组成该软件的程序安装到内置计算机或者例如通过从 记录介质安装各种程序等等能够执行各种功能的通用计算机。</p>
    <p>[0432]	计算机的结构例子</p>
    <p>[0433]	接下来，图21示出了通过程序执行以上一系列处理的个人计算机的结构例子。</p>
    <p>[0434]	CPU(中央处理单元)361根据存储在R0M(只读存储器)362或存储单元368中的 程序执行各种处理。由CPU 361执行的程序、数据等等适当地存储在RAM(随机访问存储 器）363中。这些CPU 361, ROM 362和RAM 363通过总线364进行相互连接。</p>
    <p>[0435]	另外，输入/输出接口 365经由总线364连接到CPU 361。由键盘、鼠标、麦克风 等等组成的输入单元366和由显示器、扬声器等等组成的输出单元367连接到输入/输出 接口 365。CPU 361响应于从输入单元366输入的命令执行各种类型的处理。接下来，CPU 361将处理结果输出到输出单元367。</p>
    <p>[0436]	连接到输入/输出接口 365的存储单元368例如由硬盘组成并且存储由CPU 361 执行的程序或者各种类型的数据。通信单元369经由网络（例如，互联网、局域网）与外部 装置进行通信。</p>
    <p>[0437]	或者，可以进行一种设置，其中，经由通信单元369获得程序并且存储在存储单元 368 中。</p>
    <p>[0438]	在可移动介质371(例如，磁盘、光盘或半导体）安装在驱动器370上的情况下，连 接到输入/输出接口 365的驱动器370驱动该介质，以获得记录在该驱动器370上的程序、 数据等等。获得的程序或数据适当地传输并存储到存储单元368中。</p>
    <p>[0439]	如图21所示，用于记录（存储）安装到计算机中并且通过计算机使得处于可执 行状态的程序的记录介质由可移动介质371、或者临时或永久存储程序的ROM 362、或者 组成存储单元368的硬盘等等构成，其中，该可移动介质371由磁盘（包括软盘）、光盘 (CD-ROM(紧凑盘只读存储器）),DVD (数字多功能盘）、磁光盘（包括MD (迷你盘）)、半导体 存储器等等组成。通过利用有线或无线通信介质（例如，局域网、互联网或数字卫星广播） 经由作为接口的通信单元369 (例如路由器或调制解调器）把程序记录到记录介质。</p>
    <p>[0440]	注意：根据本说明书，描述以上一系列处理的步骤不仅包括按照时序沿描述的次 序执行的处理，还包括并非按照时序进行处理而是并行或独立进行执行的处理。</p>
    <p>[0441]	另外，本发明的实施例不限于以上实施例，并且在不脱离本发明的本质的情况下 可以执行各种变型。[0442]	本申请包含与在于2010年1月27日提交到日本专利局的日本优先权专利申请JP 2010-015087中公开的主题有关的主题，该日本优先权专利申请的全部内容以引用方式并入本文。</p>
    <p>[0443]	本领域技术人员应该明白，可以根据设计要求和其它因素构思各种修改、组合、子 组合和替换，只要它们位于权利要求或它们的等同物的范围内即可。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101030244A?cl=zh">CN101030244A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2006年3月3日</td><td class="patent-data-table-td patent-date-value">2007年9月5日</td><td class="patent-data-table-td ">中国科学院自动化研究所</td><td class="patent-data-table-td ">基于人体生理图像中排序测度特征的自动身份识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101458764A?cl=zh">CN101458764A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年12月5日</td><td class="patent-data-table-td patent-date-value">2009年6月17日</td><td class="patent-data-table-td ">索尼株式会社</td><td class="patent-data-table-td ">学习设备、学习方法、识别设备、识别方法和程序</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009640000">G06K9/64</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/4676">G06K9/4676</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/6261">G06K9/6261</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=vrxxBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/6249">G06K9/6249</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">G06K9/62B4S</span>, <span class="nested-value">G06K9/46R1</span>, <span class="nested-value">G06K9/62B10</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2011年8月10日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2011年9月21日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2014年4月23日</td><td class="patent-data-table-td ">C02</td><td class="patent-data-table-td ">Deemed withdrawal of patent application after publication (patent law 2001)</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/2bc0f899c59369f93937/CN102147868A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E5%AD%A6%E4%B9%A0%E8%A3%85%E7%BD%AE_%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95_%E8%AF%86%E5%88%AB%E8%A3%85%E7%BD%AE.pdf?id=vrxxBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U25dTrOeUMjaZ1KjpDbAgS8KfX4HA"},"sample_url":"https://www.google.com/patents/reader?id=vrxxBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>