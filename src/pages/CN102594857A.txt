<!DOCTYPE html><html><head><title>专利 CN102594857A - 移动设备上的图像识别和共享 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="移动设备上的图像识别和共享"><meta name="DC.contributor" content="A&#183;阿克巴扎德" scheme="inventor"><meta name="DC.contributor" content="D&#183;P&#183;Z&#183;尼斯特" scheme="inventor"><meta name="DC.contributor" content="S&#183;J&#183;贝克" scheme="inventor"><meta name="DC.contributor" content="S&#183;费恩" scheme="inventor"><meta name="DC.contributor" content="微软公司" scheme="assignee"><meta name="DC.date" content="2011-10-11" scheme="dateSubmitted"><meta name="DC.description" content="分析捕获图像，以识别其中描绘的个人和/或场景元素。一旦用户确认一个或多个识别的个人和/或场景元素，访问实体信息，以确定是否具有与当前捕获图像中识别的个人或场景元素相对应或者以其他方式链接到当前捕获图像中识别的个人或场景元素的任何可用的通信地址，例如电子邮件地址、基于SMS的地址、网站等等。当前捕获图像随后能够被自动发送到为所识别的个人或场景元素定位的那些地址，而无需任何其他的用户努力。"><meta name="DC.date" content="2012-7-18"><meta name="DC.relation" content="CN:101843086:A" scheme="references"><meta name="DC.relation" content="KR:20090093663" scheme="references"><meta name="DC.relation" content="US:20050011959:A1" scheme="references"><meta name="DC.relation" content="US:20060133699:A1" scheme="references"><meta name="DC.relation" content="US:20080218407:A1" scheme="references"><meta name="DC.relation" content="US:20090280859:A1" scheme="references"><meta name="DC.relation" content="US:7068309" scheme="references"><meta name="citation_patent_publication_number" content="CN:102594857:A"><meta name="citation_patent_application_number" content="CN:201110364483"><link rel="canonical" href="https://www.google.com/patents/CN102594857A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN102594857A?cl=zh"/><meta name="title" content="专利 CN102594857A - 移动设备上的图像识别和共享"/><meta name="description" content="分析捕获图像，以识别其中描绘的个人和/或场景元素。一旦用户确认一个或多个识别的个人和/或场景元素，访问实体信息，以确定是否具有与当前捕获图像中识别的个人或场景元素相对应或者以其他方式链接到当前捕获图像中识别的个人或场景元素的任何可用的通信地址，例如电子邮件地址、基于SMS的地址、网站等等。当前捕获图像随后能够被自动发送到为所识别的个人或场景元素定位的那些地址，而无需任何其他的用户努力。"/><meta property="og:title" content="专利 CN102594857A - 移动设备上的图像识别和共享"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN102594857A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN102594857A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN102594857A&amp;usg=AFQjCNE_FsbLjVtPOPkOKP_UdZ_6-bETRA" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/6bbc7fbe5b4c61a3e8e1/CN102594857A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/6bbc7fbe5b4c61a3e8e1/CN102594857A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN102594857A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN102594857A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN102594857A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN102594857B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN102594857A?cl=zh" style="display:none"><span itemprop="description">分析捕获图像，以识别其中描绘的个人和/或场景元素。一旦用户确认一个或多个识别的个人和/或场景元素，访问实体信息，以确定是否具有与当前捕获图像中识别的个人或场景元素相对应或者以其他方式链接到当前捕获图像中 ...</span><span itemprop="url">https://www.google.com/patents/CN102594857A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN102594857A - 移动设备上的图像识别和共享</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN102594857A - 移动设备上的图像识别和共享" title="专利 CN102594857A - 移动设备上的图像识别和共享"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN102594857 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 201110364483</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2012年7月18日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2011年10月11日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2010年10月11日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102594857B?hl=zh-CN&amp;cl=zh">CN102594857B</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120086792?hl=zh-CN&amp;cl=zh">US20120086792</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2012050672A2?hl=zh-CN&amp;cl=zh">WO2012050672A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2012050672A3?hl=zh-CN&amp;cl=zh">WO2012050672A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">201110364483.X, </span><span class="patent-bibdata-value">CN 102594857 A, </span><span class="patent-bibdata-value">CN 102594857A, </span><span class="patent-bibdata-value">CN 201110364483, </span><span class="patent-bibdata-value">CN-A-102594857, </span><span class="patent-bibdata-value">CN102594857 A, </span><span class="patent-bibdata-value">CN102594857A, </span><span class="patent-bibdata-value">CN201110364483, </span><span class="patent-bibdata-value">CN201110364483.X</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22A%C2%B7%E9%98%BF%E5%85%8B%E5%B7%B4%E6%89%8E%E5%BE%B7%22">A&#183;阿克巴扎德</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22D%C2%B7P%C2%B7Z%C2%B7%E5%B0%BC%E6%96%AF%E7%89%B9%22">D&#183;P&#183;Z&#183;尼斯特</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22S%C2%B7J%C2%B7%E8%B4%9D%E5%85%8B%22">S&#183;J&#183;贝克</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22S%C2%B7%E8%B4%B9%E6%81%A9%22">S&#183;费恩</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E5%BE%AE%E8%BD%AF%E5%85%AC%E5%8F%B8%22">微软公司</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN102594857A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102594857A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN102594857A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">专利引用</a> (7),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (16),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D201110364483&amp;usg=AFQjCNHLeDb4_q3JoOsodwhtVvrvRLwHYw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D102594857A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNELzzWYH4JtR6b1YvOw6jXo0tHLHA"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT114097063" lang="ZH" load-source="patent-office">移动设备上的图像识别和共享</invention-title>
      </span><br><span class="patent-number">CN 102594857 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA98445164" lang="ZH" load-source="patent-office">
    <div class="abstract">分析捕获图像，以识别其中描绘的个人和/或场景元素。一旦用户确认一个或多个识别的个人和/或场景元素，访问实体信息，以确定是否具有与当前捕获图像中识别的个人或场景元素相对应或者以其他方式链接到当前捕获图像中识别的个人或场景元素的任何可用的通信地址，例如电子邮件地址、基于SMS的地址、网站等等。当前捕获图像随后能够被自动发送到为所识别的个人或场景元素定位的那些地址，而无需任何其他的用户努力。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(15)</span></span></div><div class="patent-text"><div mxw-id="PCLM44442830" lang="ZH" load-source="patent-office" class="claims">
    <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1.	一种用于发送捕获图像到通信地址的方法，所述方法包括：处理捕获图像，以便为捕获图像中描绘的个人生成最佳猜测标识（124)；输出捕获图像给用户（126)；输出生成的最佳猜测标识给用户（126)；接收最佳猜测标识准确指定在捕获图像中描绘的个人的确认（128)；自动确定用于最佳猜测标识的通信地址（136);以及自动发送捕获图像到确定的通信地址（140)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.权利要求I的用于发送捕获图像到通信地址的方法，其中所述方法运行在移动相机设备(350)上。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.权利要求I的用于发送捕获图像到通信地址的方法，进一步包括：一旦接收到最佳猜测标识准确指定在捕获图像中描绘的个人的确认（128)，则将捕获图像自动发送到确定的通信地址（140)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.权利要求I的用于发送捕获图像到通信地址的方法，进一步包括：从用户接收包括发送捕获图像（280)的命令的输入；和一旦从用户接收到包括发送捕获图像（280)的命令的输入，自动发送捕获图像到确定的通信地址（140)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.权利要求I的用于发送捕获图像到通信地址的方法，进一步包括：将从电子地址簿获得的信息作为实体信息存储在数据库中（104);以及访问数据库中存储的信息，以自动确定用于最佳猜测标识的通信地址（136)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.权利要求I的用于发送捕获图像到通信地址的方法，进一步包括：处理捕获图像，以尝试为其面部被描绘在捕获图像中的每个个人生成最佳猜测标识 (124)；输出每个生成的最佳猜测标识给用户（126)；在至少一个数据库中搜索与对其而言接收到确认的每个最佳猜测标识相关联的至少一个通信地址，其中被定位的每一个这样的通信地址是定位的通信地址（136);以及自动发送捕获图像到每个定位的通信地址（140)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7.权利要求6的用于发送捕获图像到通信地址的方法，进一步包括：从用户接收包括输出给用户的所有的最佳猜测标识被确认为准确指定捕获图像（265)中描绘的个人的标识的输入。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.权利要求6的用于发送捕获图像到通信地址的方法，进一步包括：从用户接收个人身份信息，其中个人身份信息包括其面部被描绘在捕获图像中且没有为其生成最佳猜测标识的个人的身份（146)；在至少一个数据库中搜索与接收到的个人身份信息相关联的至少一个通信地址，其中个人身份信息包括其面部被描绘在捕获图像中的个人的身份，其中每一个这样的通信地址是个人的通信地址（150);以及自动发送捕获图像到个人的通信地址之中的至少一个通信地址（154)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.权利要求8的用于发送捕获图像到通信地址的方法，进一步包括：自动发送捕获图像到个人的通信地址之中的每一个通信地址（154)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.权利要求6的用于发送捕获图像到通信地址的方法，进一步包括：处理捕获图像，以便为捕获图像中描绘的个人生成包括至少两个最佳猜测标识的最佳猜测池(124)；输出最佳猜测池中的最佳猜测标识给用户（126);以及接收最佳猜测池中的一个最佳猜测标识准确指定捕获图像中描绘的个人的确认 (128)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11.权利要求6的用于自动发送捕获图像到通信地址的方法，进一步包括：从用户接收对于生成的最佳猜测标识的拒绝确认，其中拒绝确认包括最佳猜测标识是不正确的指示（128)；从用户接收个人身份信息，其中个人身份信息包括对其而言接收到对于生成的最佳猜测标识的拒绝确认的个人的身份（132)；将从用户接收的个人身份信息输出给用户（134)；在至少一个数据库中搜索与接收到的个人身份信息相关联的至少一个通信地址，其中个人身份信息包括对其而言接收到对于生成的最佳猜测标识的拒绝确认的个人的身份，其中每一个这样的通信地址是个人的通信地址（136);和自动发送捕获图像到个人的通信地址中的至少一个通信地址（140)。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12.权利要求I的用于自动发送捕获图像到通信地址的方法，进一步包括：处理捕获图像，以便为捕获图像的场景元素生成最佳猜测场景确定符（156)；输出最佳猜测场景确定符给用户（158)；接收最佳猜测场景确定符准确指定捕获图像的场景元素的确认（160)；自动确定用于最佳猜测场景确定符的通信地址（168);以及自动发送捕获图像到确定的用于最佳猜测场景确定符的通信地址（172)。</div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13.	&#8212;种移动相机设备，包括捕获图像以及自动发送捕获图像到至少一个通信地址的能力，所述移动相机设备包括：包括捕获图像（335)的能力的相机（35O)；包括利用面部识别技术为捕获图像（335)中描绘的至少一个个人（205)生成最佳猜测标识的能力的程序（325)；包括与用户（370)通信以便向用户（370)显示（290)捕获图像（335)的能力的程序 (425)；包括与用户（370)通信以便向用户（370)示生成的最佳猜测标识（210)的能力的程序 (425)；包括与用户（370)通信以接收包括生成的最佳猜测标识（375)的确认的用户输入的能力的程序（425)；包括将通信地址与捕获图像（335)中描绘的个人（205)相关联的能力的程序（325)，其中对所述个人而言确认（375)生成的最佳猜测标识；以及包括与通信网络（365)通信以便自动发送捕获图像（355)到与捕获图像（335)中描绘的个人（205)相关联的通信地址的能力的程序（415)，其中对所述个人而言确认（375)生成的最佳猜测标识。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14.权利要求13的移动相机设备，进一步包括：从先前捕获的图像（345)中提取的存储特征（355)的数据库（320)，其中包括利用面部识别技术为捕获图像（335)中描绘的至少一个个人（205)生成最佳猜测标识的能力的程序 (325)为了最佳猜测标识的生成而访问所述数据库；以及联系信息（380)的数据库（310)，其包括至少两个人员的标识以及用于至少两个人员之中的每一个人员的至少一个通信地址的关联性，其中包括将通信地址与捕获图像（335) 中描绘的个人（205)相关联的能力的程序（325)为了通信地址与捕获图像（335)中描绘的个人（205)的关联性而访问所述数据库，其中对所述个人而言确认（375)生成的最佳猜测标识。</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15.权利要求13的移动相机设备，进一步包括：GPS技术（410)，其包括为捕获图像（335)生成至少一个位置标识符的能力；存储在移动相机设备（350)上的规则（380)，其中所述规则包括与至少一个生成的位置标识符相关联的通信地址的标识；包括利用所述规则（380)将与至少一个生成的位置标识符相关联的通信地址和捕获图像（335)相关联的能力的程序（325);以及包括与通信网络（365)通信以便自动发送捕获图像（355)到与捕获图像（335)相关联的通信地址的能力的程序（415)。</div>
    </div>
  </div> </div>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES50194077" lang="ZH" load-source="patent-office" class="description">
    <p>移动设备上的图像识别和共享</p>
    <p>背景技术</p>
    <p>[0001]	例如蜂窝电话之类的移动设备现今具有日益复杂且增强的相机，这些相机支持用户捕获在这里被统称为图像的摄影图像和视频。此外，相机最有可能将具有与因特网或万维网（WWW)通信的能力，从而使之籍此成为移动设备。移动设备和相机现今也具有越来越高性能计算能力，即，其是具有能够应用于执行或辅助处理各种应用的大量计算能力的计算设备。</p>
    <p>[0002]	在这里被称为移动相机设备的具有相机能力的移动设备的用户利用其移动相机设备来捕获和存储图像。在这里也被称为摄影师的这些用户则时常希望与一个或多个其他的人、网站或网络（web)位置和/或其他的用户设备、例如摄影师的基于家庭的计算机等等共享其捕获的图像之中的一个或多个图像。</p>
    <p>[0003]	一般来说，然而，借助于现有技术，对于摄影师而言，传送或以其他方式下载其捕获的图像到其台式计算机以及在台式计算机上检查捕获的图像以识别他们希望转发哪些图像给其他的用户、设备和/或网站是繁琐且耗时的。只有到那时，摄影师才能够草拟例如电子邮件之类的合适发送消息、选择预期的接收方以及最终将适当的个人图像转发至期望的接收方或其他位置、和/或与网站或网络（web)位置交互，以便向其上传个人图像。</p>
    <p>[0004]	因而，希望利用用户的移动相机设备的计算和通信能力来辅助用户有效地识别捕获图像的接收方，以及利用最低的用户努力来与识别的接收方共享捕获图像。</p>
    <p>发明内容</p>
    <p>[0005]	提供这个概述部分来以简化形式介绍下面在具体描述部分中进一步描述的概念的选择。这个概述部分不打算来识别所请求保护的主题的关键特征或基本特征，也不打算用作辅助手段来确定所请求保护的主题的范围。</p>
    <p>[0006]	在这里讨论的实施例包括用于处理捕获图像以及自动发送捕获图像到用于一个或多个通信网络例如因特网、一个或多个基于SMS的网络、一个或多个电话系统网络等等的一个或多个地址的系统和方法。</p>
    <p>[0007]	在实施例中，捕获图像被自动处理，以尝试识别其中描绘的人员。在实施例中，捕获图像中个人的最佳猜测标识被输出到用户，以便确认。在实施例中，当用户确认在当前捕获图像中描绘的个人的最佳猜测标识时，在一个或多个数据库中搜索与确认的被描绘的个人相关联的用于发送通信到诸如但不限于电子邮件和文本消息的一个或多个通信地址，例如，基于因特网的地址、SMS(短消息服务）文本消息传送地址等等，这些地址在这里被统称为通信（com)地址。在实施例中，如果一个或多个相关联的通信地址被定位或以其他方式被识别，则自动发送捕获图像到定位的通信地址。</p>
    <p>[0008]	在实施例中，捕获图像也被自动处理，以尝试识别其中描绘的场景元素，诸如捕获图像的位置、在捕获图像内描绘的地标和/或其他对象或实体，例如建筑物、家庭宠物等等。在实施例中，识别一个或多个描绘的场景元素的最佳猜测场景确定符（determinator) 被生成并被输出给用户，以便确认。在实施例中，当用户确认最佳猜测场景确定符时，在一个或多个数据库中搜索将一个或多个通信地址与确认的场景元素相关联的一个或多个规则，并且如果被定位的话，则自动发送捕获图像到定位的通信地址。</p>
    <p>[0009]	在实施例中，用户输入能够用于识别在捕获图像中描绘的一个或多个个人和/或场景元素。在实施例中，对用户输入进行搜索，以搜索任何相关联的通信地址，如果任何相关联的通信地址被定位的话，则自动发送捕获图像到相关联的通信地址。</p>
    <p>附图说明</p>
    <p>[0010]	现在将参考旨在例证而非限制的某些实施例和示例的附图来描述这些和其他的特征，并且其中：</p>
    <p>[0011]	图1A-1D示出用于识别捕获图像的接收方并且与识别的接收方共享捕获图像的实施例逻辑流程。</p>
    <p>[0012]	图2描绘利用具有识别捕获图像的接收方并与识别的接收方共享捕获图像的能力的实施例图像共享系统来处理的示例的捕获图像。</p>
    <p>[0013]	图3描绘实施例移动设备图像共享应用，其在这里也被称为图像共享应用（app)。</p>
    <p>[0014]	图4描绘具有捕获图像、识别捕获图像的接收方并与识别的接收方共享捕获图像的能力的实施例移动相机设备。</p>
    <p>[0015]	图5是具有处理软件、即程序代码或指令的能力的示例的基本计算设备的框图。 具体实施方式</p>
    <p>[0016]	在下面的描述中，为了解释的目的，阐述许多具体的细节，以便提供在这里描述的实施例的透彻理解。对于本领域技术人员而言，这些实施例可以在没有这些具体细节的情况下被实践，这将是显然的。在其他的实例中，为了避免不必要的模糊，众所周知的结构和设备或简单地以框图形式进行引用或显示。自始至终使用的任何的以及所有的标题仅仅为了便于解释，而不用于任何限制使用。</p>
    <p>[0017]	图1A-1D示出用于利用最少限度的用户交互来有效和高效地识别捕获图像的接收方并快速地与所识别的接收方共享捕获图像的实施例逻辑流程。虽然相对于在这里描绘的系统进行下面的讨论，但是所描述的操作可以在其他系统中进行实现。这里描述的操作并不限于所显示的顺序。另外，在其他的替代实施例中，可以执行更多或更少的操作。进一步，所描绘的操作可以利用在图3中描绘并在下面进一步讨论的实施例图像共享应用300 来执行，或者利用实施例图像共享应用300结合一个或多个其他的系统实体、组件和/或应用来执行。</p>
    <p>[0018]	在一个实施例中，图1A-1D的逻辑流程在用户的移动相机设备上进行处理。在另一实施例中，图1A-1D的逻辑流程的步骤的子集在用户的移动相机设备上进行处理，并且该逻辑流程的剩余步骤在一个或多个其他的移动或不移动的设备上进行处理。出于讨论的目的，图1A-1D的步骤将参考其中在用户的移动相机设备上处理该逻辑流程的实施例来讨论。</p>
    <p>[0019]	在一个实施例中，移动相机设备是具有计算和摄影能力的移动设备。在一个实施例中，计算能力是运行软件应用或程序或计算机程序、即运行软件指令或计算机代码的能力。在一个实施例中，具有计算能力的移动设备包括具有用于运行软件应用的处理器的设备。</p>
    <p>[0020]	在一个实施例中，摄影能力是捕获图像、例如照片和/或视频的能力。在一个实施例中，摄影能力也包括处理捕获图像、例如利用技术来尝试识别捕获图像中的个人和/或场景元素、为捕获图像生成标签、存储捕获图像等等的能力。</p>
    <p>[0021]	在一个实施例中，移动设备是能够在各种位置上按照预期操作的设备，并且没有被硬布线或以其他方式对于任何设置时间被连接到一个特定位置，诸如台式计算机。移动相机设备的示例包括但不限于蜂窝电话、智能电话、数码相机等等。</p>
    <p>[0022]	参考图1A，在一个实施例中，在判定块102，确定是否用户希望获得或以其他方式向其移动相机设备上传现有实体信息。在一个实施例中，现有实体信息是识别通信地址的信息，用于发送通信至例如电子邮件地址、网站或在这里被统称为网站的网络位置、SMS文本消息传送地址等等。电子邮件和/或网站地址在这里也被称为基于因特网的地址。现有实体信息的示例是存储在用户的台式计算机、蜂窝电话等等上的联系人列表或电子地址簿。</p>
    <p>[0023]	在一个实施例中，现有实体信息是一个或多个图像共享规则，这些规则识别捕获图像中所描绘的个人和/或用于一个或多个个人的通信地址。因而，例如，图像共享规则能够是这样的规则，其利用捕获的John(约翰）的图像来识别个人John，以便描述John的每一个捕获图像将与John相关联，并最终被发送到实体信息中隶属于John的通信地址。作为另一示例，图像共享规则能够是这样的规则，其利用捕获的Alice (艾利斯）的图像并且也利用捕获的另一个人Bill (比尔）的图像来识别个人Alice，以致描绘Alice的每一个捕获图像以及描绘Bill的每一个捕获图像将与Alice相关联，并最终被发送到实体信息中隶属于Alice的通信地址。</p>
    <p>[0024]	在一个实施例中，现有实体信息也是一个或多个图像共享规则，这些规则识别一个或多个图像特性的个人和/或个人的通信地址或者元素或组件。实施例图像特性的示例包括但不限于图像捕获时间帧、图像捕获位置、所描绘的地标、所描绘的一个或多个个人的群组、其他描绘的实体，例如动物、宠物、花卉、汽车等等。</p>
    <p>[0025]	因而，例如，图像共享规则能够是这样的规则，其利用花卉来识别个人Jack(杰克），以致描绘一个或多个花卉的每一个捕获图像将Jack相关联，并最终被发送到实体信息中隶属于Jack的通信地址。作为另一示例，图像共享规则能够是这样的规则，其利用在 Washington (华盛顿）州捕获的图像来识别个人Sue (休），以致在Washington拍摄的每一个捕获图像将与Sue相关联，并最终被发送到实体信息中隶属于Sue的通信地址。</p>
    <p>[0026]	在一个实施例中，如果在判定块102确定用户不希望获得或以其他方式上传现有实体信息到其移动相机设备，那么所识别的现有实体信息被检索或以其他方式被上传并被存储在用户的移动相机设备104上。</p>
    <p>[0027]	在一个实施例中，在判定块106，确定是否用户希望生成实体信息，即生成一个或多个联系人（contact)和/或生成一个或多个图像共享规则，其中每一个联系人识别具有一个或多个通信地址的一个或多个个人，而每一个图像共享规则识别一个或多个个人和/ 或具有一个或多个图像特性的个人的通信地址。如果是的话，在一个实施例中，用户输入的实体信息被接收并被存储在用户的移动相机设备108上。</p>
    <p>[0028]	在实施例中，用户生成的实体信息能够利用一种或多种输入仪器被输入到用户的移动相机设备。输入仪器的示例包括但不限于用户在其上键入以生成实体信息并将实体信息输入到用户的移动相机设备的小型键盘、用户用于生成实体信息并将实体信息输入到用户的移动相机设备的触摸屏、用户对着其讲话以生成实体信息并将实体信息输入到用户的移动相机设备的语音激活组件等等。</p>
    <p>[0029]	在一个实施例中，在判定块110，确定用户是否希望将图像和/或捕获图像特征上传到用户的移动相机设备。在一个实施例中，用户可能希望上传图像和/或捕获图像特征， 以便在识别在用户的移动相机设备上捕获的未来图像中的个人、所描绘的位置、地标以及其他的实体和对象中使用。例如，上传的图像或捕获的图像特征能够与面部识别技术结合使用来识别在用户的移动相机设备上未来捕获的图像中的个人。</p>
    <p>[0030]	在一个实施例中，如果在判定块110确定用户确实希望获得或以其他方式上传现有图像和/或捕获图像特征到其移动相机设备，则所识别的现有图像和/或捕获图像特征被检索或以其他方式被上传并被存储在用户的移动相机设备112上。在一个实施例中，与上传的图像和上传的捕获图像特征相关联的任何标签也被上传并被存储在用户的移动相机设备112上。</p>
    <p>[0031]	在一个实施例中，在判定块114，确定是否用户已利用其移动相机设备捕获了图像，例如拍摄了照片。如果没有的话，在一个实施例中，该逻辑返回到判定块102，在那儿确定用户是否希望获得现有实体信息。</p>
    <p>[0032]	如果在判定块114用户已利用其移动相机设备捕获了图像，则在一个实施例中时间标记被生成并作为捕获图像116的实体信息和/或标签进行存储。在一个实施例中，GPS 全球定位系统仪器和应用用于为捕获图像116导出时间标记。在替代实施例中，时间标记由移动相机设备利用其他设备和/或系统116例如移动相机设备时钟、蜂窝电话传输塔等等来生成。</p>
    <p>[0033]	参考图1B，在一个实施例中，在判定块118，确定是否具有可用于捕获图像的当前 GPS位置信息；即，确定移动相机设备是否支持用于捕获图像的GPS位置收集信息，例如纬度、经度等等，以及是否为捕获图像成功导出可靠的GPS位置信息。如果是的话，在一个实施例中，用于捕获图像的GPS位置信息作为捕获图像120的实体信息和/或标签进行存储。</p>
    <p>[0034]	在一个实施例中，在判定块122，确定是否具有在捕获图像中描绘的一个或多个人员。在一个实施例中，面部检测、识别技术用于确定是否具有描绘在捕获图像122中的一个或多个人员。如果是的话，在一个实施例中，运行面部识别技术，即一个或多个能够处理面部识别计算的应用，以尝试为捕获图像124中描绘的每个个人的身份生成最佳猜测。</p>
    <p>[0035]	在替代实施例中，如果在判定块122确定具有在捕获图像中描绘的一个或多个个人，则运行面部识别技术，以尝试为捕获图像124中描绘的每个个人的身份生成两个或更多的最佳猜测，即，最佳猜测池（pool)。在这个替代实施例的一个方面，对于图像捕获的个人的两个或更多最佳猜测的最佳猜测池包括对于图像捕获的个人的最大预定义数量例如两个、三个等等的最有利的预期的最佳猜测标识。</p>
    <p>[0036]	在一个实施例中，用于为每个描绘的个人生成最佳猜测或替代地生成最佳猜测池的面部识别技术利用存储的图像和/或从中辨别的面部特征的标识来将先前图像中识别的面部或面部特征与当前捕获的图像中个人的面部或面部特征进行比较。</p>
    <p>[0037]	在一个实施例中，面部识别技术利用先前捕获图像和/或先前从中辨别的面部特征的标识来尝试为捕获图像124中的每个个人的身份生成最佳猜测或替代地生成最佳猜测池，其中先前捕获图像和/或面部特征的标识被存储在用户的移动相机设备上，或以其他方式由移动相机设备例如借助于插入式存储驱动器等直接可访问的，其在这里被统称为存储在用户的移动相机设备上。在替代实施例中，存储在用户的移动相机设备之外的其他位置上、例如存储在由服务器托管（host)的网站上、存储在用户的台式计算机等等上的图像和/或先前从中辨别的面部特征标识由用户的移动相机设备借助于无线通信来访问，并由面部识别技术用于尝试为捕获图像124中的每个人人的身份生成最佳猜测或替代地生成最佳猜测池。在第二替代实施例中，由面部识别技术利用存储在用户的移动相机设备上的图像和/或先前从中辨别的面部特征标识以及存储在别处并由移动相机设备借助于无线通信访问的图像和/或先前从中辨别的面部特征标识来尝试为捕获图像124中的每个个人的身份生成最佳猜测或替代地生成最佳猜测池。</p>
    <p>[0038]	在一个实施例中，每一个为捕获图像中描绘的个人的身份生成的最佳猜测与照片 126中相应显示的人员相关联，即与之一起进行展示或输出。例如，并且参考图2，在移动相机设备290上输出给用户的示例捕获图像200中拍摄三个个人，即人员A 205、人员B 225 和人员C 235。在一个实施例中，面部识别技术用于尝试为捕获图像200中每个描绘的个人生成最佳猜测或替代地生成最佳猜测池，其中每个生成的最佳猜测是所描绘的个人的确定。在一个实施例以及图2的示例中，为人员A 205生成最佳猜测标识，为人员B 225生成最佳猜测标识，并且为人员C 235生成最佳猜测标识。在替代实施例以及图2的示例中， 为人员A 205生成两个或更多最佳猜测标识的最佳猜测池，为人员B 225生成两个或更多最佳猜测标识的最佳猜测池，并且为人员C 235生成两个或更多最佳猜测标识的最佳猜测池。</p>
    <p>[0039]	在一个实施例以及图2的示例中，为人员A 205的身份生成的最佳猜测或最佳猜测池210与在移动相机设备显示器290上输出给用户的捕获图像200中显示的人员A 205 相关联，即与之一起进行输出。例如，假设为人员A 205生成Joe(乔）的最佳猜测。在一个实施例以及图2的示例中，“Joe”210与在移动相机设备显示器290上输出的捕获图像 200中的人员A 205的图像相关联并与该图像一起进行显示。在这个实施例和示例的一个方面，“Joe”210被写在移动相机设备显示器290上输出的捕获图像200中所描绘的人员A 205的面部之上。在这个实施例的其他方面，最佳猜测在捕获图像200中在其他的图像位置中、例如在该个人的身体之上、在该个人的头部上方、在该个人的脚下等等进行输出。</p>
    <p>[0040]	在一个实施例以及图2的示例中，为人员B 225的身份生成的最佳猜测或最佳猜测池220与捕获图像200中显示的人员B 225相关联。例如，假设为人员B 225生成Sue 的最佳猜测。在一个实施例以及图2的示例中，“Sue”220与移动相机设备显示器290上输出的捕获图像200中人员B 225的图像相关联并与之一起进行显示。作为第二示例，假设为人员B 225生成Sue、Amy (艾米）和Ruth (鲁思）的最佳猜测池。在一个实施例以及图 2的示例中，“Sue”、“Amy”和“Ruth”220与在移动相机设备显示器290上输出的人员B 225 的图像相关联并与之一起进行显示。</p>
    <p>[0041]	在一个实施例以及图2的示例中，为人员C 235的身份生成的最佳猜测230与在捕获图像200中显示的人员C 235相关联。例如，假设为人员C 235生成Ann (安）的最佳猜测。在一个实施例以及图2的示例中，“Ann”230与在移动相机设备显示器290上输出的人员C 235的图像相关联并与之一起进行显示。</p>
    <p>[0042]	在一个实施例中，如果不能为捕获图像中描绘的个人生成最佳猜测，则没有什么被覆盖或者以其他方式与所显示的人员的图像相关联。因而，例如，在图2中，如果不能为人员C 235生成最佳猜测，则在移动相机设备显示器290上输出的人员C 235的显示仅保留人员C 235的图像。</p>
    <p>[0043]	在替代实施例中，如果不能为捕获图像中描绘的个人生成最佳猜测，则这样的指示被覆盖或者以其他方式与所显示的该人员的图像相关联。因而，例如，在图2中，在替代实施例中，如果不能为人员C 235生成最佳猜测，则这样的指示、例如问号（“？ ”）等与在移动相机设备显示器290上输出的人员C 235的图像相关联并与之一起进行显示。在这些替代实施例和示例的一个方面，问号（“？ ”）被写在移动相机设备显示器290上输出的捕获图像200中描绘的人员C 235的面部之上。在这些替代实施例的其他方面，不能为个人生成最佳猜测的指示在捕获图像200中在其他图像位置中、例如在该个人的身体之上、在该个人的头部上方、在该个人的脚下等等进行输出。</p>
    <p>[0044]	再次参考图1B，在一个实施例中，在判定块128，确定是否用户已确认在捕获图像中描绘的人员的身份。在一个实施例中，用户通过触摸与捕获图像中人员的描写相关联并与之一起显示的最佳猜测标识来确认所描绘人员的身份。例如，并且参考图2，在这个实施例中，用户通过触摸与捕获图像200中的人员A 205相关联并与之一起显示的“Joe”210而将人员A 205的身份确认为“Joe”。</p>
    <p>[0045]	在一个实施例中，用户通过在最佳猜测池中选择与捕获图像中人员的描写相关联并与之一起显示的最佳猜测来确认所描绘人员的身份。例如，并且再次参考图2，在这个实施例中，用户通过选择和触摸与捕获图像200中的人员B 225相关联并与之一起显示的 “Ruth” 220而将人员B 225的身份确认为“Ruth”。</p>
    <p>[0046]	在其他的实施例中，用户通过各种其他的输入机制、例如选择最佳猜测并按压在触摸屏上显示的与移动相机设备相关联的确认按钮260、选择最佳猜测并在移动相机设备小型键盘上键入预定义按键等来确认已为之生成至少一个最佳猜测的所描绘人员的身份。</p>
    <p>[0047]	如果在判定块128用户已确认在捕获图像中描绘的个人的最佳猜测标识，则在一个实施例中将该最佳猜测标识存储为捕获图像130的标签。在一个实施例中，与描绘所确认的个人的在先图像和/或捕获图像特征一起存储的任何相关的标签信息也被存储为捕获图像130的标签。</p>
    <p>[0048]	在一个实施例中，如果在判定块128用户交替地已指示最佳猜测或最佳猜测池即所有显示的最佳猜测是不正确的，则在判定块132确定是否具有对于在捕获图像中描绘的个人的用户输入。例如，并且再次参考图2，当例如通过用户首先选择所显示的某个人员的图像等而选择对其的最佳猜测或最佳猜测池是错误的个人时，用户可以例如通过在移动相机设备显示器290上选择触摸屏错误按钮270而指示对于人员A 205的最佳猜测“ Joe”210 是不正确的。用户可以此后通过例如使用与移动相机设备相关联的小型键盘或触摸屏来键入该人员的名字、从存储的实体信息中选择正确识别人员A 205的联系人等而输入对于人员A 205的正确标识，例如“Sam(山姆）”。</p>
    <p>[0049]	返回参考图1B，如果在判定块132对于用户并不接受为其生成的最佳猜测的所描绘个人具有用户输入，则在一个实施例中该用户输入被存储为用于捕获图像134的标签。在一个实施例中，识别所描绘个人的用户输入与在移动相机设备显示器134上在捕获图像中相应显示的人员相关联或以其他方式与之一起进行展示或输出。</p>
    <p>[0050]	在一个实施例中，无论用户是已确认了对于捕获图像中所描绘的个人的最佳猜测标识还是指示了最佳猜测或最佳猜测池是不正确的并提供了正确的标识，对实体信息进行搜索，以查找与已确认的个人136的身份相关联的任何通信地址。在一个实施例中，在判定块138，确定在已存储的实体信息中是否具有与确认的个人相关联的任何通信地址。如果是的话，在一个实施例中，捕获图像被自动发送到与实体信息140中已确认的个人相关联的每个通信地址。</p>
    <p>[0051]	参考图1C，在一个实施例中，在判定块142，确定是否在捕获图像中存在具有最佳猜测或最佳猜测池的任何更多的用户尚未确认或以其他方式起作用、即指示为错误的个人。如果是的话，在一个实施例中，该逻辑流程返回到图IB的判定块128，在那儿再次确定用户是否已确认捕获图像中描绘的个人的最佳猜测标识。</p>
    <p>[0052]	如果在图IC的判定块142不存在具有生成的最佳猜测标识的捕获图像中描绘的更多个人，则在一个实施例中在判定块144确定是否具有在捕获图像中描绘的没有最佳猜测的任何更多的个人。如果是的话，在一个实施例中，在判定块146确定是否对于在捕获图像中描绘的没有为之生成最佳猜测标识的个人具有用户输入。例如，并且再次参考图2，假设不能为人员C 235生成最佳猜测标识，但是用户通过例如在移动相机设备的小型键盘或触摸屏上键入“Ann”、从存储的实体信息中选择“Ann”等等而已将人员C 235识别为“Ann”。</p>
    <p>[0053]	返回参考图1C，如果对于捕获图像中描绘的个人具有用户输入，则在一个实施例中该用户输入作为捕获图像148的标签进行存储。在当前示例中，由用户提供的“Ann”的标识作为捕获图像200的标签进行存储。在一个实施例中，识别所描绘个人的用户输入与在移动相机设备显示器148上在捕获图像中相应显示的人员相关联或以其他方式与之一起进行展示或输出。</p>
    <p>[0054]	在一个实施例中，对实体信息进行搜索，以查找与捕获图像150中描绘的个人的已确认身份相关联的通信地址。在一个实施例中，在判定块152确定是否在已存储的实体信息中具有与已确认的个人相关联的任何通信地址。如果是的话，在一个实施例中，捕获图像被自动发送到实体信息154中与已确认的个人相关联的每一个通信地址。</p>
    <p>[0055]	在一个实施例中，无论在判定块152具有用于对其输出捕获图像的任何通信地址与否，在方框144再次确定是否具有在捕获图像中描绘的对其而言没有最佳猜测或确认其身份的任何更多的个人。</p>
    <p>[0056]	在一个实施例中，如果在判定块144在捕获图像中没有更多的对其而言没有最佳猜测或确认其身份的所描绘个人或者在判定块146对于捕获图像中描绘的个人没有用户输入，那么参考图1D，执行场景识别技术，即一个或多个能够处理场景图像计算的应用，以尝试识别有关捕获图像156的附加信息。这样的在这里被称为场景信息的附加信息或元素或组件能够包括但不限于或者能够是摄影捕获位置、即拍摄照片的地方、例如拉什莫尔山、 埃菲尔铁塔等等的任何捕获的地标、例如家庭犬“Rex”、花卉、汽车等等的其他描绘的实体或对象的子集等。</p>
    <p>[0057]	在一个实施例中，利用场景识别技术来尝试为在捕获图像156中描绘的一个或多个场景元素或组件的身份生成最佳猜测。在替代实施例中，利用场景识别技术来尝试为捕获图像156中描绘的一个或多个场景元素或组件的身份生成两个或更多的最佳猜测，即最佳猜测池。在这个替代实施例的一个方面，用于图像捕获的场景元素的两个或更多的最佳猜测的最佳猜测池包括用于图像捕获的场景元素的最大预定义数量例如两个、三个等等的最有利的预期最佳猜测标识。</p>
    <p>[0058]	在一个实施例中，用于为一个或多个场景元素生成最佳猜测或交替地生成最佳猜测池的场景识别技术利用已存储的图像和/或场景元素的标识或者场景元素特征和/或分类符（classifier)来将在先图像中识别的场景信息或者场景元素特征和/或分类符与当前图像156中捕获的场景和对象以及实体进行比较。</p>
    <p>[0059]	在一个实施例中，场景识别技术利用存储在用户的移动相机设备上或以其他方式由移动相机设备例如借助于插入式存储驱动器等等直接可访问的、在这里被统称为存储在用户的移动相机设备上的在先捕获的图像和/或场景元素特征和/或分类符来尝试为捕获图像156中的一个或多个场景元素生成最佳猜测或交替地生成最佳猜测池。在替代实施例中，存储在用户的移动相机设备之外的位置上、例如存储在由服务器托管的网站上、存储在用户的台式计算机等等上的图像和/或场景元素特征和/或分类符由用户的移动相机设备借助于无线通信来访问，并且由场景识别技术用于尝试为捕获图像156中的一个或多个场景元素生成最佳猜测或交替地生成最佳猜测池。在第二替代实施例中，利用存储在用户的移动相机设备上的图像和/或场景元素特征和/或分类符以及存储在别处并由移动相机设备借助于无线通信访问的图像和/或场景元素特征和/或分类符。</p>
    <p>[0060]	在一个实施例中，每一个为场景元素、即捕获图像中描绘的场景和/或一个或多个实体或对象生成的最佳猜测与显示图像158中相应的场景或实体或对象相关联。例如， 并且参考图2，在一个实施例中，场景识别技术用于生成捕获图像200中的场景位置以及所描绘的树245的最佳猜测标识或最佳猜测场景确定符。</p>
    <p>[0061]	在一个实施例以及图2的示例中，为场景位置生成的最佳猜测250与捕获图像200 相关联并与之一起显示。例如，假设为捕获图像场景200生成“Redmond, Washington” 250 的最佳猜测。在一个实施例以及图2的示例中，“Redmond, Washington” 250与移动相机设备显示器290上的捕获图像200相关联并显示在该捕获图像内。在这个实施例和示例的一个方面中，“Redmond，Washington” 250被写入在移动相机设备显示器290上输出的捕获图像200中或者以其他方式被覆盖在捕获图像200上。</p>
    <p>[0062]	在一个实施例以及图2的示例中，为所描绘的树245生成的最佳猜测240与在捕获图像200中显示的树245相关联。例如，假设为所描绘的树245生成“树” 240的最佳猜测。在一个实施例以及图2的示例中，“树”240与在移动相机设备显示器290上输出的捕获图像200中的树245的图像相关联并与之一起显示。</p>
    <p>[0063]	再次参考图1D，在一个实施例中，在判定块160确定是否用户已确认已为之生成一个或多个最佳猜测的捕获图像中的场景和/或描绘的实体和/或对象的身份。在一个实施例中，用户通过触摸与捕获图像中的场景、实体或对象相关联并与之一起显示的最佳猜测标识来确认所描绘的场景或实体或对象的身份。例如，并且参考图2，在这个实施例中，用户通过触摸与在移动相机设备显示器290上输出的捕获图像200相关联并显示在捕获图像200内的“Redmond, Washington” 250而将所描绘的场景身份确认为“Redmond, Washington，，。[0064]	在其他的实施例中，用户通过各种其他的输入机制、例如通过选择最佳猜测并按压移动相机设备显示器290上的触摸屏确认按钮260、选择最佳猜测并在移动相机设备小型键盘上键入预定按键等等来确认其中描绘的已为之生成了至少一个最佳猜测的所描绘场景、实体和对象的身份。</p>
    <p>[0065]	如果在判定块160用户已确认场景信息的最佳猜测标识，那么在一个实施例中最佳猜测标识作为捕获图像162的标签进行存储。在一个实施例中，与描绘所确认的场景信息的在先图像、场景元素特征和/或分类符一起存储的任何相关的标签信息也作为捕获图像162的标签来存储。</p>
    <p>[0066]	如果在判定块160用户交替地指示用于场景信息的最佳猜测或最佳猜测池中所有的最佳猜测是不正确的，那么在一个实施例中，在判定块164确定是否存在对于捕获图像的场景或所描绘的实体或对象的用户输入。例如，并且再次参考图2，当例如通过用户首先选择了在输出给用户的捕获图像上显示的一个或多个最佳猜测标识等而选择错误的捕获场景最佳猜测标识250时，例如，通过选择在移动相机设备显示器290上的触摸屏错误按钮270,用户可以指示用于捕获图像场景的“Redmond, Washington” 250的最佳猜测是不正确的。用户可以此后通过例如在使用与移动相机设备相关联的小型键盘或触摸屏中键入这个标识、从实体信息中存储的并由用户可访问的列表中选择正确的场景标识等等而输入用于捕获图像的正确的场景标识，例如“Sammamish, Washington”。</p>
    <p>[0067]	返回参考图1D，如果在判定块164对于用户未接受为之生成的任何最佳猜测的捕获图像中描绘的场景信息具有用户输入，那么在一个实施例中，该用户输入作为捕获图像 166的标签来存储。</p>
    <p>[0068]	在一个实施例中，无论用户是已确认对于场景信息的最佳猜测标识还是指示最佳猜测或最佳猜测池是不正确的并提供正确的标识，对实体信息进行搜索，以查找与已确认的场景信息168的身份相关联的任何通信地址。在一个实施例中，在判定块170确定是否存在与已存储的实体信息中已确认的场景信息相关联的任何通信地址。如果是的话，在一个实施例中，捕获图像被自动发送到每一个与实体信息172中已确认的场景信息相关联的通信地址。</p>
    <p>[0069]	在一个实施例中，在判定块174确定是否具有对于用户尚未确认或者交替地已指示是错误的场景信息的任何更多的最佳猜测。如果是的话，在一个实施例中，该逻辑流程返回到判定块160，在那儿再次确定用户是否已确认了场景信息的最佳猜测标识。</p>
    <p>[0070]	如果在判定块174没有更多的对于尚未被用户确认或校正的场景信息的最佳猜测，则在一个实施例中该逻辑流程返回到图IA的判定块102，在那儿再次确定是否用户希望获得现有实体信息。</p>
    <p>[0071]	在一个实施例中，用户能够同时确认为捕获图像中描绘的个人生成的所有的最佳猜测。在这个实施例的一个方面中，如果用户确定为捕获图像中的个人生成的每一个最佳猜测是正确的，那么用户能够选择在移动相机设备显示器290上的触摸屏确认所有按钮 265，并且每一个为显示的个人生成的最佳猜测将被确认并被处理，如在上面的实施例中所讨论的。在这个实施例的其他方面中，如果用户确定为捕获图像中的个人生成的每一个最佳猜测是正确的，那么用户能够利用其他的输入机制、例如在移动相机设备小型键盘上键击预定义按键等等来同时确认所有的这些最佳猜测。[0072]	在一个实施例中，用户能够同时确认为捕获图像中描绘的场景元素生成的所有的最佳猜测。在这个实施例的一个方面中，如果用户确定为捕获图像中的场景元素生成的每一个最佳猜测是正确的，那么用户能够在移动相机设备显示器290上选择触摸屏确认所有按钮265，并且每一个为显示的场景元素生成的最佳猜测将被确认和被处理，如在上面的实施例中所讨论的。在这个实施例的其他方面中，如果用户确定为捕获图像中的场景元素生成的每一个最佳猜测是正确的，那么用户能够利用其他的输入机制、例如在移动相机设备小型键盘上键击预定义按键等来同时确认所有的这些最佳猜测。</p>
    <p>[0073]	在一个实施例中，用户能够同时将所有的为捕获图像中描绘的个人生成的最佳猜测识别为不正确的。在这个实施例的一个方面中，如果用户确定为捕获图像中的个人生成的每一个最佳猜测是不正确的，那么用户能够在移动相机设备显示器290上选择触摸屏全部错误按钮275，并且每一个为显示的个人生成的最佳猜测将根据上面讨论的实施例被处理为错误的。在这个实施例的其他方面，如果用户确定为捕获图像中的个人生成的每一个最佳猜测是不正确的，那么用户能够利用其他的输入机制、例如键击移动相机设备小型键盘上的预定义按键等等而将所有的这些最佳猜测识别为错误的。</p>
    <p>[0074]	在一个实施例中，用户能够将所有的为捕获图像中描绘的场景元素生成的最佳猜测同时识别为不正确的。在这个实施例的一个方面，如果用户确定为捕获图像中的场景元素生成的每一个最佳猜测是不正确的，那么用户能够在移动相机设备显示器290上选择触摸屏全部错误按钮275，并且每一个为显示的场景元素生成的最佳猜测将依照在上面讨论的实施例被处理为错误的。在这个实施例的其他方面，如果用户确定为捕获图像中的场景元素生成的每一个最佳猜测是不正确的，那么用户能够同时利用其他的输入机制、例如在移动相机设备小型键盘上键击预定义按键等等而将所有的这些最佳猜测识别为错误的。</p>
    <p>[0075]	在替代实施例中，一旦捕获图像中描绘的一个或多个个人和/或一个或多个场景元素被正确地识别并与一个或多个通信地址相关联，用户主动确认将发送捕获图像到一个或多个通信地址。在这个替代实施例中，在选择个人或场景等等的同时，用户通过例如选择确认按钮260等等来指示对于个人或场景元素的最佳猜测是正确的。在这个替代实施例中，用户此后通过例如第二次选择确认按钮260、选择在移动相机设备显示器290上的第二发送按钮280、键击在移动相机设备小型键盘上的预定义按键等等来确认将发送捕获图像到相关联的通信地址。</p>
    <p>[0076]	在这个替代实施例的一个方面中，通过例如从输出给用户的列表中选择一个或多个通信地址等等，用户能够选择与捕获图像中识别的个人或场景元素相关联的该图像应被发送至或者交替地不应被发送至的一个或多个通信地址。在这个替代实施例的这个方面中，捕获图像此后将被自动发送到用户已选择用于发送的通信地址，或者交替地，捕获图像将不被发送到用户已指示不应用于转发捕获图像至的那些通信地址。</p>
    <p>[0077]	如前所提到的，在一个实施例中，图1A-1D的逻辑流程在用户的移动相机设备上进行处理。在其他的实施例中，图1A-1D的逻辑流程的步骤的子集在另一个设备上、例如在服务器上托管的云（cloud)或不同于用户的移动相机设备的其他计算设备上进行处理。例如，在一个替代实施例中，用户的移动相机设备发送捕获图像和/或其中描绘的特征到云， 其中云对捕获图像和/或描绘特征运行面部识别和图像场景识别技术。在这个替代实施例中，云将其结果发回给用户的移动相机设备，以便进行任何进一步的用户交互，例如任何生成的最佳猜测的用户确认。</p>
    <p>[0078]	参考图3，实施例图像共享应用或图像共享应用300处理在用户的移动相机设备 350上捕获的图像，以便发送到其他的用户和/或设备。在一个实施例中，图像共享应用300 在用户的移动相机设备350上进行托管和运行。</p>
    <p>[0079]	在一个实施例中，图像共享应用300中的上传图像程序315管理当前存储在用户的移动相机设备350之外的其他设备上、例如当前存储在硬盘驱动器、用户的台式计算机、 USB棒驱动器等上的在先捕获图像345以及任何相关联的标签340的上传。在一个实施例中，上传图像程序315分析与每一个上传的图像345相关联的标签340，并将上传的图像 355及其相关联的标签340存储在图像数据库320中。在一个实施例中，图像数据库320在用户的移动相机设备350上进行托管。在其他的实施例中，图像数据库320在用户的移动相机设备350通信可访问的其他存储设备例如USB棒驱动器上进行托管。在一个实施例中， 相关联的标签340被包括在包含捕获图像345的文件内。</p>
    <p>[0080]	在实施例中，上传图像程序315并且或交替地管理从在先捕获图像345以及任何相关联的标签340中提取的图像特征345例如面部特征、图像对象和/或元素例如树、山脉、汽车等等和/或图像对象和/或元素特征例如树上的叶子、汽车上的轮子等等的上传。 在一个实施例中，上传的图像特征355以及任何相关联的标签340被存储在图像数据库320 中。在一个实施例中，相关联的标签340被包括在包含捕获的特征、对象和/或元素345的文件内。在一个实施例中，上传的特征345由图像共享应用300的面部识别技术和场景识别技术用来为捕获的图像个人和元素生成最佳猜测。</p>
    <p>[0081]	在一个实施例中，图像共享应用300中的上传图像程序315生成、填充、修改和访问图像数据库320，并因而为了在这里描述的目的，图像数据库320被显示为图像共享应用 300的组件。</p>
    <p>[0082]	在一个实施例中，用户370能够启动现有实体信息330例如联系人列表、地址薄、 图像共享规则等等到用户的移动相机设备350的上传。在一个实施例中，用户370也能够或交替地使用例如小型键盘、触摸屏、语音激活等等将实体信息330输入到用户的移动相机设备350。在一个实施例中，图像共享应用300的实体信息程序305管理现有实体信息 330的上传以及用户生成的实体信息330到用户的移动相机设备350的输入。</p>
    <p>[0083]	在一个实施例中，实体信息程序305分析接收到的实体信息330，并将实体信息 380或从380中导出的实体信息存储在实体信息数据库310中。在一个实施例中，实体信息数据库310在用户的移动相机设备350上进行托管。在其他实施例中，实体信息数据库310 在用户的移动相机设备350通信可访问的其他存储设备例如USB棒驱动器上进行托管。</p>
    <p>[0084]	在一个实施例中，实体信息程序305生成、填充、修改和访问实体信息数据库310， 并因而为了在这里描述的目的，该实体信息数据库310被显示为图像共享应用300的组件。</p>
    <p>[0085]	在一个实施例中，用户370利用其包括相机的移动相机设备350来捕获图像355， 例如拍照。在一个实施例中，捕获图像335利用图像共享应用300的图像程序325来处理。 在一个实施例中，图像程序325结合在图像数据库320中存储的一个或多个其他图像355 和/或从在先捕获图像345中提取的一个或多个存储的特征355来分析捕获图像335，以尝试为捕获图像335中描绘的一个或多个人员生成最佳猜测或交替地生成最佳猜测池。在一个实施例中，该图像程序325结合在图像数据库320中存储的一个或多个其他图像355和/或从在先捕获图像345中提取的一个或多个存储的特征和/或分类符355来分析捕获图像335，以尝试为一个或多个场景元素例如图像场景位置、任何图像地标和/或一个或多个图像实体或对象例如花卉、汽车、建筑物等等生成最佳猜测或交替地生成最佳猜测池。</p>
    <p>[0086]	在一个实施例中，图像程序325在为捕获图像个人和场景元素生成最佳猜测中利用存储的标签355中的信息。</p>
    <p>[0087]	在一个实施例中，图像程序325将其最佳猜测覆盖在图2的示例中所描绘的并对照图2的示例所描述的捕获图像335中相应的个人或场景元素上，并且结果在移动相机设备显示器290上被输出给用户370，以便确认和/或用户输入。在一个实施例中，当图像共享应用300接收到对于图像共享应用生成的最佳猜测的用户确认375时，图像程序325访问实体信息数据库310，以确定是否具有与所确认的个人或场景元素相关联的任何通信地址。如果是的话，在一个实施例中，图像程序325经由一个或多个通信网络365例如因特网、 一个或多个基于SMS的网络、一个或多个电话系统网络等等将捕获图像335自动发送到与确认的个人或场景元素相关联的通信地址。在这个实施例的一个方面中，图像程序325借助于其相关联的一个或多个通信网络365将捕获图像335无线发送到相应的通信地址。</p>
    <p>[0088]	在一个实施例中，当图像共享应用300接收到识别捕获图像个人或场景元素的用户输入385时，图像程序325访问实体信息数据库310，以确定是否具有与用户识别的个人或场景元素相关联的任何通信地址。如果是的话，在一个实施例中，图像程序325经由一个或多个通信网络365将捕获图像335自动发送到与用户识别的个人或场景元素相关联的通信地址。在这个实施例的一个方面中，图像程序325将捕获图像335经由其相关联的一个或多个通信网络365无线发送到相应的通信地址。</p>
    <p>[0089]	在一个替代实施例中，如果存在与用户确认的最佳猜测或与用户识别的捕获图像 335中的个人或场景元素相关联的通信地址，用户370则通过例如第二次在移动相机设备显示器290上选择触摸屏确认按钮260、在移动相机设备显示器290上选择触摸屏发送按钮280、键击与移动相机设备350相关联的小型键盘上的预定义按键等等来明确命令移动相机设备350发送捕获图像335到一个或多个相关联的通信地址。</p>
    <p>[0090]	在一个实施例中，被用户370确认375的所生成的最佳猜测信息例如个人身份、图像捕获位置、地标标识等用于为捕获图像335生成一个或多个标签。在一个实施例中，用户生成的捕获图像个人和场景元素的标识例如个人身份、图像捕获位置、地标标识等等用于为捕获图像335生成一个或多个标签。在一个实施例中，所生成的标签355与图像数据库 320中存储的捕获图像355和/或捕获图像提取的特征355 &#8212;起进行存储或以其他方式与之相关联。</p>
    <p>[0091]	在一个实施例中，图像程序325取得与捕获图像335相关的GPS生成的信息，例如可靠的位置和时间信息，并在一个或多个与捕获图像335相关联的标签中使用这个信息。 在替代实施例中，由图像共享应用300用于处理和标记捕获图像335的时间信息由其他设备和/或系统例如移动相机设备时钟、蜂窝电话传输塔等等来生成。</p>
    <p>[0092]	在一个实施例中，图像程序325将捕获图像335存储在图像数据库320中。在一个替代实施例中，捕获图像335可由上传图像程序315访问，其中该程序分析为捕获图像335 生成的任何标签，并将捕获图像335及其相关联的标签存储在图像数据库320中。</p>
    <p>[0093]	在实施例中，捕获图像提取的特征例如面部特征、图像元素和/或对象、和/或图像元素和/或对象特征也被存储或替代地被存储在图像数据库320中。在一个实施例中， 图像程序325将捕获图像提取的特征存储在图像数据库320中。在一个替代实施例中，从捕获图像335中提取的特征可由上传图像程序315访问，其中该程序分析为捕获图像335 生成的任何标签和/或其提取的特征，并将提取的特征以及任何图像或特征相关联的标签存储在图像数据库320中。</p>
    <p>[0094]	在一个替代实施例中，一个或多个用于处理捕获图像335以及发送捕获图像335 到一个或多个通信地址和/或用户的移动相机设备350之外的设备的任务在对于图像共享应用300而言经由一个或多个通信网络365例如因特网是可访问的云360中执行,也就是说，所述任务借助于云计算来运行。在这个替代实施例的一个方面中，图像数据库320在远离用户的移动相机设备350的远程服务器上进行托管。在这个替代实施例的这个方面中， 当用户370捕获到图像335时，图像程序325发送捕获图像335到云360。在这个替代实施例的这个方面中，云360相对于图像数据库320中存储的在先捕获图像355和/或从在先捕获图像355中提取的特征来分析捕获图像335，并尝试为捕获图像335中描绘的个人和/ 或场景元素生成最佳猜测。在这个替代实施例的这个方面中，云360发送其生成的最佳猜测到图像共享应用300，其中所述应用借助于图像程序325将最佳猜测覆盖在捕获图像335 中相应的个人或场景元素上，如图2的示例中所描绘的，并且结果被输出给用户370，以便确认和/或用户输入。</p>
    <p>[0095]	图4描述具有捕获图像、识别捕获图像的接收方以及与识别的接收方共享捕获图像的能力的移动相机设备350的实施例。在一个实施例中，参考图3讨论的图像共享应用 300运行在移动相机设备350上。在一个实施例中，捕获图像程序420运行在移动相机设备 350上，用于捕获图像335，该图像随后能够被用户、摄影师370以及其他人查看、存储并利用图像共享应用300来处理，以便与其他个人和/或设备共享。</p>
    <p>[0096]	在一个实施例中,GPS全球定位系统程序410运行在移动相机设备350上，以导出与捕获图像335相关的可靠的位置和时间信息。在一个实施例中，GPS程序410与能够识别当前时间以及当前位置的一个或多个方面例如经度、纬度等等的移动相机设备350的一个或多个传感器通信。在一个实施例中，GPS程序410为捕获图像335导出当前GPS信息， 其随后对于图像共享应用300而言可用于处理和共享捕获图像335。</p>
    <p>[0097]	在一个实施例中，用户I/O输入/输出程序425运行在移动相机设备350上，以便与用户370通信。在实施例中，用户I/O程序425借助于一个或多个输入机制从用户370 接收输入例如数据、命令等，其中输入机制包括但不限于小型键盘、触摸屏、语音激活技术等等。在实施例中，用户I/O程序425向用户370输出图像和数据，例如最佳猜测、命令屏幕等等。在一个实施例中，用户I/O程序425与图像共享应用300通信或以其他方式与之协力操作，以提供用户输入给图像共享应用300和接收图像、其上覆盖有最佳猜测的图像、 将经由例如移动相机设备显示器290等等输出给用户370的命令屏幕。</p>
    <p>[0098]	在一个实施例中，设备I/O程序435运行在移动相机设备350上，以便与其他设备 440例如USB棒驱动器等通信，从而上传或输入（import)先前捕获的图像345、和/或从先前捕获的图像345中提取的特征和/或先前生成的实体信息330。在一个实施例中，设备I/ O程序435也能够与例如USB棒驱动器等的其他设备440通信，从而下载或输出（export) 捕获图像355和/或从355中提取的特征、捕获图像和/或提取的特征标签355和/或用户生成的实体信息380，以便存储在其上面。在一个实施例中，设备I/O程序435与图像共享应用300通信或以其他方式与之协力操作，以输入或输出捕获图像和/或从中提取的特征、输入或输出捕获图像和/或提取的特征标签、输入或输出实体信息等等。</p>
    <p>[0099]	在一个实施例中，在这里也被称为comnet (通信网络）1/0程序的通信网络I/O程序415运行在移动相机设备350上，以便与一个或多个通信网络365通信,从而例如上传先前捕获的图像345、上传从先前捕获的图像345中提取的特征345、上传先前生成的实体信息330、发送捕获图像355到一个或多个个人或其他设备、与云360通信，用于图像处理和共享目的等等。在一个实施例中，通信网络I/O程序415与图像共享应用300通信或以其他方式与之协力操作，以执行无线通信网络输入和输出操作，其中所述操作支持图像共享应用对捕获图像335的处理和共享。</p>
    <p>[0100]计算设备系统配置</p>
    <p>[0101]图5是示出能够对其实现实施例的示例计算设备系统500的框图。计算设备系统或计算设备500的示例包括但不限于：计算机，例如台式计算机、在这里也被称为膝上型计算机的计算机膝上型、笔记本等等；智能电话；拍照电话；具有因特网通信和处理能力的相机等等。</p>
    <p>[0102]	实施例计算设备系统500包括总线505或用于传送信息的其他机制以及与总线 505相耦合以处理信息的处理单元510，其中处理单元510在这里也被称为处理器510。计算设备系统500也包括系统存储器515，其可以是易失性的或动态的，诸如随机存取存储器 (RAM)，也可以是非易失性的或静态的，诸如只读存储器（ROM)或闪存，或这二者的某种组合。系统存储器515被耦合到总线505，用于存储信息以及将由处理单元510执行的指令， 并且也可以用于在由处理器510运行指令期间存储临时变量或其他的中间信息。系统存储器515时常包含操作系统以及一个或多个程序或应用和/或软件代码，并且也可以包括程序数据。</p>
    <p>[0103]	在一个实施例中，诸如磁盘或光盘之类的存储设备520也被耦合到总线505，以存储包括指令的程序代码和/或数据的信息。在实施例计算设备系统500中，存储设备520 是计算机可读存储设备或机器可读存储设备520。</p>
    <p>[0104]	实施例计算设备系统500 &#8212;般包括一个或多个用于向计算设备用户提供信息的显示设备535，诸如但不限于例如阴极射线管（CRT)或液晶显示器（LCD)之类的显示屏、打印机以及一个或多个扬声器。实施例计算设备系统500也一般包括一个或多个输入设备 530，诸如但不限于小型键盘、鼠标、轨迹球、笔、一个或多个语音输入设备以及触摸输入设备，其中用户可以利用这些输入设备来向处理器510传送信息和命令选择。所有这些设备在本领域中是已知的，并且无需在这里对其进行详细讨论。</p>
    <p>[0105]	处理器510运行包含在系统存储器515中的一个或多个序列的一个或多个程序或应用和/或软件代码指令。这些指令可以从另一计算设备可读介质读入系统存储器515 中，其中计算设备可读介质包括但不限于存储设备520。在替代实施例中，可以使用硬布线电路来替代软件指令或与之相结合。实施例计算设备系统500环境不限于硬件电路和/或软件的任何特定组合。</p>
    <p>[0106]	这里使用的术语“计算设备可读介质”指的是任何能够参与向处理器510提供程序或应用和/或软件指令以便运行的介质。这样的介质可以采用许多形式，这包括但不限于存储媒体和传输媒体。存储媒体的示例包括但不限于RAM、R0M、EEPR0M、闪存、CD_R0M、USB 棒驱动器、数字多用途碟片（DVD)、磁带盒、磁带、磁盘存储设备或任何其他的磁介质、软盘、 柔性盘、凿孔卡、纸带或任何其他的具有孔洞图案的物理介质、存储器芯片或盒式磁盘。实施例计算设备500中的系统存储器515和存储设备520是存储媒体的进一步示例。传输媒体的示例包括但不限于：有线媒体，诸如一条或多条同轴电缆、铜线和光纤，以及无线媒体， 诸如光信号、声信号、RF信号和红外信号。</p>
    <p>[0107]	实施例计算设备系统500也包括耦合到总线505的一个或多个通信连接550。一个或多个实施例通信连接550提供从计算设备系统500耦合到局域网（LAN) 565和/或广域网（WAN)上的其他计算设备的双向数据通信，其中广域网包括万维网或因特网570以及各种其他的通信网络365，例如基于SMS的网络、电话系统网络等等。一个或多个通信连接 550的示例包括但不限于综合服务数字网络（ISDN)卡、调制解调器、LAN卡以及任何能够发送和接收电信号、电磁信号、光信号、声信号、RF或红外信号的设备。</p>
    <p>[0108]	由实施例计算设备系统500接收的通信能够包括程序或应用和/或软件指令和数据。由实施例计算设备系统500接收的指令可以在被接收时由处理器510运行和/或存储在存储设备520或其他的非易失性存储设备中，以便稍后运行。</p>
    <p>[0109]</p>
    <p>[0110]	虽然在这里描述各种实施例，但是这些实施例仅利用示例来介绍，并且不打算限制所请求保护的主题的范围。保留在随后的权利要求书的范围内的众多变体是可能的。这样的变体在检查这里的说明书、附图和权利要求书之后是清楚的。因此，除了利用随后的权利要求书及其等价物所限定的之外，所请求保护主题的广度和范围将不受限制。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用的专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101843086A?cl=zh">CN101843086A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年6月23日</td><td class="patent-data-table-td patent-date-value">2010年9月22日</td><td class="patent-data-table-td ">诺基亚公司</td><td class="patent-data-table-td ">在维持于电子设备中的联系人列表中使用图像的装置、方法和计算机程序产品</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D20090093663A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGLKmskR7dv1RRvVDG-Zc-oXGVvSQ">KR20090093663A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">没有名称</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7068309">US7068309</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2001年10月9日</td><td class="patent-data-table-td patent-date-value">2006年6月27日</td><td class="patent-data-table-td ">Microsoft Corp.</td><td class="patent-data-table-td ">Image exchange with image annotation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050011959">US20050011959</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2004年6月15日</td><td class="patent-data-table-td patent-date-value">2005年1月20日</td><td class="patent-data-table-td ">Grosvenor David Arthur</td><td class="patent-data-table-td ">Tags and automated vision</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060133699">US20060133699</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2005年10月7日</td><td class="patent-data-table-td patent-date-value">2006年6月22日</td><td class="patent-data-table-td ">Bernard Widrow</td><td class="patent-data-table-td ">Cognitive memory and auto-associative neural network based search engine for computer and network located images and photographs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080218407">US20080218407</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2007年3月8日</td><td class="patent-data-table-td patent-date-value">2008年9月11日</td><td class="patent-data-table-td ">Carl Jacob Norda</td><td class="patent-data-table-td ">Digital camera with GNSS picture location determination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090280859">US20090280859</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2008年5月12日</td><td class="patent-data-table-td patent-date-value">2009年11月12日</td><td class="patent-data-table-td ">Sony Ericsson Mobile Communications Ab</td><td class="patent-data-table-td ">Automatic tagging of photos in mobile devices</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0029120000">H04L29/12</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04M0001725000">H04M1/725</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=H04L0029080000">H04L29/08</a></span></td></tr><tr><td class="patent-data-table-td "> 合作分类</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32096">H04N1/32096</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3253">H04N2201/3253</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32037">H04N1/32037</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3205">H04N2201/3205</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/00307">H04N1/00307</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/0044">H04N1/0044</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=VpiJBwABERAJ&amp;q=http://worldwide.espacenet.com/classification&amp;usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32128">H04N1/32128</a></span></td></tr><tr><td class="patent-data-table-td "> 欧洲专利分类号</td><td class="patent-data-table-td "><span class="nested-value">H04N1/00D3D4</span>, <span class="nested-value">H04N1/00C7D</span>, <span class="nested-value">H04N1/32B</span>, <span class="nested-value">H04N1/32C17</span>, <span class="nested-value">H04N1/32B11</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2012年7月18日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2012年9月19日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Entry into substantive examination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年6月24日</td><td class="patent-data-table-td ">C41</td><td class="patent-data-table-td ">Transfer of patent application or patent right or utility model</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年6月24日</td><td class="patent-data-table-td ">ASS</td><td class="patent-data-table-td ">Succession or assignment of patent right</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MICROSOFT TECHNOLOGY LICENSING LLC</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FORMER OWNER: MICROSOFT CORP.</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20150608</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">2015年11月25日</td><td class="patent-data-table-td ">C14</td><td class="patent-data-table-td ">Grant of patent or utility model</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/6bbc7fbe5b4c61a3e8e1/CN102594857A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E4%B8%8A%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%92%8C%E5%85%B1%E4%BA%AB.pdf?id=VpiJBwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U2x-9wOM3UvFWK2XVXRx7jLtullGA"},"sample_url":"https://www.google.com/patents/reader?id=VpiJBwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>