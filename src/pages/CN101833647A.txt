<!DOCTYPE html><html><head><title>专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法 -  Google 专利</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_6e802a6b2b28d51711baddc2f3bec198/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_6e802a6b2b28d51711baddc2f3bec198__zh_cn.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "zh",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="掌纹图像的获取设备及掌纹图像处理方法"><meta name="DC.contributor" content="孙哲南" scheme="inventor"><meta name="DC.contributor" content="谭剑波" scheme="inventor"><meta name="DC.contributor" content="谭铁牛" scheme="inventor"><meta name="DC.contributor" content="韩宇飞" scheme="inventor"><meta name="DC.contributor" content="中国科学院自动化研究所" scheme="assignee"><meta name="DC.date" content="2009-3-11" scheme="dateSubmitted"><meta name="DC.description" content="本发明涉及一种掌纹图像获取设备及掌纹图像处理方法，图像传感器和点状光源封装在小盒中，点状光源均匀散布于图像传感器周边；图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于在环境光中获取放置在手放置台上的包含用户手形状信息的手图像；个人计算机使用掌纹图像处理方法从图像传感器获取的手图像中提取掌纹图像，并从中提取掌纹图像特征，然后与存储设备存储用户注册的掌纹图像特征模板进行掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实现对用户身份的鉴别。掌纹图像处理方法校正手位置不固定带来的手图像的偏移和偏转，得到掌纹图像，消除环境光单调性变化带来的影响，提取稳定的掌纹图像特征。"><meta name="DC.date" content="2010-9-15"><meta name="citation_patent_publication_number" content="CN:101833647:A"><meta name="citation_patent_application_number" content="CN:200910079804"><link rel="canonical" href="https://www.google.com/patents/CN101833647A?cl=zh"/><meta property="og:url" content="https://www.google.com/patents/CN101833647A?cl=zh"/><meta name="title" content="专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法"/><meta name="description" content="本发明涉及一种掌纹图像获取设备及掌纹图像处理方法，图像传感器和点状光源封装在小盒中，点状光源均匀散布于图像传感器周边；图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于在环境光中获取放置在手放置台上的包含用户手形状信息的手图像；个人计算机使用掌纹图像处理方法从图像传感器获取的手图像中提取掌纹图像，并从中提取掌纹图像特征，然后与存储设备存储用户注册的掌纹图像特征模板进行掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实现对用户身份的鉴别。掌纹图像处理方法校正手位置不固定带来的手图像的偏移和偏转，得到掌纹图像，消除环境光单调性变化带来的影响，提取稳定的掌纹图像特征。"/><meta property="og:title" content="专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}

#gbar { padding:.3em .6em !important;}</style></head><body ><div id=gbar><nobr><a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&sa=N&tab=tw">搜索</a> <a class=gb1 href="https://www.google.com/search?cl=zh&hl=zh-CN&tbm=isch&source=og&sa=N&tab=ti">图片</a> <a class=gb1 href="https://maps.google.com/maps?cl=zh&hl=zh-CN&sa=N&tab=tl">地图</a> <a class=gb1 href="https://play.google.com/?cl=zh&hl=zh-CN&sa=N&tab=t8">Play</a> <a class=gb1 href="https://www.youtube.com/results?cl=zh&hl=zh-CN&sa=N&tab=t1">YouTube</a> <a class=gb1 href="https://news.google.com/nwshp?hl=zh-CN&tab=tn">新闻</a> <a class=gb1 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a class=gb1 href="https://drive.google.com/?tab=to">云端硬盘</a> <a class=gb1 style="text-decoration:none" href="https://www.google.com/intl/zh-CN/options/"><u>更多</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN&hl=zh-CN" class=gb4>登录</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="https://www.google.com/patents/CN101833647A?cl=zh&amp;hl=zh-CN&amp;output=html_text" title="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"><img border="0" src="//www.google.com/images/cleardot.gif"alt="屏幕阅读器用户请注意：点击此链接可进入无障碍模式。阅读器在无障碍模式下具有同样的基本功能，但可让用户获得更好的体验。"></a></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents?hl=zh-CN"> 专利</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/CN101833647A"></a><a id="appbar-patents-discuss-this-link" href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpublication%3DCN101833647A&amp;usg=AFQjCNH0kOMxzUiYgbGgPKSP4JcEx97kjg" data-is-grant="false"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/99b28bf0a2cd883142bd/CN101833647A.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/99b28bf0a2cd883142bd/CN101833647A.pdf"></a><a class="appbar-content-language-link" data-selected="true" data-label="中文" href="/patents/CN101833647A?cl=zh&amp;hl=zh-CN"></a><a class="appbar-content-language-link" data-label="英语" href="/patents/CN101833647A?cl=en&amp;hl=zh-CN"></a><a class="appbar-application-grant-link" data-selected="true" data-label="申请" href="/patents/CN101833647A?hl=zh-CN&amp;cl=zh"></a><a class="appbar-application-grant-link" data-label="授权" href="/patents/CN101833647B?hl=zh-CN&amp;cl=zh"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="https://www.google.com/patents/CN101833647A?cl=zh" style="display:none"><span itemprop="description">本发明涉及一种掌纹图像获取设备及掌纹图像处理方法，图像传感器和点状光源封装在小盒中，点状光源均匀散布于图像传感器周边；图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于在环境光中获取放...</span><span itemprop="url">https://www.google.com/patents/CN101833647A?cl=zh&amp;utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法</span><img itemprop="image" src="https://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法" title="专利 CN101833647A - 掌纹图像的获取设备及掌纹图像处理方法"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="https://www.google.com/advanced_patent_search?hl=zh-CN"> 高级专利搜索</a></li></ol></div><div id="volume-main"><div id="volume-center"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata patent-drawings-missing"><tr><td class="patent-bibdata-heading"> 公开号</td><td class="single-patent-bibdata">CN101833647 A</td></tr><tr><td class="patent-bibdata-heading">发布类型</td><td class="single-patent-bibdata">申请</td></tr><tr><td class="patent-bibdata-heading"> 专利申请号</td><td class="single-patent-bibdata">CN 200910079804</td></tr><tr><td class="patent-bibdata-heading">公开日</td><td class="single-patent-bibdata">2010年9月15日</td></tr><tr><td class="patent-bibdata-heading"> 申请日期</td><td class="single-patent-bibdata">2009年3月11日</td></tr><tr><td class="patent-bibdata-heading"> 优先权日<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="优先日期属于假设性质，不具任何法律效力。Google 对于所列日期的正确性并没有进行法律分析，也不作任何陈述。"></span></td><td class="single-patent-bibdata">2009年3月11日</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">公告号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101833647B?hl=zh-CN&amp;cl=zh">CN101833647B</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading"> 公开号</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">200910079804.4, </span><span class="patent-bibdata-value">CN 101833647 A, </span><span class="patent-bibdata-value">CN 101833647A, </span><span class="patent-bibdata-value">CN 200910079804, </span><span class="patent-bibdata-value">CN-A-101833647, </span><span class="patent-bibdata-value">CN101833647 A, </span><span class="patent-bibdata-value">CN101833647A, </span><span class="patent-bibdata-value">CN200910079804, </span><span class="patent-bibdata-value">CN200910079804.4</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 发明者</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E5%AD%99%E5%93%B2%E5%8D%97%22">孙哲南</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B0%AD%E5%89%91%E6%B3%A2%22">谭剑波</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E8%B0%AD%E9%93%81%E7%89%9B%22">谭铁牛</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=ininventor:%22%E9%9F%A9%E5%AE%87%E9%A3%9E%22">韩宇飞</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading"> 申请人</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="https://www.google.com/search?tbo=p&amp;tbm=pts&amp;hl=en&amp;q=inassignee:%22%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80%22">中国科学院自动化研究所</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">导出引文</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN101833647A.bibtex?cl=zh">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101833647A.enw?cl=zh">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101833647A.ris?cl=zh">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#forward-citations"> 被以下专利引用</a> (11),</span> <span class="patent-bibdata-value"><a href="#classifications">分类</a> (3),</span> <span class="patent-bibdata-value"><a href="#legal-events">法律事件</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">外部链接:&nbsp;</span><span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp%3Frecid%3D200910079804&amp;usg=AFQjCNG4wUL49nI4LXV1JzEX3U8cvweYGw"> 中国国家知识产权局</a>, </span><span class="patent-bibdata-value"><a href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DCN%26NR%3D101833647A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGvfBMnH6DpGWIKMjqvvfUjniVRqw"> 欧洲专利数据库 (Espacenet)</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT97855295" lang="ZH" load-source="patent-office">掌纹图像的获取设备及掌纹图像处理方法</invention-title>
      </span><br><span class="patent-number">CN 101833647 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title"> 摘要</span></div><div class="patent-text"><abstract mxw-id="PA80331688" lang="ZH" load-source="patent-office">
    <div class="abstract">本发明涉及一种掌纹图像获取设备及掌纹图像处理方法，图像传感器和点状光源封装在小盒中，点状光源均匀散布于图像传感器周边；图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于在环境光中获取放置在手放置台上的包含用户手形状信息的手图像；个人计算机使用掌纹图像处理方法从图像传感器获取的手图像中提取掌纹图像，并从中提取掌纹图像特征，然后与存储设备存储用户注册的掌纹图像特征模板进行掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实现对用户身份的鉴别。掌纹图像处理方法校正手位置不固定带来的手图像的偏移和偏转，得到掌纹图像，消除环境光单调性变化带来的影响，提取稳定的掌纹图像特征。</div>
  </abstract>
  </div></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">权利要求<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><ol mxw-id="PCLM33150165" lang="ZH" load-source="patent-office" class="claims">
    <li class="claim"> <div num="1" class="claim">
      <div class="claim-text">一种掌纹图像的获取设备，其特征在于，该获取设备包含：图像传感器和点状光源封装在小盒中，点状光源均匀散布于图像传感器周边，用于给图像传感器提供光照；所述图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于在环境光中获取放置在手放置台上的包含用户手形状信息的手图像；存储设备和图像传感器通过基于通用串行总线接口协议的连接线分别与个人计算机连接；所述个人计算机使用掌纹图像处理方法从图像传感器获取的手图像中提取掌纹图像，并从中提取掌纹图像特征，然后与存储设备存储用户注册的掌纹图像特征模板进行掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实现对用户身份的鉴别。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2.根据权利要求1所述的设备，其特征在于，所述图像传感器与手放置台之间具有一 固定的距离，所述手放置台固定在支架或是嵌装在墙体或是物体上。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3.根据权利要求1所述的设备，其特征在于，所述手放置台的手形凹陷，用于提示手的 放置位置及放置方式，限定手最大的姿态变化。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4.根据权利要求1所述的设备，其特征在于，所述图像传感器采集用户手图像时，用户 手掌背面放在手放置台的手形凹陷中。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5.根据权利要求1所述的设备，其特征在于，所述手放置台还具有手指区域和手掌区 域镂空的手形凹陷。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6.根据权利要求5所述的设备，其特征在于，所述图像传感器采集用户手图像时，用户 手掌心放在手放置台的手指区域和手掌区域镂空的手形凹陷中或用户手掌背放在手放置 台的手指区域和手掌区域镂空的手形凹陷中。</div>
    </div>
    </li> <li class="claim"> <div num="7" class="claim">
      <div class="claim-text">7.	一种从图像传感器获取的手图像中提取掌纹图像，并获取掌纹图像特征的掌纹图像 处理方法，其特征在于，通过所述图像传感器和具有手形凹陷的手放置台获取手图像，在所 述个人计算机上通过所述掌纹图像处理方法处理所述手图像，获取掌纹图像，提取掌纹图 像特征，并将掌纹图像特征存储在存储设备中，其掌纹图像处理步骤包括：步骤1 ：用户将手放置在基于环境光中的手放置台上的手形凹陷中采集手图像，结合 手表皮颜色分布模型，图像传感器从采集到的手图像中将手从背景中分割出来，获得包含 手形状信息的二值化手图像；步骤2 ：个人计算机利用二值化手图像的形状矩对手图像的相对于图像坐标系水平方 向的偏转角度进行估计，以手图像中心为坐标原点，根据偏转角度将手图像旋转至图像坐 标系的水平方向，从而实现对手图像的旋转变化进行校正，得到旋转校正后的二值化的手 图像；步骤3:在旋转校正后的二值化的手图像中，采用形态学腐蚀操作去除手指区域，或采 用逐行扫描二值化手图像判断每行的图像连通性，从而去除手指区域，得到手图像的掌心 区域位置；步骤4:以掌心区域质心点为中心建立直角坐标系，消除手图像平移变化对掌纹图像 处理带来的不利影响，从而实现手图像的平移变化的校正；在所述直角坐标系中固定位置 截取固定大小的感兴趣的图像区域作为掌纹图像，并将掌纹图像作为特征提取区域；步骤5 ：利用一阶高斯导数滤波器求取经旋转和平移校正后的掌纹图像的梯度方向特 征，将每个像素点的梯度方向进行量化编码，由此构成一个二维的基于量化梯度方向特征的掌纹图像特征模板，并存储于存储设备中，用以解决单调环境光的变化对掌纹图像识别 的影响；通过计算在两个掌纹图像特征模板的对应位置上出现相同量化梯度方向编码的频 率，来衡量两个掌纹图像特征模板的相似性。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8.根据权利要求7所述的掌纹图像处理方法，其特征在于，从采集到的手图像中将手 从背景中分割出来，是利用所述原始图像的灰度图像里手区域和背景区域的像素灰度值的 分布差异确定二值化的阈值，所述二值化的阈值是利用所述原始图像里手表皮颜色在颜色 空间内的分布确定二值化的阈值。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9.根据权利要求7所述的掌纹图像理方法，其特征在于，对所述掌纹图像的梯度方向 的特征提取和比对，包括步骤：步骤a ：应用经旋转和平移校正后的掌纹图像水平和竖直方向上的二维一阶高斯导数 滤波器，对归一化掌纹图像进行滤波，求取归一化掌纹图像的每个像素点上梯度方向的角 度，其取值范围为W，2ji]；步骤b:将梯度方向角按照角度值大小量化为6个量化等级，每个梯度方向角度的量化 编码的取值范围为{0，1，2，3，4，5}中的任何一个整数由此构成一个二维的基于量化梯度 方向特征的掌纹图像特征模板，并存储于存储设备中；步骤c ：在特征比对过程中，通过计算在两个掌纹图像特征模板的对应位置上出现相 同量化梯度方向编码的频率，来衡量两个掌纹图像特征模板的相似性；步骤d ：相似度的取值范围为[0，1]这个闭区间，数值越大说明对应的两个掌纹图像特 征模板也越相似。</div>
    </div>
    </li> <li class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10.根据权利要求9所述的掌纹图像处理方法，其特征在于，所述梯度方向角度值，是 按梯度方向角度值大小量化为n个等级，当n较大时，增强量化后编码对局部图像纹理细节 的表达能力，当n较小时，增强量化编码对局部图像噪声的鲁棒性。</div>
    </div>
  </li> </ol>
  </div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title"> 说明</span></div><div class="patent-text"><div mxw-id="PDES38443627" lang="ZH" load-source="patent-office" class="description">
    <p>掌纹图像的获取设备及掌纹图像处理方法</p>
    <p>技术领域</p>
    <p>[0001]	本发明属于数字图像处理、模式识别和数据库管理技术领域，特别是一种在环境 光中的手图像采集，并在个人计算机终端上基于掌纹图像识别进行身份鉴别的身份认证系 统及其认证方法。</p>
    <p>背景技术</p>
    <p>[0002]	随着信息技术的蓬勃发展，计算机正在使人们的日常生活变得信息化和网络化。 人们已经可以通过互联的计算机，随时随地进行在线的银行账户处理，网上文献资料的检 索和下载，以及政府管理机构的政务公开处理等。个人计算机终端处理能力的增强，更拓 宽了计算机在人们日常使用中的领域，已经有技术利用个人计算机终端远程操作家电并且 监控家中的状况。在这些应用中，人们往往需要将一些涉及机密的数据，比如私人的文档， 私人履历等存放到个人终端计算机或或者通过互联网络发送到大型的服务器计算机上。在 开放的信息化网络化环境中，这些应用系统都必须有可靠的身份鉴别和认证方法，保护个 人的隐私不被非法盗取和泄漏。并根据判别出的用户身份对数据资源设置不同的访问权 限。目前常用的身份鉴别技术主要有两种方式，一种是通过对用户所拥有的钥匙，证件等标 识物进行身份的认证。例如在用户进门时，用钥匙开锁就是一个用钥匙进行认证的过程。 在机场通关前，要核查每个通关人的护照和签证，在进入保密部门前，需要检查来访者的证 件，这些核查过程都是一种利用标识物进行认证的方法。另一类方法是通过对用户所拥有 的某种知识，例如密码，进行身份的鉴别和认证。例如在登录特定网站或者访问特定数据资 源时，需要用户输入帐户名和口令进行身份的确认。这两种方法的弊端在于它们可能会被 用户丢失，遗忘或者被破解。个人计算机终端无法分辨出合法的用户和盗取了标识物或者 知识的非法入侵者，同时携带标识物和记忆知识对用户又是非常不方便的，现代人常常要 为带大量的卡片，记忆大量的密钥口令而苦恼。本发明就是充分利用个人计算机终端的处 理能力，基于掌纹图像的识别自动判别用户身份，从而有效地保护用户的个人隐私。</p>
    <p>[0003]	掌纹图像识别技术是生物特征识别技术的一种，利用人体本身具有的特征来进行 身份的确认鉴别。每个人手掌上都具有大量方向和粗细各异纹线结构。这些纹线是由于手 指运动，组织结构和皮肤质地等原因形成的。不同人的纹线结构所处的位置，方向和粗细， 都有较大的差异。掌纹图像识别就是通过分析人手掌中这些细节的纹线结构，对人们的身 份进行区分和认证。与虹膜，人脸以及指纹图像识别技术相比较，掌纹图像识别本身具有很 多优点。</p>
    <p>[0004]	与指纹相比，人手掌可以提供远大于指纹区域的面积，因此掌纹可以提供比指纹 更多的信息。而且不容易受到皮肤区域的损坏和遮挡的影响。同时实验数据证明了，掌纹 拥有比人脸和指纹更好的可区分特性。</p>
    <p>[0005]	虹膜数据的采集需要特制的较高分辨率的图像获取设备，在成像过程中需要用户 对获取设备所处的位置进行主动配合，而清晰的掌纹纹线结构可以用低分辨率（100dpi，几 万像素左右）的成像设备捕获到。通常的网络摄像头即可满足这个要求，硬件成本比较低廉。同时人手具有很好的灵活性，对掌纹图像的获取很方便，速度快。</p>
    <p>[0006]	现有的掌纹图像获取方法有三种：</p>
    <p>[0007]	方式一：先将手掌上涂上油墨，再将手掌掌纹印在白纸上，随后通过扫描仪将掌纹 扫描成灰度图像存储到计算机当中。这种方式获得的掌纹清晰程度受用户按压白纸的力度 有关，因此获取的图像质量容易受到用户配合程度的影响，不方便进行自动的掌纹图像识 另O。同时由于要沾污用户的手掌，因此这种采集方式的接受程度很低。</p>
    <p>[0008]	方式二 ：利用数码照相机将手区域拍摄成图像，然后输入到计算机中。由于采集过 程中用户手的姿态不同，在采集得到的手图像中会有图像区域的旋转，平移和尺度变化。不 方便进行自动的掌纹图像分析。从数码摄像到将图像输入到计算机中，需要比较长的图像 传输时间，因此这种图像采集方式不利于进行在线实时的掌纹图像分析。 [0009]	方式三：在图像获取过程中，用图像获取设备平台托住 用户的手，获取设备构成一 个封闭的采集环境；并内置支架，预留一窗口仅供手伸入，放在其内置支架的固定位置进行 图像采集。由这种方式可以获得手姿态变化较小的手图像，但由于其对外界光照比较敏感， 要求用户的配合程度较高，使用不够直观、便捷，不太适合大规模人群的身份鉴别应用。</p>
    <p>[0010]	关于掌纹图像识别，现在已有多种掌纹图像识别方法，如利用掌纹图像中线条状 纹理结构的灰度信息对线条结构的方向特性进行描述，从而提取出具有区分性的掌纹图像 特征。</p>
    <p>发明内容</p>
    <p>[0011]	要解决的技术问题：</p>
    <p>[0012]	为了解决现有技术需要对手的摆放位置、角度及姿态用立柱等方式进行唯一的固 定的问题，本发明的目的是在环境光中的手图像获取方式，不需要特殊的壳体对外界光进 行屏蔽，在图像采集过程中，用户只需将手放于手放置台上，特别的，手放置台上有一手形 凹陷的手模型，以便于提示用户进行手的摆放，用户的手在手形凹陷的范围内的摆放位置、 角度及姿态不受限制，以在个人计算机上实现利用掌纹图像识别，为此，本发明的目的是提 供一种掌纹图像的获取设备及掌纹图像处理方法。</p>
    <p>[0013]	为了达成所述目的，本发明的第一方面，是提供一种掌纹图像的获取设备，含有： 图像传感器和点状光源封装在小盒中，点状光源均&#21243;散布于图像传感器周边，用于给图像 传感器提供光照；</p>
    <p>[0014]	所述图像传感器的接收端与位于环境光中的手放置台的手形凹陷相对放置，用于 在环境光中获取放置在手放置台上的包含用户手形状信息的手图像；</p>
    <p>[0015]	存储设备和图像传感器通过基于通用串行总线接口协议的连接线分别与个人计 算机连接；所述个人计算机使用掌纹图像处理方法从图像传感器获取的手图像中提取掌纹 图像，并从中提取掌纹图像特征，然后与存储设备存储用户注册的掌纹图像特征模板进行 掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实现对用户身份的鉴别。</p>
    <p>[0016]	优选地，所述图像传感器与手放置台之间具有一固定的距离，所述手放置台固定 在支架或是嵌装在墙体或是物体上。</p>
    <p>[0017]	优选地，所述手放置台的手形凹陷，用于提示手的放置位置及放置方式，限定手最 大的姿态变化。[0018]	优选地，所述图像传感器采集用户手图像时，用户手掌背面放在手放置台的手形 凹陷中。</p>
    <p>[0019]	优选地，所述手放置台还具有手指区域和手掌区域镂空的手形凹陷。</p>
    <p>[0020]	优选地，所述图像传感器采集用户手图像时，用户手掌心放在手放置台的手指区 域和手掌区域镂空的手形凹陷中或用户手掌背放在手放置台的手指区域和手掌区域镂空 的手形凹陷中。</p>
    <p>[0021]	为了达成所述目的，本发明的第二方面，是提供一种处理掌纹图像获取设备获取 的掌纹图像的处理方法，所述掌纹图像的获取设备包括：图像传感器、具有手形凹陷的手放 置台、个人计算机、存储设备。通过所述图像传感器和具有手形凹陷的手放置台获取手图 像，在所述个人计算机上通过所述掌纹图像处理方法处理所述手图像，获取掌纹图像，提取 掌纹图像特征，并将掌纹图像特征存储在存储设备中，其掌纹图像处理步骤包括：</p>
    <p>[0022]	步骤1 ：用户将手放置在基于环境光中的手放置台上的手形凹陷中采集手图像， 结合手表皮颜色分布模型，图像传感器从采集到的手图像中将手从背景中分割出来，获得 包含手形状信息的二值化手图像；</p>
    <p>[0023]	步骤2 ：个人计算机利用二值化手图像的形状矩对手图像的相对于图像坐标系水 平方向的偏转角度进行估计，以手图像中心为坐标原点，根据偏转角度将手图像旋转至图 像坐标系的水平方向，从而实现对手图像的旋转变化进行校正，得到旋转校正后的二值化 的手图像；</p>
    <p>[0024]	步骤3 ：在旋转校正后的二值化的手图像中，采用形态学腐蚀操作去除手指区域， 或采用逐行扫描二值化手图像判断每行的图像连通性，从而去除手指区域，得到手图像的 掌心区域位置；</p>
    <p>[0025]	步骤4:以掌心区域质心点为中心建立直角坐标系，消除手图像平移变化对掌纹 图像处理带来的不利影响，从而实现手图像的平移变化的校正；在所述直角坐标系中固定 位置截取固定大小的感兴趣的图像区域作为掌纹图像，并将掌纹图像作为特征提取区域；</p>
    <p>[0026]	步骤5 ：利用一阶高斯导数滤波器求取经旋转和平移校正后的掌纹图像的梯度方 向特征，将每个像素点的梯度方向进行量化编码，由此构成一个二维的基于量化梯度方向 特征的掌纹图像特征模板，并存储于存储设备中，用以解决单调环境光的变化对掌纹图像 识别的影响；通过计算在两个掌纹图像特征模板的对应位置上出现相同量化梯度方向编码 的频率，来衡量两个掌纹图像特征模板的相似性。</p>
    <p>[0027]	本发明的有益效果是：克服了以往手图像获取设备为避免环境光的影响，特意营 造一个特殊的暗室环境，比如封闭壳体的缺点。本发明允许用户在进行认证时直观的看到 整个手图像的获取过程，更具直观性；同时手放置台上有一手形凹陷的手模型，以便于提示 用户进行手的摆放，用户的手在手形凹陷的范围内的摆放位置、角度及姿态不受限制，有效 地克服了以住手图像获取设备中对手的摆放位置、角度及姿态用立柱等方式进行唯一固定 的缺点，方便用户更加便捷地进行手图像的获取。因而更容易为用户所接受。特别适用于 大规模人群的身份认证应用场合。例如机场，海防关卡的安检等。</p>
    <p>[0028]	本发明的基于环境光中手图像获取的身份认证系统应用还包括，可用于对互联网络中，个人用户对服务器数据资源的访问管理，以及向公众开放的计算机终端上特定数据 的加密和访问控制。附图说明</p>
    <p>[0029]	图Ia为本发明手图像获取设备的结构原理示意图；</p>
    <p>[0030]	图Ib为本发明中手放置台带有手形凹陷手掌区域镂空的模型背景；</p>
    <p>[0031]	图Ic为本发明中手摆放在手放置台上获取的原始手图像；</p>
    <p>[0032]	图Id为本发明中手按压在手放置台上的姿势；</p>
    <p>[0033]	图Ie为本发明中手按压在手放置台上获取的原始掌纹图像；</p>
    <p>[0034]	图2a为本发明中掌纹图像预处理流程图；</p>
    <p>[0035]	图2b为本发明中手图像旋转校正的示意图；</p>
    <p>[0036]	图2c为本发明中定位手掌中心区域的示意；</p>
    <p>[0037]	图2d为本发明中归一化掌纹图像的示意图；</p>
    <p>[0038]	图3a为本发明中掌纹图像特征提取的流程图；</p>
    <p>[0039]	图3b为本发明中图像坐标系下水平方向上的一阶高斯导数滤波器的示意图；</p>
    <p>[0040]	图3c为本发明中图像坐标系下竖直方向上的一阶高斯导数滤波器的示意图；</p>
    <p>[0041]	图4 一个完整的基于所述的手图像获取设备的身份认证系统的流程图；</p>
    <p>[0042]	图5为本发明的一个图书馆资源访问用户的身份认证的实施例流程图。</p>
    <p>具体实施方式</p>
    <p>[0043]	以下结合附图和具体实施例对本发明进行描述。但不作为本发明的限定。</p>
    <p>[0044]	图Ia为手图像获取设备的结构原理示意图，包括带USB接口的图像传感器、点状 光源、手放置台，所述USB接口的图像传感器采用摄像头103，所述点状光源采用点状发光 二极管104，所述手放置台采用单色带手形凹陷的手放置台105。</p>
    <p>[0045]	点状发光二极管104均&#21243;散布在摄像头103周围，摄像头103正对着单色手放置 台105，摄像头103和所述的本地个人计算机终端之间的连接采用基于通用串行总线接口 协议（USB)的连接线101。所述摄像头103和点状发光二极管104封装在小盒102中，小盒 102与单色手放置台105采用支架、壳体或嵌装在墙体中或是物体上，从而固定摄像头103、 发光二极管104和单色手放置台105的相对位置。手图像获取设备采集图像的时候，将连 接线101连接上所述的个人计算机终端，为摄像头103及其配置在摄像头103周围的发光 二极管阵列104提供5V的工作电压。在采集图像的过程中，由发光二极管阵列104提供稳 定均&#21243;的光照条件，由单色手放置台105来提供干净的图像背景，便于后续的掌纹图像预 处理。当用户掌心朝上摆放在单色手放置台上时，摄像头103获取到一副或多幅包含整个 用户手区域的图像，由传输连接线101将获取到的用户手区域的图像传送到所述的个人计 算机503终端里。由摄像头103获取的手区域图像可以根据需要选择彩色图像或者黑白图 像。所述摄像头103的接收端与位于环境光中的手放置台105的手形凹陷相对放置，相距 20厘米&#12316;40厘米，用于在环境光中获取放置在手放置台105上的包含用户手形状信息的手 图像，将手从背景中分割出来，获得包含手形状信息的二值化手图像；</p>
    <p>[0046]	如图5中示出个人计算机503终端，根据所述掌纹图像处理方法对获取的手图像进行掌纹图像识别；存储设备508，存储用户注册的掌纹图像特征模板。存储设备508通过 基于通用串行总线接口协议的连接线101与个人计算机503连接，通过所述摄像头103和具有手形凹陷的手放置台105获取手图像，在所述个人计算机503上通过所述掌纹图像处 理方法处理所述手图像，获取掌纹图像，提取掌纹图像特征，并与存储设备508存储用户注 册的掌纹图像特征模板进行掌纹特征比对，对获取的用户手图像的掌纹图像进行识别，实 现对用户身份的鉴别。</p>
    <p>[0047]	图Ib示出在所述的手放置台的正面是一种带有手指区域和手掌区域镂空的手形 凹陷模型用于提示用户放置手，图像传感器的接收端位于手放置台的正面时，图像采集时， 手掌心朝下按在手放置台的手指区域和手掌区域镂空的手形凹陷中（简称按压式）。或所 述手放置台本体上具有一手指区域和手掌区域镂空的手形凹陷模型用于提示用户放置手， 图像传感器接收端还可以位于手放置台的反面（所述反面为不显示手指区域的一面），图 像采集时，手掌心向上、手掌背面向下直接摆放在手放置台上的手指区域和手掌区域镂空 的手形凹陷中（简称摆放式）。所述图像传感器与手放置台之间相距20厘米&#12316;40厘米。 所述手放置台利用支架或是嵌装在墙体或是物体之上，处于环境光中。</p>
    <p>[0048]	图Ic为采用摆放式获取的原始手图像；</p>
    <p>[0049]	图Id为采用按压式时手按压姿势；</p>
    <p>[0050]	图Ie为采用按压式获取的原始掌纹图像； [0051]	如图2a示出为掌纹图像预处理流程图。用户将手放置在基于环境光中手图像获 取设备的手放置台上的手形凹陷中进行手图像获取，为克服所述手图像获取设备获取的原 始手图像201存在的平移、旋转和手指姿态的变化，由所述个人计算机上的掌纹图像处理 模块校正不同手图像的旋转，得到校正后的手图像202，并在手图像202上定位手掌中心区 域203作为提取掌纹图像特征的归一化掌纹ROI区域，方便提取稳定的掌纹图像特征。其 具体步骤如下：</p>
    <p>[0052]	步骤1-1 ：对手图像的旋转进行校正，见图2b为手图像旋转校正的示意图。首先 从所述图像获取设备获取的原始的手图像中并结合手表皮颜色分布模型，将手从背景中分 割出来，利用原始图像的灰度图像里手区域和背景区域的像素灰度值的分布差异确定二值 化的阈值，然后对该图像进行二值化处理，得到二值化黑白手区域图像，手作为前景区域， 像素值为1，背景区域像素值为0 ；</p>
    <p>[0053]	步骤1-2 ：利用手区域图像的质心坐标表达式（1)求取二值化的整个手区域图像 的质心在图像中的坐标，所述手区域包括手掌区域和手指区域。</p>
    <p>_ Cx^plCy=Ipl	(1)</p>
    <p>[0055]	其中（Xi，yi)是二值化的前景手区域图像像素点的坐标，N是所有二值化的前景手 区域图像像素点的个数。</p>
    <p>[0056]	步骤1-3 ：个人计算机利用二值化手图像的形状矩对手图像的相对于图像坐标系 水平方向的偏转角度进行估计（如式2)，以手图像中心为坐标原点，根据偏转角度将手图 像旋转至图像坐标系的水平方向，从而实现对手图像的旋转变化进行校正，得到旋转校正 后的二值化的手图像；</p>
    <p>[0057]	根据质心坐标的表达，求取手旋转方向θ的估计值，其表达式如下：</p>
    <p>N</p>
    <p>[0058]	^^argmir^Zdx &#8212; xJcos^+l^-^Jsin^)2)	(2)</p>
    <p>θ	厂1[0059]	其中（Xi，Yi)是二值化图像中手前景区域像素点的坐标。按照求取到的手旋转方 向θ，对采集到的手图像进行图像旋转，使得手旋转至图像坐标系的水平方向，见图2b。</p>
    <p>[0060]	步骤1-4 ：在经过旋转方向校正的手图像上，再次进行二值化处理，见图2c。</p>
    <p>[0061]	步骤2 ：在旋转校正后的二值化的手图像中，经过形态学腐蚀操作处理后的手图 像上，确定手掌中心区域。二值图像形态学到腐蚀操作，旨在去除手图像上的手指区域，保 留手掌掌心区域，见图2c为定位手掌掌心区域的示意图。以掌心区域质心点为中心建立直 角坐标系，消除手图像平移变化对掌纹图像处理带来的不利影响，从而实现手图像的平移 变化的校正；在所述直角坐标系中固定位置截取固定大小的感兴趣的图像区域作为掌纹图 像，并将掌纹图像作为特征提取区域。计算腐蚀后得到的手掌掌心区域的质心坐标（C' x， C' y)，其表达式如下：</p>
    <p>&lt;formula&gt;formula see original document page 9&lt;/formula&gt;[0063]	其中（χ' i，y' D是腐蚀后得到的手掌掌心区域像素点坐标。根据得到的手掌掌 心区域质心点坐标，选择以该质心点为中心，边长为q(q不超过手掌掌心区域的大小）的正 方形区域作为提取掌纹图像特征的归一化掌纹图像，见图2d为归一化掌纹图像的示意图。</p>
    <p>[0064]	图3a为掌纹图像特征提取流程图，</p>
    <p>[0065]	步骤3 ：利用一阶高斯导数求取图像梯度方向特征，将每个像素点的梯度方向进 行量化编码，由此构成一个二维的基于量化梯度方向特征的掌纹图像特征模板，并存储于 存储设备中，用以解决单调环境光的变化对掌纹图像识别的影响；通过计算在两个掌纹图 像特征模板的对应位置上出现相同量化梯度方向编码的频率，来衡量两个掌纹图像特征模 板的相似性。掌纹图像特征提取和识别具体步骤包括：</p>
    <p>[0066]	步骤3-1 ：利用经旋转和平移校正后的掌纹图像水平和竖直方向上的二维一阶高 斯导数滤波器表达式（4)对归一化掌纹图像进行滤波，求取归一化掌纹图像的每个像素点 上的梯度方向角度，其取值范围为W，2ji]。图3b示出为应用水平方向的二维一阶高斯导 数滤波器和图3c示出为竖直方向上的二维一阶高斯导数滤波器，对归一化掌纹图像进行 滤波，每次滤波的结果是滤波器所覆盖的局部掌纹图像区域的像素灰度值的加权和。</p>
    <p>JC2+^2	X2+y2</p>
    <p>[0067]	g](x^y) = ^-JL.e'-^-g^y) =	(4)</p>
    <p>λπο	Ιττ&#972;</p>
    <p>[0068]	其中gl为水平方向上二维高斯函数的一阶偏导数，g2为垂直方向上二维高斯函数 的一阶偏导数；S是高斯导数的标准方差，这里使用的是各向同性的高斯函数。通过组合</p>
    <p>两个方向上的滤波结果，可以求取该局部图像区域内灰度梯度方向α，其表达式如下： f</p>
    <p>[0069]	α = Ian"1 (^f)	(5)</p>
    <p>Jx</p>
    <p>[0070]	其中&amp;和。是水平方向和竖直方向的滤波结果。将灰度梯度的方向作为用于识 别的掌纹图像特征。</p>
    <p>[0071]	步骤3-2 ：特征编码。获得的灰度梯度的方向角度α是取值区间为^)，2π]之间 的连续浮点数值。将梯度方向角按照角度值大小量化为η个量化等级，当η较大时，增强 量化后编码对局部图像纹理细节的表达能力，当η较小时，增强量化编码对局部图像噪声 的鲁棒性。权衡增强量化后编码对局部图像纹理细节的表达能力与增强量化编码对局部图像噪声的鲁棒性，η在所述实施例中取值为6，每个梯度方向角度的量化编码的取值范围为 {0,1,2,3,4,5}中的任何一个整数，由此构成一个二维的基于量化梯度方向特征的掌纹图 像特征模板，并存储于存储设备中。量化规则表达如下：</p>
    <p>&lt;formula&gt;formula see original document page 10&lt;/formula&gt;</p>
    <p>[0073]	其中[]表示取不大于其操作数的整数，α ‘为量化的梯度方向角度编码。根据这 样的量化规则，一幅归一化的掌纹图像可以用一个二维的量化梯度方向角度特征矩阵来表 达，该矩阵的每一个元素表示在对应的局部区域里量化的灰度梯度方向特征。</p>
    <p>[0074]	步骤3-3 ：特征比对，通过计算在两个掌纹图像特征模板的对应位置上出现相同 量化梯度方向编码的频率，来衡量两个掌纹图像特征模板的相似性。根据当前输入的掌纹 图像特征和数据库中所存放的所有注册掌纹图像特征模板进行一对一的比对，从中找出最 相似的注册模板作为匹配结果。当前输入的掌纹图像特征矩阵和在数据库注册的一个掌纹 图像特征矩阵的相似性由下式定义的方法进行度量：</p>
    <p>&lt;formula&gt;formula see original document page 10&lt;/formula&gt;[0076]	其中S(x，y)为特征模板之间的相似度，相似度的取值范围为[0，1]这个闭区间， 数值越大说明对应的两个掌纹图像特征模板也越相似。χ和y分别是当前输入掌纹图像和 在数据库中注册的掌纹图像的特征矩阵。m和η是特征矩阵的长和宽，i、j为二维特征模板 上的坐标。I为示性函数，其定义如下：</p>
    <p>&lt;formula&gt;formula see original document page 10&lt;/formula&gt;[0078]	两个特征矩阵的相似度越高，表明两者来自于同一个人的同一只手的可能性就越 大。</p>
    <p>[0079]	步骤4 ：判别决策。根据基于掌纹图像特征的身份识别应用的具体需求，对掌纹图 像之间的相似性设定不同的阈值。对应不同的错误接受率（False Accept Rate)和错误拒 绝率（FRR，False Reject Rate)。如果当前输入的掌纹图像的特征与注册库存储的某个掌 纹图像特征的相似程度大于设定的阈值时，则判断当前用户属于注册用户，否则判断当前 用户还没有注册。</p>
    <p>[0080]	利用所述步骤1，2，3，4构成一个完整的掌纹识别系统。如图4所示，其中包括： 掌纹图像预处理单元、掌纹图像特征提取单元、掌纹图像特征相似度计算单元、身份判别单 元。先由所述手图像获取设备获取原始手图像，通过所述掌纹图像预处理单元获取归一化 的掌纹图像，然后由所述掌纹图像特征提取单元提取掌纹图像特征编码。如系统处于注册 过程中，将掌纹图像特征存入数据库；如系统处于识别过程中，先从数据库中提取注册的掌 纹图像特征与待识别的掌纹图像特征进行所述的特征比对，根据掌纹图像特征之间的相似 程度进行身份判别。</p>
    <p>[0081]	与当前其他身份特征鉴别方法相比较，本发明所包含的基于环境光中手图像获取 的身份认证系统和方法的新颖性在于：</p>
    <p>[0082]	1)采用环境光中的手图像采集方式，避免了在现有掌纹图像识别系统中，需要将用户的手放在封闭获取设备中给用户带来的不适。采用了带手形凹陷的单色手放置台，在 提示用户放置手的同时，也限制了手大范围内的姿态改变，使用户使用更加便捷，也提高掌 纹图像预处理的效率，克服了现有同类设备用立柱或者凸起物固定手的位置的问题，这种 不卫生的采集方式限制了大规模掌纹图像识别的应用。同时，掌纹图像预处理方法，有效地 克服了由在手位置不固定的情况下获取的手图像中存在的手姿态变化，手图像的平移和旋 转，克服了环境光单调性变化带来的影响。从而获得稳定的，高质量的归一化掌纹图像进行 掌纹图像特征识别。</p>
    <p>[0083]	2)提取掌纹图像灰度的量化梯度方向作为有区分性的掌纹图像特征。图像灰度梯 度刻画了局部图像区域的细微纹理结构。在掌纹图像中，灰度梯度表现了手掌表面纹线分 布的方向和强度这些基本特征。同时图像灰度的梯度方向是对采集图像光照条件单调性变 化鲁棒的物理量。因此图像灰度的梯度方向是一种鲁棒准确的掌纹图像特征描述方法。在 编码过程中，将梯度方向的浮点角度值量化为0到5的整数数值。该量化方式减小了掌纹 图像中的随机噪声对梯度方向浮点角度值的影响。使得特征编码更加稳定。同时由于存储 浮点数值比存储整数数值要消耗更多的存储空间。采用量化编码还可以节省掌纹图像特征 在计算机中的存储耗费。</p>
    <p>[0084]	3)在身份认证的过程中，可以根据具体硬件配置状况和应用需求，将掌纹图像特 征提取，比对和身份验证决策模块灵活地配置在不同的计算平台上。例如如果本地计算机 终端有足够的计算能力，可以将由手图像获取设备获取的图像，直接传输到本地计算机终 端上进行特征提取和比对，将特征编码发送到远程服务器上，和服务器上存储的掌纹图像 特征数据库进行特征比对，将比对结果和决策结果发送回本地的计算机终端，将决策结果 显示给用户。当应用于小规模人群的掌纹图像识别，例如公司员工的考勤管理时，可以直接 在本地计算机上存储掌纹图像特征，进行掌纹图像特征比对。</p>
    <p>[0085]	下面结合附图和实施例，对本发明进行进一步的说明。</p>
    <p>[0086]	实施例1 ：基于掌纹图像识别的图书馆数据访问控制</p>
    <p>[0087]	在图书馆资料查讯的时候，用户需要在图书馆提供的计算机终端上，输入自己的 账户和密码，根据密码确认用户身份后，方能根据用户权限访问相应的数据，囿于权限，有 些极其珍贵或者机密的图书资料，只有极少数申请购买了相关数据库的读者才能被授权访 问。但是如果被授权的用户遗忘了密码，或者密码被人窃取。很可能导致这些珍贵资料的 遗失甚至破坏，同时也会对用户的使用带来不便。如果在图书馆资料查询计算机上分别安 装接所述手图像获取设备和所述的掌纹图像处理模块，每个用户在办理图书借阅磁卡的时 候，将自己的掌纹图像特征注册到图书馆的掌纹数据库中。在进行查询的时候，预先设定必 须经过掌纹图像特征验证才能访问到自己被授权可以接触的图书馆资料，否则不允许用户 进行图书馆资源的访问操作；那么该用户进行资料查询的步骤如图5所示：</p>
    <p>[0088]	步骤501，在图书馆管理计算机终端上输入自己的账户名。</p>
    <p>[0089]	步骤502，用户将手放置在基于环境光中手图像获取设备的手放置台上进行手图 像采集。</p>
    <p>[0090]	步骤503，利用所述的掌纹图像预处理模块对手图像进行预处理，获得归一化掌纹 图像。</p>
    <p>[0091]	步骤504，利用所述掌纹图像识别模块提取归一化掌纹图像的掌纹图像特征。[0092]	步骤505，利用所述掌纹图像特征比对方法，计算用户掌纹图像特征和存储在图书 馆数据库中的注册掌纹图像特征的相似程度。</p>
    <p>[0093]	步骤506，根据获得的掌纹图像特征相似度对用户身份进行身份鉴别验证。</p>
    <p>[0094]	步骤507，根据用户身份和用户提供的帐户名是否匹配判断是否允许用户访问被 授权可以接触的图书馆资源。如果用户身份与帐户不匹配，返回步骤501，则不允许访问图 书资料，如果用户身份与帐户匹配，返回步骤501，则允许访问图书资料。</p>
    <p>[0095]	在实际使用中，用户只需要操作前两个步骤（步骤501和502)，其他步骤将自动完 成。整个流程大约需要2到4秒。引入了本发明后，对用户访问权限的管理会更加安全，即 使帐号和密码被人窃取，盗窃者仍然不能登录用户的个人账户对数据资源进行访问。</p>
    <p>[0096]	以上所述，仅为本发明中的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉该技术的人在本发明所揭露的技术范围内，可理解想到的变换或替换，都应涵盖在 本发明的包含范围之内。</p>
  </div>
  </div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title"> 被以下专利引用</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">引用专利</th><th class="patent-data-table-th"> 申请日期</th><th class="patent-data-table-th">公开日</th><th class="patent-data-table-th"> 申请人</th><th class="patent-data-table-th">专利名</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102163282A?cl=zh">CN102163282A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年5月5日</td><td class="patent-data-table-td patent-date-value">2011年8月24日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">掌纹图像感兴趣区域的获取方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102163282B?cl=zh">CN102163282B</a></td><td class="patent-data-table-td patent-date-value">2011年5月5日</td><td class="patent-data-table-td patent-date-value">2013年2月20日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">掌纹图像感兴趣区域的获取方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102254188A?cl=zh">CN102254188A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年8月4日</td><td class="patent-data-table-td patent-date-value">2011年11月23日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">掌纹识别方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102254188B?cl=zh">CN102254188B</a></td><td class="patent-data-table-td patent-date-value">2011年8月4日</td><td class="patent-data-table-td patent-date-value">2013年3月13日</td><td class="patent-data-table-td ">汉王科技股份有限公司</td><td class="patent-data-table-td ">掌纹识别方法及装置</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102540264A?cl=zh">CN102540264A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月30日</td><td class="patent-data-table-td patent-date-value">2012年7月4日</td><td class="patent-data-table-td ">北京华航无线电测量研究所</td><td class="patent-data-table-td ">一种人体隐私部位自动检测与遮挡的微波安检系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102540264B?cl=zh">CN102540264B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2011年12月30日</td><td class="patent-data-table-td patent-date-value">2014年12月10日</td><td class="patent-data-table-td ">北京华航无线电测量研究所</td><td class="patent-data-table-td ">一种人体隐私部位自动检测与遮挡的微波安检系统</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102663393A?cl=zh">CN102663393A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年3月2日</td><td class="patent-data-table-td patent-date-value">2012年9月12日</td><td class="patent-data-table-td ">哈尔滨工程大学</td><td class="patent-data-table-td ">基于旋转校正的手指静脉图像感兴趣区域提取方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102902980A?cl=zh">CN102902980A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月13日</td><td class="patent-data-table-td patent-date-value">2013年1月30日</td><td class="patent-data-table-td ">中国科学院自动化研究所</td><td class="patent-data-table-td ">一种基于线性规划模型的生物特征图像分析与识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN102902980B?cl=zh">CN102902980B</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2012年9月13日</td><td class="patent-data-table-td patent-date-value">2015年12月2日</td><td class="patent-data-table-td ">中国科学院自动化研究所</td><td class="patent-data-table-td ">一种基于线性规划模型的生物特征图像分析与识别方法</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN104333073A?cl=zh">CN104333073A</a><span class='patent-tooltip-anchor' data-tooltip-text="由审查员引用"> *</span></td><td class="patent-data-table-td patent-date-value">2014年11月10日</td><td class="patent-data-table-td patent-date-value">2015年2月4日</td><td class="patent-data-table-td ">安徽省新方尊铸造科技有限公司</td><td class="patent-data-table-td ">一种采用掌纹识别技术的电动车充电插板</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2015042783A1?cl=zh">WO2015042783A1</a></td><td class="patent-data-table-td patent-date-value">2013年9月24日</td><td class="patent-data-table-td patent-date-value">2015年4月2日</td><td class="patent-data-table-td ">北京正邦信息技术有限公司</td><td class="patent-data-table-td ">非接触式掌纹认证方法、装置及便携终端</td></tr></table><div class="patent-section-footer">* 由审查员引用</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">分类</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">国际分类号</td><td class="patent-data-table-td "><span class="nested-value"><a href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009620000">G06K9/62</a></span>, <span class="nested-value"><a href="https://www.google.com/url?id=Pp56BwABERAJ&amp;q=http://web2.wipo.int/ipcpub/&amp;usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&amp;notion=scheme&amp;version=20130101&amp;symbol=G06K0009600000">G06K9/60</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">法律事件</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> 日期</th><th class="patent-data-table-th">代码</th><th class="patent-data-table-th">事件</th><th class="patent-data-table-th">说明</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">2010年9月15日</td><td class="patent-data-table-td ">C06</td><td class="patent-data-table-td ">Publication</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">2010年11月3日</td><td class="patent-data-table-td ">C10</td><td class="patent-data-table-td ">Request of examination as to substance</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">旋转</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">原始图片</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " 未提供图片。\x3ca href\x3d//docs.google.com/viewer?url\x3dpatentimages.storage.googleapis.com/pdfs/99b28bf0a2cd883142bd/CN101833647A.pdf\x3e查看 PDF\x3c/a\x3e"});</script></div></div></div></div></div><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_6e802a6b2b28d51711baddc2f3bec198.js", Host:"https://www.google.com/", IsBooksRentalEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsImageModeNotesEnabled:1, IsOfflineBubbleEnabled:1, IsFutureOnSaleVolumesEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsMobileRequest:0, IsZipitFolderCollectionEnabled:1, IsAdsDisabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:1, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsDisabledRandomBookshelves:0});_OC_Run({"enable_p13n":false,"is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=https://www.google.com/patents%3Fcl%3Dzh%26hl%3Dzh-CN\u0026hl=zh-CN"}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"https://www.google.com/patents/download/%E6%8E%8C%E7%BA%B9%E5%9B%BE%E5%83%8F%E7%9A%84%E8%8E%B7%E5%8F%96%E8%AE%BE%E5%A4%87%E5%8F%8A%E6%8E%8C%E7%BA%B9%E5%9B%BE.pdf?id=Pp56BwABERAJ\u0026hl=zh-CN\u0026output=pdf\u0026sig=ACfU3U1nOMz_UgS63hh_KgmZ3d4QKxDB9Q"},"sample_url":"https://www.google.com/patents/reader?id=Pp56BwABERAJ\u0026hl=zh-CN\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href="https://www.google.com/search?hl=zh-CN"><nobr>Google&nbsp;首页</nobr></a> - <a href="//www.google.com/patents/sitemap/"><nobr>站点地图</nobr></a> - <a href="http://www.google.com/googlebooks/uspto.html"><nobr>美国专利商标局 (USPTO) 专利信息批量下载</nobr></a> - <a href="/intl/zh-CN/privacy/"><nobr>隐私权政策</nobr></a> - <a href="/intl/zh-CN/policies/terms/"><nobr>服务条款</nobr></a> - <a href="https://support.google.com/faqs/answer/2539193?hl=zh-CN"><nobr> 关于 Google 专利</nobr></a> - <a href="//www.google.com/tools/feedback/intl/zh-CN/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'zh-CN'});return false;}catch(e){}"><nobr>发送反馈</nobr></a></div></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>